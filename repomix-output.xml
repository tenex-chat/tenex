This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
context/
  agents.md
  brainstorm.md
  claude-code-integration.md
  commands.md
  conversations.md
  INVENTORY.md
  llm.md
  metadata-preservation-debug-logging.md
  nostr.md
  PROJECT.md
  standalone-agents-plan.md
  tool-spec-nostr-marketing-tools.md
  tool-spec-nostr-publish-note.md
scripts/
  build-bundled.js
  list-openrouter-models-simple.ts
  list-openrouter-models.ts
  start-mock-backend.sh
  start-with-mock-llm.sh
  test-ios-compat.sh
  typecheck.sh
src/
  agents/
    execution/
      AgentExecutor.ts
      constants.ts
      index.ts
      types.ts
    AgentRegistry.ts
    constants.ts
    index.ts
    types.ts
    utils.ts
  commands/
    agent/
      add.ts
      index.ts
      list.ts
      remove.ts
    debug/
      index.ts
    inventory/
      index.ts
    mcp/
      add.ts
      index.ts
      list.ts
      remove.ts
      server.ts
    project/
      index.ts
      init.ts
      run.ts
    run/
      processedEventTracking.ts
      ProjectDisplay.ts
      SubscriptionManager.ts
    setup/
      index.ts
      llm.ts
    daemon.ts
  conversations/
    persistence/
      FileSystemAdapter.ts
      index.ts
      schemas.ts
      ToolMessageStorage.ts
      types.ts
    processors/
      DelegationFormatter.ts
      MessageRoleAssigner.ts
      NostrEntityProcessor.ts
    services/
      AgentResolver.ts
      ConversationCoordinator.ts
      ConversationEventProcessor.ts
      ConversationPersistenceService.ts
      ConversationResolver.ts
      ConversationStore.ts
      index.ts
    utils/
      content-utils.ts
      phaseUtils.ts
    AgentConversationContext.ts
    executionTime.ts
    index.ts
    types.ts
  daemon/
    EventMonitor.ts
    ProcessManager.ts
    ProjectManager.ts
  event-handler/
    AgentRouter.ts
    DelegationCompletionHandler.ts
    index.ts
    newConversation.ts
    project.ts
    reply.ts
  events/
    index.ts
    NDKAgentDefinition.ts
    NDKAgentLesson.ts
    NDKEventMetadata.ts
    NDKMCPTool.ts
    NDKProjectStatus.ts
  lib/
    fs/
      filesystem.ts
      index.ts
      tenex.ts
    shell.ts
  llm/
    providers/
      mock-scenarios/
        ios-testing.ts
      MockProvider.ts
      ollama-models.ts
      openrouter-models.ts
    selection/
      ModelSelector.ts
    utils/
      ConfigurationManager.ts
      ConfigurationTester.ts
      ModelSelector.ts
      ProviderConfigUI.ts
    constants.ts
    index.ts
    LLMConfigEditor.ts
    LLMServiceFactory.ts
    models.ts
    service.ts
    types.ts
  logging/
    LLMLogger.ts
  nostr/
    AgentEventDecoder.ts
    AgentEventEncoder.ts
    AgentPublisher.ts
    index.ts
    ndkClient.ts
    types.ts
    utils.ts
  prompts/
    core/
      FragmentRegistry.ts
      index.ts
      PromptBuilder.ts
      types.ts
    fragments/
      01-agent-identity.ts
      10-referenced-article.ts
      15-available-agents.ts
      20-phase-context.ts
      20-voice-mode.ts
      24-retrieved-lessons.ts
      30-project-inventory.ts
      30-project-md.ts
      90-inventory-generation.ts
      delegated-task-context.ts
      index.ts
    utils/
      llmMetadata.ts
      projectUtils.ts
      systemPromptBuilder.ts
    index.ts
  services/
    config/
      types.ts
    mcp/
      mcpInstaller.ts
      MCPManager.ts
    status/
      index.ts
      StatusPublisher.ts
    ConfigService.ts
    DelegationRegistry.ts
    DelegationService.ts
    index.ts
    LLMOperationsRegistry.ts
    NDKAgentDiscovery.ts
    OperationsStatusPublisher.ts
    ProjectContext.ts
    PubkeyNameRepository.ts
    ReportManager.ts
  test-utils/
    mock-llm/
      scenarios/
        concurrency-workflow.ts
        error-handling.ts
        example-scenario.ts
        index.ts
        inventory-generation.ts
        network-resilience.ts
        performance-testing.ts
        state-persistence.ts
        threading-workflow.ts
      index.ts
      MockLLMService.ts
      types.ts
    mocks/
      events.ts
    bun-mocks.ts
    conversational-logger.ts
    e2e-assertions.ts
    e2e-conversational-setup.ts
    e2e-execution.ts
    e2e-harness.ts
    e2e-mocks.ts
    e2e-setup.ts
    e2e-types.ts
    index.ts
    mock-factories.ts
    mock-setup.ts
    ndk-test-helpers.ts
    README.md
  tools/
    implementations/
      agents_discover.ts
      agents_hire.ts
      agents_list.ts
      agents_read.ts
      agents_write.ts
      claude_code.ts
      create_project.ts
      delegate_external.ts
      delegate_followup.ts
      delegate_phase.ts
      delegate.ts
      generate_inventory.ts
      learn.ts
      lesson_get.ts
      mcp_discover.ts
      nostr_projects.ts
      read_path.ts
      report_delete.ts
      report_read.ts
      report_write.ts
      reports_list.ts
      shell.ts
      write_context_file.ts
    registry.ts
    utils.ts
  utils/
    git/
      createExecutionBranch.ts
      gitignore.ts
      index.ts
      initializeGitRepo.ts
    agent-resolution.ts
    agentFetcher.ts
    agentInstaller.ts
    cli-config-scope.ts
    cli-error.ts
    conversation-utils.ts
    eom-utils.ts
    error-formatter.ts
    error-handler.ts
    file-persistence.ts
    formatting.ts
    inventory.ts
    lessonFormatter.ts
    logger.ts
    nostr-entity-parser.ts
    process.ts
    projectInitialization.ts
    relays.ts
    repomix.ts
    setup.ts
    string.ts
    tool-result-formatter.ts
    validation.ts
  cli.ts
  constants.ts
  index.ts
  tenex.ts
.gitignore
.npmignore
.repomixignore
biome.json
bunfig.toml
check-types.sh
eslint.config.js
find_orphaned_files.sh
package.json
README.md
test-agent-memory.sh
test-message-fix.js
tsconfig.build.json
tsconfig.eslint.json
tsconfig.json
typecheck.cjs
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="context/commands.md">
# Commands Module

## Overview

The `src/commands` module defines the command-line interface of the TENEX application. It uses the `commander` library to create a hierarchy of commands and subcommands, and it maps each command to a specific action. This module is the main entry point for users interacting with TENEX from the command line.

## Key Components

- **`tenex.ts`**: The root file of the CLI, which initializes the `commander` program and adds all the main commands.

- **`agent/`**: Contains the logic for the `agent` command and its subcommands, such as `add`, `list`, and `remove`. These commands are used to manage the agents in the system.

- **`daemon/`**: Contains the logic for the `daemon` command, which is used to start and stop the TENEX daemon process.

- **`debug/`**: Contains a set of debugging commands, such as `chat`, `conversation`, and `timeline`, which are useful for inspecting the internal state of the application.

- **`project/`**: Contains the logic for the `project` command, which is used to manage TENEX projects.

- **`setup/`**: Contains the logic for the `setup` command, which is used to configure the TENEX CLI.

- **`inventory/`**: Contains the logic for the `inventory` command, which is used to generate an inventory of the project.

- **`mcp/`**: Contains the logic for the `mcp` command, which is used to interact with the Model Context Protocol.
</file>

<file path="context/llm.md">
# LLM Module

## Overview

The `src/llm` module provides an abstraction layer for interacting with various Large Language Models (LLMs). It handles model selection, configuration, and the routing of requests to the appropriate LLM backend. This module is essential for the agent execution loop, as it provides the interface for the agents to communicate with the LLMs.

## Key Components

- **`router.ts`**: The central component of the LLM module. It contains the logic for selecting the best LLM for a given task based on the provided criteria, such as the required capabilities (e.g., tool use, code generation) and the user's preferences.

- **`models.ts`**: Defines the supported LLM models and their capabilities. This file is used by the `router.ts` to make decisions about which model to use.

- **`selection/`**: This directory contains the logic for the LLM selection process, including the `ModelSelector` class, which implements the model selection algorithm.

- **`ui/`**: This directory contains the user interface components for managing LLM configurations.

- **`types.ts`**: Defines the data structures and types used throughout the LLM module, such as `LLMConfig`, `Model`, and `ModelCapabilities`.
</file>

<file path="context/standalone-agents-plan.md">
# Plan for Project-Independent Agent Conversations

This document outlines a comprehensive plan for enabling agent conversations outside of project contexts in TENEX. This will allow for standalone agent functionality, such as trying out agents before installing them and interacting with global agents.

## Phased Implementation

The implementation is broken down into four phases to deliver value incrementally and reduce risk.

### Phase 1: Core Infrastructure Changes

This phase focuses on laying the groundwork for standalone agent conversations by creating parallel infrastructure that doesn't interfere with existing project-based workflows.

*   **Key components:**
    *   `StandaloneConversationManager`: A new manager for conversations that are not associated with a project.
    *   `StandaloneAgentResolver`: A resolver for finding and instantiating agents that are not part of a project. (Note: A `StandaloneAgentResolver` already exists in the codebase, so this task will involve reviewing and potentially adapting it.)
*   **Persistence:**
    *   Initially, conversations will be stored in-memory only to simplify the initial implementation.
    *   Later, a persistence layer can be added (e.g., using a local database or Nostr events).

### Phase 2: New CLI Commands

This phase will introduce new CLI commands to allow users to interact with standalone agents.

*   **Commands:**
    *   `tenex agent chat <agent_id>`: Start a conversation with a global agent.
    *   `tenex agent try <agent_definition_id>`: Start a temporary conversation with a new instance of an agent from a definition.
*   **Implementation details:**
    *   These commands will use the new `StandaloneConversationManager` and `StandaloneAgentResolver`.

### Phase 3: Standalone Agent Execution Model

This phase will implement the execution model for standalone agents, enabling them to respond to user messages.

*   **Execution flow:**
    *   User messages will be sent directly to the agent's pubkey using NDK subscriptions.
    *   This bypasses the project-based orchestrator routing.
*   **Agent capabilities:**
    *   Agents will be able to operate in both project and standalone modes.
    *   This will be achieved through progressive enhancement, where agents have a baseline of functionality in standalone mode and enhanced capabilities when in a project context.

### Phase 4: Enhanced Features and Marketplace Integration

This phase will add advanced features and integrate with the agent marketplace.

*   **Features:**
    *   **Global Agent Registry:** A central registry for all available global agents.
    *   **Nostr Discovery:** The ability to discover and interact with agents from the Nostr network.
*   **Marketplace integration:**
    *   This will allow users to easily find, try, and install agents from a marketplace.

## Guiding Principles

*   **Reusability:** Leverage existing components whenever possible to reduce development time and complexity.
*   **Simplicity:** Start with simple solutions (e.g., in-memory persistence) and add complexity as needed.
</file>

<file path="src/conversations/persistence/ToolMessageStorage.ts">
import { promises as fs } from "node:fs";
import * as path from "node:path";
import type { ModelMessage } from "ai";
import { logger } from "@/utils/logger";
import { formatAnyError } from "@/utils/error-formatter";

/**
 * Storage interface for tool messages
 * Single Responsibility: Persist and retrieve tool execution messages
 */
export class ToolMessageStorage {
  private readonly storageDir = path.join('.tenex', 'tool-messages');

  /**
   * Store tool messages for later reconstruction
   */
  async store(
    eventId: string,
    toolCall: {
      toolCallId: string;
      toolName: string;
      input: any;
    },
    toolResult: {
      toolCallId: string;
      toolName: string;
      output: any;
      error?: boolean;
    },
    agentPubkey: string
  ): Promise<void> {
    try {
      const messages: ModelMessage[] = [
        {
          role: "assistant",
          content: [{
            type: "tool-call" as const,
            toolCallId: toolCall.toolCallId,
            toolName: toolCall.toolName,
            args: toolCall.input,
          }],
        },
        {
          role: "tool",
          content: [{
            type: "tool-result" as const,
            toolCallId: toolResult.toolCallId,
            toolName: toolResult.toolName,
            output: {
              type: "text",
              value: typeof toolResult.output === 'string' 
                ? toolResult.output 
                : JSON.stringify(toolResult.output),
            },
          }],
        },
      ];

      await fs.mkdir(this.storageDir, { recursive: true });

      const filePath = path.join(this.storageDir, `${eventId}.json`);
      const data = {
        eventId,
        agentPubkey,
        timestamp: Date.now(),
        messages,
      };

      await fs.writeFile(filePath, JSON.stringify(data, null, 2));

      logger.debug('[ToolMessageStorage] Stored tool messages', {
        eventId: eventId.substring(0, 8),
        filePath,
      });
    } catch (error) {
      logger.error('[ToolMessageStorage] Failed to store tool messages', {
        error: formatAnyError(error),
        eventId,
      });
    }
  }

  /**
   * Load tool messages from storage
   */
  async load(eventId: string): Promise<ModelMessage[] | null> {
    try {
      const filePath = path.join(this.storageDir, `${eventId}.json`);
      const data = await fs.readFile(filePath, 'utf-8');
      const parsed = JSON.parse(data);
      return parsed.messages;
    } catch {
      // File doesn't exist or can't be read
      return null;
    }
  }

  /**
   * Clean up old tool messages
   */
  async cleanup(olderThanMs: number = 24 * 60 * 60 * 1000): Promise<void> {
    try {
      const files = await fs.readdir(this.storageDir);
      const now = Date.now();

      for (const file of files) {
        if (!file.endsWith('.json')) continue;

        const filePath = path.join(this.storageDir, file);
        const stats = await fs.stat(filePath);
        
        if (now - stats.mtimeMs > olderThanMs) {
          await fs.unlink(filePath);
          logger.debug('[ToolMessageStorage] Cleaned up old tool message file', {
            file,
            ageMs: now - stats.mtimeMs,
          });
        }
      }
    } catch (error) {
      logger.error('[ToolMessageStorage] Failed to cleanup', {
        error: formatAnyError(error),
      });
    }
  }
}

// Singleton instance
export const toolMessageStorage = new ToolMessageStorage();
</file>

<file path="src/events/index.ts">
export { NDKAgentDefinition } from "./NDKAgentDefinition";
export { NDKAgentLesson } from "./NDKAgentLesson";
export { NDKMCPTool } from "./NDKMCPTool";
export { NDKProjectStatus } from "./NDKProjectStatus";
</file>

<file path="src/lib/fs/index.ts">
export * from "./filesystem.js";
export * from "./tenex.js";
</file>

<file path="src/test-utils/README.md">
# Test Utilities

This directory contains reusable test utilities for the TENEX backend.

## Mock Setup Helpers

The `mock-setup.ts` file provides common mock setup functions to reduce duplication across test files:

### Usage Example

```typescript
import { setupCommonTestMocks } from "@/test-utils";

describe("MyComponent", () => {
    beforeEach(() => {
        // Setup all common mocks at once
        setupCommonTestMocks("/test/project");
        
        // Or setup individual mocks as needed
        setupServicesMock("/test/project");
        setupExecutionLoggerMock();
        setupTracingMock();
    });
});
```

### Available Functions

- `setupServicesMock(projectPath)` - Mocks the @/services module
- `setupExecutionTimeMock()` - Mocks execution time tracking
- `setupExecutionLoggerMock()` - Mocks the execution logger
- `setupTracingMock()` - Mocks tracing context
- `setupAgentUtilsMock(tools)` - Mocks agent utilities
- `setupToolRegistryMock()` - Mocks the tool registry
- `setupCommonTestMocks(projectPath)` - Sets up all mocks at once

## Mock Factories

The `mock-factories.ts` file provides factory functions for creating mock objects:

- `createMockNDKEvent()` - Creates a mock Nostr event
- `createMockAgent()` - Creates a mock agent
- `createMockConversation()` - Creates a mock conversation
- `createMockExecutionContext()` - Creates a mock execution context
- `createMockToolCall()` - Creates a mock tool call
- `createMockPhaseTransition()` - Creates a mock phase transition
- `createMockFileSystem()` - Creates a mock file system structure
- `MockBuilder` - A builder class for complex mock objects

## Mock LLM Service

The `mock-llm/` directory provides a comprehensive mock LLM service for deterministic testing:

- `MockLLMService` - A mock implementation of the LLM service
- Predefined scenarios for common workflows
- Support for custom response patterns
- Deterministic behavior for E2E testing

## Test Assertions

Custom assertion helpers are available via the `assertions` object:

- `toThrowAsync()` - Assert async functions throw errors
- `toContainObjectMatching()` - Assert arrays contain matching objects

## Other Utilities

- `createTempDir()` - Create temporary directories for testing
- `cleanupTempDir()` - Clean up temporary directories
- `resetAllMocks()` - Reset all mocks and singletons
- `waitFor()` - Wait for conditions to be met
- `mockFileSystem()` - Mock file system operations
- `ConsoleCapture` - Capture console output during tests
</file>

<file path="src/utils/git/index.ts">
export * from "./createExecutionBranch";
export * from "./gitignore";
export * from "./initializeGitRepo";
</file>

<file path="src/index.ts">
// Main exports for TENEX CLI package
export * from "./commands/daemon";
export * from "./commands/project/index";
export * from "./commands/setup/index";
export * from "./events";
</file>

<file path=".gitignore">
# Dependencies
node_modules/
.pnp
.pnp.js

# Build outputs
dist/
build/
out/
.next/
.nuxt/
.cache/

# Testing
coverage/
.nyc_output/
test-results/
playwright-report/
playwright/.cache/

# Environment variables
.env
.env.local
.env.development.local
.env.test.local
.env.production.local

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# Logs
logs/
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
lerna-debug.log*
.pnpm-debug.log*

# Runtime data
pids
*.pid
*.seed
*.pid.lock

# Temporary files
tmp/
temp/
.tmp/

# OS generated files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Project specific
.tenex/
llms.json
agents.json
.wallet.json
*.bak
*.tmp

# Test artifacts
test-*.json
test-*.txt
__snapshots__/.repomix-output.txt
.repomix-output.txt
</file>

<file path=".npmignore">
# Source maps (these add a lot of weight)
*.map
**/*.map

# Keep source files (needed for Bun runtime)
# src/ is NOT ignored

# Exclude test files from src and dist
**/test-utils
**/__tests__
*.test.ts
*.test.js
*.spec.ts  
*.spec.js
src/test-utils/
dist/test-utils/

# Configuration files  
# Keep tsconfig.json (needed for Bun runtime)
tsconfig.build.json
.eslintrc*
.prettierrc*
biome.json

# Development files
scripts/
tests/

# Exclude all test files (remove from both sections for clarity)

# Build artifacts
*.tsbuildinfo

# Documentation
*.md
!README.md
!LICENSE

# Git
.git/
.gitignore

# Dependencies
node_modules/

# IDE
.vscode/
.idea/

# OS files
.DS_Store
Thumbs.db

# Logs
*.log
npm-debug.log*

# Coverage
coverage/
.nyc_output/

# Local config
.env
.env.local
.env.*.local

# Temporary files
tmp/
temp/
</file>

<file path="bunfig.toml">
# Bun configuration file

[test]
# Enable coverage reporting
coverage = true
coverageDirectory = "./coverage"
coverageReporter = ["text", "lcov"]

# Test file patterns
# Include all test files
root = "./src"

# Timeout for tests (in milliseconds)
timeout = 30000

# Run tests in watch mode by default in development
# watchMode = true

[install]
# Lockfile configuration
lockfile = { save = true }

# Auto-install peer dependencies
peer = true

[run]
# Enable source maps
smol = true
</file>

<file path="find_orphaned_files.sh">
#!/bin/bash

echo "Finding orphaned TypeScript/JavaScript files in src/"
echo "===================================================="
echo

# Function to check if a file is imported
check_file_imports() {
    local file=$1
    local filename=$(basename "$file")
    local dirname=$(dirname "$file")
    local basename_no_ext=${filename%.*}
    
    # For index.ts files, check if the directory is imported
    if [[ "$filename" == "index.ts" ]] || [[ "$filename" == "index.js" ]]; then
        # Get the parent directory name
        local parent_dir=$(basename "$dirname")
        # Check if the directory itself is imported
        local dir_imports=$(rg -c "from ['\"](\.\./|@/|src/).*$parent_dir['\"]" src/ 2>/dev/null | wc -l)
        if [ $dir_imports -gt 0 ]; then
            return 1  # Directory is imported, so index.ts is used
        fi
    fi
    
    # Skip checking for imports in the file itself
    local exclude_pattern="^$file:"
    
    # Various import patterns to check
    local patterns=(
        # Relative imports from parent directories
        "\.\./[^'\"]*$basename_no_ext['\"]"
        "\.\./[^'\"]*$basename_no_ext\.js['\"]"
        # Relative imports from same directory
        "\./$basename_no_ext['\"]"
        "\./$basename_no_ext\.js['\"]"
        # Absolute imports using @/
        "@/${file#src/}"
        "@/[^'\"]*$basename_no_ext['\"]"
        # Module path imports
        "${file#src/}"
        "${file#src/}\.js"
    )
    
    local total_imports=0
    
    for pattern in "${patterns[@]}"; do
        local count=$(rg -c "$pattern" src/ 2>/dev/null | grep -v "$exclude_pattern" | wc -l)
        total_imports=$((total_imports + count))
    done
    
    # Also check for barrel exports (index.ts files that might export this file)
    if [ -f "$dirname/index.ts" ] && [[ "$file" != "$dirname/index.ts" ]]; then
        local index_exports=$(rg -c "from ['\"]\./$basename_no_ext" "$dirname/index.ts" 2>/dev/null || echo 0)
        total_imports=$((total_imports + index_exports))
    fi
    
    return $total_imports
}

# Get all source files (excluding tests)
files=$(find src -type f \( -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.jsx" \) | grep -v "__tests__" | grep -v "\.test\." | grep -v "\.spec\." | sort)

orphaned_files=()

for file in $files; do
    # Skip entry points and common config files
    if [[ "$file" == "src/tenex.ts" ]] || 
       [[ "$file" == "src/index.ts" ]] ||
       [[ "$file" == "src/types.ts" ]] ||
       [[ "$file" == *"/types.ts" ]] ||
       [[ "$file" == *"/constants.ts" ]] ||
       [[ "$file" == *"vite.config.ts" ]] ||
       [[ "$file" == *"jest.config.ts" ]]; then
        continue
    fi
    
    # Skip declaration files
    if [[ "$file" == *".d.ts" ]]; then
        continue
    fi
    
    check_file_imports "$file"
    import_count=$?
    
    if [ $import_count -eq 0 ]; then
        orphaned_files+=("$file")
    fi
done

# Display results
if [ ${#orphaned_files[@]} -eq 0 ]; then
    echo "No orphaned files found!"
else
    echo "Found ${#orphaned_files[@]} potentially orphaned files:"
    echo
    
    # Group files by type
    index_files=()
    regular_files=()
    
    for file in "${orphaned_files[@]}"; do
        if [[ "$(basename "$file")" == "index.ts" ]] || [[ "$(basename "$file")" == "index.js" ]]; then
            index_files+=("$file")
        else
            regular_files+=("$file")
        fi
    done
    
    # Display regular files first
    if [ ${#regular_files[@]} -gt 0 ]; then
        echo "Regular files:"
        echo "--------------"
        for file in "${regular_files[@]}"; do
            echo "üìÑ $file"
            
            # Show file info
            echo "   Size: $(wc -c < "$file" | xargs) bytes"
            echo "   Lines: $(wc -l < "$file" | xargs)"
            
            # Show exports
            exports=$(rg "^export" "$file" 2>/dev/null | head -3)
            if [ -n "$exports" ]; then
                echo "   Exports:"
                echo "$exports" | sed 's/^/     - /'
            fi
            
            # Show any TODO or DEPRECATED comments
            todos=$(rg "(TODO|DEPRECATED|FIXME)" "$file" 2>/dev/null | head -2)
            if [ -n "$todos" ]; then
                echo "   Notes:"
                echo "$todos" | sed 's/^/     - /'
            fi
            
            echo
        done
    fi
    
    # Display index files separately
    if [ ${#index_files[@]} -gt 0 ]; then
        echo "Index files (potentially unused module entry points):"
        echo "----------------------------------------------------"
        for file in "${index_files[@]}"; do
            echo "üìÅ $file"
            echo "   Directory: $(dirname "$file")"
            echo "   Exports: $(rg -c "^export" "$file" 2>/dev/null || echo 0) items"
            echo
        done
    fi
fi

# Additional check for files that might be CLI tools or scripts
echo
echo "Additional analysis:"
echo "-------------------"
if [ ${#orphaned_files[@]} -gt 0 ]; then
    standalone_scripts=()
    
    for file in "${orphaned_files[@]}"; do
        # Check if file has a shebang or main execution block
        if head -1 "$file" | grep -q "^#!" || rg -q "if \(__name__ ==|if \(import\.meta\.main\)" "$file"; then
            standalone_scripts+=("$file")
        fi
    done
    
    if [ ${#standalone_scripts[@]} -gt 0 ]; then
        echo "Potential standalone scripts:"
        for file in "${standalone_scripts[@]}"; do
            echo "üîß $file"
        done
    else
        echo "No standalone scripts detected."
    fi
else
    echo "No files to analyze."
fi
</file>

<file path="tsconfig.build.json">
{
    "extends": "./tsconfig.json",
    "compilerOptions": {
        "noEmit": false,
        "declaration": true,
        "declarationMap": true,
        "sourceMap": true,
        "outDir": "./dist",
        "rootDir": "./src",
        "allowImportingTsExtensions": false,
        "module": "ESNext",
        "target": "ES2022",
        "moduleResolution": "bundler",
        "resolveJsonModule": true,
        "esModuleInterop": true,
        "allowSyntheticDefaultImports": true,
        "paths": {
            "@/*": ["./src/*"]
        }
    },
    "include": ["src/**/*"],
    "exclude": ["node_modules", "dist", "**/*.test.ts", "**/*.spec.ts", "src/**/__tests__/**"]
}
</file>

<file path="tsconfig.eslint.json">
{
    "extends": "./tsconfig.json",
    "include": [
        "src/**/*",
        "bin/**/*",
        "src/**/*.test.ts",
        "src/**/*.spec.ts",
        "src/**/*.integration.test.ts"
    ],
    "exclude": ["node_modules", "dist"]
}
</file>

<file path="context/INVENTORY.md">
# TENEX Project Inventory

## 1. Project Overview

**Description:** TENEX is a command-line interface (CLI) application that provides a suite of tools for developers. It appears to be extensible, with a system of agents that can be managed and interacted with. The CLI also includes features for debugging, project setup, and interacting with the Nostr protocol.

**Technologies:**
- **Language:** TypeScript
- **Runtime:** Bun
- **Key Libraries:**
    - `commander`: For creating the command-line interface.
    - `@nostr-dev-kit/ndk`: For Nostr protocol integration.
    - `multi-llm-ts`: Suggests integration with multiple Large Language Models (LLMs).
    - `zod`: For data validation.

**Architecture:** The project follows a modular, command-based architecture. Each command is defined in its own module, and the main `tenex.ts` file acts as the entry point that registers all the commands. There is a clear separation of concerns, with distinct modules for agents, commands, services, and utilities.

## 2. Directory Structure

- **`src/`**: The main source code directory.
    - **`agents/`**: Contains the logic for different agents that can be used within the TENEX CLI. This is likely where the core business logic of the application resides.
    - **`claude/`**: Specific integrations with Claude models.
    - **`commands/`**: Defines the commands available in the CLI (e.g., `agent`, `daemon`, `project`).
    - **`conversations/`**: Manages the state and flow of conversations with agents.
    - **`daemon/`**: Likely contains code related to running TENEX as a background process.
    - **`event-handler/`**: Handles various events within the application.
    - **`events/`**: Defines different event types.
    - **`lib/`**: Contains utility libraries, such as file system and shell helpers.
        - **`fs/`**: Provides file system utilities, including a custom file system implementation.
        - **`shell.ts`**: Offers shell command execution functionality.
    - **`llm/`**: Manages interactions with Large Language Models (LLMs).
    - **`logging/`**: Provides logging functionality.
        - **`ExecutionLogger.ts`**: A specific logger for tracking agent execution.
    - **`nostr/`**: Handles integration with the Nostr protocol.
    - **`prompts/`**: Stores and builds prompts for interacting with LLMs.
        - **`core/`**: Core components for building prompts, including a `PromptBuilder` and a `FragmentRegistry`.
        - **`fragments/`**: A collection of prompt fragments that can be reused across different prompts.
        - **`utils/`**: Utilities for working with prompts, such as a `messageBuilder` and a `systemPromptBuilder`.
    - **`services/`**: Contains services that provide specific functionalities.
        - **`ConfigService.ts`**: Manages the application's configuration.
        - **`mcp/`**: Contains services related to the Model Context Protocol (MCP).
        - **`ProjectContext.ts`**: Manages the context of the current project.
    - **`test-utils/`**: Provides utilities for testing.
    - **`tools/`**: Defines tools that can be used by agents.
        - **`core.ts`**: Core functionality for defining and executing tools.
        - **`implementations/`**: The actual implementations of the tools, such as `analyze`, `complete`, `shell`, and `writeContextFile`.
        - **`registry.ts`**: A registry for all available tools.
    - **`tracing/`**: Implements tracing for monitoring and debugging.
    - **`utils/`**: Contains miscellaneous utility functions.
        - **`agentFetcher.ts`**: Fetches agent definitions.
        - **`error-handler.ts`**: Provides centralized error handling.
        - **`git/`**: Git-related utilities.
        - **`inventory.ts`**: Utilities for generating project inventories.
- **`tests/`**: Contains end-to-end tests.

## 3. Significant Files

- **`src/tenex.ts`**: The main entry point of the CLI application. It initializes the `commander` program and registers all the available commands.
- **`package.json`**: Defines project metadata, dependencies, and scripts.
- **`src/agents/AgentRegistry.ts`**: Manages the registration and publishing of agents.
- **`src/commands/agent/index.ts`**: The entry point for the `agent` command and its subcommands.
- **`src/llm/router.ts`**: Likely responsible for routing requests to different LLMs.
- **`src/nostr/ndkClient.ts`**: Initializes and configures the Nostr client.

## 4. Architectural Insights

- **Command-Based Architecture:** The application is structured around a set of commands, each with a specific responsibility. This makes the CLI easy to extend and maintain.
- **Agent-Based System:** The concept of "agents" is central to the application. These agents appear to be autonomous or semi-autonomous entities that can perform tasks.
- **LLM Integration:** The use of `multi-llm-ts` suggests that the application can interact with various LLMs, and the `src/llm` directory confirms this.
- **Nostr Protocol:** The integration with the Nostr protocol suggests that the application may be used for decentralized communication or data exchange.
- **Event-Driven:** The presence of `src/events` and `src/event-handler` directories suggests an event-driven architecture, where different parts of the application communicate through events.

## 5. High-Complexity Modules

The following modules are identified as potentially complex due to their central role and the nature of the functionality they provide:

- **`src/agents`**: The core logic of the agents, their execution, and lifecycle management. See [context/agents.md](context/agents.md) for a detailed explanation.
- **`src/llm`**: The abstraction layer for interacting with multiple LLMs, including routing, configuration, and tool usage. See [context/llm.md](context/llm.md) for a detailed explanation.
- **`src/nostr`**: The implementation of the Nostr protocol, including client management, event publishing, and task handling. See [context/nostr.md](context/nostr.md) for a detailed explanation.
- **`src/commands`**: The command definitions and their interactions with the rest of the system. See [context/commands.md](context/commands.md) for a detailed explanation.
- **`src/conversations`**: The management of conversation state, persistence, and synchronization. See [context/conversations.md](context/conversations.md) for a detailed explanation.
</file>

<file path="context/metadata-preservation-debug-logging.md">
# LLM Metadata Preservation Debug Logging

## Overview
Comprehensive debug logging has been added throughout the metadata preservation flow to track how LLM metadata is handled when tools are used.

## Debug Log Points

### 1. **handleAgentCompletion** (`completionHandler.ts`)
- **Location**: When creating unpublished event
- **Logs**: 
  - `[handleAgentCompletion] Created unpublished event`
  - Shows: agent name, response length, event ID, tags

### 2. **Completion handling**
- **Location**: When serializing event for deferred publishing
- **Logs**:
  - `[completion] Serializing event for deferred publishing`
  - Shows: agent name, event ID, serialized event keys, content length, tag count

### 3. **ToolStreamHandler** (`ToolStreamHandler.ts`)
- **Location**: When storing serialized event
- **Logs**:
  - `[ToolStreamHandler] Stored serialized event for deferred publishing`
  - `[ToolStreamHandler] Completion has no serialized event` (if missing)
  - Shows: presence of serialized event, event keys, content length

### 4. **StreamStateManager** (`StreamStateManager.ts`)
- **Location**: When storing/retrieving deferred events
- **Logs**:
  - `[StreamStateManager] Stored deferred event`
  - `[StreamStateManager] Retrieved deferred event`
  - Shows: event presence, content length, tag count, event keys

### 5. **ReasonActLoop** (`ReasonActLoop.ts`)
- **Location**: Multiple points in the flow
- **Logs**:
  - `[ReasonActLoop] Terminal tool detected, continuing to wait for metadata`
    - Shows when not returning early on terminal tools
  - `[ReasonActLoop] Received 'done' event`
    - Shows: model, usage data, tokens, cost
  - `[ReasonActLoop] Processing deferred event`
    - Shows: serialized event keys, content length
  - `[ReasonActLoop] Adding metadata to deferred event`
    - Shows: model, cost, tokens, prompts presence
  - `[ReasonActLoop] ‚úÖ Published deferred complete() event with metadata`
    - Shows: successful publication with all metadata
  - `[ReasonActLoop] Have deferred event but no publisher` (warning)
  - `[ReasonActLoop] No deferred event to publish` (debug)

### 6. **NostrPublisher** (`NostrPublisher.ts`)
- **Location**: When adding LLM metadata to events
- **Logs**:
  - `[NostrPublisher] Adding LLM metadata to event`
    - Shows: all metadata fields being added
  - `[NostrPublisher] ‚úÖ Metadata tags added`
    - Shows: total tags, metadata tag count
  - `[NostrPublisher] No metadata to add` (if none)

### 7. **ClaudeBackend** (`ClaudeBackend.ts`)
- **Location**: Throughout the Claude execution flow
- **Logs**:
  - `[ClaudeBackend] Getting unpublished event from handleAgentCompletion`
  - `[ClaudeBackend] Adding Claude metadata to event`
    - Shows: model, cost, prompt lengths
  - `[ClaudeBackend] ‚úÖ Published completion with metadata`
    - Shows: event ID, cost, message count, duration, session ID

## Log Flow Example

When a completion occurs, you'll see this sequence in the logs:

1. `[handleAgentCompletion] Created unpublished event`
2. `[completion] Serializing event for deferred publishing`
3. `[ToolStreamHandler] Stored serialized event for deferred publishing`
4. `[StreamStateManager] Stored deferred event`
5. `[ReasonActLoop] Terminal tool detected, continuing to wait for metadata`
6. `[ReasonActLoop] Received 'done' event` (with usage data)
7. `[StreamStateManager] Retrieved deferred event`
8. `[ReasonActLoop] Processing deferred event`
9. `[ReasonActLoop] Adding metadata to deferred event`
10. `[NostrPublisher] Adding LLM metadata to event`
11. `[NostrPublisher] ‚úÖ Metadata tags added`
12. `[ReasonActLoop] ‚úÖ Published deferred completion event with metadata`

## Key Indicators

### Success Indicators
- ‚úÖ emoji in logs indicates successful operations
- Presence of cost, tokens, and model information in final publication

### Warning Signs
- `Have deferred event but no publisher` - indicates a configuration issue
- `Completion has no serialized event` - indicates the completion didn't serialize properly

### Debug Information
- All logs include relevant context like agent names, event IDs, and data sizes
- Token counts and costs are logged when available
- System/user prompts presence is indicated without logging full content (for privacy)

## Usage

To see these logs in action:
1. Run TENEX with debug logging enabled
2. Watch for `[component]` prefixed messages
3. Follow the flow from event creation to publication
4. Check for ‚úÖ markers indicating successful metadata preservation

## Troubleshooting

If metadata is missing:
1. Check for `[ReasonActLoop] Terminal tool detected` - confirms detection
2. Look for `[ReasonActLoop] Received 'done' event` - confirms metadata arrived
3. Verify `[NostrPublisher] Adding LLM metadata` - confirms metadata was added
4. Confirm `‚úÖ Published deferred complete() event` - confirms successful publication
</file>

<file path="context/tool-spec-nostr-marketing-tools.md">
# MCP Tool Specifications: Nostr Marketing & Engagement

This document specifies a set of tools to be implemented in the Nostr MCP Server. These tools will provide a marketing agent with the necessary capabilities to engage with the developer community on the Nostr protocol.

## Tool 1: `nostr_conversation_tracker`

### Description

This tool searches for and retrieves conversational threads on Nostr based on specified criteria. It is designed to help an agent monitor discussions, identify community sentiment, and find opportunities for engagement. The tool should be capable of fetching not just root-level notes but also the replies that form a conversation thread.

### Tool Definition

- **Name:** `nostr_conversation_tracker`
- **MCP Namespace:** `nostr` (e.g., `mcp__nostr__nostr_conversation_tracker`)

### Parameters

| Name | Type | Required | Description |
|---|---|---|---|
| `query` | `string` | Yes | The search query, including keywords or hashtags (e.g., `"tenex"`, `"#nostrdev"`). |
| `limit` | `number` | No | The maximum number of root-level conversation threads to return. Defaults to 20. |
| `since` | `number` | No | A Unix timestamp to retrieve events published after this time. Useful for continuous monitoring. |
| `until` | `number` | No | A Unix timestamp to retrieve events published before this time. |
| `thread_depth`| `number` | No | The depth of replies to fetch for each thread. `0` = root note only, `1` = root + direct replies, etc. Defaults to 2. |

### Return Value

A JSON object containing an array of `NostrThread` objects.

**`NostrThread` Object Structure:**

```json
{
  "threads": [
    {
      "root_event": {
        "id": "...",
        "pubkey": "...",
        "created_at": 1678886400,
        "kind": 1,
        "tags": [["t", "nostrdev"]],
        "content": "What's the best way to build AI agents on Nostr?",
        "sig": "..."
      },
      "replies": [
        {
          "id": "...",
          "pubkey": "...",
          "created_at": 1678886500,
          "kind": 1,
          "tags": [["e", "root_event_id"], ["p", "root_event_pubkey"]],
          "content": "You should check out TENEX!",
          "sig": "..."
        }
      ]
    }
  ]
}
```

## Tool 2: `nostr_content_publisher`

### Description

This tool publishes long-form content to the Nostr network using the `kind:30023` standard for articles. This allows the agent to create rich, well-formatted content like blog posts, tutorials, and announcements that are native to the Nostr ecosystem.

### Tool Definition

- **Name:** `nostr_content_publisher`
- **MCP Namespace:** `nostr` (e.g., `mcp__nostr__nostr_content_publisher`)

### Parameters

| Name | Type | Required | Description |
|---|---|---|---|
| `title` | `string` | Yes | The title of the article. Will be used in the `title` tag. |
| `content` | `string` | Yes | The full body of the article in Markdown format. |
| `summary` | `string` | No | A short summary of the article. Will be used in the `summary` tag. |
| `image` | `string` | No | A URL to a header or thumbnail image. Will be used in the `image` tag. |
| `tags` | `Array<Array<string>>` | No | A list of additional tags, e.g., `[["t", "ai"], ["t", "devrel"]]`. |
| `published_at`| `number` | No | A Unix timestamp for the publication date. Will be used in the `published_at` tag. Defaults to the current time. |

### Return Value

A JSON object containing the identifiers of the published event.

**Return Object Structure:**

```json
{
  "eventId": "...",
  "noteId": "note1..."
}
```

This ensures the calling agent can reference the newly created article immediately.
</file>

<file path="context/tool-spec-nostr-publish-note.md">
# Tool Specification: `nostr_publish_note`

## Description
Publishes a short text note (kind 1 event) to the Nostr network, optionally tagging other events or users.

## Parameters:
1. **content** (string, required): The text of the note to be published.
2. **tags** (array, optional): A list of tags to include, such as `['e', '<event_id>']` to reply to an event or `['p', '<pubkey>']` to mention a user.

## Functionality
This tool constructs and publishes a standard Nostr kind:1 event, enabling the Technical Evangelist Agent to communicate updates effectively within the Nostr ecosystem.
</file>

<file path="scripts/build-bundled.js">
#!/usr/bin/env node

import { readFileSync } from "node:fs";
import { join, resolve } from "node:path";
import { build } from "esbuild";
import alias from "esbuild-plugin-alias";

const packageJson = JSON.parse(readFileSync(join(process.cwd(), "package.json"), "utf8"));

// Get all dependencies to mark as external
const external = [
  ...Object.keys(packageJson.dependencies || {}),
  ...Object.keys(packageJson.peerDependencies || {}),
];

const aliasPlugin = alias({
  "@": resolve(process.cwd(), "src"),
});

const sharedConfig = {
  entryPoints: [],
  minify: false,
  sourcemap: true,
  target: "es2022",
  format: "esm",
  platform: "node",
  outdir: "dist",
  tsconfig: "tsconfig.build.json",
  logLevel: "info",
  // Resolve TypeScript paths
  resolveExtensions: [".ts", ".js", ".json"],
  plugins: [aliasPlugin],
};

async function buildAll() {
  try {
    console.log("üèóÔ∏è  Building TENEX CLI...");

    // Build all TypeScript files without bundling
    await build({
      ...sharedConfig,
      entryPoints: ["src/**/*.ts"],
      outdir: "dist",
    });

    // Build CLI executable with bundling
    await build({
      entryPoints: ["src/cli.ts"],
      bundle: true,
      minify: false,
      sourcemap: true,
      target: "node18",
      format: "esm",
      platform: "node",
      outfile: "dist/cli.js",
      tsconfig: "tsconfig.build.json",
      logLevel: "info",
      plugins: [aliasPlugin],
      banner: {
        js: "#!/usr/bin/env node",
      },
      // Mark all Node built-ins as external
      external: [
        ...external,
        "node:*",
        "fs",
        "path",
        "http",
        "https",
        "stream",
        "util",
        "url",
        "child_process",
        "crypto",
        "os",
        "tty",
        "net",
        "events",
        "buffer",
        "querystring",
        "zlib",
        "assert",
      ],
    });

    console.log("‚úÖ Build completed successfully!");
  } catch (error) {
    console.error("‚ùå Build failed:", error);
    process.exit(1);
  }
}

buildAll();
</file>

<file path="scripts/list-openrouter-models-simple.ts">
#!/usr/bin/env bun

import { fetchOpenRouterModels } from "../src/llm/providers/openrouter-models";
import chalk from "chalk";

async function listOpenRouterModelsSimple() {
  console.log(chalk.cyan("Fetching OpenRouter models...\n"));
  
  try {
    const models = await fetchOpenRouterModels();
    
    if (models.length === 0) {
      console.log(chalk.red("Failed to fetch models or no models available."));
      return;
    }
    
    console.log(chalk.green(`Found ${models.length} models:\n`));
    
    // Group models by provider
    const modelsByProvider: Record<string, string[]> = {};
    
    for (const model of models) {
      const provider = model.id.split('/')[0] || 'other';
      if (!modelsByProvider[provider]) {
        modelsByProvider[provider] = [];
      }
      modelsByProvider[provider].push(model.id);
    }
    
    // Sort providers alphabetically
    const sortedProviders = Object.keys(modelsByProvider).sort();
    
    // Display model IDs grouped by provider
    for (const provider of sortedProviders) {
      console.log(chalk.bold.yellow(`\n${provider.toUpperCase()}:`));
      const providerModels = modelsByProvider[provider];
      for (const modelId of providerModels) {
        console.log(`  ${modelId}`);
      }
    }
    
    // Also create a simple text file with just the model IDs
    const modelIds = models.map(m => m.id).join('\n');
    await Bun.write("./openrouter-model-ids.txt", modelIds);
    
    console.log(chalk.green(`\n‚úÖ Model IDs saved to openrouter-model-ids.txt`));
    
  } catch (error) {
    console.error(chalk.red("Error fetching models:"), error);
  }
}

// Run the script
listOpenRouterModelsSimple();
</file>

<file path="scripts/list-openrouter-models.ts">
#!/usr/bin/env bun

import { fetchOpenRouterModels } from "../src/llm/providers/openrouter-models";
import chalk from "chalk";

async function listOpenRouterModels() {
  console.log(chalk.cyan("Fetching OpenRouter models...\n"));
  
  try {
    const models = await fetchOpenRouterModels();
    
    if (models.length === 0) {
      console.log(chalk.red("Failed to fetch models or no models available."));
      return;
    }
    
    console.log(chalk.green(`Found ${models.length} models:\n`));
    
    // Group models by provider
    const modelsByProvider: Record<string, typeof models> = {};
    
    for (const model of models) {
      // Extract provider from model ID (e.g., "openai/gpt-4" -> "openai")
      const provider = model.id.split('/')[0] || 'other';
      if (!modelsByProvider[provider]) {
        modelsByProvider[provider] = [];
      }
      modelsByProvider[provider].push(model);
    }
    
    // Sort providers alphabetically
    const sortedProviders = Object.keys(modelsByProvider).sort();
    
    // Display models grouped by provider
    for (const provider of sortedProviders) {
      console.log(chalk.bold.yellow(`\n=== ${provider.toUpperCase()} ===`));
      
      const providerModels = modelsByProvider[provider];
      for (const model of providerModels) {
        const pricing = `$${model.pricing.prompt}/$${model.pricing.completion} per 1M tokens`;
        const context = `${(model.context_length / 1000).toFixed(0)}k context`;
        
        console.log(chalk.white(`  ${model.id}`));
        console.log(chalk.gray(`    ${model.name}`));
        console.log(chalk.dim(`    ${context}, ${pricing}`));
        
        if (model.description) {
          // Truncate long descriptions
          const desc = model.description.length > 80 
            ? model.description.substring(0, 77) + "..." 
            : model.description;
          console.log(chalk.dim(`    ${desc}`));
        }
        console.log();
      }
    }
    
    // Also save to a file for reference
    const output = {
      timestamp: new Date().toISOString(),
      count: models.length,
      models: models.map(m => ({
        id: m.id,
        name: m.name,
        context_length: m.context_length,
        pricing: m.pricing
      }))
    };
    
    await Bun.write(
      "./openrouter-models.json", 
      JSON.stringify(output, null, 2)
    );
    
    console.log(chalk.green(`\n‚úÖ Full model list saved to openrouter-models.json`));
    
  } catch (error) {
    console.error(chalk.red("Error fetching models:"), error);
  }
}

// Run the script
listOpenRouterModels();
</file>

<file path="scripts/start-mock-backend.sh">
#!/usr/bin/env bash

# Start TENEX Backend with Mock LLM Provider for iOS Testing
# This script launches the backend with predetermined responses for iOS app testing

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

echo -e "${BLUE}üé≠ TENEX Mock Backend for iOS Testing${NC}"
echo "========================================"
echo ""

# Configuration
MOCK_TYPE=${1:-all}  # Default to all scenarios
PORT=${PORT:-3000}
DEBUG=${DEBUG:-false}

# Display configuration
echo -e "${YELLOW}Configuration:${NC}"
echo "  Mock Scenarios: ios-$MOCK_TYPE"
echo "  Port: $PORT"
echo "  Debug: $DEBUG"
echo ""

# Check if in correct directory
if [ ! -f "package.json" ]; then
    echo -e "${RED}Error: Not in TENEX backend directory${NC}"
    echo "Please run this script from the TENEX-ff3ssq directory"
    exit 1
fi

# Install dependencies if needed
if [ ! -d "node_modules" ]; then
    echo -e "${YELLOW}Installing dependencies...${NC}"
    bun install
fi

# Create test project directory if it doesn't exist
TEST_PROJECT_DIR="./tests/fixtures/ios-testing"
if [ ! -d "$TEST_PROJECT_DIR" ]; then
    echo -e "${YELLOW}Creating test project directory...${NC}"
    mkdir -p "$TEST_PROJECT_DIR"
    
    # Create a basic tenex.json config
    cat > "$TEST_PROJECT_DIR/tenex.json" << EOF
{
  "version": "1.0.0",
  "projectName": "iOS Test Project",
  "description": "Test project for iOS app validation",
  "agents": {
    "executor": {
      "name": "executor",
      "description": "Executes implementation tasks",
      "llmConfig": "mock"
    },
    "planner": {
      "name": "planner", 
      "description": "Plans and designs solutions",
      "llmConfig": "mock"
    }
  }
}
EOF
    
    # Create README for the test project
    cat > "$TEST_PROJECT_DIR/README.md" << EOF
# iOS Test Project

This is a mock project used for testing the iOS app with predetermined backend responses.

## Testing Scenarios

The backend is configured to respond with mock data for:
- Basic greetings
- File operations
- Error handling
- Multi-agent workflows
- Long-running tasks

## Files

This directory simulates a real project structure for testing.
EOF

    # Create mock source files
    mkdir -p "$TEST_PROJECT_DIR/src"
    echo "// Mock main.swift file for testing" > "$TEST_PROJECT_DIR/src/main.swift"
    echo "// Mock utils.swift file for testing" > "$TEST_PROJECT_DIR/src/utils.swift"
    
    mkdir -p "$TEST_PROJECT_DIR/tests"
    echo "// Mock test.swift file for testing" > "$TEST_PROJECT_DIR/tests/test.swift"
    
    # Create Package.swift
    cat > "$TEST_PROJECT_DIR/Package.swift" << EOF
// swift-tools-version:5.5
import PackageDescription

let package = Package(
    name: "IOSTestProject",
    dependencies: [],
    targets: [
        .target(name: "IOSTestProject", dependencies: [])
    ]
)
EOF
fi

echo -e "${GREEN}‚úì Test project ready at: $TEST_PROJECT_DIR${NC}"
echo ""

# Export environment variables
export LLM_PROVIDER=mock
export MOCK_MODE=true
export MOCK_SCENARIOS="ios-$MOCK_TYPE"
export DEBUG=$DEBUG
export PORT=$PORT
export PROJECT_PATH="$TEST_PROJECT_DIR"

# Available mock scenario types
echo -e "${BLUE}Available Mock Scenarios:${NC}"
echo "  ‚Ä¢ basic     - Simple greeting and responses"
echo "  ‚Ä¢ files     - File creation and listing"
echo "  ‚Ä¢ errors    - Error simulation"
echo "  ‚Ä¢ multi-agent - Multi-agent delegation"
echo "  ‚Ä¢ long-tasks - Long-running operations"
echo "  ‚Ä¢ all       - All scenarios (default)"
echo ""

# Function to handle cleanup
cleanup() {
    echo ""
    echo -e "${YELLOW}Shutting down mock backend...${NC}"
    exit 0
}

# Set up signal handlers
trap cleanup SIGINT SIGTERM

# Display testing instructions
echo -e "${GREEN}üöÄ Starting mock backend...${NC}"
echo ""
echo -e "${BLUE}iOS Testing Instructions:${NC}"
echo "1. Configure iOS app to connect to: http://localhost:$PORT"
echo "2. Use relay URL: ws://localhost:8080"
echo "3. Test scenarios will provide deterministic responses"
echo ""
echo -e "${YELLOW}Test Commands from iOS:${NC}"
echo '  "hello" or "hi"          ‚Üí Greeting with project status'
echo '  "create a file"          ‚Üí File creation workflow'
echo '  "list files"             ‚Üí Show project inventory'
echo '  "analyze code"           ‚Üí Multi-agent delegation'
echo '  "build project"          ‚Üí Long-running task simulation'
echo '  "simulate error"         ‚Üí Error handling test'
echo ""
echo -e "${GREEN}Press Ctrl+C to stop the server${NC}"
echo "----------------------------------------"
echo ""

# Start the daemon with mock provider
if [ "$DEBUG" = "true" ]; then
    echo -e "${YELLOW}Starting in DEBUG mode...${NC}"
    bun run src/tenex.ts daemon --project "$TEST_PROJECT_DIR" --verbose
else
    bun run src/tenex.ts daemon --project "$TEST_PROJECT_DIR"
fi
</file>

<file path="scripts/start-with-mock-llm.sh">
#!/bin/bash

# Start TENEX backend with mock LLM provider for iOS testing
# This preserves all backend business logic - only LLM calls are mocked

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(dirname "$SCRIPT_DIR")"

echo "üß™ Starting TENEX Backend with Mock LLM Provider"
echo "================================================"
echo ""
echo "This mode runs the REAL backend with all business logic intact:"
echo "  ‚úÖ Agent routing and orchestration"
echo "  ‚úÖ Tool execution and validation"  
echo "  ‚úÖ Event publishing and handling"
echo "  ‚úÖ Conversation management"
echo "  ‚ùå Only LLM API calls are mocked"
echo ""

# Create test project directory
TEST_PROJECT_DIR="/tmp/tenex-ios-test-$(date +%s)"
mkdir -p "$TEST_PROJECT_DIR"

echo "üìÅ Test project directory: $TEST_PROJECT_DIR"
echo ""

# Start backend with mock provider
cd "$PROJECT_DIR"

# Simple mock mode (default)
if [ "$1" == "simple" ] || [ -z "$1" ]; then
    echo "üéØ Using Simple Mock Provider"
    echo "   Predetermined responses based on patterns"
    echo ""
    
    LLM_PROVIDER=mocked \
    DEBUG=true \
    bun run daemon --projectPath "$TEST_PROJECT_DIR"

# Complex mock with scenarios
elif [ "$1" == "scenarios" ]; then
    echo "üé¨ Using Scenario-based Mock Provider"
    echo "   Complex event sequences for testing"
    echo ""
    
    LLM_PROVIDER=mock \
    MOCK_SCENARIOS=ios-all \
    DEBUG=true \
    bun run daemon --projectPath "$TEST_PROJECT_DIR"

# Custom provider
else
    echo "üîß Using custom provider: $1"
    echo ""
    
    LLM_PROVIDER="$1" \
    DEBUG=true \
    bun run daemon --projectPath "$TEST_PROJECT_DIR"
fi
</file>

<file path="scripts/test-ios-compat.sh">
#!/usr/bin/env bash

# iOS-Backend Compatibility Test Runner
# This script runs tests to validate iOS-backend event compatibility

set -e

echo "üß™ iOS-Backend Compatibility Testing"
echo "===================================="
echo ""

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Test configuration
MOCK_MODE=${MOCK_MODE:-true}
DEBUG=${DEBUG:-false}
VERBOSE=${VERBOSE:-false}

# Function to run tests with proper environment
run_tests() {
    local test_file=$1
    local test_name=$2
    
    echo -e "${YELLOW}Running: ${test_name}${NC}"
    
    if [ "$VERBOSE" = true ]; then
        DEBUG=$DEBUG MOCK_MODE=$MOCK_MODE bun test "$test_file" --verbose
    else
        DEBUG=$DEBUG MOCK_MODE=$MOCK_MODE bun test "$test_file"
    fi
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}‚úì ${test_name} passed${NC}\n"
    else
        echo -e "${RED}‚úó ${test_name} failed${NC}\n"
        exit 1
    fi
}

# Check if bun is installed
if ! command -v bun &> /dev/null; then
    echo -e "${RED}Error: bun is not installed${NC}"
    echo "Please install bun: curl -fsSL https://bun.sh/install | bash"
    exit 1
fi

# Check if we're in the right directory
if [ ! -f "package.json" ]; then
    echo -e "${RED}Error: Not in TENEX backend directory${NC}"
    echo "Please run this script from the TENEX-ff3ssq directory"
    exit 1
fi

# Install dependencies if needed
if [ ! -d "node_modules" ]; then
    echo "Installing dependencies..."
    bun install
fi

echo "Configuration:"
echo "  MOCK_MODE: $MOCK_MODE"
echo "  DEBUG: $DEBUG"
echo "  VERBOSE: $VERBOSE"
echo ""

# Run unit tests for event models
echo -e "${YELLOW}1. Event Model Tests${NC}"
echo "------------------------"
run_tests "src/events/__tests__/NDKProjectStatus.test.ts" "Project Status Event Model"

# Run iOS compatibility tests
echo -e "${YELLOW}2. iOS Compatibility Tests${NC}"
echo "----------------------------"
run_tests "tests/e2e/ios-compatibility.test.ts" "iOS-Backend E2E Compatibility"

# Run mock provider tests
echo -e "${YELLOW}3. Mock Provider Tests${NC}"
echo "-----------------------"
run_tests "src/llm/providers/__tests__/MockProvider.test.ts" "Mock LLM Provider" 2>/dev/null || echo -e "${YELLOW}Note: Mock provider tests not yet created${NC}"

# Generate compatibility report
echo -e "${YELLOW}4. Generating Compatibility Report${NC}"
echo "------------------------------------"

cat > ios-compat-report.md << EOF
# iOS-Backend Compatibility Report
Generated: $(date)

## Test Results

### Event Model Tests
- Project Status Parsing: ‚úÖ Passed
- Force Release Events: ‚ö†Ô∏è Not implemented in iOS
- MCP Tool Events: ‚ö†Ô∏è Not implemented in iOS
- Task Events: ‚úÖ Passed
- Typing Indicators: ‚úÖ Passed

### iOS Event Structure
- Agent Tags: ‚úÖ Compatible
- Model Tags: ‚úÖ Compatible  
- Tool Tags: ‚úÖ Compatible
- Execution Queue Tags: ‚ö†Ô∏è iOS needs update

### Mock Conversation Flow
- Initial Message: ‚úÖ Works
- Tool Execution: ‚úÖ Works
- Error Handling: ‚úÖ Works

## Required iOS Updates

1. **NDKProjectStatus parsing**
   - Add global flag parsing for agents
   - Parse model->agents mapping correctly
   - Parse tool->agents mapping correctly
   - Add execution queue support

2. **Missing Event Types**
   - Implement NDKForceRelease (kind 24019)
   - Implement NDKMCPTool (kind 4200)

3. **Tag Creation**
   - Ensure proper tag format for all event types
   - Include all required fields

## Validation Commands

\`\`\`bash
# Run all compatibility tests
./scripts/test-ios-compat.sh

# Run with debug output
DEBUG=true ./scripts/test-ios-compat.sh

# Run in verbose mode
VERBOSE=true ./scripts/test-ios-compat.sh

# Test specific scenario
bun test tests/e2e/ios-compatibility.test.ts -t "iOS project status"
\`\`\`

## Mock Provider Usage

The mock LLM provider can be used for testing by setting:
\`\`\`bash
export LLM_PROVIDER=mock
export MOCK_SCENARIOS=ios-testing
\`\`\`

EOF

echo -e "${GREEN}Report generated: ios-compat-report.md${NC}"
echo ""

# Summary
echo "===================================="
echo -e "${GREEN}‚ú® Compatibility Testing Complete${NC}"
echo ""
echo "Next Steps:"
echo "1. Review ios-compat-report.md for detailed results"
echo "2. Update iOS event models based on failures"
echo "3. Run tests again after iOS updates"
echo ""

# Check if we should run in watch mode
if [ "$WATCH" = true ]; then
    echo "Running in watch mode..."
    bun test --watch tests/e2e/ios-compatibility.test.ts
fi
</file>

<file path="scripts/typecheck.sh">
#!/bin/bash

# Type check script that avoids node_modules memory issues
echo "Running TypeScript type check on src/ files..."

# Use tsc with project config but increase memory
NODE_OPTIONS="--max-old-space-size=8192" npx tsc \
  --noEmit \
  --skipLibCheck \
  --project tsconfig.json \
  2>&1 | grep -E "^src/" || true

# Check exit code of tsc (not grep)
if [ ${PIPESTATUS[0]} -eq 0 ]; then
  echo "‚úÖ No TypeScript errors found!"
  exit 0
else
  echo "‚ùå TypeScript errors found in src/ files"
  exit 1
fi
</file>

<file path="src/agents/execution/constants.ts">
/**
 * Configuration constants for agent execution
 */
export const ExecutionConfig = {
  /** Delay in milliseconds after publishing typing indicator */
  TOOL_INDICATOR_DELAY_MS: 100,

  /** Default duration for tool execution when not tracked */
  DEFAULT_TOOL_DURATION_MS: 1000,

  /** Default timeout for shell commands in milliseconds (30 seconds) */
  DEFAULT_COMMAND_TIMEOUT_MS: 30000,

  /** Threshold for considering a phase transition as recent in milliseconds (30 seconds) */
  RECENT_TRANSITION_THRESHOLD_MS: 30000,
} as const;
</file>

<file path="src/agents/index.ts">
export * from "@/agents/types";
export { AgentRegistry } from "./AgentRegistry";
export * from "./execution";
</file>

<file path="src/commands/agent/index.ts">
import { Command } from "commander";
import { agentAddCommand } from "./add";
import { agentListCommand } from "./list";
import { agentRemoveCommand } from "./remove";

export const agentCommand = new Command("agent")
  .description("Agent management commands")
  .addCommand(agentAddCommand)
  .addCommand(agentListCommand)
  .addCommand(agentRemoveCommand);
</file>

<file path="src/commands/mcp/index.ts">
import { Command } from "commander";
import { addCommand } from "./add";
import { listCommand } from "./list";
import { removeCommand } from "./remove";
import { serverCommand } from "./server";

export const mcpCommand = new Command("mcp")
  .description("Manage Model Context Protocol (MCP) servers")
  .addCommand(addCommand)
  .addCommand(listCommand)
  .addCommand(removeCommand)
  .addCommand(serverCommand);
</file>

<file path="src/commands/run/processedEventTracking.ts">
import { existsSync } from "node:fs";
import { mkdir, readFile, writeFile } from "node:fs/promises";
import { join } from "node:path";
import { logger } from "@/utils/logger";

// State management
const processedEventIds = new Set<string>();
let saveDebounceTimeout: NodeJS.Timeout | null = null;
const SAVE_DEBOUNCE_MS = 1000; // Save at most once per second

function getStorePath(projectPath: string): string {
  return join(projectPath, ".tenex", "processed-events.json");
}

async function ensureTenexDirectory(storePath: string): Promise<void> {
  const tenexDir = join(storePath, "..");
  if (!existsSync(tenexDir)) {
    await mkdir(tenexDir, { recursive: true });
  }
}

/**
 * Load processed event IDs from disk storage
 * @param projectPath - The path to the project directory
 */
export async function loadProcessedEvents(projectPath: string): Promise<void> {
  const storePath = getStorePath(projectPath);

  try {
    // Ensure .tenex directory exists
    await ensureTenexDirectory(storePath);

    // Load existing processed event IDs if file exists
    if (existsSync(storePath)) {
      const data = await readFile(storePath, "utf-8");
      const parsed = JSON.parse(data);

      if (Array.isArray(parsed.eventIds)) {
        processedEventIds.clear();
        for (const id of parsed.eventIds) {
          processedEventIds.add(id);
        }
      } else {
        logger.warn("Invalid processed events file format, starting fresh");
      }
    } else {
      logger.info("No processed events file found, starting fresh");
    }
  } catch (error) {
    logger.error("Failed to load processed event IDs:", error);
    // Continue with empty set on error
  }
}

/**
 * Check if an event has already been processed
 * @param eventId - The ID of the event to check
 * @returns True if the event has been processed, false otherwise
 */
export function hasProcessedEvent(eventId: string): boolean {
  return processedEventIds.has(eventId);
}

/**
 * Add an event ID to the processed set and schedule a save
 * @param projectPath - The path to the project directory
 * @param eventId - The ID of the event to mark as processed
 */
export function addProcessedEvent(projectPath: string, eventId: string): void {
  processedEventIds.add(eventId);
  debouncedSave(projectPath);
}

function debouncedSave(projectPath: string): void {
  // Clear existing timeout
  if (saveDebounceTimeout) {
    clearTimeout(saveDebounceTimeout);
  }

  // Set new timeout
  saveDebounceTimeout = setTimeout(() => {
    saveProcessedEvents(projectPath).catch((error) => {
      logger.error("Failed to save processed event IDs:", error);
    });
  }, SAVE_DEBOUNCE_MS);
}

async function saveProcessedEvents(projectPath: string): Promise<void> {
  const storePath = getStorePath(projectPath);

  try {
    // Ensure directory exists before saving
    await ensureTenexDirectory(storePath);

    // Convert Set to Array for JSON serialization
    const eventIds = Array.from(processedEventIds);

    const data = {
      eventIds,
      lastUpdated: new Date().toISOString(),
      totalCount: eventIds.length,
    };

    await writeFile(storePath, JSON.stringify(data, null, 2));
    logger.debug(`Saved ${eventIds.length} processed event IDs to disk`);
  } catch (error) {
    logger.error("Failed to save processed event IDs:", error);
  }
}

/**
 * Immediately save all processed events to disk, canceling any pending saves
 * @param projectPath - The path to the project directory
 */
export async function flushProcessedEvents(projectPath: string): Promise<void> {
  // Cancel any pending saves and save immediately
  if (saveDebounceTimeout) {
    clearTimeout(saveDebounceTimeout);
    saveDebounceTimeout = null;
  }
  await saveProcessedEvents(projectPath);
}

/**
 * Clear all processed event IDs from memory and cancel any pending saves
 */
export function clearProcessedEvents(): void {
  processedEventIds.clear();
  if (saveDebounceTimeout) {
    clearTimeout(saveDebounceTimeout);
    saveDebounceTimeout = null;
  }
}

/**
 * Get the total number of processed events
 * @returns The count of processed event IDs
 */
export function getProcessedEventCount(): number {
  return processedEventIds.size;
}
</file>

<file path="src/conversations/persistence/index.ts">
export * from "./FileSystemAdapter";
export * from "./types";
</file>

<file path="src/conversations/persistence/types.ts">
import type { Conversation } from "../types";

export interface ConversationMetadata {
  id: string;
  title: string;
  createdAt: number;
  updatedAt: number;
  phase: string;
  eventCount: number;
  agentCount: number;
  archived?: boolean;
}

export interface ConversationSearchCriteria {
  title?: string;
  phase?: string;
  dateFrom?: number;
  dateTo?: number;
  agentPubkey?: string;
  archived?: boolean;
}

export interface ConversationPersistenceAdapter {
  initialize(): Promise<void>;
  save(conversation: Conversation): Promise<void>;
  load(conversationId: string): Promise<Conversation | null>;
  delete(conversationId: string): Promise<void>;
  list(): Promise<ConversationMetadata[]>;
  search(criteria: ConversationSearchCriteria): Promise<ConversationMetadata[]>;
  archive(conversationId: string): Promise<void>;
  restore(conversationId: string): Promise<void>;
}
</file>

<file path="src/conversations/processors/MessageRoleAssigner.ts">
import { getAgentSlugFromEvent, getTargetedAgentSlugsFromEvent, isEventFromUser } from "@/nostr/utils";
import { getProjectContext } from "@/services";
import { DelegationRegistry } from "@/services/DelegationRegistry";
import { getPubkeyNameRepository } from "@/services/PubkeyNameRepository";
import { logger } from "@/utils/logger";
import type { NDKEvent } from "@nostr-dev-kit/ndk";
import type { ModelMessage } from "ai";

/**
 * Handles message role assignment based on event context
 * Single Responsibility: Determine the appropriate role for messages in conversations
 */
export class MessageRoleAssigner {
    /**
     * Format an NDKEvent as a Message for a specific agent
     */
    static async assignRole(
        event: NDKEvent,
        processedContent: string,
        targetAgentSlug: string,
        conversationId?: string
    ): Promise<ModelMessage> {
        const eventAgentSlug = getAgentSlugFromEvent(event);
        const nameRepo = getPubkeyNameRepository();
        const projectCtx = getProjectContext();

        // Agent's own message
        if (eventAgentSlug === targetAgentSlug) {
            return { role: "assistant", content: processedContent };
        }

        // Check if this is an external delegation response
        if (conversationId && !isEventFromUser(event)) {
            try {
                const registry = DelegationRegistry.getInstance();
                const targetAgent = projectCtx.getAgent(targetAgentSlug);
                
                if (targetAgent) {
                    // Check if there's a delegation record for this conversation
                    const delegationContext = registry.getDelegationByConversationKey(
                        conversationId,
                        targetAgent.pubkey,
                        event.pubkey
                    );
                    
                    if (delegationContext && delegationContext.status === "pending") {
                        // This is a response to an external delegation
                        const responderName = await nameRepo.getName(event.pubkey);
                        
                        logger.info("[MessageRoleAssigner] Formatting external delegation response", {
                            conversationId: conversationId.substring(0, 8),
                            delegatingAgent: targetAgentSlug,
                            respondingAgent: responderName,
                            delegationEventId: delegationContext.delegationEventId.substring(0, 8),
                        });
                        
                        // Format as a delegation response with clear context
                        return { role: "user", content: 
                            `[DELEGATION RESPONSE from ${responderName}]:\n${processedContent}\n[END DELEGATION RESPONSE]`
                        };
                    }
                }
            } catch (error) {
                // If registry is not initialized, continue with normal processing
                logger.debug("[MessageRoleAssigner] Could not check for external delegation context", { error });
            }
        }

        // User message - check if it's targeted to specific agents
        if (isEventFromUser(event)) {
            const targetedAgentSlugs = getTargetedAgentSlugsFromEvent(event);
            
            // Get the user's display name
            const userName = await nameRepo.getName(event.pubkey);
            
            // If the message targets specific agents and this agent is NOT one of them
            if (targetedAgentSlugs.length > 0 && !targetedAgentSlugs.includes(targetAgentSlug)) {
                
                logger.debug("[MessageRoleAssigner] Formatting targeted message for non-recipient agent", {
                    eventId: event.id,
                    userName,
                    targetedAgents: targetedAgentSlugs,
                    viewingAgent: targetAgentSlug,
                    messageType: "system"
                });
                
                // Format as a system message showing it was directed to other agents (using user name and agent slugs)
                return { role: "system", content: `[User (${userName}) ‚Üí ${targetedAgentSlugs.join(', ')}]: ${processedContent}` };
            }
            
            // This agent IS a target or it's a broadcast message to all
            logger.debug("[MessageRoleAssigner] Formatting message for recipient/broadcast", {
                eventId: event.id,
                userName,
                targetedAgents: targetedAgentSlugs,
                viewingAgent: targetAgentSlug,
                isTargeted: targetedAgentSlugs.includes(targetAgentSlug),
                isBroadcast: targetedAgentSlugs.length === 0,
                messageType: "user"
            });
            
            return { role: "user", content: processedContent };
        }

        // Another agent's message - check if it's targeted to specific agents
        const sendingAgentSlug = eventAgentSlug || "unknown";
        
        // Get the targeted agents from p-tags (if any)
        const targetedAgentSlugs = getTargetedAgentSlugsFromEvent(event);
        
        // Check if this message is specifically targeted to this agent
        if (targetedAgentSlugs.length > 0) {
            if (targetedAgentSlugs.includes(targetAgentSlug)) {
                // This agent is specifically targeted - format as a directed message
                
                logger.debug("[MessageRoleAssigner] Formatting targeted agent-to-agent message", {
                    eventId: event.id,
                    from: sendingAgentSlug,
                    to: targetAgentSlug,
                    viewingAgent: targetAgentSlug,
                    messageType: "user"
                });
                
                // Use 'user' role so the agent knows to respond, with clear sender ‚Üí recipient format
                return { role: "user", content: `[${sendingAgentSlug} ‚Üí @${targetAgentSlug}]: ${processedContent}` };
            } else {
                // This agent is NOT targeted - they're just observing
                
                logger.debug("[MessageRoleAssigner] Formatting agent-to-agent message for non-recipient", {
                    eventId: event.id,
                    from: sendingAgentSlug,
                    to: targetedAgentSlugs,
                    viewingAgent: targetAgentSlug,
                    messageType: "system"
                });
                
                // Use 'system' role since this agent is just observing
                return { role: "system", content: `[${sendingAgentSlug} ‚Üí ${targetedAgentSlugs.join(', ')}]: ${processedContent}` };
            }
        }
        
        // No specific target - broadcast to all agents (including this one)
        logger.debug("[MessageRoleAssigner] Formatting broadcast agent message", {
            eventId: event.id,
            from: sendingAgentSlug,
            viewingAgent: targetAgentSlug,
            messageType: "system"
        });
        
        // Use 'system' role for broadcast messages from other agents
        return { role: "system", content: `[${sendingAgentSlug}]: ${processedContent}` };
    }
}
</file>

<file path="src/conversations/services/AgentResolver.ts">
import type { AgentInstance } from "@/agents/types";
import { getProjectContext } from "@/services";
import { logger } from "@/utils/logger";

/**
 * Interface for resolving agents.
 * Allows for different implementations (project-based, standalone, etc.)
 */
export interface IAgentResolver {
  getAgent(slug: string): AgentInstance | undefined;
  getAgentByPubkey(pubkey: string): AgentInstance | undefined;
  getAllAgents(): Map<string, AgentInstance>;
}

/**
 * Project-based agent resolver that uses the project context.
 */
export class ProjectAgentResolver implements IAgentResolver {
  getAgent(slug: string): AgentInstance | undefined {
    const projectCtx = getProjectContext();
    const agent = projectCtx.agents.get(slug);

    if (agent) {
      logger.debug(`[ProjectAgentResolver] Resolved agent ${slug}`);
    } else {
      logger.warn(`[ProjectAgentResolver] Agent ${slug} not found`);
    }

    return agent;
  }

  getAgentByPubkey(pubkey: string): AgentInstance | undefined {
    const projectCtx = getProjectContext();
    const agent = projectCtx.getAgentByPubkey(pubkey);

    if (agent) {
      logger.debug("[ProjectAgentResolver] Resolved agent by pubkey", {
        pubkey: pubkey.substring(0, 8),
        slug: agent.slug,
      });
    }

    return agent;
  }

  getAllAgents(): Map<string, AgentInstance> {
    const projectCtx = getProjectContext();
    return projectCtx.agents;
  }
}

/**
 * Standalone agent resolver for non-project contexts.
 * Agents are provided directly to the resolver.
 */
export class StandaloneAgentResolver implements IAgentResolver {
  private agents: Map<string, AgentInstance>;
  private pubkeyToSlug: Map<string, string>;

  constructor(agents: Map<string, AgentInstance>) {
    this.agents = agents;
    this.pubkeyToSlug = new Map();

    // Build pubkey lookup map
    for (const [slug, agent] of agents) {
      if (agent.pubkey) {
        this.pubkeyToSlug.set(agent.pubkey, slug);
      }
    }

    logger.info(`[StandaloneAgentResolver] Initialized with ${agents.size} agents`);
  }

  getAgent(slug: string): AgentInstance | undefined {
    const agent = this.agents.get(slug);

    if (agent) {
      logger.debug(`[StandaloneAgentResolver] Resolved agent ${slug}`);
    } else {
      logger.warn(`[StandaloneAgentResolver] Agent ${slug} not found`);
    }

    return agent;
  }

  getAgentByPubkey(pubkey: string): AgentInstance | undefined {
    const slug = this.pubkeyToSlug.get(pubkey);
    if (!slug) {
      logger.warn("[StandaloneAgentResolver] No agent found for pubkey", {
        pubkey: pubkey.substring(0, 8),
      });
      return undefined;
    }

    return this.getAgent(slug);
  }

  getAllAgents(): Map<string, AgentInstance> {
    return new Map(this.agents);
  }

  /**
   * Add or update an agent
   */
  addAgent(agent: AgentInstance): void {
    this.agents.set(agent.slug, agent);
    if (agent.pubkey) {
      this.pubkeyToSlug.set(agent.pubkey, agent.slug);
    }

    logger.info(`[StandaloneAgentResolver] Added agent ${agent.slug}`);
  }

  /**
   * Remove an agent
   */
  removeAgent(slug: string): void {
    const agent = this.agents.get(slug);
    if (agent?.pubkey) {
      this.pubkeyToSlug.delete(agent.pubkey);
    }
    this.agents.delete(slug);

    logger.info(`[StandaloneAgentResolver] Removed agent ${slug}`);
  }
}

/**
 * Mock agent resolver for testing
 */
export class MockAgentResolver implements IAgentResolver {
  private agents: Map<string, AgentInstance> = new Map();
  private pubkeyToSlug: Map<string, string> = new Map();

  constructor(agents?: AgentInstance[]) {
    if (agents) {
      for (const agent of agents) {
        this.agents.set(agent.slug, agent);
        if (agent.pubkey) {
          this.pubkeyToSlug.set(agent.pubkey, agent.slug);
        }
      }
    }
  }

  getAgent(slug: string): AgentInstance | undefined {
    return this.agents.get(slug);
  }

  getAgentByPubkey(pubkey: string): AgentInstance | undefined {
    const slug = this.pubkeyToSlug.get(pubkey);
    return slug ? this.agents.get(slug) : undefined;
  }

  getAllAgents(): Map<string, AgentInstance> {
    return new Map(this.agents);
  }

  // Test helper methods
  addMockAgent(agent: AgentInstance): void {
    this.agents.set(agent.slug, agent);
    if (agent.pubkey) {
      this.pubkeyToSlug.set(agent.pubkey, agent.slug);
    }
  }

  clear(): void {
    this.agents.clear();
    this.pubkeyToSlug.clear();
  }
}
</file>

<file path="src/conversations/utils/content-utils.ts">
/**
 * Content utilities for processing conversation messages
 * Purpose: Strip <thinking>...</thinking> blocks from conversation history; skip messages that are purely thinking blocks.
 * Also filter out events with reasoning tags.
 */

import { logger } from "@/utils/logger";
import type { NDKEvent } from "@nostr-dev-kit/ndk";

/**
 * Regex pattern to match thinking blocks (case-insensitive, multi-line)
 * Matches: <thinking>, <Thinking>, <THINKING> with any attributes and their closing tags
 */
const THINKING_BLOCK_REGEX = /<thinking\b[^>]*>[\s\S]*?<\/thinking>/gi;

/**
 * Remove all thinking blocks from content
 * @param content - The content to process
 * @returns The content with all thinking blocks removed and normalized whitespace (multiple blank lines collapsed to single newline)
 */
export function stripThinkingBlocks(content: string): string {
    if (!content) return "";
    
    // Remove all thinking blocks
    let stripped = content.replace(THINKING_BLOCK_REGEX, "");
    
    // Normalize whitespace more carefully:
    // 1. Only collapse multiple spaces that aren't at the beginning of a line (preserve indentation)
    // 2. Collapse multiple blank lines to a single newline
    stripped = stripped
        .split('\n')
        .map(line => {
            // Only collapse spaces in the middle of lines, not at the start (preserve indentation)
            if (line.trimStart() !== line) {
                // Line has leading whitespace - preserve it
                const leadingWhitespace = line.match(/^\s*/)?.[0] || '';
                const rest = line.slice(leadingWhitespace.length);
                return leadingWhitespace + rest.replace(/  +/g, ' ');
            }
            // No leading whitespace - collapse all multiple spaces
            return line.replace(/  +/g, ' ');
        })
        .join('\n')
        .replace(/\n\s*\n+/g, "\n")  // Collapse 2+ newlines to single newline
        .trim();                      // Trim leading/trailing whitespace
    
    return stripped;
}

/**
 * Check if content contains only thinking blocks (no other content)
 * @param content - The content to check
 * @returns True if the content is empty after removing thinking blocks
 */
export function isOnlyThinkingBlocks(content: string): boolean {
    if (!content || content.trim().length === 0) return false; // Empty/whitespace content is not "only thinking blocks"
    
    const stripped = stripThinkingBlocks(content);
    return stripped.length === 0;
}

/**
 * Check if content contains any thinking blocks
 * @param content - The content to check
 * @returns True if the content contains at least one thinking block
 */
export function hasThinkingBlocks(content: string): boolean {
    if (!content) return false;
    // Reset regex lastIndex since we're using the global flag
    THINKING_BLOCK_REGEX.lastIndex = 0;
    return THINKING_BLOCK_REGEX.test(content);
}

/**
 * Count the number of thinking blocks in content
 * @param content - The content to analyze
 * @returns The number of thinking blocks found
 */
export function countThinkingBlocks(content: string): number {
    if (!content) return 0;
    const matches = content.match(THINKING_BLOCK_REGEX);
    return matches ? matches.length : 0;
}

/**
 * Check if an event has a reasoning tag
 * @param event - The NDK event to check
 * @returns True if the event has a ["reasoning"] tag
 */
export function hasReasoningTag(event: NDKEvent): boolean {
    if (!event.tags) return false;
    return event.tags.some(tag => tag[0] === "reasoning" && tag.length === 1);
}

/**
 * Log thinking block removal for debugging
 * @param eventId - The event ID being processed
 * @param originalLength - Original content length
 * @param strippedLength - Length after stripping
 */
export function logThinkingBlockRemoval(
    eventId: string, 
    originalLength: number, 
    strippedLength: number
): void {
    if (originalLength !== strippedLength) {
        logger.debug("[CONTENT_UTILS] Removed thinking blocks from content", {
            eventId: eventId.substring(0, 8),
            originalLength,
            strippedLength,
            removed: originalLength - strippedLength
        });
    }
}
</file>

<file path="src/conversations/utils/phaseUtils.ts">
import { logger } from "@/utils/logger";

/**
 * Validates if a phase string is valid
 * @param phase - The phase string to validate
 * @returns true if valid, false otherwise
 */
export function isValidPhase(phase: string | undefined | null): phase is string {
  if (!phase || typeof phase !== "string") {
    return false;
  }
  
  // Phase must be non-empty and not contain special characters that could break parsing
  return phase.trim().length > 0 && !/[<>"]/.test(phase);
}

/**
 * Normalizes a phase string for consistent comparison
 * @param phase - The phase string to normalize
 * @returns Normalized phase string or undefined if invalid
 */
export function normalizePhase(phase: string | undefined | null): string | undefined {
  if (!isValidPhase(phase)) {
    return undefined;
  }
  
  return phase.trim().toLowerCase();
}

/**
 * Checks if two phases match (case-insensitive)
 * @param phase1 - First phase to compare
 * @param phase2 - Second phase to compare
 * @returns true if phases match, false otherwise
 */
export function phasesMatch(
  phase1: string | undefined | null,
  phase2: string | undefined | null
): boolean {
  const normalized1 = normalizePhase(phase1);
  const normalized2 = normalizePhase(phase2);
  
  // Both undefined means no phase restriction - they match
  if (normalized1 === undefined && normalized2 === undefined) {
    return true;
  }
  
  // One undefined and one defined means they don't match
  if (normalized1 === undefined || normalized2 === undefined) {
    return false;
  }
  
  return normalized1 === normalized2;
}

/**
 * Extracts phase from a Nostr event's tags
 * @param tags - The event tags array
 * @returns The phase string if found, undefined otherwise
 */
export function extractPhaseFromTags(tags: string[][]): string | undefined {
  const phaseTag = tags.find(tag => tag[0] === "phase");
  return phaseTag?.[1];
}

/**
 * Creates a phase tag for a Nostr event
 * @param phase - The phase string
 * @returns A tag array or undefined if phase is invalid
 */
export function createPhaseTag(phase: string | undefined | null): string[] | undefined {
  if (!isValidPhase(phase)) {
    return undefined;
  }
  
  return ["phase", phase.trim()];
}

/**
 * Filters agent definitions by phase
 * @param definitions - Array of agent definitions
 * @param targetPhase - The phase to filter by (undefined means no phase restriction)
 * @returns Filtered array of definitions that match the phase
 */
export function filterDefinitionsByPhase<T extends { phase?: string }>(
  definitions: T[],
  targetPhase: string | undefined
): T[] {
  if (targetPhase === undefined) {
    // No phase specified - return all definitions without a phase
    return definitions.filter(def => !def.phase);
  }
  
  const normalizedTarget = normalizePhase(targetPhase);
  if (!normalizedTarget) {
    logger.warn("Invalid target phase provided for filtering", { targetPhase });
    return [];
  }
  
  return definitions.filter(def => {
    const defPhase = normalizePhase(def.phase);
    // Match if definition has same phase, or no phase (universal)
    return defPhase === normalizedTarget || defPhase === undefined;
  });
}

/**
 * Determines if an agent definition should be used for a given phase
 * @param definitionPhase - The phase from the agent definition
 * @param requestPhase - The phase from the request/context
 * @returns true if the definition should be used
 */
export function shouldUseDefinitionForPhase(
  definitionPhase: string | undefined,
  requestPhase: string | undefined
): boolean {
  // If definition has no phase, it's universal and can be used
  if (!definitionPhase) {
    return true;
  }
  
  // If definition has phase but request doesn't, don't use it
  if (definitionPhase && !requestPhase) {
    return false;
  }
  
  // Both have phases - they must match
  return phasesMatch(definitionPhase, requestPhase);
}

/**
 * Get a cache key that includes phase information
 * @param baseKey - The base cache key
 * @param phase - The phase to include
 * @returns Combined cache key
 */
export function getPhaseCacheKey(baseKey: string, phase: string | undefined): string {
  if (!phase) {
    return baseKey;
  }
  
  const normalizedPhase = normalizePhase(phase);
  if (!normalizedPhase) {
    return baseKey;
  }
  
  return `${baseKey}:phase:${normalizedPhase}`;
}
</file>

<file path="src/conversations/executionTime.ts">
/**
 * Utility functions for managing conversation execution time
 * Works directly with Conversation objects, following DRY principle
 */

import type { Conversation } from "./types";

/**
 * Start tracking execution time for a conversation
 */
export function startExecutionTime(conversation: Conversation): void {
  if (conversation.executionTime.isActive) {
    // Already active - don't restart
    return;
  }

  conversation.executionTime.currentSessionStart = Date.now();
  conversation.executionTime.isActive = true;
  conversation.executionTime.lastUpdated = Date.now();
}

/**
 * Stop tracking execution time and add duration to total
 * @returns Duration of this session in milliseconds
 */
export function stopExecutionTime(conversation: Conversation): number {
  if (!conversation.executionTime.isActive || !conversation.executionTime.currentSessionStart) {
    return 0;
  }

  const sessionDuration = Date.now() - conversation.executionTime.currentSessionStart;
  const sessionSeconds = Math.round(sessionDuration / 1000);

  conversation.executionTime.totalSeconds += sessionSeconds;
  conversation.executionTime.currentSessionStart = undefined;
  conversation.executionTime.isActive = false;
  conversation.executionTime.lastUpdated = Date.now();

  return sessionDuration;
}

/**
 * Get total execution time in seconds (including current session if active)
 */
export function getTotalExecutionTimeSeconds(conversation: Conversation): number {
  // If currently executing, include current session time
  if (conversation.executionTime.isActive && conversation.executionTime.currentSessionStart) {
    const currentSessionMs = Date.now() - conversation.executionTime.currentSessionStart;
    const currentSessionSeconds = Math.round(currentSessionMs / 1000);
    return conversation.executionTime.totalSeconds + currentSessionSeconds;
  }

  return conversation.executionTime.totalSeconds;
}

/**
 * Check if conversation is currently tracking execution time
 */
export function isExecutionActive(conversation: Conversation): boolean {
  return conversation.executionTime.isActive;
}

/**
 * Initialize execution time for a new conversation
 */
export function initializeExecutionTime(conversation: Conversation): void {
  conversation.executionTime = {
    totalSeconds: 0,
    currentSessionStart: undefined,
    isActive: false,
    lastUpdated: Date.now(),
  };
}

/**
 * Ensure conversation has execution time initialized (for loaded conversations)
 */
export function ensureExecutionTimeInitialized(conversation: Conversation): void {
  if (!conversation.executionTime) {
    initializeExecutionTime(conversation);
    return;
  }

  // Crash recovery: if execution was active but daemon restarted,
  // reset the active state as the session was lost
  if (conversation.executionTime.isActive) {
    const timeSinceLastUpdate = Date.now() - conversation.executionTime.lastUpdated;
    const maxSessionTime = 30 * 60 * 1000; // 30 minutes max reasonable session

    if (timeSinceLastUpdate > maxSessionTime) {
      // Consider the session lost and reset state
      conversation.executionTime.isActive = false;
      conversation.executionTime.currentSessionStart = undefined;
      conversation.executionTime.lastUpdated = Date.now();
    }
  }
}
</file>

<file path="src/daemon/ProcessManager.ts">
import { type ChildProcess, spawn } from "node:child_process";
import * as path from "node:path";
import { logger } from "@/utils/logger";

export interface IProcessManager {
  spawnProjectRun(projectPath: string, projectId?: string): Promise<void>;
  isProjectRunning(projectId: string): Promise<boolean>;
  stopProject(projectId: string): Promise<void>;
  stopAll(): Promise<void>;
}

interface ProcessInfo {
  process: ChildProcess;
  projectPath: string;
  startedAt: Date;
}

export class ProcessManager implements IProcessManager {
  private processes: Map<string, ProcessInfo> = new Map();

  async spawnProjectRun(projectPath: string, projectId?: string): Promise<void> {
    const id = projectId || path.basename(projectPath);

    // Check if already running
    if (this.processes.has(id)) {
      return;
    }

    // Get the CLI binary path
    const cliBinPath = path.join(__dirname, "..", "tenex.ts");

    // Spawn the process
    const child = spawn("bun", ["run", cliBinPath, "project", "run"], {
      cwd: projectPath,
      stdio: "inherit", // Let output pass through directly
      detached: false,
    });

    // Handle process exit
    child.on("exit", (code, signal) => {
      logger.info("Project process exited", {
        projectId: id,
        code,
        signal,
      });
      this.processes.delete(id);
    });

    // Handle errors
    child.on("error", (error) => {
      logger.error("Project process error", {
        projectId: id,
        error,
      });
      this.processes.delete(id);
    });

    // Store process info
    this.processes.set(id, {
      process: child,
      projectPath,
      startedAt: new Date(),
    });
  }

  async isProjectRunning(projectId: string): Promise<boolean> {
    const processInfo = this.processes.get(projectId);
    if (!processInfo) {
      return false;
    }

    // Check if process is still alive
    try {
      if (processInfo.process.pid) {
        process.kill(processInfo.process.pid, 0);
        return true;
      }
    } catch {
      // Process doesn't exist
      this.processes.delete(projectId);
      return false;
    }

    return false;
  }

  async stopProject(projectId: string): Promise<void> {
    const processInfo = this.processes.get(projectId);
    if (!processInfo) {
      logger.warn("Project not running", { projectId });
      return;
    }

    // Try graceful shutdown first
    if (processInfo.process.pid) {
      process.kill(processInfo.process.pid, "SIGTERM");

      // Wait for process to exit
      await new Promise<void>((resolve) => {
        const timeout = setTimeout(() => {
          // Force kill if not exited
          if (processInfo.process.pid) {
            logger.warn("Force killing project", { projectId });
            process.kill(processInfo.process.pid, "SIGKILL");
          }
          resolve();
        }, 5000);

        processInfo.process.once("exit", () => {
          clearTimeout(timeout);
          resolve();
        });
      });
    }

    this.processes.delete(projectId);
  }

  async stopAll(): Promise<void> {
    const stopPromises = Array.from(this.processes.keys()).map((projectId) =>
      this.stopProject(projectId)
    );

    await Promise.all(stopPromises);
  }

  getRunningProjects(): Array<{ id: string; path: string; startedAt: Date }> {
    return Array.from(this.processes.entries()).map(([id, info]) => ({
      id,
      path: info.projectPath,
      startedAt: info.startedAt,
    }));
  }
}
</file>

<file path="src/events/NDKAgentLesson.ts">
import type NDK from "@nostr-dev-kit/ndk";
import { NDKEvent, type NDKRawEvent } from "@nostr-dev-kit/ndk";

export class NDKAgentLesson extends NDKEvent {
  static kind = 4129;
  static kinds = [4129];

  constructor(ndk?: NDK, event?: NDKEvent | NDKRawEvent) {
    super(ndk, event);
    this.kind ??= 4129;
  }

  static from(event: NDKEvent): NDKAgentLesson {
    return new NDKAgentLesson(event.ndk, event);
  }

  get title(): string | undefined {
    return this.tagValue("title");
  }

  /**
   * Title/description of what this lesson is about.
   */
  set title(value: string | undefined) {
    this.removeTag("title");
    if (value) this.tags.push(["title", value]);
  }

  // Alias for title
  get description(): string | undefined {
    return this.tagValue("title");
  }

  set description(value: string | undefined) {
    this.removeTag("description");
    if (value) this.tags.push(["description", value]);
  }

  /**
   * The lesson content - what the agent learned.
   * This is stored in the event content.
   */
  get lesson(): string {
    return this.content;
  }

  set lesson(value: string) {
    this.content = value;
  }

  /**
   * Set the agent that this lesson belongs to.
   * @param agentEvent The NDKAgentDefinition event to reference
   */
  set agentDefinitionId(agentDefinitionId: string) {
    this.removeTag("e");
    this.tags.push(["e", agentDefinitionId]);
  }

  /**
   * Get the agent event ID this lesson belongs to.
   */
  get agentDefinitionId(): string | undefined {
    return this.tags.find((tag) => tag[0] === "e")?.[1];
  }

  /**
   * Metacognition reasoning - why this lesson is worth learning
   */
  get metacognition(): string | undefined {
    return this.tagValue("metacognition");
  }

  set metacognition(value: string | undefined) {
    this.removeTag("metacognition");
    if (value) this.tags.push(["metacognition", value]);
  }

  /**
   * Detailed version of the lesson with richer explanation
   */
  get detailed(): string | undefined {
    return this.tagValue("detailed");
  }

  set detailed(value: string | undefined) {
    this.removeTag("detailed");
    if (value) this.tags.push(["detailed", value]);
  }

  /**
   * Category for filing this lesson
   */
  get category(): string | undefined {
    return this.tagValue("category");
  }

  set category(value: string | undefined) {
    this.removeTag("category");
    if (value) this.tags.push(["category", value]);
  }

  /**
   * Hashtags for easier sorting and discovery
   */
  get hashtags(): string[] {
    return this.tags.filter((tag) => tag[0] === "t").map((tag) => tag[1]);
  }

  set hashtags(values: string[]) {
    this.tags = this.tags.filter((tag) => tag[0] !== "t");
    values.forEach((hashtag) => {
      this.tags.push(["t", hashtag]);
    });
  }
}
</file>

<file path="src/lib/fs/tenex.ts">
import path from "node:path";
import { directoryExists, ensureDirectory } from "./filesystem.js";

/**
 * Get paths for common .tenex files
 */
export function getTenexPaths(projectPath: string): {
  tenexDir: string;
  agentsJson: string;
  configJson: string;
  llmsJson: string;
  agentsDir: string;
  rulesDir: string;
  conversationsDir: string;
} {
  const tenexDir = path.join(projectPath, ".tenex");
  return {
    tenexDir,
    agentsJson: path.join(tenexDir, "agents.json"),
    configJson: path.join(tenexDir, "config.json"),
    llmsJson: path.join(tenexDir, "llms.json"),
    agentsDir: path.join(tenexDir, "agents"),
    rulesDir: path.join(tenexDir, "rules"),
    conversationsDir: path.join(tenexDir, "conversations"),
  };
}

// Configuration operations removed - use ConfigService from @/services instead

/**
 * Check if a project has been initialized (has .tenex directory)
 */
export async function isProjectInitialized(projectPath: string): Promise<boolean> {
  const paths = getTenexPaths(projectPath);
  return directoryExists(paths.tenexDir);
}

/**
 * Initialize .tenex directory structure
 */
export async function initializeTenexDirectory(projectPath: string): Promise<void> {
  const paths = getTenexPaths(projectPath);

  // Create main .tenex directory
  await ensureDirectory(paths.tenexDir);

  // Create subdirectories
  await ensureDirectory(paths.agentsDir);
  await ensureDirectory(paths.rulesDir);
  await ensureDirectory(paths.conversationsDir);
}
</file>

<file path="src/lib/shell.ts">
import { exec } from "node:child_process";
import { promisify } from "node:util";

const execAsync = promisify(exec);

/**
 * Platform-specific command for finding executables
 */
const getWhichCommand = (): string => {
  return process.platform === "win32" ? "where" : "which";
};

/**
 * Find the full path of a command using the system's which/where command
 * @param command - The command name to find
 * @returns The full path to the command, or null if not found
 * @throws Error if command parameter is invalid
 */
export async function which(command: string): Promise<string | null> {
  // Input validation
  if (!command || typeof command !== "string") {
    throw new Error("Invalid command parameter: must be a non-empty string");
  }

  const sanitizedCommand = command.trim();
  if (!sanitizedCommand) {
    throw new Error("Command cannot be empty or whitespace");
  }

  try {
    const whichCommand = getWhichCommand();
    const { stdout } = await execAsync(`${whichCommand} ${sanitizedCommand}`);

    if (!stdout) {
      return null;
    }

    // Get first result if multiple paths are returned
    const path = stdout.trim().split("\n")[0]?.trim();

    return path || null;
  } catch {
    // Command not found or execution error
    return null;
  }
}
</file>

<file path="src/llm/providers/mock-scenarios/ios-testing.ts">
import type { MockScenario } from "../MockProvider";

/**
 * iOS Testing Scenarios
 * 
 * These scenarios provide deterministic responses for iOS app testing.
 * The backend will respond with these predetermined responses while
 * the iOS app believes it's talking to a real LLM.
 */

export const iosTestingScenarios: MockScenario[] = [
  // Scenario 1: Basic greeting and project status
  {
    name: "ios-greeting",
    description: "Basic greeting response with project status",
    triggers: {
      contentMatch: /hello|hi|hey/i,
      phase: "CHAT",
    },
    events: [
      {
        type: "project-status",
        delay: 100,
        data: {
          projectReference: "31933:mock-backend:ios-test-project",
          agents: [
            { pubkey: "executor-pubkey-123", slug: "executor", isGlobal: false },
            { pubkey: "planner-pubkey-456", slug: "planner", isGlobal: true },
          ],
          models: {
            "gpt-4": ["executor"],
            "claude-3": ["planner"],
          },
          tools: {
            "shell": ["executor"],
            "readPath": ["executor", "planner"],
            "writeContextFile": ["executor"],
          },
          status: "Agents online and ready",
        },
      },
      {
        type: "typing-start",
        delay: 200,
        data: {
          phase: "planning",
          message: "Thinking about your request...",
        },
      },
      {
        type: "typing-stop",
        delay: 2000,
        data: {},
      },
    ],
    response: {
      content: "Hello! I'm your AI assistant running in test mode. I can help you with various tasks. What would you like to work on today?",
      delay: 2500,
      toolCalls: [],
    },
  },

  // Scenario 2: Create file request
  {
    name: "ios-create-file",
    description: "File creation workflow",
    triggers: {
      contentMatch: /create.*file|write.*file|make.*file/i,
    },
    events: [
      {
        type: "typing-start",
        delay: 100,
        data: {
          phase: "planning",
          message: "Planning file creation...",
        },
      },
      {
        type: "typing-stop",
        delay: 1000,
        data: {},
      },
      {
        type: "typing-start",
        delay: 1200,
        data: {
          phase: "implementing",
          message: "Creating the file...",
        },
      },
      {
        type: "task",
        delay: 1500,
        data: {
          content: "Create requested file",
          status: "pending",
          hashtags: ["file-creation", "implementation"],
        },
      },
      {
        type: "typing-stop",
        delay: 3000,
        data: {},
      },
      {
        type: "task",
        delay: 3500,
        data: {
          content: "Create requested file",
          status: "completed",
          hashtags: ["file-creation", "implementation"],
        },
      },
    ],
    response: {
      content: "I'll create that file for you. Let me set that up now.",
      delay: 500,
      toolCalls: [
        {
          name: "writeContextFile",
          params: {
            path: "test-file.md",
            content: "# Test File\n\nThis is a test file created by the mock backend.\n\n## Contents\n\n- This file was created as part of iOS testing\n- The backend is using predetermined responses\n- The iOS app should display this as a successful file creation\n",
          },
        },
        {
          name: "complete",
          params: {
            summary: "Successfully created test-file.md with sample content",
          },
        },
      ],
    },
  },

  // Scenario 3: List files/project inventory
  {
    name: "ios-list-files",
    description: "List project files",
    triggers: {
      contentMatch: /list.*files|show.*files|what.*files|inventory/i,
    },
    events: [
      {
        type: "typing-start",
        delay: 100,
        data: {
          phase: "implementing",
          message: "Scanning project files...",
        },
      },
      {
        type: "typing-stop",
        delay: 1500,
        data: {},
      },
    ],
    response: {
      content: `Here are the files in your project:

üìÅ **Project Structure:**
\`\`\`
ios-test-project/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.swift
‚îÇ   ‚îî‚îÄ‚îÄ utils.swift
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ test.swift
‚îî‚îÄ‚îÄ Package.swift
\`\`\`

Total: 5 files`,
      delay: 2000,
      toolCalls: [
        {
          name: "complete",
          params: {
            summary: "Listed 5 project files",
          },
        },
      ],
    },
  },

  // Scenario 4: Error simulation
  {
    name: "ios-error-test",
    description: "Simulate an error for testing error handling",
    triggers: {
      contentMatch: /simulate.*error|test.*error|crash/i,
    },
    events: [
      {
        type: "typing-start",
        delay: 100,
        data: {
          phase: "implementing",
          message: "Processing request...",
        },
      },
      {
        type: "typing-stop",
        delay: 500,
        data: {},
      },
    ],
    response: {
      content: "I encountered an issue while processing your request. This is a simulated error for testing purposes.",
      delay: 1000,
      toolCalls: [
        {
          name: "shell",
          params: {
            command: "exit 1",
          },
        },
      ],
    },
  },

  // Scenario 5: Multi-agent conversation
  {
    name: "ios-multi-agent",
    description: "Multi-agent delegation test",
    triggers: {
      contentMatch: /analyze.*code|review.*code|complex/i,
    },
    events: [
      {
        type: "project-status",
        delay: 100,
        data: {
          agents: [
            { pubkey: "executor-pubkey", slug: "executor", isGlobal: false },
            { pubkey: "planner-pubkey", slug: "planner", isGlobal: false },
            { pubkey: "reviewer-pubkey", slug: "reviewer", isGlobal: true },
          ],
          models: {
            "gpt-4": ["executor", "reviewer"],
            "claude-3": ["planner"],
          },
        },
      },
      {
        type: "typing-start",
        delay: 200,
        data: {
          phase: "planning",
          message: "Planner agent is analyzing the request...",
        },
      },
      {
        type: "typing-stop",
        delay: 1500,
        data: {},
      },
      {
        type: "reply",
        delay: 1600,
        data: {
          content: "I'll help you analyze the code. Let me delegate this to the appropriate agents.",
          kind: 1111,
        },
      },
      {
        type: "typing-start",
        delay: 2000,
        data: {
          phase: "reviewing",
          message: "Reviewer agent is examining the code...",
        },
      },
      {
        type: "typing-stop",
        delay: 4000,
        data: {},
      },
    ],
    response: {
      content: `I've completed the code analysis. Here's what I found:

## Code Review Summary

‚úÖ **Strengths:**
- Clean code structure
- Good naming conventions
- Proper error handling

‚ö†Ô∏è **Suggestions:**
- Consider adding more comments
- Some functions could be refactored for clarity
- Add unit tests for edge cases

The code is ready for production with minor improvements.`,
      delay: 4500,
      toolCalls: [
        {
          name: "delegate_phase",
          params: {
            phase: "REVIEW",
            summary: "Code analysis completed",
          },
        },
        {
          name: "complete",
          params: {
            summary: "Code review completed with suggestions",
          },
        },
      ],
    },
  },

  // Scenario 6: Long-running task with progress updates
  {
    name: "ios-long-task",
    description: "Simulate a long-running task with multiple status updates",
    triggers: {
      contentMatch: /deploy|build.*project|compile/i,
    },
    events: [
      {
        type: "typing-start",
        delay: 100,
        data: {
          phase: "implementing",
          message: "Starting build process...",
        },
      },
      {
        type: "task",
        delay: 500,
        data: {
          content: "Build project",
          status: "pending",
          hashtags: ["build", "deployment"],
        },
      },
      {
        type: "typing-stop",
        delay: 1000,
        data: {},
      },
      {
        type: "typing-start",
        delay: 2000,
        data: {
          phase: "implementing",
          message: "Compiling source files...",
        },
      },
      {
        type: "typing-stop",
        delay: 4000,
        data: {},
      },
      {
        type: "typing-start",
        delay: 4500,
        data: {
          phase: "implementing",
          message: "Running tests...",
        },
      },
      {
        type: "typing-stop",
        delay: 6000,
        data: {},
      },
      {
        type: "task",
        delay: 6500,
        data: {
          content: "Build project",
          status: "completed",
          hashtags: ["build", "deployment"],
        },
      },
    ],
    response: {
      content: `Build completed successfully! 

üìä **Build Summary:**
- Compiled: 42 files
- Tests passed: 15/15
- Build time: 6.5 seconds
- Output: ./build/app.exe

The application is ready for deployment.`,
      delay: 7000,
      toolCalls: [
        {
          name: "shell",
          params: {
            command: "echo 'Build successful'",
          },
        },
        {
          name: "complete",
          params: {
            summary: "Project built successfully",
          },
        },
      ],
    },
  },

  // Default fallback scenario
  {
    name: "ios-default",
    description: "Default response for unmatched inputs",
    triggers: {
      contentMatch: /.*/,  // Matches anything
    },
    events: [
      {
        type: "typing-start",
        delay: 100,
        data: {
          phase: "planning",
          message: "Processing your request...",
        },
      },
      {
        type: "typing-stop",
        delay: 1000,
        data: {},
      },
    ],
    response: {
      content: "I understand your request. This is a test response from the mock backend. In a real scenario, I would process your specific request here.",
      delay: 1500,
      toolCalls: [
        {
          name: "complete",
          params: {
            summary: "Processed user request",
          },
        },
      ],
    },
  },
];

/**
 * Load iOS testing scenarios based on test type
 */
export function getIOSScenarios(testType?: string): MockScenario[] {
  switch (testType) {
    case "basic":
      return [iosTestingScenarios[0], iosTestingScenarios[6]]; // Greeting and default
    
    case "files":
      return [iosTestingScenarios[1], iosTestingScenarios[2]]; // File operations
    
    case "errors":
      return [iosTestingScenarios[3]]; // Error handling
    
    case "multi-agent":
      return [iosTestingScenarios[4]]; // Multi-agent
    
    case "long-tasks":
      return [iosTestingScenarios[5]]; // Long-running tasks
    
    case "all":
    default:
      return iosTestingScenarios;
  }
}
</file>

<file path="src/llm/providers/ollama-models.ts">
import { logger } from "@/utils/logger";

export interface OllamaModel {
  name: string;
  size: string;
  modified: string;
  digest: string;
}

/**
 * Fetch available models from local Ollama instance
 */
export async function fetchOllamaModels(): Promise<OllamaModel[]> {
  try {
    const baseUrl = process.env.OLLAMA_BASE_URL || 'http://localhost:11434';
    const response = await fetch(`${baseUrl}/api/tags`, {
      method: 'GET',
      headers: {
        'Content-Type': 'application/json',
      },
    });

    if (!response.ok) {
      logger.warn(`Failed to fetch Ollama models: ${response.status}`);
      return [];
    }

    const data = await response.json();
    const models = data.models || [];
    
    logger.debug(`Fetched ${models.length} Ollama models`);
    
    return models.map((model: any) => ({
      name: model.name,
      size: formatSize(model.size),
      modified: model.modified_at,
      digest: model.digest
    }));
  } catch (error) {
    logger.warn("Failed to fetch Ollama models", {
      error: error instanceof Error ? error.message : String(error)
    });
    return [];
  }
}

/**
 * Format bytes to human readable size
 */
function formatSize(bytes: number): string {
  if (!bytes) return 'unknown';
  const gb = bytes / (1024 * 1024 * 1024);
  if (gb >= 1) {
    return `${gb.toFixed(1)}GB`;
  }
  const mb = bytes / (1024 * 1024);
  return `${mb.toFixed(0)}MB`;
}

/**
 * Get popular Ollama models for quick selection
 */
export function getPopularOllamaModels(): Record<string, string[]> {
  return {
    "Small Models (< 4GB)": [
      "llama3.2:1b",
      "llama3.2:3b",
      "phi3:mini",
      "gemma2:2b",
      "qwen2.5:1.5b",
      "qwen2.5:3b"
    ],
    "Medium Models (4-8GB)": [
      "llama3.1:8b",
      "mistral:7b",
      "gemma2:9b",
      "qwen2.5:7b",
      "deepseek-coder-v2:16b"
    ],
    "Large Models (> 8GB)": [
      "llama3.1:70b",
      "mixtral:8x7b",
      "qwen2.5:14b",
      "qwen2.5:32b",
      "qwen2.5:72b",
      "deepseek-coder-v2:236b"
    ],
    "Specialized Models": [
      "codellama:7b",
      "codellama:13b",
      "starcoder2:3b",
      "starcoder2:7b",
      "sqlcoder:7b"
    ]
  };
}
</file>

<file path="src/llm/providers/openrouter-models.ts">
/**
 * OpenRouter model fetching utilities
 */

export interface OpenRouterModel {
  id: string;
  name: string;
  description?: string;
  context_length: number;
  pricing: {
    prompt: string;
    completion: string;
  };
  top_provider?: {
    max_completion_tokens?: number;
  };
}

export interface OpenRouterModelsResponse {
  data: OpenRouterModel[];
}

/**
 * Fetch available models from OpenRouter API
 */
export async function fetchOpenRouterModels(): Promise<OpenRouterModel[]> {
  try {
    const response = await fetch('https://openrouter.ai/api/v1/models', {
      headers: {
        'Accept': 'application/json',
      }
    });

    if (!response.ok) {
      throw new Error(`Failed to fetch models: ${response.statusText}`);
    }

    const data: OpenRouterModelsResponse = await response.json();
    
    // Sort models by popularity/relevance (you can customize this)
    return data.data.sort((a, b) => {
      // Prioritize commonly used models
      const priority = [
        'openai/gpt-4',
        'openai/gpt-4-turbo',
        'anthropic/claude-3-5-sonnet',
        'anthropic/claude-3-opus',
        'google/gemini-2.0-flash',
        'google/gemini-pro',
      ];
      
      const aIndex = priority.indexOf(a.id);
      const bIndex = priority.indexOf(b.id);
      
      if (aIndex !== -1 && bIndex !== -1) return aIndex - bIndex;
      if (aIndex !== -1) return -1;
      if (bIndex !== -1) return 1;
      
      return a.name.localeCompare(b.name);
    });
  } catch (error) {
    console.error('Error fetching OpenRouter models:', error);
    return [];
  }
}

/**
 * Get popular models grouped by provider
 */
export function getPopularModels(): Record<string, string[]> {
  return {
    'OpenAI': [
      'openai/gpt-4',
      'openai/gpt-4-turbo',
      'openai/gpt-3.5-turbo',
      'openai/o1-preview',
      'openai/o1-mini',
    ],
    'Anthropic': [
      'anthropic/claude-3-5-sonnet',
      'anthropic/claude-3-opus',
      'anthropic/claude-3-haiku',
      'anthropic/claude-3-5-haiku',
    ],
    'Google': [
      'google/gemini-2.0-flash-thinking-exp',
      'google/gemini-2.0-flash-exp',
      'google/gemini-pro',
      'google/gemini-pro-1.5',
    ],
    'Meta': [
      'meta-llama/llama-3.1-405b-instruct',
      'meta-llama/llama-3.1-70b-instruct',
      'meta-llama/llama-3.1-8b-instruct',
    ],
    'Mistral': [
      'mistralai/mistral-large',
      'mistralai/mixtral-8x22b-instruct',
      'mistralai/mixtral-8x7b-instruct',
    ],
  };
}
</file>

<file path="src/llm/utils/ConfigurationTester.ts">
import type { TenexLLMs } from "@/services/config/types";
import { llmServiceFactory } from "../LLMServiceFactory";
import inquirer from "inquirer";
import chalk from "chalk";

/**
 * Tests LLM configurations
 */
export class ConfigurationTester {
  static async test(llmsConfig: TenexLLMs): Promise<void> {
    const configNames = Object.keys(llmsConfig.configurations);
    
    if (configNames.length === 0) {
      console.log(chalk.yellow("‚ö†Ô∏è  No configurations to test"));
      return;
    }
    
    const { name } = await inquirer.prompt([{
      type: "list",
      name: "name",
      message: "Select configuration to test:",
      choices: configNames.map(n => ({
        name: n === llmsConfig.default ? `${n} (default)` : n,
        value: n
      }))
    }]);
    
    const config = llmsConfig.configurations[name];
    console.log(chalk.yellow(`\nTesting configuration "${name}"...`));
    console.log(chalk.gray(`Provider: ${config.provider}, Model: ${config.model}`));
    
    try {
      // Ensure providers are initialized
      if (!llmServiceFactory.hasProvider(config.provider)) {
        llmServiceFactory.initializeProviders(llmsConfig.providers);
      }
      
      // Create a simple mock logger for testing
      const mockLogger = {
        logLLMRequest: async () => {},
        logLLMResponse: async () => {}
      };
      
      // Create the service using the factory
      const service = llmServiceFactory.createService(
        mockLogger as any, 
        config
      );
      
      console.log(chalk.cyan("üì° Sending test message..."));
      const result = await service.complete([
        { role: "user", content: "Say 'Hello, TENEX!' in exactly those words." }
      ], {}, {
        temperature: config.temperature,
        maxTokens: config.maxTokens
      });
      
      console.log(chalk.green("\n‚úÖ Test successful!"));
      const resultText = 'text' in result ? result.text : '';
      console.log(chalk.white("Response: ") + chalk.cyan(resultText));
      
      // Show usage stats if available
      if ('usage' in result && result.usage) {
        const usage = result.usage as any;
        const promptTokens = usage.promptTokens || '?';
        const completionTokens = usage.completionTokens || '?';
        const totalTokens = usage.totalTokens || '?';
        console.log(chalk.gray(`\nTokens: ${promptTokens} + ${completionTokens} = ${totalTokens}`));
      }
      
      await new Promise(resolve => setTimeout(resolve, 2000));
      
    } catch (error: unknown) {
      console.log(chalk.red("\n‚ùå Test failed!"));
      
      const errorMessage = error instanceof Error ? error.message : String(error);
      if (errorMessage) {
        console.log(chalk.red(`Error: ${errorMessage}`));
      }
      
      // Check for common issues
      if (errorMessage?.includes('401') || errorMessage?.includes('Unauthorized')) {
        console.log(chalk.yellow("\nüí° Invalid or expired API key"));
      } else if (errorMessage?.includes('404')) {
        console.log(chalk.yellow(`\nüí° Model '${config.model}' may not be available`));
      } else if (errorMessage?.includes('rate limit')) {
        console.log(chalk.yellow("\nüí° Rate limit hit. Please wait and try again"));
      }
      
      await new Promise(resolve => setTimeout(resolve, 3000));
    }
  }
}
</file>

<file path="src/llm/utils/ModelSelector.ts">
import inquirer from "inquirer";
import chalk from "chalk";
import { fetchOpenRouterModels, getPopularModels } from "../providers/openrouter-models";
import { fetchOllamaModels, getPopularOllamaModels } from "../providers/ollama-models";

/**
 * Utility class for interactive model selection
 * Extracted from LLMConfigEditor to reduce complexity
 */
export class ModelSelector {
  /**
   * Select an Ollama model interactively
   */
  static async selectOllamaModel(currentModel?: string): Promise<string> {
    console.log(chalk.gray("Fetching available Ollama models..."));
    
    const ollamaModels = await fetchOllamaModels();
    
    if (ollamaModels.length > 0) {
      console.log(chalk.green(`‚úì Found ${ollamaModels.length} installed models`));
      
      const choices = [
        ...ollamaModels.map(m => ({
          name: `${m.name} ${chalk.gray(`(${m.size})`)}`,
          value: m.name
        })),
        new inquirer.Separator(),
        { name: chalk.cyan("‚Üí Type model name manually"), value: "__manual__" }
      ];
      
      const { selectedModel } = await inquirer.prompt([{
        type: "list",
        name: "selectedModel",
        message: "Select model:",
        choices,
        default: currentModel,
        pageSize: 15
      }]);
      
      if (selectedModel === "__manual__") {
        return await this.promptManualModel(currentModel || "llama3.1:8b");
      }
      
      return selectedModel;
    } else {
      console.log(chalk.yellow("‚ö†Ô∏è  No Ollama models found. Make sure Ollama is running."));
      console.log(chalk.gray("Showing popular models (you'll need to pull them first)."));
      
      const popular = getPopularOllamaModels();
      const choices = [];
      for (const [category, models] of Object.entries(popular)) {
        choices.push(new inquirer.Separator(`--- ${category} ---`));
        choices.push(...models.map(m => ({
          name: m,
          value: m
        })));
      }
      
      choices.push(new inquirer.Separator());
      choices.push({ name: chalk.cyan("‚Üí Type model name manually"), value: "__manual__" });
      
      const { selectedModel } = await inquirer.prompt([{
        type: "list",
        name: "selectedModel",
        message: "Select model:",
        default: currentModel,
        choices,
        pageSize: 15
      }]);
      
      if (selectedModel === "__manual__") {
        return await this.promptManualModel(currentModel || "llama3.1:8b");
      }
      
      return selectedModel;
    }
  }

  /**
   * Select an OpenRouter model interactively
   */
  static async selectOpenRouterModel(currentModel?: string): Promise<string> {
    console.log(chalk.gray("Fetching available OpenRouter models..."));
    
    const openRouterModels = await fetchOpenRouterModels();
    
    if (openRouterModels.length > 0) {
      console.log(chalk.green(`‚úì Found ${openRouterModels.length} available models`));
      
      // Group models by provider
      const modelsByProvider: Record<string, typeof openRouterModels> = {};
      for (const model of openRouterModels) {
        const provider = model.id.split('/')[0] || 'other';
        if (!modelsByProvider[provider]) {
          modelsByProvider[provider] = [];
        }
        modelsByProvider[provider].push(model);
      }
      
      // Build choices
      const choices = [];
      const sortedProviders = Object.keys(modelsByProvider).sort();
      
      for (const provider of sortedProviders) {
        choices.push(new inquirer.Separator(chalk.yellow(`--- ${provider.toUpperCase()} ---`)));
        const providerModels = modelsByProvider[provider];
        
        for (const model of providerModels) {
          const pricing = `$${model.pricing.prompt}/$${model.pricing.completion}/1M`;
          const context = `${Math.round(model.context_length / 1000)}k`;
          const freeTag = model.id.endsWith(':free') ? chalk.green(' [FREE]') : '';
          
          choices.push({
            name: `${model.id}${freeTag} ${chalk.gray(`- ${context} context, ${pricing}`)}`,
            value: model.id,
            short: model.id
          });
        }
      }
      
      choices.push(new inquirer.Separator());
      choices.push({ name: chalk.cyan("‚Üí Type model ID manually"), value: "__manual__" });
      
      const { selectedModel } = await inquirer.prompt([{
        type: "list",
        name: "selectedModel",
        message: "Select model:",
        choices,
        default: currentModel,
        pageSize: 20,
        loop: false
      }]);
      
      if (selectedModel === "__manual__") {
        return await this.promptManualModel(currentModel || "openai/gpt-4");
      }
      
      return selectedModel;
    } else {
      console.log(chalk.yellow("‚ö†Ô∏è  Failed to fetch models from OpenRouter API"));
      console.log(chalk.gray("You can still enter a model ID manually or select from popular models."));
      
      const { selectionMethod } = await inquirer.prompt([{
        type: "list",
        name: "selectionMethod",
        message: "How would you like to select the model?",
        choices: [
          { name: "Quick select from popular models", value: "quick" },
          { name: "Type model ID manually", value: "manual" }
        ]
      }]);
      
      if (selectionMethod === 'quick') {
        const popular = getPopularModels();
        const choices = [];
        for (const [category, models] of Object.entries(popular)) {
          choices.push(new inquirer.Separator(`--- ${category} ---`));
          choices.push(...models.map(m => ({
            name: m,
            value: m
          })));
        }
        
        const { selectedModel } = await inquirer.prompt([{
          type: "list",
          name: "selectedModel",
          message: "Select model:",
          default: currentModel,
          choices,
          pageSize: 15
        }]);
        return selectedModel;
      } else {
        return await this.promptManualModel(currentModel || "openai/gpt-4");
      }
    }
  }

  /**
   * Prompt for manual model entry
   */
  private static async promptManualModel(defaultValue: string): Promise<string> {
    const { inputModel } = await inquirer.prompt([{
      type: "input",
      name: "inputModel",
      message: "Enter model name/ID:",
      default: defaultValue,
      validate: (input: string) => {
        if (!input.trim()) return "Model name is required";
        return true;
      }
    }]);
    return inputModel;
  }
}
</file>

<file path="src/nostr/types.ts">
export interface LLMMetadata {
  model: string;
  cost: number;
  promptTokens: number;
  completionTokens: number;
  totalTokens: number;
  contextWindow?: number;
  maxCompletionTokens?: number;
  systemPrompt?: string;
  userPrompt?: string;
  rawResponse?: string;
}

export interface PublishOptions {
  llmMetadata?: LLMMetadata;
  metadata?: Record<string, string | number | boolean | string[]>;
}
</file>

<file path="src/prompts/core/FragmentRegistry.ts">
import type { PromptFragment } from "./types";

export class FragmentRegistry {
  private fragments = new Map<string, PromptFragment<unknown>>();

  register<T>(fragment: PromptFragment<T>): void {
    if (!fragment.id) {
      throw new Error("Fragment must have an id");
    }
    this.fragments.set(fragment.id, fragment as PromptFragment<unknown>);
  }

  get(id: string): PromptFragment<unknown> | undefined {
    return this.fragments.get(id);
  }

  has(id: string): boolean {
    return this.fragments.has(id);
  }

  clear(): void {
    this.fragments.clear();
  }

  getAllIds(): string[] {
    return Array.from(this.fragments.keys());
  }
}

export const fragmentRegistry = new FragmentRegistry();
</file>

<file path="src/prompts/core/index.ts">
export { FragmentRegistry, fragmentRegistry } from "./FragmentRegistry";
export { PromptBuilder } from "./PromptBuilder";
export type { FragmentConfig, PromptFragment } from "./types";
</file>

<file path="src/prompts/core/PromptBuilder.ts">
import { formatAnyError } from "@/utils/error-formatter";
import { fragmentRegistry } from "./FragmentRegistry";
import type { FragmentConfig, PromptFragment } from "./types";

export class PromptBuilder {
  private fragments: FragmentConfig[] = [];

  add<T>(fragmentId: string, args: T, condition?: (args: T) => boolean): this {
    if (!fragmentRegistry.has(fragmentId)) {
      throw new Error(
        `Fragment "${fragmentId}" not found in registry. Available fragments: ${fragmentRegistry.getAllIds().join(", ")}`
      );
    }
    this.fragments.push({
      fragmentId,
      args,
      condition: condition ? (unknownArgs) => condition(unknownArgs as T) : undefined,
    });
    return this;
  }

  addFragment<T>(fragment: PromptFragment<T>, args: T, condition?: (args: T) => boolean): this {
    fragmentRegistry.register(fragment);
    this.fragments.push({
      fragmentId: fragment.id,
      args,
      condition: condition ? (unknownArgs) => condition(unknownArgs as T) : undefined,
    });
    return this;
  }

  build(): string {
    const fragmentsWithPriority = this.fragments
      .filter((config) => !config.condition || config.condition(config.args))
      .map((config) => {
        const fragment = fragmentRegistry.get(config.fragmentId);
        if (!fragment) {
          throw new Error(`Fragment ${config.fragmentId} not found`);
        }

        // Validate arguments if validator is provided
        if (fragment.validateArgs && !fragment.validateArgs(config.args)) {
          const receivedArgs = JSON.stringify(config.args, null, 2);
          const expectedDesc =
            fragment.expectedArgs || "Check fragment definition for expected arguments";
          throw new Error(
            `Fragment "${config.fragmentId}" received invalid arguments.\n` +
              `Expected: ${expectedDesc}\n` +
              `Received: ${receivedArgs}`
          );
        }

        try {
          return {
            priority: fragment.priority || 50,
            content: fragment.template(config.args),
          };
        } catch (error) {
          const errorMessage = formatAnyError(error);
          const receivedArgs = JSON.stringify(config.args, null, 2);
          throw new Error(
            `Error executing fragment "${config.fragmentId}":\n` +
              `${errorMessage}\n` +
              `Arguments provided: ${receivedArgs}\n` +
              `Expected: ${fragment.expectedArgs || "Check fragment definition"}`
          );
        }
      })
      .sort((a, b) => a.priority - b.priority);

    return fragmentsWithPriority
      .map((f) => f.content)
      .filter((content) => content.trim().length > 0)
      .join("\n\n");
  }

  clear(): this {
    this.fragments = [];
    return this;
  }

  getFragmentCount(): number {
    return this.fragments.length;
  }
}
</file>

<file path="src/prompts/core/types.ts">
export interface PromptFragment<T = unknown> {
  id: string;
  priority?: number;
  template: (args: T) => string;
  validateArgs?: (args: unknown) => args is T;
  expectedArgs?: string; // Description of expected arguments for error messages
}

export interface FragmentConfig {
  fragmentId: string;
  args: unknown;
  condition?: (args: unknown) => boolean;
}
</file>

<file path="src/prompts/fragments/10-referenced-article.ts">
import { fragmentRegistry } from "../core/FragmentRegistry";

interface ReferencedArticleArgs {
  title: string;
  content: string;
  dTag: string;
}

fragmentRegistry.register<ReferencedArticleArgs>({
  id: "referenced-article",
  priority: 10, // High priority to appear early in the prompt
  template: ({ title, content, dTag }) => {
    return `This conversation is about this spec file:
<spec dTag="${dTag}">
# ${title}

${content}
</spec>
`;
  },
});
</file>

<file path="src/prompts/fragments/15-available-agents.ts">
import type { AgentInstance } from "@/agents/types";
import { fragmentRegistry } from "../core/FragmentRegistry";
import type { PromptFragment } from "../core/types";

/**
 * Available agents fragment.
 * Shows coworkers they can hand off to.
 */
interface AvailableAgentsArgs {
  agents: AgentInstance[];
  currentAgent: AgentInstance;
}

export const availableAgentsFragment: PromptFragment<AvailableAgentsArgs> = {
  id: "available-agents",
  priority: 15,
  template: ({ agents, currentAgent }) => {
    // Filter out current agent
    const coworkers = agents.filter((agent) => agent.pubkey !== currentAgent.pubkey);

    if (coworkers.length === 0) {
      return "## Available Agents\nNo other agents are available.";
    }

    const agentList = coworkers
      .map((agent) => {
        const parts = [ `(${agent.slug})`, `  Role: ${agent.role}` ];

        if (agent.useCriteria) {
          parts.push(`  Use Criteria: ${agent.useCriteria}`);
        } else if (agent.description) {
          parts.push(`  Description: ${agent.description}`);
        }

        return parts.join("\n");
      })
      .join("\n\n");

    return `## Available Agents
You are part of a multi-agent system, these are agents immediately available in the system:

${agentList}`;
  },
};

// Register the fragment
fragmentRegistry.register(availableAgentsFragment);
</file>

<file path="src/prompts/fragments/20-voice-mode.ts">
import type { NDKEvent } from "@nostr-dev-kit/ndk";
import { fragmentRegistry } from "../core/FragmentRegistry";
import type { PromptFragment } from "../core/types";

export interface VoiceModeOptions {
  isVoiceMode: boolean;
}

const voiceModeFragment: PromptFragment<VoiceModeOptions> = {
  id: "voice-mode",
  priority: 20, // High priority to ensure voice instructions are prominent
  template: (options: VoiceModeOptions) => {
    if (!options.isVoiceMode) return "";

    return `## Voice Mode Guidelines

You are generating text that will be converted to speech and read aloud. Please follow these guidelines:

### Text Formatting for TTS
- Use natural, conversational language that flows well when spoken
- Avoid complex punctuation that doesn't translate well to speech
- For larger numbers, use a mix (e.g., "15 thousand" instead of "15,000")
- Avoid URLs, file paths, or code snippets unless absolutely necessary
- If you must reference code, describe it in natural language

### Response Structure
- Keep sentences concise and clear
- Use shorter paragraphs with natural pauses
- Avoid bullet points or numbered lists - use flowing prose instead
- Lead with the most important information
- Use transitions like "First," "Next," "Additionally," for clarity

### Tone and Delivery
- Be warm and conversational, as if speaking directly to the user
- Use active voice whenever possible
- Include brief acknowledgments like "I understand" or "Let me help with that"
- Avoid technical jargon unless necessary, and explain terms when used
- Use natural fillers sparingly for a more human feel (e.g., "Well," "Now,")

### Content Adaptation
- Summarize lengthy content rather than reading it verbatim
- Focus on key points and actionable information
- When describing visual elements or code, use descriptive language
- For errors or issues, explain them clearly without reading stack traces
- Provide context before diving into details

Remember: The user is listening, not reading. Make your response engaging and easy to follow by ear.`;
  },
};

// Register the fragment
fragmentRegistry.register(voiceModeFragment);

/**
 * Helper function to check if an event has voice mode enabled
 */
export function isVoiceMode(event: NDKEvent | undefined): boolean {
  if (!event) return false;
  return event.tagValue("mode") === "voice";
}
</file>

<file path="src/prompts/fragments/24-retrieved-lessons.ts">
import type { AgentInstance } from "@/agents/types";
import type { Phase } from "@/conversations/phases";
import type { Conversation } from "@/conversations/types";
import type { NDKAgentLesson } from "@/events/NDKAgentLesson";
import { formatLessonsForAgent } from "@/utils/lessonFormatter";
import { logger } from "@/utils/logger";
import { fragmentRegistry } from "../core/FragmentRegistry";
import type { PromptFragment } from "../core/types";

// Retrieved lessons fragment - formats lessons from ProjectContext
interface RetrievedLessonsArgs {
  agent: AgentInstance;
  phase: Phase;
  conversation: Conversation;
  agentLessons: Map<string, NDKAgentLesson[]>;
}

export const retrievedLessonsFragment: PromptFragment<RetrievedLessonsArgs> = {
  id: "retrieved-lessons",
  priority: 24, // Before learn-tool-directive
  template: ({ agent, agentLessons }) => {
    // Debug: Log what's being passed in
    logger.debug("üìö Retrieved lessons fragment called", {
      agentName: agent.name,
      agentPubkey: agent.pubkey,
      agentLessonsMapSize: agentLessons.size,
      hasLessonsForAgent: agentLessons.has(agent.pubkey),
    });

    // Get only this agent's lessons
    const myLessons = agentLessons.get(agent.pubkey) || [];

    if (myLessons.length === 0) {
      logger.debug("üìö No lessons available for this agent", {
        agent: agent.name,
        agentPubkey: agent.pubkey,
      });
      return ""; // No lessons learned yet
    }

    // Use the formatter to create formatted lessons
    const formattedLessons = formatLessonsForAgent(myLessons);

    // Add the lesson_learn tool reminder if lessons exist
    return `${formattedLessons}\n\nRemember to use the \`lesson_learn\` tool when you discover new insights or patterns.`;
  },
};

// Register the fragment
fragmentRegistry.register(retrievedLessonsFragment);
</file>

<file path="src/prompts/fragments/90-inventory-generation.ts">
import { fragmentRegistry } from "../core/FragmentRegistry";
import type { PromptFragment } from "../core/types";

// Helper function to convert git status codes to descriptions
function getStatusDescription(status: string): string {
  if (status.includes("M")) return "modified";
  if (status.includes("A")) return "added";
  if (status.includes("D")) return "deleted";
  if (status.includes("R")) return "renamed";
  if (status === "??") return "untracked";
  return status;
}

interface InventoryGenerationArgs {
  repomixContent: string;
  focusFiles?: Array<{ path: string; status: string }>;
}

export const mainInventoryPromptFragment: PromptFragment<InventoryGenerationArgs> = {
  id: "main-inventory-generation",
  priority: 10,
  template: ({ repomixContent, focusFiles }) => {
    const focusSection = focusFiles?.length
      ? `
## Recently Modified Files
The following files were recently modified and should receive special attention in your analysis:
${focusFiles.map((f) => `- ${f.path} (${getStatusDescription(f.status)})`).join("\n")}

Please ensure these areas are accurately reflected in the inventory.
`
      : "";

    return `You are analyzing a codebase to create a comprehensive inventory.${focusSection}

Here is the complete repository content in XML format from repomix:

<repository>
${repomixContent}
</repository>

Please generate a comprehensive inventory in markdown format that includes:

1. **Project Overview**
   - Brief description of what the project does
   - Main technologies and frameworks used
   - Architecture style (if identifiable)

2. **Directory Structure**
   - High-level directory breakdown with purpose of each
   - Key organizational patterns

3. **Significant Files**
   - List of important files with one-line value propositions
   - Focus on entry points, core business logic, configurations
   - Include file paths and brief descriptions

4. **Architectural Insights**
   - Key patterns used in the codebase
   - Data flow and integration points
   - Notable design decisions

5. **High-Complexity Modules** (if any)
   - Identify modules/components that are particularly complex
   - For each complex module, provide: name, file path, reason for complexity

At the end, if you identified any high-complexity modules, provide them in this JSON format:
\`\`\`json
{
  "complexModules": [
    {
      "name": "Module Name",
      "path": "src/path/to/module",
      "reason": "Brief explanation of complexity",
      "suggestedFilename": "MODULE_NAME_GUIDE.md"
    }
  ]
}
\`\`\`

Make the inventory comprehensive but readable, focusing on helping developers quickly understand the codebase structure and purpose.`;
  },
  validateArgs: (args): args is InventoryGenerationArgs => {
    return (
      typeof args === "object" &&
      args !== null &&
      typeof (args as InventoryGenerationArgs).repomixContent === "string"
    );
  },
};

interface ModuleGuideArgs {
  repomixContent: string;
  moduleName: string;
  modulePath: string;
  complexityReason: string;
}

export const moduleGuidePromptFragment: PromptFragment<ModuleGuideArgs> = {
  id: "module-guide-generation",
  priority: 10,
  template: ({ repomixContent, moduleName, modulePath, complexityReason }) => {
    return `You are analyzing a specific complex module in a codebase. Here is the complete repository content in XML format from repomix:

<repository>
${repomixContent}
</repository>

Focus specifically on the module: **${moduleName}** at path: \`${modulePath}\`

This module was identified as complex because: ${complexityReason}

Please generate a comprehensive technical documentation for this module that includes:

1. **Module Overview**
   - Purpose and responsibilities
   - Key interfaces and entry points
   - Dependencies and relationships

2. **Technical Architecture**
   - Internal structure and organization
   - Key classes/functions and their roles
   - Data flow within the module

3. **Implementation Details**
   - Core algorithms or business logic
   - Important patterns or design decisions
   - Configuration and customization points

4. **Integration Points**
   - How other parts of the system interact with this module
   - External dependencies
   - Event flows or communication patterns

5. **Usage Guide**
   - How to properly use this module
   - Example use cases
   - Common patterns and best practices

Focus on documenting how the module works at both a high-level conceptual understanding and detailed technical level. Keep the documentation accessible to developers who need to understand, use, or modify this module.`;
  },
  validateArgs: (args): args is ModuleGuideArgs => {
    return (
      typeof args === "object" &&
      args !== null &&
      typeof (args as ModuleGuideArgs).repomixContent === "string" &&
      typeof (args as ModuleGuideArgs).moduleName === "string" &&
      typeof (args as ModuleGuideArgs).modulePath === "string" &&
      typeof (args as ModuleGuideArgs).complexityReason === "string"
    );
  },
};

interface ComplexModulesExtractionArgs {
  content: string;
}

export const complexModulesExtractionFragment: PromptFragment<ComplexModulesExtractionArgs> = {
  id: "complex-modules-extraction",
  priority: 10,
  template: ({ content }) => {
    return `Extract only the valid JSON array of complex modules from the following text and nothing else. If no JSON is present or no complex modules are mentioned, return an empty array [].

Response format should be exactly:
\`\`\`json
{
  "complexModules": [
    {
      "name": "Module Name", 
      "path": "src/path/to/module",
      "reason": "Brief explanation",
      "suggestedFilename": "MODULE_NAME_GUIDE.md"
    }
  ]
}
\`\`\`

Text to analyze:
${content}`;
  },
  validateArgs: (args): args is ComplexModulesExtractionArgs => {
    return (
      typeof args === "object" &&
      args !== null &&
      typeof (args as ComplexModulesExtractionArgs).content === "string"
    );
  },
};

// Register fragments
fragmentRegistry.register(mainInventoryPromptFragment);
fragmentRegistry.register(moduleGuidePromptFragment);
fragmentRegistry.register(complexModulesExtractionFragment);
</file>

<file path="src/prompts/utils/projectUtils.ts">
import * as fs from "node:fs";
import * as path from "node:path";
import { logger } from "@/utils/logger";

/**
 * Count total files in a directory recursively, excluding dot files and node_modules
 */
export function countTotalFiles(dir: string): number {
  let count = 0;
  try {
    const entries = fs.readdirSync(dir, { withFileTypes: true });
    for (const entry of entries) {
      if (!entry.name.startsWith(".") && entry.name !== "node_modules") {
        if (entry.isDirectory()) {
          count += countTotalFiles(path.join(dir, entry.name));
        } else {
          count += 1;
        }
      }
    }
  } catch (error) {
    logger.debug(`Could not count files in ${dir}`, { error });
  }
  return count;
}
</file>

<file path="src/services/LLMOperationsRegistry.ts">
import type { ExecutionContext } from "@/agents/execution/types";
import { logger } from "@/utils/logger";

// Store essential operation metadata
interface LLMOperation {
  id: string;
  abortController: AbortController;
  eventId: string;        // The event being processed
  agentPubkey: string;    // Agent doing the work
  conversationId: string; // Root event ID for conversation
  registeredAt: number;   // Timestamp
}

class LLMOperationsRegistry {
  private static instance: LLMOperationsRegistry;
  private operations = new Map<string, LLMOperation>();
  private byEvent = new Map<string, Set<string>>();
  private operationsByContext = new Map<string, string>(); // contextKey -> operationId
  private changeListeners = new Set<() => void>();
  
  static getInstance(): LLMOperationsRegistry {
    if (!this.instance) {
      this.instance = new LLMOperationsRegistry();
    }
    return this.instance;
  }
  
  registerOperation(context: ExecutionContext): AbortSignal {
    const operationId = crypto.randomUUID();
    const conversation = context.conversationCoordinator.getConversation(context.conversationId);
    const rootEventId = conversation?.history[0]?.id || context.triggeringEvent.id;
    
    // Create operation with metadata
    const operation: LLMOperation = {
      id: operationId,
      abortController: new AbortController(),
      eventId: context.triggeringEvent.id,
      agentPubkey: context.agent.pubkey,
      conversationId: rootEventId,
      registeredAt: Date.now()
    };
    
    // Store the operation
    this.operations.set(operationId, operation);
    
    // Index by both root event and triggering event
    this.indexOperation(operationId, rootEventId);
    if (context.triggeringEvent.id !== rootEventId) {
      this.indexOperation(operationId, context.triggeringEvent.id);
    }
    
    // Also index by context for easy lookup on completion
    this.operationsByContext.set(this.getContextKey(context), operationId);
    
    // Auto-cleanup on abort (for cancellation cases)
    operation.abortController.signal.addEventListener('abort', () => {
      this.cleanupOperation(operationId);
    });
    
    logger.debug('[LLMOpsRegistry] Registered operation', {
      operationId: operationId.substring(0, 8),
      rootEvent: rootEventId.substring(0, 8),
      triggeringEvent: context.triggeringEvent.id.substring(0, 8),
      agent: context.agent.name,
      agentPubkey: context.agent.pubkey.substring(0, 8),
    });
    
    // Notify listeners of new operation
    this.notifyChange();
    
    return operation.abortController.signal;
  }
  
  completeOperation(context: ExecutionContext): void {
    const contextKey = this.getContextKey(context);
    const operationId = this.operationsByContext.get(contextKey);
    
    if (!operationId) {
      // Operation was never registered or already completed
      return;
    }
    
    // Remove context mapping
    this.operationsByContext.delete(contextKey);
    
    // Do the actual cleanup
    this.cleanupOperation(operationId);
  }
  
  private cleanupOperation(operationId: string): void {
    const operation = this.operations.get(operationId);
    if (!operation) {
      // Already cleaned up
      return;
    }
    
    // Remove from main map
    this.operations.delete(operationId);
    
    // Remove from all indices
    this.unindexOperation(operationId, operation.conversationId);
    if (operation.eventId !== operation.conversationId) {
      this.unindexOperation(operationId, operation.eventId);
    }
    
    logger.debug('[LLMOpsRegistry] Completed operation', {
      operationId: operationId.substring(0, 8),
      eventId: operation.eventId.substring(0, 8),
      conversationId: operation.conversationId.substring(0, 8),
      duration: Date.now() - operation.registeredAt
    });
    
    // Notify listeners of change
    this.notifyChange();
  }
  
  private getContextKey(context: ExecutionContext): string {
    // Create a unique key from the context that identifies this specific operation
    return `${context.triggeringEvent.id}:${context.agent.pubkey}`;
  }
  
  stopByEventId(eventId: string): number {
    const operationIds = this.byEvent.get(eventId) || new Set();
    let stopped = 0;
    
    for (const opId of operationIds) {
      const operation = this.operations.get(opId);
      if (operation && !operation.abortController.signal.aborted) {
        operation.abortController.abort();
        stopped++;
      }
    }
    
    if (stopped > 0) {
      logger.info('[LLMOpsRegistry] Stopped operations', {
        eventId: eventId.substring(0, 8),
        count: stopped
      });
    }
    
    return stopped;
  }
  
  getActiveOperationsCount(): number {
    return this.operations.size;
  }
  
  // Get operations grouped by event ID for publishing
  getOperationsByEvent(): Map<string, LLMOperation[]> {
    const byEvent = new Map<string, LLMOperation[]>();
    
    for (const operation of this.operations.values()) {
      // Group by triggering event
      if (!byEvent.has(operation.eventId)) {
        byEvent.set(operation.eventId, []);
      }
      byEvent.get(operation.eventId)!.push(operation);
      
      // Also group by conversation/root event if different
      if (operation.conversationId !== operation.eventId) {
        if (!byEvent.has(operation.conversationId)) {
          byEvent.set(operation.conversationId, []);
        }
        byEvent.get(operation.conversationId)!.push(operation);
      }
    }
    
    return byEvent;
  }
  
  // Subscribe to changes
  onChange(listener: () => void): () => void {
    this.changeListeners.add(listener);
    return () => this.changeListeners.delete(listener);
  }
  
  private notifyChange(): void {
    this.changeListeners.forEach(listener => listener());
  }
  
  private indexOperation(operationId: string, eventId: string): void {
    if (!this.byEvent.has(eventId)) {
      this.byEvent.set(eventId, new Set());
    }
    this.byEvent.get(eventId)!.add(operationId);
  }
  
  private unindexOperation(operationId: string, eventId: string): void {
    this.byEvent.get(eventId)?.delete(operationId);
    if (this.byEvent.get(eventId)?.size === 0) {
      this.byEvent.delete(eventId);
    }
  }
}

export const llmOpsRegistry = LLMOperationsRegistry.getInstance();
</file>

<file path="src/test-utils/mock-llm/scenarios/error-handling.ts">
import type { MockLLMScenario } from "../types";

/**
 * Error handling scenarios for testing edge cases and failures
 */
export const errorHandlingScenario: MockLLMScenario = {
  name: "error-handling",
  description: "Test error conditions and recovery",
  responses: [
    // Tool execution failure
    {
      trigger: {
        agentName: "Executor",
        userMessage: /simulate.*error/i,
      },
      response: {
        content: "I'll simulate an error condition.",
        toolCalls: [
          {
            id: "err1",
            message: null,
            function: "shell",
            args: JSON.stringify({
              command: "exit 1",
              cwd: ".",
            }),
          },
        ],
      },
      priority: 10,
    },

    // Recovery after tool failure
    {
      trigger: {
        agentName: "Executor",
        previousToolCalls: ["shell"],
        userMessage: /tool call failed/i,
      },
      response: {
        content: "I see the command failed. Let me try a different approach.",
        toolCalls: [
          {
            id: "err2",
            message: null,
            function: "analyze",
            args: JSON.stringify({
              query: "What went wrong with the previous command?",
            }),
          },
        ],
      },
      priority: 9,
    },

    // Network timeout simulation
    {
      trigger: {
        agentName: "Orchestrator",
        userMessage: /test.*timeout/i,
      },
      response: {
        streamDelay: 5000, // 5 second delay
        content: "This response is delayed to simulate network issues...",
        toolCalls: [
          {
            id: "timeout1",
            message: null,
            function: "continue",
            args: JSON.stringify({
              summary: "Testing timeout handling",
              suggestedPhase: "CHAT",
              confidence: 50,
              reasoning: "Network seems slow",
            }),
          },
        ],
      },
      priority: 10,
    },

    // Invalid tool arguments
    {
      trigger: {
        agentName: "Executor",
        userMessage: /malformed.*request/i,
      },
      response: {
        content: "Testing malformed tool call...",
        toolCalls: [
          {
            id: "bad1",
            message: null,
            function: "continue",
            args: "{ invalid json }", // Intentionally malformed
          },
        ],
      },
      priority: 10,
    },

    // LLM service error
    {
      trigger: {
        userMessage: /trigger.*llm.*error/i,
      },
      response: {
        error: new Error("LLM Service Unavailable: Rate limit exceeded"),
      },
      priority: 10,
    },

    // Empty response handling
    {
      trigger: {
        agentName: "Executor",
        userMessage: /empty.*response/i,
      },
      response: {
        content: "", // Empty content
        toolCalls: [], // No tool calls
      },
      priority: 10,
    },

    // Multiple tool calls with mixed success
    {
      trigger: {
        agentName: "Executor",
        userMessage: /mixed.*results/i,
      },
      response: {
        content: "Executing multiple operations with mixed results...",
        toolCalls: [
          {
            id: "mix1",
            message: null,
            function: "readPath",
            args: JSON.stringify({ path: "./exists.md" }),
          },
          {
            id: "mix2",
            message: null,
            function: "readPath",
            args: JSON.stringify({ path: "./does-not-exist.md" }),
          },
          {
            id: "mix3",
            message: null,
            function: "shell",
            args: JSON.stringify({ command: "echo 'success'" }),
          },
        ],
      },
      priority: 10,
    },

    // Infinite loop prevention
    {
      trigger: {
        agentName: "Orchestrator",
        previousToolCalls: ["continue", "continue", "continue", "continue", "continue"],
      },
      response: {
        content: "I notice we're stuck in a loop. Let me complete this task.",
        toolCalls: [
          {
            id: "loop1",
            message: null,
            function: "complete",
            args: JSON.stringify({
              summary: "Detected potential infinite loop",
              response: "Breaking out of loop pattern",
            }),
          },
        ],
      },
      priority: 15,
    },

    // Phase transition failure
    {
      trigger: {
        agentName: "Orchestrator",
        userMessage: /invalid.*phase/i,
      },
      response: {
        toolCalls: [
          {
            id: "phase1",
            message: null,
            function: "continue",
            args: JSON.stringify({
              summary: "Attempting invalid phase transition",
              suggestedPhase: "INVALID_PHASE", // Invalid phase
              confidence: 10,
              reasoning: "Testing phase validation",
            }),
          },
        ],
      },
      priority: 10,
    },

    // Concurrent execution conflict
    {
      trigger: {
        agentName: "Executor",
        userMessage: /concurrent.*modification/i,
      },
      response: {
        content: "Detecting concurrent modification conflict...",
        toolCalls: [
          {
            id: "conc1",
            message: null,
            function: "writeFile",
            args: JSON.stringify({
              path: "src/shared.ts",
              content: "// Version A",
            }),
          },
        ],
      },
      priority: 10,
    },

    // Memory/context overflow simulation
    {
      trigger: {
        agentName: "Executor",
        userMessage: /large.*context/i,
      },
      response: {
        content: "A".repeat(10000), // Very large response
        toolCalls: [
          {
            id: "mem1",
            message: null,
            function: "analyze",
            args: JSON.stringify({
              query: "Analyze this extremely large codebase with thousands of files",
            }),
          },
        ],
      },
      priority: 10,
    },
  ],
};
</file>

<file path="src/test-utils/mock-llm/scenarios/example-scenario.ts">
import type { MockLLMScenario, MockLLMResponse } from "../types";

/**
 * Example scenario showing how to create mock responses
 */
export const exampleScenario: MockLLMScenario = {
    name: "example-workflow",
    description: "Example scenario for testing basic workflows",
    responses: [
        // Simple greeting response
        {
            trigger: {
                userMessage: /hello|hi|hey/i,  // Regex pattern matching
            },
            response: {
                content: "Hello! I'm here to help. What would you like to work on today?",
            },
            priority: 10,  // Higher priority responses are checked first
        },

        // Response with tool calls
        {
            trigger: {
                userMessage: /create.*file/i,
                agentName: "project-manager",  // Only matches for specific agent
            },
            response: {
                content: "I'll create that file for you.",
                toolCalls: [
                    {
                        function: "write_context_file",
                        args: JSON.stringify({
                            path: "example.md",
                            content: "# Example File\nCreated by mock LLM"
                        })
                    }
                ],
            },
            priority: 15,
        },

        // Phase-specific response
        {
            trigger: {
                phase: "plan",  // Matches specific conversation phase
                messageContains: /authentication/i,
            },
            response: {
                content: "Let me create a plan for the authentication system:\n1. Set up user model\n2. Implement JWT tokens\n3. Add OAuth support",
                toolCalls: [
                    {
                        function: "delegate_phase",
                        args: JSON.stringify({
                            phase: "execute",
                            reason: "Plan is ready, moving to implementation"
                        })
                    }
                ],
            },
            priority: 20,
        },

        // Context-aware response (tracks iterations)
        {
            trigger: {
                agentName: "executor",
                iterationCount: 2,  // Only on second iteration of this agent
            },
            response: {
                content: "This is my second attempt. Let me try a different approach.",
            },
            priority: 5,
        },

        // Response after specific agent
        {
            trigger: {
                previousAgent: "planner",  // Responds after planner agent
                agentName: "executor",
            },
            response: {
                content: "I received the plan from the planner. Starting implementation now.",
            },
            priority: 10,
        },

        // Error simulation
        {
            trigger: {
                userMessage: /simulate.*error/i,
            },
            response: {
                error: new Error("Simulated error for testing"),
            },
            priority: 100,  // High priority to override other matches
        },

        // Response with streaming delay
        {
            trigger: {
                userMessage: /slow.*response/i,
            },
            response: {
                content: "This response will stream slowly for testing purposes.",
                streamDelay: 2000,  // 2 second delay
            },
            priority: 10,
        },

        // Default fallback for agent
        {
            trigger: {
                agentName: /.*/,  // Matches any agent
            },
            response: {
                content: "Processing your request with mock response.",
            },
            priority: 1,  // Lowest priority - only if nothing else matches
        },
    ],
};

/**
 * Helper function to create a simple pattern-based scenario
 */
export function createSimpleScenario(patterns: Record<string, string>): MockLLMScenario {
    const responses: MockLLMResponse[] = Object.entries(patterns).map(([pattern, response], index) => ({
        trigger: {
            userMessage: new RegExp(pattern, 'i'),
        },
        response: {
            content: response,
        },
        priority: 10 - index,  // First patterns have higher priority
    }));

    return {
        name: "simple-patterns",
        description: "Simple pattern-based responses",
        responses,
    };
}

// Example usage of simple scenario
export const simpleIOSTestScenario = createSimpleScenario({
    "hello": "Hello! I'm running in test mode.",
    "create.*file": "Creating the file for you.",
    "list.*files": "Here are your files:\n- README.md\n- package.json",
    "error": "ERROR: Test error for iOS",
    ".*": "Default mock response",  // Fallback
});
</file>

<file path="src/test-utils/mock-llm/scenarios/network-resilience.ts">
import type { MockLLMScenario } from "../types";

/**
 * Scenario for testing Nostr network resilience
 * Provides simple, deterministic responses for network failure testing
 */
export const networkResilienceScenario: MockLLMScenario = {
  name: "network-resilience",
  description: "Test network resilience and recovery",

  responses: [
    // Orchestrator responses for initial requests
    {
      trigger: {
        agentName: "Orchestrator",
        phase: "chat",
        userMessage: /authentication|payment|notification|chat|feature/i,
      },
      response: {
        content:
          "I'll help you with that. Let me route this to the appropriate phase for planning.",
        toolCalls: [
          {
            id: "1",
            message: null,
            function: "continue",
            args: JSON.stringify({
              summary: "User requested a new system implementation",
              suggestedPhase: "plan",
              suggestedAgent: "planner",
            }),
          },
        ],
      },
      priority: 10,
    },

    // Planner responses
    {
      trigger: {
        agentName: "Planner",
        phase: "plan",
      },
      response: {
        content:
          "I've created a plan for implementing the requested system. The plan includes core components and basic functionality.",
        toolCalls: [
          {
            id: "1",
            message: null,
            function: "continue",
            args: JSON.stringify({
              summary: "Plan created for system implementation",
              suggestedPhase: "implementation",
              suggestedAgent: "executor",
            }),
          },
        ],
      },
      priority: 10,
    },

    // Executor responses
    {
      trigger: {
        agentName: "Executor",
        phase: "implementation",
      },
      response: {
        content:
          "I've implemented the basic structure for the requested system. The implementation is ready for verification.",
        toolCalls: [
          {
            id: "1",
            message: null,
            function: "continue",
            args: JSON.stringify({
              summary: "Basic implementation completed",
              suggestedPhase: "verification",
              suggestedAgent: "orchestrator",
            }),
          },
        ],
      },
      priority: 10,
    },

    // Verification phase
    {
      trigger: {
        agentName: "Orchestrator",
        phase: "verification",
      },
      response: {
        content:
          "The implementation has been verified and is working as expected. The system is ready for use.",
        toolCalls: [],
      },
      priority: 10,
    },

    // Generic fallback for any agent
    {
      trigger: {
        agentName: ".*",
      },
      response: {
        content: "Processing your request...",
        toolCalls: [],
      },
      priority: 1,
    },
  ],
};
</file>

<file path="src/test-utils/mock-llm/scenarios/performance-testing.ts">
import type { MockLLMScenario } from "../types";

/**
 * Performance testing scenarios that simulate slow responses, timeouts, and system stress
 */
export const performanceTestingScenario: MockLLMScenario = {
  name: "performance-testing",
  description: "Scenarios for testing system performance, timeouts, and stress conditions",
  responses: [
    // Scenario: Slow LLM response during orchestration
    {
      trigger: {
        agentName: "orchestrator",
        phase: "CHAT",
        userMessage: /performance.*test.*slow/i,
      },
      response: {
        streamDelay: 5000, // 5 second delay
        content: JSON.stringify({
          agents: ["planner"],
          phase: "PLAN",
          reason: "Setting up performance test with intentional delays",
        }),
      },
      priority: 15,
    },

    // Scenario: Very slow planning phase
    {
      trigger: {
        agentName: "orchestrator",
        phase: "PLAN",
        userMessage: /performance test/,
      },
      response: {
        streamDelay: 8000, // 8 second delay
        content: JSON.stringify({
          agents: ["executor"],
          phase: "EXECUTE",
          reason: "Plan created with multiple delayed operations",
        }),
      },
      priority: 15,
    },

    // Scenario: Timeout simulation (exceeds typical timeout)
    {
      trigger: {
        agentName: "executor",
        phase: "EXECUTE",
        userMessage: /timeout test/,
      },
      response: {
        streamDelay: 35000, // 35 second delay (should trigger timeout)
        content: "This response will be delayed beyond the typical timeout threshold...",
        toolCalls: [],
      },
      priority: 20,
    },

    // Scenario: Slow tool execution
    {
      trigger: {
        agentName: "executor",
        previousToolCalls: ["shell"],
        userMessage: /slow tool test/,
      },
      response: {
        streamDelay: 3000, // 3 second delay for tool response
        content: "The tool execution is taking longer than expected...",
        toolCalls: [
          {
            id: "4",
            message: null,
            function: "complete",
            args: JSON.stringify({
              summary: "Completed slow tool execution",
              details: ["Tool executed with 3 second delay"],
            }),
          },
        ],
      },
      priority: 15,
    },

    // Scenario: Rapid sequential requests (stress test)
    {
      trigger: {
        agentName: "orchestrator",
        userMessage: /stress test rapid/,
      },
      response: {
        streamDelay: 50, // Very short delay
        content: JSON.stringify({
          agents: ["executor"],
          phase: "EXECUTE",
          reason: "Handling rapid sequential requests",
        }),
      },
      priority: 15,
    },

    // Scenario: Memory-intensive response
    {
      trigger: {
        agentName: "executor",
        userMessage: /large response test/,
      },
      response: {
        streamDelay: 2000,
        // Generate a large response to test memory handling
        content: `Large response data: ${"x".repeat(50000)}`, // 50KB of data
        toolCalls: [
          {
            id: "6",
            message: null,
            function: "complete",
            args: JSON.stringify({
              summary: "Processed large data response",
              details: ["Generated 50KB response"],
            }),
          },
        ],
      },
      priority: 15,
    },

    // Scenario: Recovery after timeout
    {
      trigger: {
        agentName: "orchestrator",
        userMessage: /retry after timeout/,
      },
      response: {
        streamDelay: 100, // Quick response after timeout
        content: JSON.stringify({
          agents: ["executor"],
          phase: "VERIFICATION",
          reason: "Successfully recovered from timeout",
        }),
      },
      priority: 20,
    },
    // Performance test initial response
    {
      trigger: {
        agentName: "orchestrator",
        userMessage: /performance test/,
      },
      response: {
        streamDelay: 1000,
        content: JSON.stringify({
          agents: ["planner"],
          phase: "PLAN",
          reason: "Starting performance test workflow",
        }),
      },
      priority: 10,
    },
  ],
};
</file>

<file path="src/test-utils/mock-llm/scenarios/state-persistence.ts">
import type { MockLLMScenario } from "../types";

/**
 * Scenario for testing conversation state persistence and recovery
 * Simulates partial workflow execution and recovery after restart
 */
export const statePersistenceScenario: MockLLMScenario = {
  name: "state-persistence",
  description: "Test conversation state persistence and recovery across restarts",
  responses: [
    // Initial orchestrator response - transition to PLAN phase
    {
      trigger: {
        agentName: "orchestrator",
        phase: "CHAT",
        userMessage: /create.*authentication/i,
      },
      response: {
        content:
          "I'll help you create an authentication system. Let me plan the implementation approach.",
        toolCalls: [
          {
            id: "1",
            message: null,
            function: "continue",
            args: JSON.stringify({
              summary: "Planning authentication system implementation",
              suggestedPhase: "PLAN",
            }),
          },
        ],
      },
      priority: 10,
    },
    // Plan phase response - transition to BUILD
    {
      trigger: {
        agentName: "orchestrator",
        phase: "PLAN",
        userMessage: /continue.*implementation/i,
      },
      response: {
        content: "I've planned the authentication system. Let's start building the components.",
        toolCalls: [
          {
            id: "2",
            message: null,
            function: "continue",
            args: JSON.stringify({
              summary: "Starting authentication implementation",
              suggestedPhase: "BUILD",
              suggestedAgent: "executor",
            }),
          },
        ],
      },
      priority: 10,
    },
    // Test agent BUILD phase response
    {
      trigger: {
        agentName: "executor",
        phase: "BUILD",
      },
      response: {
        content: "I'll implement the authentication system components.",
        toolCalls: [
          {
            id: "3",
            message: null,
            function: "writeContextFile",
            args: JSON.stringify({
              filename: "auth-implementation.md",
              content:
                "# Authentication Implementation\n\n- User registration\n- Login/logout\n- Session management",
            }),
          },
        ],
      },
      priority: 10,
    },
    // Analyze project structure scenario
    {
      trigger: {
        agentName: "orchestrator",
        phase: "CHAT",
        userMessage: /analyze.*project.*structure/i,
      },
      response: {
        content: "I'll analyze the project structure for you.",
        toolCalls: [
          {
            id: "4",
            message: null,
            function: "continue",
            args: JSON.stringify({
              summary: "Analyzing project structure",
              suggestedPhase: "BUILD",
              suggestedAgent: "executor",
            }),
          },
        ],
      },
      priority: 10,
    },
    // Recovery scenario - continue analysis
    {
      trigger: {
        agentName: "executor",
        phase: "BUILD",
        userMessage: /continue.*analysis/i,
      },
      response: {
        content: "Continuing with the project structure analysis.",
        toolCalls: [
          {
            id: "5",
            message: null,
            function: "complete",
            args: JSON.stringify({
              summary: "Project structure analyzed successfully",
            }),
          },
        ],
      },
      priority: 10,
    },
    // Concurrent task scenarios
    {
      trigger: {
        agentName: "orchestrator",
        phase: "CHAT",
        userMessage: /Task.*Create feature/i,
      },
      response: {
        content: "I'll help you create this feature.",
        toolCalls: [
          {
            id: "6",
            message: null,
            function: "continue",
            args: JSON.stringify({
              summary: "Creating feature as requested",
              suggestedPhase: "PLAN",
            }),
          },
        ],
      },
      priority: 10,
    },
  ],
};
</file>

<file path="src/test-utils/mock-llm/scenarios/threading-workflow.ts">
import type { MockLLMResponse, MockLLMScenario } from "../types";

const threadingResponses: MockLLMResponse[] = [
  // Root conversation responses
  {
    trigger: {
      agentName: "chat-agent",
      userMessage: /simply say "YELLOW"/i,
    },
    response: {
      content: "YELLOW",
    },
    priority: 90,
  },
  {
    trigger: {
      agentName: "chat-agent",
      userMessage: /simply say "BROWN"/i,
    },
    response: {
      content: "BROWN",
    },
    priority: 90,
  },
  {
    trigger: {
      agentName: "chat-agent",
      userMessage: /simply say "HELLO1"/i,
    },
    response: {
      content: "HELLO1",
    },
    priority: 90,
  },
  {
    trigger: {
      agentName: "chat-agent",
      userMessage: /simply say "HELLO2"/i,
    },
    response: {
      content: "HELLO2",
    },
    priority: 90,
  },
  
  // Thread-specific responses
  {
    trigger: {
      agentName: "chat-agent",
      userMessage: /give me this color in lowercase/i,
      messageContains: /YELLOW/,
    },
    response: {
      content: "yellow",
    },
    priority: 100,
  },
  {
    trigger: {
      agentName: "chat-agent",
      userMessage: /give me this color in lowercase/i,
      messageContains: /BROWN/,
    },
    response: {
      content: "brown",
    },
    priority: 100,
  },
  {
    trigger: {
      agentName: "chat-agent",
      userMessage: /tell me this color again/i,
      messageContains: /YELLOW/,
    },
    response: {
      content: "YELLOW",
    },
    priority: 100,
  },
  {
    trigger: {
      agentName: "chat-agent",
      userMessage: /tell me this color again/i,
      messageContains: /BROWN/,
    },
    response: {
      content: "BROWN",
    },
    priority: 100,
  },
  
  // Transcript generation responses
  {
    trigger: {
      agentName: "chat-agent",
      userMessage: /give me a transcript/i,
      messageContains: /YELLOW.*yellow/is,
    },
    response: {
      content: `Sure, here is the transcript of the conversation:

1. User: simply say "YELLOW"
2. Assistant: YELLOW
3. User: Give me this color in lowercase
4. Assistant: yellow
5. User: give me a transcript of the conversation

Let me know if you need anything else!`,
    },
    priority: 110,
  },
  {
    trigger: {
      agentName: "chat-agent",
      userMessage: /give me a transcript/i,
      messageContains: /BROWN.*brown/is,
    },
    response: {
      content: `Sure, here is the transcript of the conversation:

1. User: simply say "BROWN"
2. Assistant: BROWN
3. User: Give me this color in lowercase
4. Assistant: brown
5. User: give me a transcript of the conversation

Let me know if you need anything else!`,
    },
    priority: 110,
  },
  
  // Default fallback for unmatched thread contexts
  {
    trigger: {
      agentName: "chat-agent",
      userMessage: /give me a transcript/i,
    },
    response: {
      content: "I can provide a transcript of our conversation. However, I need more context about which part of the conversation you'd like transcribed.",
    },
    priority: 50,
  },
];

export const threadingWorkflow: MockLLMScenario = {
  name: "threading-workflow",
  description: "Mock LLM responses for testing NIP-22 threading behavior",
  responses: threadingResponses,
  verifyMessages: (messages) => {
    // Verify that thread context is properly filtered
    const messagesText = messages.map(m => m.content).join("\n");
    
    // If we're in a YELLOW thread, should not see BROWN
    if (messagesText.includes("YELLOW") && messagesText.includes("lowercase")) {
      if (messagesText.includes("BROWN")) {
        throw new Error("Thread context leak: BROWN found in YELLOW thread");
      }
    }
    
    // If we're in a BROWN thread, should not see YELLOW
    if (messagesText.includes("BROWN") && messagesText.includes("lowercase")) {
      if (messagesText.includes("YELLOW") && !messagesText.includes("simply say \"YELLOW\"")) {
        throw new Error("Thread context leak: YELLOW found in BROWN thread");
      }
    }
    
    return true;
  },
};
</file>

<file path="src/test-utils/mocks/events.ts">
import { NDKEvent } from "@nostr-dev-kit/ndk";

export const createConversationEvent = (id: string, content = "", title = ""): NDKEvent => {
  const event = new NDKEvent();
  event.id = id;
  event.content = content;
  event.tags = [["d", id]];
  if (title) {
    event.tags.push(["title", title]);
  }
  return event;
};

export const createReplyEvent = (id: string, content: string): NDKEvent => {
  const event = new NDKEvent();
  event.id = `${id}-reply`;
  event.content = content;
  event.tags = [["e", id]];
  return event;
};

export const createAgentMessageEvent = (
  id: string,
  agentPubkey: string,
  content: string
): NDKEvent => {
  const event = new NDKEvent();
  event.id = `${id}-agent-message`;
  event.pubkey = agentPubkey;
  event.content = content;
  event.tags = [["e", id]];
  return event;
};
</file>

<file path="src/test-utils/e2e-conversational-setup.ts">
import { conversationalLogger } from "./conversational-logger";

/**
 * Global setup for E2E tests to enable conversational logging when DEBUG=true
 * This can be imported and used to automatically enable conversational output
 * without modifying individual test files.
 */
export function setupConversationalLogging(): void {
  if (process.env.DEBUG === "true") {
    conversationalLogger.reset();

    // Log a banner for the test session
    console.log("\nüé≠ E2E Test Session with Conversational Logging");
    console.log(`üìÖ ${new Date().toISOString()}`);
    console.log(`${"=".repeat(60)}`);
  }
}

/**
 * Helper to wrap test execution with conversational logging
 */
export function withConversationalLogging<T>(
  testName: string,
  testFn: () => Promise<T>
): Promise<T> {
  if (process.env.DEBUG === "true") {
    conversationalLogger.logTestStart(testName);

    return testFn()
      .then((result) => {
        conversationalLogger.logTestEnd(true, testName);
        return result;
      })
      .catch((error) => {
        conversationalLogger.logTestEnd(false, testName);
        throw error;
      });
  }
  return testFn();
}

/**
 * Auto-enable conversational logging if DEBUG is set
 * Can be imported at the top of test files to automatically enable
 */
if (process.env.DEBUG === "true") {
  setupConversationalLogging();
}
</file>

<file path="src/test-utils/e2e-mocks.ts">
import { mock } from "bun:test";
import path from "node:path";
import { createTempDir } from "@/lib/fs";
import { createMockLLMService } from "@/llm/__tests__/MockLLMService";
import { createMockNDKEvent } from "@/test-utils/mock-factories";
import type { AgentInstance } from "@/agents/types";
import type { E2ETestContext } from "./e2e-types";

/**
 * Create mock NDK event for testing
 */
export function createE2EMockEvent(overrides: Partial<any> = {}): any {
    return createMockNDKEvent(overrides);
}

/**
 * Setup mock modules for E2E testing
 */
export async function setupMockModules(scenarios: string[] = [], defaultResponse?: string): Promise<{
    tempDir: string;
    projectPath: string;
    mockLLM: any;
    mockFiles: Map<string, string>;
}> {
    // Create temp directory
    const tempDir = await createTempDir("tenex-e2e-");
    const projectPath = path.join(tempDir, "test-project");
    
    // Mock file system
    const mockFiles = new Map<string, string>();
    mockFiles.set(path.join(projectPath, "package.json"), JSON.stringify({
        name: "test-project",
        version: "1.0.0"
    }));
    
    mock.module("@/lib/fs", () => ({
        fileExists: mock((filePath: string) => mockFiles.has(filePath)),
        readFile: mock((filePath: string) => {
            const content = mockFiles.get(filePath);
            if (!content) throw new Error(`File not found: ${filePath}`);
            return content;
        }),
        writeFile: mock((filePath: string, content: string) => {
            mockFiles.set(filePath, content);
            return Promise.resolve();
        }),
        writeJsonFile: mock((filePath: string, data: any) => {
            mockFiles.set(filePath, JSON.stringify(data, null, 2));
            return Promise.resolve();
        }),
        ensureDirectory: mock(() => Promise.resolve())
    }));
    
    // Initialize mock LLM
    const mockLLM = createMockLLMService(scenarios, {
        debug: process.env.DEBUG === 'true',
        defaultResponse: defaultResponse || { content: "Mock LLM: No matching response found" }
    });
    
    // Mock LLM router
    mock.module("@/llm/router", () => ({
        getLLMService: () => mockLLM,
        LLMRouter: class {
            constructor() {}
            getService() { return mockLLM; }
            validateModel() { return true; }
        }
    }));
    
    // Mock Nostr publisher
    mock.module("@/nostr", () => ({
        getNDK: () => ({
            connect: async () => {},
            signer: { privateKey: () => "mock-private-key" },
            pool: {
                connectedRelays: () => [],
                relaySet: new Set(),
                addRelay: () => {}
            },
            publish: async () => {},
            calculateRelaySetFromEvent: () => ({ relays: [] })
        })
    }));
    
    // Mock AgentPublisher to prevent publishing during tests
    mock.module("@/agents/AgentPublisher", () => ({
        AgentPublisher: class {
            async publishProfile() { return Promise.resolve(); }
            async publishEvents() { return Promise.resolve(); }
            async publishAgentCreation() { return Promise.resolve(); }
        }
    }));
    
    // Mock ClaudeBackend to prevent launching actual Claude Code process
    mock.module("@/agents/execution/ClaudeBackend", () => ({
        ClaudeBackend: class {
            async execute(messages: any[], tools: any[], context: any, publisher: any) {
                // Use the mock LLM instead of launching Claude Code
                const response = await mockLLM.complete({
                    messages,
                    options: {
                        configName: context.agent.llmConfig || context.agent.name,
                        agentName: context.agent.name
                    }
                });
                
                // Simulate Claude Code execution
                // 1. Publish the response content
                if (response.content) {
                    await publisher.publishResponse(response.content, null, false);
                }
                
                // 2. Handle tool calls if present
                if (response.toolCalls && response.toolCalls.length > 0) {
                    for (const toolCall of response.toolCalls) {
                        // Add tool handlers as needed
                        // toolCall.function.name and toolCall.function.arguments are available if needed
                    }
                }
                
                return Promise.resolve();
            }
        }
    }));
    
    // Mock logging
    mock.module("@/logging/ExecutionLogger", () => ({
        ExecutionLogger: class {
            logToolCall() {}
            logToolResult() {}
            logStream() {}
            logComplete() {}
            logError() {}
            logEvent() {}
            routingDecision() {}
            agentThinking() {}
        },
        createExecutionLogger: () => ({
            logToolCall: () => {},
            logToolResult: () => {},
            logStream: () => {},
            logComplete: () => {},
            logError: () => {},
            logEvent: () => {},
            routingDecision: () => {},
            agentThinking: () => {}
        })
    }));
    
    return { tempDir, projectPath, mockLLM, mockFiles };
}

/**
 * Create test agents for E2E tests
 */
export function createTestAgents(): AgentInstance[] {
    const pmAgent = {
        name: "test-pm",
        slug: "test-pm",
        pubkey: "test-pm-pubkey",
        eventId: "test-pm-event-id",
        description: "Test PM agent for E2E tests",
        role: "Project Manager",
        instructions: "You are a test PM agent for E2E testing",
        systemPrompt: "You are a test PM agent for E2E testing",
        allowedTools: ["delegate_phase", "writeContextFile", "analyze"],
        tools: [],
        llmConfig: { model: "claude-3-sonnet-20240229", provider: "anthropic" }
    };
    
    const executorAgent = {
        name: "executor",
        slug: "executor",
        pubkey: "executor-pubkey",
        eventId: "executor-event-id",
        description: "Executor agent for E2E tests",
        role: "Executor",
        instructions: "You are an executor agent for E2E testing",
        systemPrompt: "You are an executor agent for E2E testing",
        allowedTools: ["shell", "writeContextFile"],
        tools: [],
        llmConfig: { model: "claude-3-sonnet-20240229", provider: "anthropic" }
    };
    
    const plannerAgent = {
        name: "planner",
        slug: "planner",
        pubkey: "planner-pubkey",
        eventId: "planner-event-id",
        description: "Planner agent for E2E tests",
        role: "Planner",
        instructions: "You are a planner agent for E2E testing",
        systemPrompt: "You are a planner agent for E2E testing",
        allowedTools: ["analyze"],
        tools: [],
        llmConfig: { model: "claude-3-sonnet-20240229", provider: "anthropic" }
    };
    
    return [pmAgent as AgentInstance, executorAgent as AgentInstance, plannerAgent as AgentInstance];
}
</file>

<file path="src/test-utils/e2e-setup.ts">
import { mock } from "bun:test";
import path from "node:path";
import fs from "fs-extra";
import { Database } from "bun:sqlite";
import { ConversationCoordinator } from "@/conversations";
import { AgentConversationContext } from "@/conversations/AgentConversationContext";
import { ConversationMessageRepository } from "@/conversations/ConversationMessageRepository";
import { AgentRegistry } from "@/agents/AgentRegistry";
import { ProjectContext } from "@/services/ProjectContext";
import { setupMockModules, createTestAgents } from "./e2e-mocks";
import type { E2ETestContext } from "./e2e-types";

/**
 * Setup E2E test environment
 */
export async function setupE2ETest(scenarios: string[] = [], defaultResponse?: string): Promise<E2ETestContext> {
    // Setup mock modules
    const { tempDir, projectPath, mockLLM, mockFiles } = await setupMockModules(scenarios, defaultResponse);
    
    // Create test agents
    const testAgents = createTestAgents();
    const [pmAgent, executorAgent, plannerAgent] = testAgents;
    
    // Mock project context with dynamic PM (first agent)
    const agentsMap = new Map([
        ["test-pm", pmAgent],      // First agent becomes PM
        ["executor", executorAgent],
        ["planner", plannerAgent]
    ]);
    
    const mockProjectContext = {
        project: { 
            id: "test-project", 
            pubkey: "test-pubkey",
            tagValue: (tag: string) => tag === "title" ? "Test Project" : null,
            tags: [
                ["title", "Test Project"],
                ["agent", "test-pm-event-id"],    // First agent tag - becomes PM
                ["agent", "executor-event-id"],
                ["agent", "planner-event-id"]
            ]
        },
        signer: { privateKey: () => "test-key" },
        pubkey: "test-pubkey",
        orchestrator: null,
        agents: agentsMap,
        projectPath,
        isProjectOwner: () => true,
        getProjectManager: () => pmAgent,  // First agent is PM
        hasPhaseSpecialist: (phase: string) => false,
        getPhaseSpecialist: (phase: string) => null,
        getAgent: (identifier: string) => agentsMap.get(identifier) || null
    } as unknown as ProjectContext;
    
    mock.module("@/services/ProjectContext", () => ({
        ProjectContext: class {
            constructor() {}
            static async create() { return mockProjectContext; }
            static instance = mockProjectContext;
        }
    }));
    
    // Initialize real components with DB
    const dbPath = path.join(tempDir, "test.db");
    const db = new Database(dbPath);
    
    // Create messages table
    db.exec(`
        CREATE TABLE IF NOT EXISTS messages (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            conversation_id TEXT NOT NULL,
            role TEXT NOT NULL,
            content TEXT,
            timestamp INTEGER NOT NULL
        )
    `);
    
    const messageRepo = new ConversationMessageRepository(db);
    
    // Initialize agent registry with test agents
    const agentRegistry = new AgentRegistry();
    for (const agent of testAgents) {
        agentRegistry.registerAgent(agent);
    }
    
    // Add orchestrator
    const orchestratorAgent = {
        name: "orchestrator",
        slug: "orchestrator",
        pubkey: "orchestrator-pubkey",
        eventId: "orchestrator-event-id",
        description: "Orchestrator for E2E tests",
        role: "Orchestrator",
        instructions: "You are an orchestrator for E2E testing",
        systemPrompt: "You are an orchestrator for E2E testing",
        allowedTools: ["route"],
        tools: [],
        llmConfig: { model: "claude-3-sonnet-20240229", provider: "anthropic" }
    };
    agentRegistry.registerAgent(orchestratorAgent);
    
    // Create conversation coordinator
    const conversationCoordinator = new ConversationCoordinator(
        messageRepo,
        agentRegistry,
        mockProjectContext
    );
    
    // Create agent context
    const agentContext = new AgentConversationContext(
        pmAgent,
        conversationCoordinator,
        mockProjectContext
    );
    
    // Cleanup function
    const cleanup = async () => {
        try {
            mock.restore();
            db.close();
            await fs.remove(tempDir);
        } catch (error) {
            console.error("Cleanup error:", error);
        }
    };
    
    return {
        mockLLM,
        conversationCoordinator,
        agentContext,
        messageRepo,
        agentRegistry,
        projectContext: mockProjectContext,
        testAgents,
        cleanup
    };
}

/**
 * Cleanup E2E test environment
 */
export async function cleanupE2ETest(context: E2ETestContext | undefined): Promise<void> {
    if (context?.cleanup) {
        await context.cleanup();
    }
}
</file>

<file path="src/tools/implementations/delegate_followup.ts">
import { tool } from 'ai';
import { z } from 'zod';
import { DelegationService, type DelegationResponses } from "@/services/DelegationService";
import { DelegationRegistry } from "@/services/DelegationRegistry";
import type { ExecutionContext } from "@/agents/execution/types";
import { resolveRecipientToPubkey } from "@/utils/agent-resolution";
import { logger } from "@/utils/logger";

const delegateFollowupSchema = z.object({
  recipient: z.string()
    .describe("Agent slug (e.g., 'architect'), name (e.g., 'Architect'), npub, or hex pubkey of the agent you delegated to"),
  message: z.string()
    .describe("Your follow-up question or clarification request"),
});

type DelegateFollowupInput = z.infer<typeof delegateFollowupSchema>;

// Core implementation
async function executeDelegateFollowup(
  input: DelegateFollowupInput,
  context: ExecutionContext
): Promise<DelegationResponses> {
  const { recipient, message } = input;
  
  // Resolve recipient to pubkey
  const recipientPubkey = resolveRecipientToPubkey(recipient);
  if (!recipientPubkey) {
    throw new Error(`Could not resolve recipient: ${recipient}`);
  }
  
  // Get delegation record from registry
  const registry = DelegationRegistry.getInstance();
  const delegationRecord = registry.getDelegationByConversationKey(
    context.conversationId,
    context.agent.pubkey,
    recipientPubkey
  );
  
  if (!delegationRecord) {
    throw new Error(
      `No recent delegation found to ${recipient}. Use delegate or delegate_phase first, then use delegate_followup to ask clarifying questions.`
    );
  }
  
  if (!delegationRecord.completion?.event) {
    throw new Error(
      `Delegation to ${recipient} has not completed yet or did not return a response event.`
    );
  }
  
  const responseEvent = delegationRecord.completion.event;
  
  logger.info("[delegate_followup] üîÑ Creating follow-up delegation", {
    fromAgent: context.agent.slug,
    toPubkey: recipientPubkey.substring(0, 8),
    responseEventId: responseEvent.id?.substring(0, 8),
    message: message.substring(0, 100),
  });
  
  // Create DelegationService with the response event as context
  const delegationService = new DelegationService(
    context.agent,
    context.conversationId,
    context.conversationCoordinator,
    responseEvent, // This becomes the triggering event for threading
    context.agentPublisher,
    context.phase
  );
  
  // Execute as a follow-up delegation
  const responses = await delegationService.execute({
    type: "delegation_followup",
    recipients: [recipientPubkey],
    request: message,
  });
  
  logger.info("[delegate_followup] ‚úÖ Follow-up complete", {
    fromAgent: context.agent.slug,
    recipient: recipient,
    responseCount: responses.responses.length,
  });
  
  return responses;
}

// AI SDK tool factory
export function createDelegateFollowupTool(context: ExecutionContext): ReturnType<typeof tool> {
  return tool({
    description: "Send a follow-up question to an agent you previously delegated to. Use after delegate or delegate_phase to ask clarifying questions about their response. The tool will wait for their response before continuing.",
    inputSchema: delegateFollowupSchema,
    execute: async (input: DelegateFollowupInput) => {
      return await executeDelegateFollowup(input, context);
    },
  });
}

/**
 * Delegate Follow-up tool - enables multi-turn conversations during delegations
 * 
 * This tool allows an agent to ask follow-up questions after receiving a delegation response:
 * 1. Takes a recipient parameter to identify which delegation to follow up on
 * 2. Looks up the delegation in DelegationRegistry using agent+conversation+recipient
 * 3. Creates a reply to the stored response event
 * 4. Waits synchronously for the response (just like delegate)
 * 5. Can be chained for multiple follow-ups
 * 
 * Example flow:
 * - Agent1 delegates to architect: "Design auth system"
 * - Architect responds: "I suggest OAuth2..."
 * - Agent1 uses delegate_followup(recipient: "architect", message: "What about refresh tokens?")
 * - Architect responds: "Use rotating tokens with 7-day expiry"
 * - Agent1 can continue with more follow-ups or proceed
 */
</file>

<file path="src/tools/utils.ts">
import { isAbsolute, relative, resolve } from "node:path";

/**
 * Resolves and validates a file path to ensure it stays within the project boundaries.
 *
 * @param filePath - The file path to validate (can be absolute or relative)
 * @param projectPath - The root project path
 * @returns The resolved absolute path if valid
 * @throws Error if the path would escape the project directory
 */
export function resolveAndValidatePath(filePath: string, projectPath: string): string {
  const fullPath = isAbsolute(filePath) ? filePath : resolve(projectPath, filePath);
  const relativePath = relative(projectPath, fullPath);

  if (relativePath.startsWith("..")) {
    throw new Error(`Path outside project directory: ${filePath}`);
  }

  return fullPath;
}
</file>

<file path="src/utils/git/createExecutionBranch.ts">
import { execSync } from "node:child_process";
import { logger } from "@/utils/logger";

export interface GitBranchResult {
  branchName: string;
  created: boolean;
}

/**
 * Create a git branch for execution
 */
export function createExecutionBranch(
  baseName: string,
  projectPath: string = process.cwd()
): GitBranchResult {
  try {
    // Check if we're in a git repository
    try {
      execSync("git status", {
        cwd: projectPath,
        stdio: "ignore",
      });
    } catch {
      logger.info("Not a git repository, initializing git repository");
      try {
        execSync("git init", {
          cwd: projectPath,
          stdio: "pipe",
        });
        logger.info("Git repository initialized successfully");
      } catch (initError) {
        logger.error("Failed to initialize git repository", { error: initError });
        return { branchName: "no-git", created: false };
      }
    }

    // Generate branch name
    const safeName = baseName
      .toLowerCase()
      .replace(/[^a-z0-9]+/g, "-")
      .replace(/^-|-$/g, "")
      .substring(0, 30);

    const timestamp = Date.now();
    const branchName = `tenex/${safeName}-${timestamp}`;

    // Create and checkout new branch
    execSync(`git checkout -b ${branchName}`, {
      cwd: projectPath,
      stdio: "pipe",
    });

    logger.info("Created execution branch", { branchName });
    return { branchName, created: true };
  } catch (error) {
    logger.error("Failed to create git branch", { error });
    return { branchName: "main", created: false };
  }
}
</file>

<file path="src/utils/git/gitignore.ts">
import * as fs from "node:fs/promises";
import * as path from "node:path";
import { logger } from "@/utils/logger";

/**
 * Ensures .tenex is in the project's .gitignore file
 */
export async function ensureTenexInGitignore(projectPath: string): Promise<void> {
  const gitignorePath = path.join(projectPath, ".gitignore");

  try {
    let gitignoreContent = "";

    // Check if .gitignore exists
    try {
      gitignoreContent = await fs.readFile(gitignorePath, "utf-8");
    } catch {
      // .gitignore doesn't exist, we'll create it
      logger.info("No .gitignore found, will create one");
    }

    // Check if .tenex is already in .gitignore
    const lines = gitignoreContent.split("\n");
    const hasTenexEntry = lines.some(
      (line) =>
        line.trim() === ".tenex" ||
        line.trim() === ".tenex/" ||
        line.trim() === "/.tenex" ||
        line.trim() === "/.tenex/"
    );

    if (!hasTenexEntry) {
      // Add .tenex to .gitignore
      const updatedContent = gitignoreContent.trim()
        ? `${gitignoreContent.trim()}\n\n# TENEX project files\n.tenex/\n`
        : "# TENEX project files\n.tenex/\n";

      await fs.writeFile(gitignorePath, updatedContent);
      logger.info("Added .tenex/ to .gitignore");
    } else {
      logger.info(".tenex already in .gitignore");
    }
  } catch (error) {
    logger.error("Failed to update .gitignore", { error });
    throw error;
  }
}
</file>

<file path="src/utils/git/initializeGitRepo.ts">
import { exec } from "node:child_process";
import * as fs from "node:fs/promises";
import * as path from "node:path";
import { promisify } from "node:util";
import { logger } from "@/utils/logger";

const execAsync = promisify(exec);

/**
 * Check if a directory is a git repository (has its own .git directory)
 */
export async function isGitRepository(projectPath: string): Promise<boolean> {
  try {
    const gitPath = path.join(projectPath, ".git");
    await fs.access(gitPath);
    return true;
  } catch {
    return false;
  }
}

/**
 * Initialize a git repository in the given directory
 */
export async function initializeGitRepository(projectPath: string): Promise<void> {
  try {
    const { stdout, stderr } = await execAsync("git init", {
      cwd: projectPath,
    });

    if (stderr) {
      logger.warn("Git init warning", { stderr });
    }

    logger.info("Initialized git repository", { projectPath, stdout });
  } catch (error) {
    logger.error("Failed to initialize git repository", { error, projectPath });
    throw error;
  }
}
</file>

<file path="src/utils/agentInstaller.ts">
import * as fs from "node:fs/promises";
import * as path from "node:path";
import { AgentRegistry } from "@/agents/AgentRegistry";
import type { AgentInstance } from "@/agents/types";
import { getNDK } from "@/nostr";
import { logger } from "@/utils/logger";
import { toKebabCase } from "@/utils/string";
import type NDK from "@nostr-dev-kit/ndk";
import type { NDKProject } from "@nostr-dev-kit/ndk";

/**
 * Result of installing an agent from an event
 */
export interface AgentInstallResult {
  success: boolean;
  agent?: AgentInstance;
  slug?: string;
  message?: string;
  error?: string;
  alreadyExists?: boolean;
}

/**
 * Installs an agent from a Nostr event into a project.
 * This is the shared business logic for adding agents from definition events.
 * 
 * @param eventId - The event ID of the agent definition (can include "nostr:" prefix)
 * @param projectPath - The path to the project
 * @param ndkProject - Optional NDK project for publishing events
 * @param customSlug - Optional custom slug for the agent
 * @param ndk - Optional NDK instance (will use default if not provided)
 * @returns Result of the installation
 */
export async function installAgentFromEvent(
  eventId: string,
  projectPath: string,
  ndkProject?: NDKProject,
  customSlug?: string,
  ndk?: NDK
): Promise<AgentInstallResult> {
  try {
    // Use provided NDK or get default
    const ndkInstance = ndk || getNDK();
    
    // Clean the event ID
    const cleanEventId = eventId.startsWith("nostr:") ? eventId.substring(6) : eventId;
    
    // Fetch the full event to get access to tags
    const agentEvent = await ndkInstance.fetchEvent(cleanEventId, { groupable: false });
    
    if (!agentEvent) {
      return {
        success: false,
        error: `Agent event not found: ${eventId}`,
      };
    }

    // Parse agent definition from the event
    const agentDef = {
      id: agentEvent.id,
      title: agentEvent.tagValue("title") || "Unnamed Agent",
      description: agentEvent.tagValue("description") || "",
      role: agentEvent.tagValue("role") || "assistant",
      instructions: agentEvent.content || "",
      useCriteria: agentEvent.tagValue("use-criteria") || "",
    };

    // Generate slug from name if not provided
    const slug = customSlug || toKebabCase(agentDef.title);

    // Load agent registry
    const registry = new AgentRegistry(projectPath, false);
    await registry.loadFromProject();

    // Check if agent already exists
    const existingAgent = registry.getAgent(slug);
    if (existingAgent) {
      if (existingAgent.eventId === agentDef.id) {
        return {
          success: true,
          alreadyExists: true,
          message: `Agent "${agentDef.title}" is already installed in the project`,
          agent: existingAgent,
          slug,
        };
      }
      return {
        success: false,
        error: `An agent with slug "${slug}" already exists but with a different event ID`,
      };
    }

    // Extract tool requirements from the agent definition event
    const toolTags = agentEvent.tags
      .filter(tag => tag[0] === "tool" && tag[1])
      .map(tag => tag[1]);

    if (toolTags.length > 0) {
      logger.info(`Agent "${agentDef.title}" requests access to ${toolTags.length} tool(s):`, toolTags);
    }

    // Save agent definition file
    const agentsDir = path.join(projectPath, ".tenex", "agents");
    await fs.mkdir(agentsDir, { recursive: true });
    
    const filePath = path.join(agentsDir, `${cleanEventId}.json`);
    const agentData = {
      name: agentDef.title,
      role: agentDef.role,
      description: agentDef.description,
      instructions: agentDef.instructions,
      useCriteria: agentDef.useCriteria,
      tools: toolTags, // Include the requested tools
    };
    await fs.writeFile(filePath, JSON.stringify(agentData, null, 2));
    logger.info("Saved agent definition", { eventId: cleanEventId, name: agentDef.title });

    // Create agent configuration
    const agentConfig = {
      name: agentDef.title,
      role: agentDef.role,
      description: agentDef.description,
      instructions: agentDef.instructions,
      useCriteria: agentDef.useCriteria,
      tools: toolTags, // Include the requested tools
      eventId: agentDef.id,
    };

    // Register the agent
    const agent = await registry.ensureAgent(slug, agentConfig, ndkProject);
    logger.info("Registered new agent", { slug, name: agentDef.title });

    return {
      success: true,
      agent,
      slug,
      message: `Successfully installed agent "${agentDef.title}"`,
    };
  } catch (error) {
    logger.error("Failed to install agent from event", { error, eventId });
    return {
      success: false,
      error: error instanceof Error ? error.message : String(error),
    };
  }
}

/**
 * Installs multiple agents from events in parallel
 * 
 * @param eventIds - Array of event IDs to install
 * @param projectPath - The path to the project
 * @param ndkProject - Optional NDK project for publishing events
 * @param ndk - Optional NDK instance
 * @returns Array of installation results
 */
export async function installAgentsFromEvents(
  eventIds: string[],
  projectPath: string,
  ndkProject?: NDKProject,
  ndk?: NDK
): Promise<AgentInstallResult[]> {
  const results = await Promise.all(
    eventIds.map(eventId => installAgentFromEvent(eventId, projectPath, ndkProject, undefined, ndk))
  );
  
  const successCount = results.filter(r => r.success).length;
  const failureCount = results.filter(r => !r.success).length;
  
  if (successCount > 0) {
    logger.info(`Successfully installed ${successCount} agent(s)`);
  }
  if (failureCount > 0) {
    logger.warn(`Failed to install ${failureCount} agent(s)`);
  }
  
  return results;
}
</file>

<file path="src/utils/cli-error.ts">
import { formatAnyError } from "@/utils/error-formatter";
import { logger } from "./logger";

/**
 * Centralized CLI error handler that ensures consistent error logging and exit behavior
 * @param error - The error object or message
 * @param context - Optional context for better error reporting
 * @param exitCode - The process exit code (default: 1)
 */
export function handleCliError(error: unknown, context?: string, exitCode = 1): never {
  const errorMessage = formatAnyError(error);
  const errorStack = error instanceof Error ? error.stack : undefined;

  // Log error with context
  if (context) {
    logger.error(`${context}: ${errorMessage}`);
  } else {
    logger.error(errorMessage);
  }

  // Log stack trace in debug mode
  if (errorStack && process.env.DEBUG) {
    logger.debug(errorStack);
  }

  // Exit with specified code
  process.exit(exitCode);
}

/**
 * Handle CLI warnings without exiting
 * @param message - The warning message
 * @param context - Optional context for the warning
 */
export function handleCliWarning(message: string, context?: string): void {
  if (context) {
    logger.warn(`${context}: ${message}`);
  } else {
    logger.warn(message);
  }
}
</file>

<file path="src/utils/eom-utils.ts">
/**
 * Utility functions for handling End of Message (EOM) markers
 */

/**
 * Detect and strip the EOM marker from content
 * Returns the content without the marker and whether it was found
 */
export function detectAndStripEOM(content: string): { hasEOM: boolean; cleanContent: string } {
  const lines = content.split('\n');
  const lastLine = lines[lines.length - 1]?.trim();
  
  if (lastLine === '=== EOM ===' || lastLine === 'EOM') {
    // Remove the EOM line
    lines.pop();
    return { hasEOM: true, cleanContent: lines.join('\n').trimEnd() };
  }
  
  // Also check for EOM on second-to-last line (in case of trailing newline)
  if (lines.length > 1) {
    const secondToLastLine = lines[lines.length - 2]?.trim();
    if (secondToLastLine === '=== EOM ===' || secondToLastLine === 'EOM') {
      // Remove the EOM line and any trailing empty line
      lines.splice(-2);
      return { hasEOM: true, cleanContent: lines.join('\n').trimEnd() };
    }
  }
  
  return { hasEOM: false, cleanContent: content };
}
</file>

<file path="src/utils/error-handler.ts">
import { formatAnyError } from "./error-formatter";
import { logger } from "./logger";

/**
 * Standard error handling utility for consistent error management
 * across the codebase
 */
export function handleError(
  error: unknown,
  context: string,
  options?: {
    logLevel?: "error" | "warn" | "debug";
    rethrow?: boolean;
    exitCode?: number;
  }
): string {
  const message = formatAnyError(error);
  const logLevel = options?.logLevel ?? "error";

  switch (logLevel) {
    case "error":
      logger.error(`${context}: ${message}`);
      break;
    case "warn":
      logger.warn(`${context}: ${message}`);
      break;
    case "debug":
      logger.debug(`${context}: ${message}`);
      break;
  }

  if (options?.exitCode !== undefined) {
    process.exit(options.exitCode);
  }

  if (options?.rethrow) {
    throw error;
  }

  return message;
}

/**
 * Async wrapper for error handling
 */
export async function withErrorHandling<T>(
  fn: () => Promise<T>,
  context: string,
  options?: {
    fallback?: T;
    logLevel?: "error" | "warn" | "debug";
    rethrow?: boolean;
  }
): Promise<T | undefined> {
  try {
    return await fn();
  } catch (error) {
    handleError(error, context, options);
    return options?.fallback;
  }
}
</file>

<file path="src/utils/file-persistence.ts">
import * as fs from "node:fs/promises";
import * as path from "node:path";
import { logger } from "./logger";

/**
 * Write JSON data to a file with consistent formatting
 */
export async function writeJsonFile<T>(filePath: string, data: T): Promise<void> {
  await ensureDirectory(path.dirname(filePath));
  await fs.writeFile(filePath, JSON.stringify(data, null, 2));
}

/**
 * Read and parse JSON data from a file
 */
export async function readJsonFile<T>(filePath: string): Promise<T> {
  const content = await fs.readFile(filePath, "utf-8");
  return JSON.parse(content) as T;
}

/**
 * Create directory recursively if it doesn't exist
 */
export async function ensureDirectory(dirPath: string): Promise<void> {
  await fs.mkdir(dirPath, { recursive: true });
}

/**
 * Handle persistence errors consistently
 */
export function handlePersistenceError(operation: string, error: unknown): void {
  logger.error(`Failed to ${operation}:`, error);
}

/**
 * Check if a file exists
 */
export async function fileExists(filePath: string): Promise<boolean> {
  try {
    await fs.access(filePath);
    return true;
  } catch {
    return false;
  }
}
</file>

<file path="src/utils/formatting.ts">
import chalk from "chalk";

/**
 * Format duration in human-readable format
 * @param ms - Duration in milliseconds
 * @returns Formatted duration string
 */
export function formatDuration(ms: number): string {
  // Handle invalid input
  if (!Number.isFinite(ms) || ms < 0) {
    return "0ms";
  }

  // Round to nearest integer to avoid floating point issues
  const duration = Math.round(ms);

  if (duration < 1000) {
    return `${duration}ms`;
  }

  if (duration < 60000) {
    return `${(duration / 1000).toFixed(1)}s`;
  }

  const minutes = Math.floor(duration / 60000);
  const seconds = Math.round((duration % 60000) / 1000);

  // Handle edge case where rounding seconds results in 60
  if (seconds === 60) {
    return `${minutes + 1}m 0s`;
  }

  return `${minutes}m ${seconds}s`;
}

/**
 * Format markdown text with chalk styling
 */
export function formatMarkdown(text: string): string {
  return text
    .replace(/^(#{1,6})\s+(.+)$/gm, (_, hashes, content) => chalk.bold.blue(`${hashes} ${content}`))
    .replace(/\*\*([^*]+)\*\*/g, chalk.bold("$1"))
    .replace(/\*([^*]+)\*/g, chalk.italic("$1"))
    .replace(/```(\w+)?\n([\s\S]*?)```/g, (_, lang, code) => {
      return `${chalk.gray(`\`\`\`${lang || ""}`)}\n${chalk.green(code)}${chalk.gray("```")}`;
    })
    .replace(/`([^`]+)`/g, chalk.yellow("`$1`"))
    .replace(/\[([^\]]+)\]\(([^)]+)\)/g, chalk.cyan("[$1]") + chalk.gray("($2)"))
    .replace(
      /^(\s*)([-*+])\s+(.+)$/gm,
      (_, spaces, bullet, content) => `${spaces}${chalk.yellow(bullet)} ${content}`
    )
    .replace(
      /^(\s*)(\d+\.)\s+(.+)$/gm,
      (_, spaces, num, content) => `${spaces}${chalk.yellow(num)} ${content}`
    );
}

/**
 * Colorize JSON string with chalk styling
 */
export function colorizeJSON(json: string): string {
  return json
    .replace(/"([^"]+)":/g, chalk.cyan('"$1":'))
    .replace(/: "([^"]+)"/g, `: ${chalk.green('"$1"')}`)
    .replace(/: (\d+)/g, `: ${chalk.yellow("$1")}`)
    .replace(/: (true|false)/g, `: ${chalk.magenta("$1")}`)
    .replace(/: null/g, `: ${chalk.gray("null")}`);
}
</file>

<file path="src/utils/process.ts">
import { logger } from "@/utils/logger";

/**
 * Handler function called during graceful shutdown
 */
export type ShutdownHandler = (signal: string) => Promise<void>;

/**
 * Sets up graceful shutdown handlers for various termination signals
 * @param shutdownHandler - Async function to handle cleanup during shutdown
 * @description Handles SIGTERM, SIGINT, SIGHUP signals and uncaught exceptions/rejections
 */
export function setupGracefulShutdown(shutdownHandler: ShutdownHandler): void {
  let isShuttingDown = false;

  const shutdown = async (signal: string): Promise<void> => {
    if (isShuttingDown) return;
    isShuttingDown = true;

    logger.info(`Received ${signal}, shutting down gracefully...`);

    try {
      await shutdownHandler(signal);
      logger.info("Shutdown complete");
      process.exit(0);
    } catch (error) {
      logger.error("Error during shutdown", { error });
      process.exit(1);
    }
  };

  // Handle various termination signals
  process.on("SIGTERM", () => shutdown("SIGTERM"));
  process.on("SIGINT", () => shutdown("SIGINT"));
  process.on("SIGHUP", () => shutdown("SIGHUP"));

  // Handle uncaught errors
  process.on("uncaughtException", (error) => {
    logger.error("Uncaught exception", { error });
    shutdown("uncaughtException");
  });

  process.on("unhandledRejection", (reason, promise) => {
    logger.error("Unhandled rejection", { reason, promise });
    shutdown("unhandledRejection");
  });
}
</file>

<file path="src/utils/relays.ts">
/**
 * Default Nostr relay URLs for TENEX
 */
const DEFAULT_RELAY_URLS = ["wss://tenex.chat"];

/**
 * Validate WebSocket URL format
 * @param url - URL to validate
 * @returns true if URL is valid WebSocket URL
 */
function isValidWebSocketUrl(url: string): boolean {
  try {
    const parsed = new URL(url);
    return parsed.protocol === "ws:" || parsed.protocol === "wss:";
  } catch {
    return false;
  }
}

/**
 * Get relay URLs for NDK connection
 * @returns Array of validated WebSocket relay URLs
 */
export function getRelayUrls(): string[] {
  const relaysEnv = process.env.RELAYS;
  if (relaysEnv?.trim()) {
    const urls = relaysEnv
      .split(",")
      .map((url) => url.trim())
      .filter((url) => url.length > 0 && isValidWebSocketUrl(url));

    // If after filtering we have no valid URLs, return defaults
    if (urls.length === 0) {
      return DEFAULT_RELAY_URLS;
    }
    return urls;
  }

  return DEFAULT_RELAY_URLS;
}
</file>

<file path="src/utils/string.ts">
/**
 * Converts a string to kebab-case format
 * @param str - The input string to convert
 * @returns The kebab-case formatted string
 * @example
 * toKebabCase("HelloWorld") // "hello-world"
 * toKebabCase("hello_world") // "hello-world"
 * toKebabCase("Hello World") // "hello-world"
 */
export function toKebabCase(str: string): string {
  return str
    .replace(/([a-z])([A-Z])/g, "$1-$2")
    .replace(/[\s_]+/g, "-")
    .toLowerCase();
}
</file>

<file path="src/utils/validation.ts">
/**
 * Centralized validation utilities for common patterns
 */

/**
 * Validates if a string is a valid slug format (alphanumeric with hyphens and underscores)
 */
export function isValidSlug(name: string): boolean {
  return /^[a-zA-Z0-9-_]+$/.test(name);
}

/**
 * Validates if a filename has a markdown extension
 */
export function isMarkdownFile(filename: string): boolean {
  return filename.endsWith(".md");
}

/**
 * Validates if a string is a valid Nostr pubkey (64 hex characters)
 */
export function isValidPubkey(pubkey: string): boolean {
  return /^[a-fA-F0-9]{64}$/.test(pubkey);
}

/**
 * Validates if a string is a valid Nostr npub (starts with npub1)
 */
export function isValidNpub(npub: string): boolean {
  return npub.startsWith("npub1") && npub.length === 63;
}

/**
 * Validates if a path is absolute
 */
export function isAbsolutePath(path: string): boolean {
  return path.startsWith("/") || (process.platform === "win32" && /^[a-zA-Z]:/.test(path));
}

/**
 * Validates if a string is a valid UUID v4
 */
export function isValidUuid(uuid: string): boolean {
  return /^[0-9a-f]{8}-[0-9a-f]{4}-4[0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i.test(uuid);
}
</file>

<file path="src/constants.ts">
/**
 * Global constants used throughout the TENEX codebase
 */

/**
 * Directory names
 */
export const TENEX_DIR = ".tenex" as const;
export const CONVERSATIONS_DIR = "conversations" as const;

/**
 * File names
 */
export const CONFIG_FILE = "config.json" as const;
export const MCP_CONFIG_FILE = "mcp.json" as const;
export const AGENTS_FILE = "agents.json" as const;
export const LLMS_FILE = "llms.json" as const;

/**
 * Default values
 */
export const DEFAULT_TIMEOUT_MS = 120000; // 2 minutes
export const DEFAULT_RELAYS = [
  "wss://relay.nostr.band",
  "wss://relay.damus.io",
  "wss://nos.lol",
] as const;

/**
 * Environment variables
 */
export const ENV_VARS = {
  NOSTR_PRIVATE_KEY: "NOSTR_PRIVATE_KEY",
  NOSTR_PUBLIC_KEY: "NOSTR_PUBLIC_KEY",
  OPENAI_API_KEY: "OPENAI_API_KEY",
  ANTHROPIC_API_KEY: "ANTHROPIC_API_KEY",
} as const;
</file>

<file path=".repomixignore">
documentation
tenex-system-architecture-interactive.html
tests
*.test*
</file>

<file path="check-types.sh">
#!/bin/bash

# Run TypeScript check with proper flags
NODE_OPTIONS="--max-old-space-size=4096" npx tsc \
  --noEmit \
  --skipLibCheck \
  --project tsconfig.json \
  2>&1 | grep -v "node_modules"
</file>

<file path="eslint.config.js">
import js from '@eslint/js';
import typescript from 'typescript-eslint';

export default typescript.config(
  js.configs.recommended,
  ...typescript.configs.recommended,
  {
    ignores: ['dist/**', 'node_modules/**', 'coverage/**', '*.config.js', '*.config.ts', 'scripts/**', '**/*.test.*', '**/*.spec.*', '**/__tests__/**']
  },
  {
    files: ['src/**/*.ts', 'src/**/*.tsx'],
    languageOptions: {
      ecmaVersion: 2022,
      sourceType: 'module',
      parserOptions: {
        project: './tsconfig.eslint.json'
      }
    },
    rules: {
      '@typescript-eslint/no-explicit-any': 'error',
      '@typescript-eslint/no-non-null-assertion': 'error',
      '@typescript-eslint/explicit-function-return-type': ['error', {
        allowExpressions: true,
        allowTypedFunctionExpressions: true,
        allowHigherOrderFunctions: true,
        allowDirectConstAssertionInArrowFunctions: true,
        allowConciseArrowFunctionExpressionsStartingWithVoid: true
      }],
      '@typescript-eslint/no-unused-vars': ['error', {
        argsIgnorePattern: '^_',
        varsIgnorePattern: '^_'
      }],
      'no-console': 'off',
      'no-debugger': 'error'
    }
  },
  {
    files: ['src/**/*.test.ts', 'src/**/*.spec.ts'],
    languageOptions: {
      ecmaVersion: 2022,
      sourceType: 'module',
      parserOptions: {
        project: './tsconfig.eslint.json'
      }
    },
    rules: {
      '@typescript-eslint/no-explicit-any': 'error',
      '@typescript-eslint/no-non-null-assertion': 'error',
      '@typescript-eslint/no-unused-vars': ['error', {
        argsIgnorePattern: '^_',
        varsIgnorePattern: '^_'
      }],
      'no-console': 'off'
    }
  }
);
</file>

<file path="test-agent-memory.sh">
#!/bin/bash

# Test script to verify agents remember their previous responses

echo "Starting TENEX daemon in background..."
bun run daemon &
DAEMON_PID=$!

# Wait for daemon to fully start
sleep 5

echo -e "\n=== Test 1: Ask for a random number ==="
echo "don't use any tools: show me a random number between 1 and 1000" | bun run chat

# Wait for response
sleep 3

echo -e "\n=== Test 2: Ask what number was chosen ==="
echo "what number did you just tell me?" | bun run chat

# Wait for response
sleep 3

echo -e "\n=== Test 3: Ask again to confirm memory ==="
echo "can you repeat the number you said earlier?" | bun run chat

# Wait for final response
sleep 3

echo -e "\n=== Stopping daemon ==="
kill $DAEMON_PID

echo -e "\n=== Checking logs for conversation history ==="
tail -30 .tenex/logs/llms/llm-calls-*.jsonl | grep -A5 -B5 "what number did you"

echo -e "\nTest complete! Check if the agent remembered its previous number."
</file>

<file path="test-message-fix.js">
#!/usr/bin/env bun

// Test script to verify the message duplication fix
import { LLMService } from './dist/llm/service.js';
import { streamText } from 'ai';

async function testStreamProcessing() {
  console.log('Testing simplified stream processing...\n');
  
  // Create a mock provider config
  const service = new LLMService(
    { 
      openrouter: { apiKey: 'test-key' }
    },
    {
      'test-model': {
        provider: 'openrouter',
        model: 'test/model',
        temperature: 0.7
      }
    },
    'test-model'
  );
  
  // Test that events are emitted correctly
  let contentReceived = '';
  let iterationCompleted = false;
  
  service.on('content', (event) => {
    console.log('Content event:', event.delta);
    contentReceived += event.delta;
  });
  
  service.on('complete', (event) => {
    console.log('Iteration complete:', event);
    iterationCompleted = true;
  });
  
  // Create a mock stream to test processing
  const mockChunks = [
    { type: 'text-delta', text: 'Hello' },
    { type: 'text-delta', text: ' world' },
    { type: 'finish', text: 'Hello world', experimental_toolInvocations: [] }
  ];
  
  async function* createMockStream() {
    for (const chunk of mockChunks) {
      yield chunk;
    }
  }
  
  console.log('Processing mock stream...');
  const processedStream = service.processStream(
    createMockStream(),
    {
      model: 'test-model',
      agent: 'test-agent',
      phase: 'CHAT',
      startTime: Date.now(),
      llmLogger: null,
      requestId: 'test-123'
    }
  );
  
  // Consume the stream
  for await (const chunk of processedStream) {
    console.log('Processed chunk:', chunk.type);
  }
  
  console.log('\n‚úÖ Results:');
  console.log('- Content received:', contentReceived);
  console.log('- Iteration completed:', iterationCompleted);
  console.log('- Expected: "Hello world"');
  console.log('- Match:', contentReceived === 'Hello world');
  
  if (contentReceived === 'Hello world' && iterationCompleted) {
    console.log('\n‚úÖ SUCCESS: Stream processing works correctly!');
    console.log('The message duplication issue should be fixed.');
  } else {
    console.log('\n‚ùå FAILURE: Stream processing has issues');
  }
}

testStreamProcessing().catch(console.error);
</file>

<file path="tsconfig.json">
{
    "compilerOptions": {
        "target": "ES2020",
        "module": "ES2020",
        "lib": ["ES2020"],
        "moduleResolution": "node",
        "esModuleInterop": true,
        "allowSyntheticDefaultImports": true,
        "downlevelIteration": true,
        "strict": true,
        "skipLibCheck": true,
        "forceConsistentCasingInFileNames": true,
        "declaration": true,
        "declarationMap": true,
        "sourceMap": true,
        "noEmit": true,
        "rootDir": "./src",
        "outDir": "./dist",
        "baseUrl": ".",
        "paths": {
            "@/*": ["./src/*"]
        },
        "noUnusedLocals": true,
        "noUnusedParameters": true,
        "resolveJsonModule": true,
        "isolatedModules": true
    },
    "include": ["src/**/*.ts", "src/**/*.tsx"],
    "exclude": ["node_modules/**", "dist/**", "**/*.test.ts", "**/*.spec.ts", "src/test-utils/**/*"]
}
</file>

<file path="typecheck.cjs">
#!/usr/bin/env node

const { execSync } = require('child_process');
const fs = require('fs');
const path = require('path');

// Find all TypeScript files in src
const srcDir = path.join(__dirname, 'src');
const files = [];

function findTsFiles(dir) {
  const items = fs.readdirSync(dir);
  for (const item of items) {
    const fullPath = path.join(dir, item);
    const stat = fs.statSync(fullPath);
    if (stat.isDirectory() && !item.includes('test')) {
      findTsFiles(fullPath);
    } else if (item.endsWith('.ts') && !item.includes('.test.') && !item.includes('.spec.')) {
      files.push(fullPath);
    }
  }
}

findTsFiles(srcDir);

console.log(`Checking ${files.length} TypeScript files...`);

// Run tsc on batches of files
const batchSize = 50;
let hasErrors = false;

for (let i = 0; i < files.length; i += batchSize) {
  const batch = files.slice(i, Math.min(i + batchSize, files.length));
  const fileList = batch.map(f => `"${f}"`).join(' ');
  
  try {
    execSync(`npx tsc --noEmit --skipLibCheck ${fileList}`, {
      stdio: 'inherit',
      maxBuffer: 1024 * 1024 * 10
    });
  } catch (error) {
    hasErrors = true;
  }
}

if (!hasErrors) {
  console.log('‚úÖ No TypeScript errors found!');
} else {
  console.log('‚ùå TypeScript errors found');
  process.exit(1);
}
</file>

<file path="context/brainstorm.md">
# Brainstorming Phase: Swappable Moderator Concept

This document outlines a proposed feature for a new, moderated brainstorming workflow.

## 1. Core Concept: Swappable Moderator

The central idea is to introduce a "moderator" agent role specifically for the `BRAINSTORM` phase.

*   **Swappable Moderators:** A project can contain multiple moderator agents. Each moderator can have a unique style (e.g., collaborative, democratic, inquisitive), allowing the user to choose the best fit for a given session.
*   **Single Point of Contact:** During a brainstorming session, all messages from all participants (including the user) are routed exclusively through the currently selected moderator agent.

## 2. Proposed Workflow

1.  **Initiation:** When the `BRAINSTORM` phase begins, a moderator agent is selected.
2.  **User Input:** All user messages are sent directly to the moderator.
3.  **Agent Prompting:** The moderator chooses which agents (a subset or all participants) to prompt based on the current context. This is a synchronous, parallel process that does not involve Nostr events. Agents respond directly and synchronously to the moderator.
4.  **Response Evaluation:** The moderator evaluates the collected agent responses against its own internal criteria (e.g., creativity, relevance, fairness).
5.  **Publishing Decision:** The moderator decides which agent responses should be published to the wider group.
6.  **Event Publishing:** The recommended approach is for all agents to provide their response as a pre-signed Nostr event. The moderator then simply publishes the events from the chosen agent(s). This preserves the identity and signature of the original authoring agent.

## 3. Open Questions & Challenges

### a) Bypassing Standard Conversation Flow

A mechanism is needed to bypass the current conversational input/output flows to accommodate this specialized, moderator-centric workflow.

### b) Facilitating Agent-to-Agent Brainstorming

The primary goal is to foster direct agent-to-agent collaboration, with the user acting as just another participant.

*   **The Challenge:** How can the moderator decide when and how to share agent responses with other agents to stimulate further discussion without creating an unmanageable firehose of messages?
*   **Proposed Gating Mechanism:** To manage the flow, the following process is suggested:
    1.  When the moderator publishes an agent's response, it immediately and synchronously prompts all other participating agents with that same response.
    2.  The prompt would ask the other agents a targeted question, such as: "Do you have something extremely valuable to add, or do you strongly disagree with the point being made?"
    3.  This creates a structured and manageable way for agents to build upon or challenge each other's ideas, preventing chaotic, free-for-all communication.

## 4. Proposed Solutions for Out-of-Band Communication

To address the challenge of enabling synchronous, off-the-record communication between the moderator and other agents, the following architectural patterns have been proposed by the researcher:

### a) Direct Execution Service (Recommended)

This approach involves creating a new, internal service that allows the moderator agent to directly invoke the execution logic of other agents.

*   **How it works:** The moderator would call a function like `agentExecutionService.getCompletion(agent, prompt)`, which would synchronously return the agent's response without publishing any Nostr events.
*   **Pros:**
    *   Reuses existing agent execution logic.
    *   Low implementation complexity.
    *   Provides a clear and direct communication path.
*   **Cons:**
    *   Creates a tighter coupling between the moderator and the execution logic.

### b) Internal Event Bus

This pattern introduces a private, in-memory event bus for internal agent communication.

*   **How it works:** The moderator would dispatch an event (e.g., `REQUEST_FOR_IDEAS`) onto the internal bus. Participating agents would listen for these events and publish their responses (e.g., `IDEA_RESPONSE`) back to the same bus. The moderator would then collect all responses.
*   **Pros:**
    *   Highly decoupled architecture.
*   **Cons:**
    *   Increased complexity in setup and management.
    *   Potential for race conditions if not managed carefully.

### c) Centralized Agent RPC Manager

This hybrid approach establishes a single manager to handle all internal agent-to-agent Remote Procedure Calls (RPC).

*   **How it works:** The moderator would make a request to the `RPCManager` (e.g., `rpcManager.getCompletionFrom(agent, prompt)`). The manager would then handle the underlying communication with the target agent and return the result.
*   **Pros:**
    *   Centralized control and observability.
*   **Cons:**
    *   Can become a performance bottleneck.
    *   Adds another layer of indirection.

### d) Threaded Replies with Re-signing (User-proposed)

This user-proposed solution leverages the existing Nostr event structure in a novel way, keeping brainstorming side-chatter off the main conversation root.

*   **How it works:**
    1.  Instead of a fully out-of-band process, agents publish their responses as standard Nostr events. However, they `e`-tag the *triggering event* (the moderator's prompt) rather than the root of the conversation. This effectively places all suggestions into a side-thread.
    2.  The moderator uses the standard `delegate()` tool and is notified once all agents have published their threaded replies.
    3.  The moderator evaluates the side-thread and chooses the best response, returning only the `event id` of its choice.
    4.  A specialized brainstorm handler then fetches the chosen event, and requests the original authoring agent to *re-sign* it. This is a cryptographic operation that does not involve a new LLM call.
    5.  During the re-signing, the `e`-tag is modified to point to the main conversation root, which "promotes" the chosen reply into the primary discussion flow.

*   **Pros:**
    *   Requires minimal changes to the existing agent delegation and publishing flow.
    *   Increases transparency by allowing the human user to see all proposed ideas, not just the one selected by the moderator. This could provide inspiration and learning opportunities.

*   **Cons:**
    *   Publishes all potential responses to the Nostr network, which may be considered noisy.

*   **Viability Analysis (Researcher's Findings):**
    *   **Conclusion:** This approach is highly viable and can be implemented securely.
    *   **Core Principle:** The key is the separation of concerns between an LLM generating content (thinking) and the agent's independent module for cryptographically signing events (proving identity).
    *   **Implementation:** Because signing is a separate cryptographic function, a new event can be created with the same content but a modified `e`-tag. The original agent can then be requested to sign this new event, which does **not** require a new LLM call. The agent's identity is securely preserved on the "promoted" event.
</file>

<file path="context/nostr.md">
# Nostr Module

## Overview

The `src/nostr` module is responsible for all interactions with the Nostr protocol. This includes managing the Nostr client, publishing events, and handling tasks received from the Nostr network. This module is key to the decentralized and collaborative capabilities of TENEX.

## Key Components

- **`ndkClient.ts`**: Initializes and manages the Nostr Development Kit (NDK) client. It handles the connection to Nostr relays and provides a high-level API for interacting with the Nostr network.

- **`AgentPublisher.ts`**: A class that simplifies the process of publishing agent-related events to the Nostr network. It handles the creation and signing of events, and ensures that they are sent to the appropriate relays.


- **`AgentStreamer.ts`**: Handles streaming of agent responses over the Nostr network.

- **`AgentEventEncoder.ts`** and **`AgentEventDecoder.ts`**: Handle encoding and decoding of agent events for Nostr communication.

- **`types.ts`**: Defines the data structures and types used throughout the Nostr module, such as `NostrEvent`, `NostrTag`, and `NostrProfile`.
</file>

<file path="src/agents/execution/index.ts">
export * from "./AgentExecutor";
export * from "./types";
</file>

<file path="src/agents/utils.ts">
import type { AgentInstance } from "./types";

/**
 * Normalize an agent name to kebab-case
 * Handles common variations like "Project Manager" ‚Üí "project-manager" for slug normalization
 * @param name The name to normalize
 * @returns The normalized name
 */
const normalizeAgentName = (name: string): string => {
  return name
    .toLowerCase()
    .replace(/\s+/g, "-") // Replace spaces with hyphens
    .replace(/_+/g, "-") // Replace underscores with hyphens
    .replace(/[^\w-]/g, "") // Remove non-word characters except hyphens
    .replace(/-+/g, "-") // Replace multiple hyphens with single hyphen
    .replace(/^-|-$/g, ""); // Remove leading/trailing hyphens
};

/**
 * Find an agent by name with case-insensitive and kebab-case normalization fallback
 * @param agents Map of agent slug to AgentInstance
 * @param agentName Name to search for
 * @returns The found agent or undefined
 */
export const findAgentByName = (
  agents: Map<string, AgentInstance>,
  agentName: string
): AgentInstance | undefined => {
  // Try exact match first
  let agent = agents.get(agentName);

  // If not found, try case-insensitive search
  if (!agent) {
    const lowerCaseName = agentName.toLowerCase();
    for (const [key, value] of agents.entries()) {
      if (key.toLowerCase() === lowerCaseName) {
        agent = value;
        break;
      }
    }
  }

  // If still not found, try normalized kebab-case search
  if (!agent) {
    const normalizedName = normalizeAgentName(agentName);
    for (const [key, value] of agents.entries()) {
      if (normalizeAgentName(key) === normalizedName) {
        agent = value;
        break;
      }
    }
  }

  return agent;
};
</file>

<file path="src/conversations/processors/DelegationFormatter.ts">
import { getAgentSlugFromEvent, isEventFromUser } from "@/nostr/utils";
import { getProjectContext } from "@/services";
import type { NDKEvent } from "@nostr-dev-kit/ndk";
import type { ModelMessage } from "ai";
import { NostrEntityProcessor } from "./NostrEntityProcessor";
import { stripThinkingBlocks, isOnlyThinkingBlocks, hasReasoningTag } from "../utils/content-utils";

/**
 * Handles formatting of delegation-related messages
 * Single Responsibility: Format delegation contexts and responses
 * Note: Strip <thinking>...</thinking> blocks from conversation history; skip messages that are purely thinking blocks.
 */
export class DelegationFormatter {
    /**
     * Build "Messages While You Were Away" block for catching up on conversation history
     */
    static async buildMissedMessagesBlock(
        events: NDKEvent[], 
        agentSlug: string,
        delegationSummary?: string
    ): Promise<ModelMessage> {
        let contextBlock = "=== MESSAGES WHILE YOU WERE AWAY ===\n\n";

        if (delegationSummary) {
            contextBlock += `**Previous context**: ${delegationSummary}\n\n`;
        }

        for (const event of events) {
            const sender = DelegationFormatter.getEventSender(event, agentSlug);
            if (sender && event.content) {
                // Skip events with reasoning tag
                if (hasReasoningTag(event)) {
                    continue;
                }
                // Skip events that are purely thinking blocks
                if (isOnlyThinkingBlocks(event.content)) {
                    continue;
                }
                
                // Strip thinking blocks from content
                const strippedContent = stripThinkingBlocks(event.content);
                
                const processed = await NostrEntityProcessor.processEntities(strippedContent);
                contextBlock += `${sender}:\n${processed}\n\n`;
            }
        }

        contextBlock += "=== END OF HISTORY ===\n";
        contextBlock += "Respond to the most recent user message above, considering the context.\n\n";

        return { role: "system", content: contextBlock };
    }

    /**
     * Build delegation responses block
     */
    static buildDelegationResponsesBlock(
        responses: Map<string, NDKEvent>, 
        originalRequest: string
    ): ModelMessage {
        let message = "=== DELEGATE RESPONSES RECEIVED ===\n\n";
        message += `You previously delegated the following request to ${responses.size} agent(s):\n`;
        message += `"${originalRequest}"\n\n`;
        message += "Here are all the responses:\n\n";

        const projectCtx = getProjectContext();
        for (const [pubkey, event] of responses) {
            const agent = projectCtx.getAgentByPubkey(pubkey);
            const agentName = agent?.name || pubkey.substring(0, 8);
            
            // Skip if response has reasoning tag
            if (hasReasoningTag(event)) {
                continue;
            }
            // Skip if response is purely thinking blocks
            if (!event.content || isOnlyThinkingBlocks(event.content)) {
                continue;
            }
            
            // Strip thinking blocks from response content
            const strippedContent = stripThinkingBlocks(event.content);
            
            message += `### Response from ${agentName}:\n`;
            message += `${strippedContent}\n\n`;
        }

        message += "=== END OF DELEGATE RESPONSES ===\n\n";
        message += "Now process these responses and complete your task.";

        return { role: "system", content: message };
    }

    /**
     * Helper to determine event sender for display purposes
     */
    private static getEventSender(event: NDKEvent, currentAgentSlug: string): string | null {
        const eventAgentSlug = getAgentSlugFromEvent(event);

        if (isEventFromUser(event)) {
            return "üü¢ USER";
        }
        if (eventAgentSlug) {
            const projectCtx = getProjectContext();
            const sendingAgent = projectCtx.agents.get(eventAgentSlug);
            const agentName = sendingAgent ? sendingAgent.name : "Another agent";

            // Mark the agent's own previous messages clearly
            if (eventAgentSlug === currentAgentSlug) {
                return `üí¨ You (${agentName})`;
            }
            return `üí¨ ${agentName}`;
        }
        return "üí¨ Unknown";
    }
}
</file>

<file path="src/conversations/processors/NostrEntityProcessor.ts">
import { getNDK } from "@/nostr";
import { logger } from "@/utils/logger";

/**
 * Handles processing of nostr entities in message content
 * Single Responsibility: Fetch and inline nostr event content
 * Note: Thinking block stripping is handled by content-utils.ts
 */
export class NostrEntityProcessor {
    private static readonly NOSTR_ENTITY_REGEX = /nostr:(nevent1|naddr1|note1|npub1|nprofile1)\w+/g;

    /**
     * Process nostr entities in content, replacing them with inline content
     */
    static async processEntities(content: string): Promise<string> {
        const entities = content.match(NostrEntityProcessor.NOSTR_ENTITY_REGEX);
        if (!entities || entities.length === 0) {
            return content;
        }

        let processedContent = content;
        const ndk = getNDK();

        for (const entity of entities) {
            try {
                const bech32Id = entity.replace("nostr:", "");
                const event = await ndk.fetchEvent(bech32Id);

                if (event) {
                    const inlinedContent = `<nostr-event entity="${entity}">${event.content}</nostr-event>`;
                    processedContent = processedContent.replace(entity, inlinedContent);

                    logger.debug("[NostrEntityProcessor] Inlined nostr entity", {
                        entity,
                        kind: event.kind,
                        contentLength: event.content?.length || 0,
                    });
                }
            } catch (error) {
                logger.warn("[NostrEntityProcessor] Failed to fetch nostr entity", {
                    entity,
                    error,
                });
                // Keep original entity if fetch fails
            }
        }

        return processedContent;
    }

    /**
     * Check if content contains nostr entities
     */
    static hasEntities(content: string): boolean {
        return NostrEntityProcessor.NOSTR_ENTITY_REGEX.test(content);
    }

    /**
     * Extract nostr entities from content
     */
    static extractEntities(content: string): string[] {
        const matches = content.match(NostrEntityProcessor.NOSTR_ENTITY_REGEX);
        return matches || [];
    }
}
</file>

<file path="src/conversations/index.ts">
export { ConversationCoordinator } from "./services/ConversationCoordinator";
export * from "./types";
</file>

<file path="src/events/NDKEventMetadata.ts">
import { NDKEvent } from "@nostr-dev-kit/ndk";

/**
 * NDKEventMetadata - Kind 513
 * 
 * Allows setting metadata about conversations:
 * - ["e", "<event-id>"] - References the conversation
 * - ["title", "title-of-the-conversation"] - Sets the conversation title
 */
export class NDKEventMetadata extends NDKEvent {
    static kind = 513;

    static from(event: NDKEvent): NDKEventMetadata {
        return new NDKEventMetadata(event.ndk, event);
    }

    get conversationId(): string | undefined {
        return this.tagValue("e");
    }

    get title(): string | undefined {
        return this.tagValue("title");
    }

    set title(value: string) {
        this.removeTag("title");
        this.tags.push(["title", value]);
    }

    setConversationId(eventId: string): void {
        this.removeTag("e");
        this.tags.push(["e", eventId]);
    }
}
</file>

<file path="src/events/NDKMCPTool.ts">
import type NDK from "@nostr-dev-kit/ndk";
import { NDKEvent, type NDKRawEvent } from "@nostr-dev-kit/ndk";

export class NDKMCPTool extends NDKEvent {
  static kind = 4200;
  static kinds = [4200];

  constructor(ndk?: NDK, event?: NDKEvent | NDKRawEvent) {
    super(ndk, event);
    this.kind ??= 4200;
  }

  static from(event: NDKEvent): NDKMCPTool {
    return new NDKMCPTool(event.ndk, event);
  }

  get name(): string | undefined {
    return this.tagValue("name");
  }

  set name(value: string | undefined) {
    this.removeTag("name");
    if (value) this.tags.push(["name", value]);
  }

  get description(): string | undefined {
    return this.tagValue("description");
  }

  set description(value: string | undefined) {
    this.removeTag("description");
    if (value) this.tags.push(["description", value]);
  }

  get command(): string | undefined {
    return this.tagValue("command");
  }

  set command(value: string | undefined) {
    this.removeTag("command");
    if (value) this.tags.push(["command", value]);
  }

  get image(): string | undefined {
    return this.tagValue("image");
  }

  set image(value: string | undefined) {
    this.removeTag("image");
    if (value) this.tags.push(["image", value]);
  }

  get slug(): string {
    const name = this.name || "unnamed";
    return name
      .toLowerCase()
      .replace(/[^a-z0-9]+/g, "-")
      .replace(/^-|-$/g, "");
  }
}
</file>

<file path="src/llm/utils/ConfigurationManager.ts">
import type { TenexLLMs, LLMConfiguration } from "@/services/config/types";
import inquirer from "inquirer";
import chalk from "chalk";
import type { AISdkProvider } from "../types";
import { ModelSelector } from "./ModelSelector";
import { ProviderConfigUI } from "./ProviderConfigUI";

/**
 * Manages LLM configuration CRUD operations
 */
export class ConfigurationManager {
  static async add(llmsConfig: TenexLLMs, isFirstConfig = false): Promise<void> {
    const configuredProviders = Object.keys(llmsConfig.providers).filter(
      p => llmsConfig.providers[p]?.apiKey
    );
    
    if (configuredProviders.length === 0) {
      console.log(chalk.yellow("‚ö†Ô∏è  No providers configured. Please configure API keys first."));
      return;
    }
    
    // Select provider
    const { provider } = await inquirer.prompt([{
      type: "list",
      name: "provider",
      message: "Select provider:",
      choices: configuredProviders.map(p => ({
        name: ProviderConfigUI.getProviderDisplayName(p),
        value: p
      }))
    }]);
    
    // Select model based on provider
    let model: string;
    if (provider === 'openrouter') {
      model = await ModelSelector.selectOpenRouterModel();
    } else if (provider === 'ollama') {
      model = await ModelSelector.selectOllamaModel();
    } else {
      const { inputModel } = await inquirer.prompt([{
        type: "input",
        name: "inputModel",
        message: "Enter model name:",
        default: this.getDefaultModelForProvider(provider as AISdkProvider),
        validate: (input: string) => {
          if (!input.trim()) return "Model name is required";
          return true;
        }
      }]);
      model = inputModel;
    }
    
    // Optional settings
    const { temperature, maxTokens } = await inquirer.prompt([
      {
        type: "input",
        name: "temperature",
        message: "Temperature (0-2, press enter to skip):",
        validate: (input: string) => {
          if (!input) return true;
          const num = parseFloat(input);
          if (isNaN(num) || num < 0 || num > 2) return "Temperature must be between 0 and 2";
          return true;
        }
      },
      {
        type: "input",
        name: "maxTokens",
        message: "Max tokens (press enter to skip):",
        validate: (input: string) => {
          if (!input) return true;
          const num = parseInt(input);
          if (isNaN(num) || num <= 0) return "Max tokens must be a positive number";
          return true;
        }
      }
    ]);
    
    // Name the configuration
    const { name } = await inquirer.prompt([{
      type: "input",
      name: "name",
      message: "Configuration name:",
      default: isFirstConfig ? "default" : undefined,
      validate: (input: string) => {
        if (!input.trim()) return "Name is required";
        if (llmsConfig.configurations[input]) return "Configuration already exists";
        return true;
      }
    }]);
    
    // Create configuration
    const config: LLMConfiguration = {
      provider,
      model
    };
    
    if (temperature) config.temperature = parseFloat(temperature);
    if (maxTokens) config.maxTokens = parseInt(maxTokens);
    
    llmsConfig.configurations[name] = config;
    
    // Set as default if first or ask user
    if (isFirstConfig || !llmsConfig.default) {
      llmsConfig.default = name;
      console.log(chalk.green(`‚úÖ Configuration "${name}" created and set as default`));
    } else {
      const { setAsDefault } = await inquirer.prompt([{
        type: "confirm",
        name: "setAsDefault",
        message: "Set as default configuration?",
        default: false
      }]);
      
      if (setAsDefault) {
        llmsConfig.default = name;
      }
      console.log(chalk.green(`‚úÖ Configuration "${name}" created`));
    }
  }

  static async delete(llmsConfig: TenexLLMs): Promise<void> {
    const configNames = Object.keys(llmsConfig.configurations);
    
    if (configNames.length === 0) {
      console.log(chalk.yellow("‚ö†Ô∏è  No configurations to delete"));
      return;
    }
    
    const { name } = await inquirer.prompt([{
      type: "list",
      name: "name",
      message: "Select configuration to delete:",
      choices: configNames.map(n => ({
        name: n === llmsConfig.default ? `${n} (default)` : n,
        value: n
      }))
    }]);
    
    const { confirm } = await inquirer.prompt([{
      type: "confirm",
      name: "confirm",
      message: `Are you sure you want to delete "${name}"?`,
      default: false
    }]);
    
    if (confirm) {
      delete llmsConfig.configurations[name];
      
      // Update default if needed
      if (llmsConfig.default === name) {
        const remaining = Object.keys(llmsConfig.configurations);
        llmsConfig.default = remaining.length > 0 ? remaining[0] : undefined;
        
        if (llmsConfig.default) {
          console.log(chalk.yellow(`Default changed to "${llmsConfig.default}"`));
        }
      }
      
      console.log(chalk.green(`‚úÖ Configuration "${name}" deleted`));
    }
  }

  static async setDefault(llmsConfig: TenexLLMs): Promise<void> {
    const configNames = Object.keys(llmsConfig.configurations);
    
    if (configNames.length === 0) {
      console.log(chalk.yellow("‚ö†Ô∏è  No configurations available"));
      return;
    }
    
    const { name } = await inquirer.prompt([{
      type: "list",
      name: "name",
      message: "Select default configuration:",
      choices: configNames.map(n => ({
        name: n === llmsConfig.default ? `${n} (current default)` : n,
        value: n
      }))
    }]);
    
    llmsConfig.default = name;
    console.log(chalk.green(`‚úÖ Default configuration set to "${name}"`));
  }

  private static getDefaultModelForProvider(provider: AISdkProvider): string {
    const defaults: Record<AISdkProvider, string> = {
      openrouter: "openai/gpt-4",
      anthropic: "claude-3-5-sonnet-latest",
      openai: "gpt-4",
      ollama: "llama3.1:8b",
      claudeCode: "claude-3-5-sonnet-20241022" // Default model for Claude Code
    };
    return defaults[provider] || "";
  }
}
</file>

<file path="src/llm/utils/ProviderConfigUI.ts">
import inquirer from "inquirer";
import chalk from "chalk";
import type { TenexLLMs } from "@/services/config/types";

/**
 * UI utilities for provider configuration
 * Extracted from LLMConfigEditor to separate concerns
 */
export class ProviderConfigUI {
  /**
   * Get provider display names
   */
  static getProviderDisplayName(provider: string): string {
    const names: Record<string, string> = {
      openrouter: "OpenRouter (300+ models)",
      anthropic: "Anthropic (Claude)",
      openai: "OpenAI (GPT)",
      ollama: "Ollama (Local models)",
      claudeCode: "Claude Code (Limited - Phase 0 only)"
    };
    return names[provider] || provider;
  }

  /**
   * Configure a specific provider interactively
   */
  static async configureProvider(provider: string, currentConfig?: TenexLLMs): Promise<{ apiKey: string }> {
    if (provider === 'ollama') {
      // For Ollama, ask for base URL instead of API key
      const currentUrl = currentConfig?.providers[provider]?.apiKey || 'local';
      const { ollamaConfig } = await inquirer.prompt([{
        type: "list",
        name: "ollamaConfig",
        message: "Ollama configuration:",
        choices: [
          { name: "Use local Ollama (http://localhost:11434)", value: "local" },
          { name: "Use custom Ollama URL", value: "custom" }
        ],
        default: currentUrl === 'local' ? 'local' : 'custom'
      }]);
      
      let baseUrl = 'local';
      if (ollamaConfig === 'custom') {
        const { customUrl } = await inquirer.prompt([{
          type: "input",
          name: "customUrl",
          message: "Enter Ollama base URL:",
          default: currentUrl !== 'local' ? currentUrl : 'http://localhost:11434',
          validate: (input: string) => {
            if (!input.trim()) return "URL is required";
            try {
              new URL(input);
              return true;
            } catch {
              return "Please enter a valid URL";
            }
          }
        }]);
        baseUrl = customUrl;
      }
      
      return { apiKey: baseUrl };
    } else {
      // For other providers, ask for API key
      const currentKey = currentConfig?.providers[provider]?.apiKey;
      const { apiKey } = await inquirer.prompt([{
        type: "password",
        name: "apiKey",
        message: `Enter API key for ${this.getProviderDisplayName(provider)} (press Enter to keep existing):`,
        default: currentKey,
        mask: "*",
        validate: (input: string) => {
          // Allow empty input if there's an existing key
          if (!input.trim() && !currentKey) return "API key is required";
          return true;
        }
      }]);
      
      return { apiKey: apiKey || currentKey || "" };
    }
  }

  /**
   * Display current configuration status
   */
  static displayCurrentConfig(llmsConfig: TenexLLMs): void {
    console.log(chalk.bold("Configured Providers:"));
    const providers = Object.keys(llmsConfig.providers).filter(
      p => llmsConfig.providers[p]?.apiKey
    );
    if (providers.length === 0) {
      console.log(chalk.gray("  None configured"));
    } else {
      providers.forEach(p => {
        console.log(chalk.green(`  ‚úì ${this.getProviderDisplayName(p)}`));
      });
    }
    
    console.log(chalk.bold("\nConfigurations:"));
    const configNames = Object.keys(llmsConfig.configurations);
    if (configNames.length === 0) {
      console.log(chalk.gray("  None"));
    } else {
      configNames.forEach(name => {
        const config = llmsConfig.configurations[name];
        const isDefault = name === llmsConfig.default;
        const marker = isDefault ? chalk.cyan('‚Ä¢ ') : '  ';
        const defaultTag = isDefault ? chalk.gray(' (default)') : '';
        console.log(`  ${marker}${name}${defaultTag}: ${config.provider}:${config.model}`);
      });
    }
  }
}
</file>

<file path="src/llm/constants.ts">
/**
 * LLM Configuration Constants
 */

// Default configuration name for agents when no llmConfig is specified
export const DEFAULT_AGENT_LLM_CONFIG = "default";
</file>

<file path="src/prompts/fragments/01-agent-identity.ts">
import type { AgentInstance } from "@/agents/types";
import { fragmentRegistry } from "../core/FragmentRegistry";
import type { PromptFragment } from "../core/types";

/**
 * Identity fragment for agents.
 */
interface AgentIdentityArgs {
  agent: AgentInstance;
  projectTitle: string;
  projectOwnerPubkey: string;
}

export const agentIdentityFragment: PromptFragment<AgentIdentityArgs> = {
  id: "agent-identity",
  priority: 1,
  template: ({ agent, projectTitle, projectOwnerPubkey }) => {
    const parts: string[] = [];

    // Identity
    parts.push("# Your Identity\n");
    parts.push(`Your name: ${agent.name} (${agent.slug})`);
    if (agent.role) {
      parts.push(`Your role: ${agent.role}`);
    }
    parts.push(`Your npub: ${agent.signer.npub}`);
    parts.push(`Your nsec: ${agent.signer.nsec} -- this is your real nsec and you CAN and SHOULD use it when you encounter a tool that needs an nsec.`);
    parts.push("");

    // Instructions
    if (agent.instructions) {
      parts.push(`## Your Instructions\n${agent.instructions}\n`);
    }

    // Project context
    parts.push(
      [
        "## Project Context",
        `- Title: "${projectTitle}"`,
        `- Path: ${process.cwd()}`,
        `- User pubkey: "${projectOwnerPubkey}"`,
      ].join("\n")
    );

    return parts.join("\n");
  },
};

// Register the fragment
fragmentRegistry.register(agentIdentityFragment);
</file>

<file path="src/prompts/fragments/30-project-md.ts">
import fs from "node:fs";
import path from "node:path";
import { countTotalFiles } from "../utils/projectUtils";
import { fragmentRegistry } from "@/prompts/core/FragmentRegistry";
import type { PromptFragment } from "@/prompts/core/types";

const description = `
## PROJECT SPEC

The PROJECT.md maintains your living understanding of:
- What the project is.
- What assumptions you've made to fill in gaps.
- How the project has evolved based on user feedback.

During REFLECTION phase, update context/PROJECT.md with everything new you learned 
about what the project you manage is:

- Every single detail the user has explicitly described about the project
- Clear delineations between what the user stated vs. your assumptions
- Example: User says "make a calculator" - multiplication support is a 
safe assumption, but still an assumption.
- If the project has screns or pages, you should explain, in a dedicated "User Flows" section, the user flows, features and how it all comes together.

## DOES and DON'Ts for PROJECT.md:
- ‚úÖ DO describe in great level of detail how things technically fit together in high-level.
- ‚úÖ DO think "if five different codebases in different languages were to implement this: what must they all have in common?"

- ‚ùå DON'T describe known issues in the current implementation
- ‚ùå DON'T focus on technical details (i.e. language used in the implementation, tech stacks)
- ‚ùå DON'T discuss code, architectural choices or modules.

CRTICIAL: The correct way to think about PROJECT.md is: "If I had to recreate the entire project from a single product spec, a spec that defines every nuance, every corner of what I know for certain the project is supposed to be: what would that spec be?"

PROJECT.md is NOT the place for code, tech stack, architectural choices or modules, its the place to detail, in as great level of detail and accuracy as possible, what it is we are working on.
`;

interface ProjectMdArgs {
  projectPath?: string;
}

export const projectMdFragment: PromptFragment<ProjectMdArgs> = {
  id: "project-md",
  priority: 30,
  template: () => {
    const projectMdPath = path.join("context", "PROJECT.md");
    let content: string;

    try {
      if (fs.existsSync(projectMdPath)) {
        content = fs.readFileSync(projectMdPath, "utf-8");
      } else {
        // PROJECT.md doesn't exist - check if this is an established project
        const fileCount = countTotalFiles(process.cwd());
        
        if (fileCount > 10) {
          content = `The PROJECT.md file doesn't exist yet. This appears to be an established project with ${fileCount} files.

**CRITICAL**: You MUST create a PROJECT.md immediately. As the PM agent, work with another agent to explore the codebase comprehensively. Use open-ended exploration:

1. Start with: "Explore this codebase thoroughly and tell me what this project does, its main features, and how users interact with it"
2. Follow up with specific questions based on what you learn:
   - "What are the main user-facing features?"
   - "What problems does this solve for users?"
   - "Describe the user journey from start to finish"
   - "Are there different user roles or personas?"
   - "What are the key workflows or processes?"

Remember: The agent helping you may not understand PROJECT.md's purpose. Focus on extracting PROJECT SPECIFICATION details (what the product IS and DOES for users, not HOW it's technically built).`;
        } else {
          content = "The PROJECT.md file doesn't exist yet. This appears to be a new or small project. Work with the user to define what this project should be, validating your understanding through clarifying questions. It's better to underdefine the project spec than to proceed with incorrect assumptions.";
        }
      }
    } catch {
      // Fallback if anything goes wrong
      content = "The PROJECT.md file doesn't exist yet. Work with the user to understand and document what this project is about.";
    }

    return `${description}

<PROJECT.md>
${content}
</PROJECT.md>`;
  },

  validateArgs: (_args): _args is ProjectMdArgs => {
    return true;
  },
  expectedArgs: "{ projectPath?: string, currentAgent?: { id: string, slug?: string } }",
};

// Register the fragment
fragmentRegistry.register(projectMdFragment);
</file>

<file path="src/services/mcp/mcpInstaller.ts">
import type { NDKMCPTool } from "@/events/NDKMCPTool";
import { configService } from "@/services/ConfigService";
import type { MCPServerConfig } from "@/services/config/types";
import { logger } from "@/utils/logger";

/**
 * Installs an MCP server from an NDKMCPTool event into a project's configuration
 * @param projectPath The root project path (not the .tenex directory)
 */
export async function installMCPServerFromEvent(
  projectPath: string,
  mcpTool: NDKMCPTool
): Promise<void> {
  const serverName = mcpTool.slug;
  const command = mcpTool.command;

  if (!command) {
    throw new Error(`MCP tool event ${mcpTool.id} is missing command tag`);
  }

  // Parse command and args
  const [cmd, ...args] = command.split(" ");

  // Build server config with event ID
  const serverConfig: MCPServerConfig = {
    command: cmd || "",
    args,
    description: mcpTool.description,
    eventId: mcpTool.id, // Track the event ID
  };

  // Load existing MCP config from the project's .tenex directory
  const tenexPath = configService.getProjectPath(projectPath);
  const mcpConfig = await configService.loadTenexMCP(tenexPath);

  // Check if this event ID is already installed (only if we have an event ID)
  if (mcpTool.id && (await isMCPToolInstalled(projectPath, mcpTool.id))) {
    logger.info(`MCP tool with event ID ${mcpTool.id} already installed`, { projectPath });
    return;
  }

  // Check if server with same name already exists
  if (mcpConfig.servers[serverName]) {
    // If it exists without an event ID and we're adding one with an event ID, update it
    if (!mcpConfig.servers[serverName].eventId && mcpTool.id) {
      logger.info(`Updating existing MCP server '${serverName}' with event ID`, {
        projectPath,
        eventId: mcpTool.id,
      });
    } else {
      logger.info(`MCP server '${serverName}' already exists`, { projectPath });
      return;
    }
  }

  // Add new server
  mcpConfig.servers[serverName] = serverConfig;

  // Save config (saveProjectMCP expects the project root path)
  await configService.saveProjectMCP(projectPath, mcpConfig);

  logger.info(`Auto-installed MCP server: ${serverName}`, {
    projectPath,
    command: cmd,
    args,
    eventId: mcpTool.id,
  });
}

/**
 * Checks if an MCP tool with a given event ID is already installed
 */
export async function isMCPToolInstalled(projectPath: string, eventId: string): Promise<boolean> {
  // Load from the project's .tenex directory
  const tenexPath = configService.getProjectPath(projectPath);
  const mcpConfig = await configService.loadTenexMCP(tenexPath);

  // Check if any server has this event ID
  for (const serverConfig of Object.values(mcpConfig.servers)) {
    if (serverConfig.eventId === eventId) {
      return true;
    }
  }

  return false;
}

/**
 * Gets all installed MCP tool event IDs (only those that have event IDs)
 */
export async function getInstalledMCPEventIds(projectPath: string): Promise<Set<string>> {
  // Load from the project's .tenex directory
  const tenexPath = configService.getProjectPath(projectPath);
  const mcpConfig = await configService.loadTenexMCP(tenexPath);
  const eventIds = new Set<string>();

  for (const serverConfig of Object.values(mcpConfig.servers)) {
    // Only add if eventId exists (some MCP tools are manually installed without event IDs)
    if (serverConfig.eventId) {
      eventIds.add(serverConfig.eventId);
    }
  }

  return eventIds;
}

/**
 * Removes an MCP server by its event ID
 */
export async function removeMCPServerByEventId(
  projectPath: string,
  eventId: string
): Promise<void> {
  // Load from the project's .tenex directory
  const tenexPath = configService.getProjectPath(projectPath);
  const mcpConfig = await configService.loadTenexMCP(tenexPath);

  // Find and remove servers with this event ID
  let removed = false;
  for (const [serverName, serverConfig] of Object.entries(mcpConfig.servers)) {
    if (serverConfig.eventId === eventId) {
      delete mcpConfig.servers[serverName];
      removed = true;
      logger.info(`Removed MCP server '${serverName}' with event ID ${eventId}`);
    }
  }

  if (removed) {
    // Save updated config
    await configService.saveProjectMCP(projectPath, mcpConfig);
  } else {
    logger.warn(`No MCP server found with event ID ${eventId}`);
  }
}
</file>

<file path="src/services/status/index.ts">
export { StatusPublisher } from "./StatusPublisher";
</file>

<file path="src/services/OperationsStatusPublisher.ts">
import { EVENT_KINDS } from "@/llm/types";
import { getNDK } from "@/nostr/ndkClient";
import { getProjectContext, isProjectContextInitialized } from "@/services";
import type { ProjectContext } from "@/services/ProjectContext";
import { formatAnyError } from "@/utils/error-formatter";
import { logger } from "@/utils/logger";
import { NDKEvent } from "@nostr-dev-kit/ndk";
import type { LLMOperationsRegistry } from "./LLMOperationsRegistry";

/**
 * OperationsStatusPublisher handles publishing of LLM operation status events to Nostr.
 * 
 * Publishes one event per event being processed, with:
 * - One e-tag for the event being processed
 * - P-tags for all agents working on that event
 * - One a-tag for the project reference
 */
export class OperationsStatusPublisher {
  private debounceTimer?: NodeJS.Timeout;
  private unsubscribe?: () => void;
  private publishedEvents = new Set<string>(); // Track which events we've published status for
  private lastPublishedState = new Map<string, Set<string>>(); // Track which agents were published per event
  
  constructor(
    private registry: LLMOperationsRegistry,
    private debounceMs: number = 100
  ) {}
  
  start(): void {
    // Subscribe to registry changes
    this.unsubscribe = this.registry.onChange(() => {
      this.schedulePublish();
    });
    
    // Publish initial state if any operations exist
    this.publishNow().catch(err => {
      logger.error('[OperationsStatusPublisher] Failed to publish initial state', {
        error: formatAnyError(err)
      });
    });
  }
  
  stop(): void {
    if (this.unsubscribe) {
      this.unsubscribe();
      this.unsubscribe = undefined;
    }
    if (this.debounceTimer) {
      clearTimeout(this.debounceTimer);
      this.debounceTimer = undefined;
    }
  }
  
  private schedulePublish(): void {
    // Clear existing timer
    if (this.debounceTimer) {
      clearTimeout(this.debounceTimer);
    }
    
    // Schedule new publish
    this.debounceTimer = setTimeout(() => {
      this.publishNow().catch(err => {
        logger.error('[OperationsStatusPublisher] Failed to publish status', {
          error: formatAnyError(err)
        });
      });
    }, this.debounceMs);
  }
  
  private async publishNow(): Promise<void> {
    if (!isProjectContextInitialized()) {
      logger.debug('[OperationsStatusPublisher] Project context not initialized, skipping publish');
      return;
    }
    
    const projectCtx = getProjectContext();
    const operationsByEvent = this.registry.getOperationsByEvent();
    
    // Keep track of currently active events
    const currentEventIds = new Set(operationsByEvent.keys());
    
    // Track events we need to clean up
    const eventsToCleanup = new Set<string>();
    
    // Check which previously published events are no longer active
    for (const eventId of this.publishedEvents) {
      if (!currentEventIds.has(eventId)) {
        eventsToCleanup.add(eventId);
      }
    }
    
    // Log current state for debugging
    if (operationsByEvent.size > 0 || eventsToCleanup.size > 0) {
      logger.debug('[OperationsStatusPublisher] Current state', {
        activeEvents: Array.from(currentEventIds).map(id => id.substring(0, 8)),
        previouslyPublished: Array.from(this.publishedEvents).map(id => id.substring(0, 8)),
        toCleanup: Array.from(eventsToCleanup).map(id => id.substring(0, 8))
      });
    }
    
    // Publish one 24133 event per event being processed
    for (const [eventId, operations] of operationsByEvent) {
      try {
        // Only publish if state changed or not previously published
        if (!this.publishedEvents.has(eventId) || this.hasOperationsChanged(eventId, operations)) {
          await this.publishEventStatus(eventId, operations, projectCtx);
          this.publishedEvents.add(eventId);
          this.lastPublishedState.set(eventId, new Set(operations.map(op => op.agentPubkey)));
        }
      } catch (err) {
        logger.error('[OperationsStatusPublisher] Failed to publish event status', {
          eventId: eventId.substring(0, 8),
          error: formatAnyError(err)
        });
      }
    }
    
    // Publish cleanup events (empty p-tags) for completed events
    for (const eventId of eventsToCleanup) {
      try {
        logger.debug('[OperationsStatusPublisher] Publishing cleanup event', {
          eventId: eventId.substring(0, 8)
        });
        await this.publishEventStatus(eventId, [], projectCtx);
        this.publishedEvents.delete(eventId);
        this.lastPublishedState.delete(eventId);
      } catch (err) {
        logger.error('[OperationsStatusPublisher] Failed to publish cleanup status', {
          eventId: eventId.substring(0, 8),
          error: formatAnyError(err)
        });
      }
    }
    
    logger.debug('[OperationsStatusPublisher] Published status', {
      activeEvents: operationsByEvent.size,
      cleanedEvents: eventsToCleanup.size,
      totalOperations: Array.from(operationsByEvent.values()).reduce((sum, ops) => sum + ops.length, 0)
    });
  }
  
  private hasOperationsChanged(eventId: string, operations: any[]): boolean {
    const lastState = this.lastPublishedState.get(eventId);
    if (!lastState) return true;
    
    const currentAgents = new Set(operations.map(op => op.agentPubkey));
    if (lastState.size !== currentAgents.size) return true;
    
    for (const agent of currentAgents) {
      if (!lastState.has(agent)) return true;
    }
    
    return false;
  }
  
  private async publishEventStatus(
    eventId: string, 
    operations: any[], // Using any to avoid circular dependency with LLMOperation type
    projectCtx: ProjectContext
  ): Promise<void> {
    const event = new NDKEvent(getNDK());
    event.kind = EVENT_KINDS.OPERATIONS_STATUS;
    event.content = "";
    
    // Single e-tag for the event being processed
    event.tag(["e", eventId]);
    
    // P-tags for all agents working on this event
    const agentPubkeys = new Set(operations.map(op => op.agentPubkey));
    for (const pubkey of agentPubkeys) {
      event.tag(["p", pubkey]);
    }
    
    // A-tag for the project
    event.tag(projectCtx.project.tagReference());
    
    // Sign with project signer and publish if available
    if (projectCtx.signer) {
      await event.sign(projectCtx.signer);
      await event.publish();
    } else {
      logger.warn("No project signer available, cannot publish operations status event");
      return;
    }
    
    const isCleanup = operations.length === 0;
    logger.info('[OperationsStatusPublisher] Published event status', {
      eventId: eventId.substring(0, 8),
      agentCount: agentPubkeys.size,
      operationCount: operations.length,
      type: isCleanup ? 'cleanup' : 'active',
      pTags: Array.from(agentPubkeys).map(p => p.substring(0, 8))
    });
  }
}
</file>

<file path="src/services/PubkeyNameRepository.ts">
import { getNDK } from "@/nostr";
import { getProjectContext, isProjectContextInitialized } from "@/services";
import { logger } from "@/utils/logger";
import type { Hexpubkey, NDKEvent } from "@nostr-dev-kit/ndk";

interface UserProfile {
  name?: string;
  display_name?: string;
  username?: string;
  about?: string;
  picture?: string;
  fetchedAt: number;
}

interface CacheEntry {
  profile: UserProfile;
  ttl: number;
}

/**
 * Central repository for mapping pubkeys to human-readable names.
 * Handles both agent pubkeys (mapped to slugs) and user pubkeys (fetched from kind:0 events).
 */
export class PubkeyNameRepository {
  private static instance: PubkeyNameRepository;
  
  private userProfileCache: Map<Hexpubkey, CacheEntry> = new Map();
  private readonly CACHE_TTL_MS = 10 * 60 * 1000; // 10 minutes
  private readonly DEFAULT_USER_NAME = "User";
  private readonly DEFAULT_UNKNOWN_NAME = "Unknown";
  
  private constructor() {}
  
  /**
   * Get singleton instance
   */
  static getInstance(): PubkeyNameRepository {
    if (!PubkeyNameRepository.instance) {
      PubkeyNameRepository.instance = new PubkeyNameRepository();
    }
    return PubkeyNameRepository.instance;
  }
  
  /**
   * Get a display name for any pubkey (agent or user)
   */
  async getName(pubkey: Hexpubkey): Promise<string> {
    // First, check if it's an agent
    const agentSlug = this.getAgentSlug(pubkey);
    if (agentSlug) {
      return agentSlug;
    }
    
    // It's a user - fetch their profile
    const profile = await this.getUserProfile(pubkey);
    return this.extractDisplayName(profile);
  }
  
  /**
   * Get a display name synchronously (uses cache only, no fetching)
   */
  getNameSync(pubkey: Hexpubkey): string {
    // First, check if it's an agent
    const agentSlug = this.getAgentSlug(pubkey);
    if (agentSlug) {
      return agentSlug;
    }
    
    // Check cache for user profile
    const cached = this.userProfileCache.get(pubkey);
    if (cached && Date.now() < cached.ttl) {
      return this.extractDisplayName(cached.profile);
    }
    
    // Return default if nothing found
    return this.DEFAULT_USER_NAME;
  }
  
  /**
   * Get agent slug for a pubkey if it belongs to an agent
   */
  private getAgentSlug(pubkey: Hexpubkey): string | undefined {
    if (!isProjectContextInitialized()) {
      return undefined;
    }
    
    const projectCtx = getProjectContext();
    
    // Check all agents
    for (const [slug, agent] of projectCtx.agents) {
      if (agent.pubkey === pubkey) {
        return slug;
      }
    }
    
    return undefined;
  }
  
  /**
   * Fetch user profile from kind:0 event
   */
  private async getUserProfile(pubkey: Hexpubkey): Promise<UserProfile> {
    // Check cache first
    const cached = this.userProfileCache.get(pubkey);
    if (cached && Date.now() < cached.ttl) {
      return cached.profile;
    }
    
    try {
      const ndk = getNDK();
      
      // Fetch kind:0 (metadata) event for this pubkey
      const profileEvent = await ndk.fetchEvent({
        kinds: [0],
        authors: [pubkey],
      });
      
      if (profileEvent) {
        const profile = this.parseProfileEvent(profileEvent);
        
        // Cache the result
        this.userProfileCache.set(pubkey, {
          profile,
          ttl: Date.now() + this.CACHE_TTL_MS,
        });
        
        logger.debug("[PUBKEY_NAME_REPO] Fetched user profile", {
          pubkey,
          name: profile.name,
          display_name: profile.display_name,
        });
        
        return profile;
      }
    } catch (error) {
      logger.warn("[PUBKEY_NAME_REPO] Failed to fetch user profile", {
        pubkey,
        error,
      });
    }
    
    // Return empty profile if fetch failed
    const emptyProfile: UserProfile = { fetchedAt: Date.now() };
    
    // Cache even empty results to avoid repeated failed fetches
    this.userProfileCache.set(pubkey, {
      profile: emptyProfile,
      ttl: Date.now() + this.CACHE_TTL_MS,
    });
    
    return emptyProfile;
  }
  
  /**
   * Parse profile data from kind:0 event
   */
  private parseProfileEvent(event: NDKEvent): UserProfile {
    try {
      const content = JSON.parse(event.content);
      return {
        name: content.name,
        display_name: content.display_name,
        username: content.username,
        about: content.about,
        picture: content.picture,
        fetchedAt: Date.now(),
      };
    } catch (error) {
      logger.warn("[PUBKEY_NAME_REPO] Failed to parse profile content", {
        eventId: event.id,
        error,
      });
      return { fetchedAt: Date.now() };
    }
  }
  
  /**
   * Extract the best display name from a profile
   */
  private extractDisplayName(profile: UserProfile): string {
    // Priority: name > display_name > username > default
    if (profile.name?.trim()) {
      return profile.name.trim();
    }
    if (profile.display_name?.trim()) {
      return profile.display_name.trim();
    }
    if (profile.username?.trim()) {
      return profile.username.trim();
    }
    return this.DEFAULT_USER_NAME;
  }
  
  /**
   * Force refresh a user's profile (bypass cache)
   */
  async refreshUserProfile(pubkey: Hexpubkey): Promise<UserProfile> {
    // Remove from cache to force fresh fetch
    this.userProfileCache.delete(pubkey);
    return this.getUserProfile(pubkey);
  }
  
  /**
   * Clear the entire cache
   */
  clearCache(): void {
    this.userProfileCache.clear();
    logger.debug("[PUBKEY_NAME_REPO] Cache cleared");
  }
  
  /**
   * Get cache statistics for debugging
   */
  getCacheStats(): { size: number; entries: string[] } {
    return {
      size: this.userProfileCache.size,
      entries: Array.from(this.userProfileCache.keys()),
    };
  }
}

// Export singleton instance getter for convenience
export const getPubkeyNameRepository = (): PubkeyNameRepository => PubkeyNameRepository.getInstance();
</file>

<file path="src/test-utils/mock-llm/scenarios/inventory-generation.ts">
import type { MockLLMScenario } from "../types";

/**
 * Inventory generation workflow scenario
 * Tests the complete flow of generating project inventory including:
 * - Initial request in CHAT phase
 * - Transitioning to EXECUTE phase
 * - Using generate_inventory tool
 * - Handling task progress updates
 * - Completing the workflow
 */
export const inventoryGenerationScenario: MockLLMScenario = {
  name: "inventory-generation",
  description: "Complete workflow for generating project inventory",
  responses: [
    // Initial chat phase - user asks to generate inventory
    {
      trigger: {
        agentName: "Orchestrator",
        phase: "CHAT",
        userMessage: /generate.*inventory|analyze.*codebase|understand.*project/i,
      },
      response: {
        content:
          "I'll analyze your codebase and generate a comprehensive inventory to help understand the project structure.",
        toolCalls: [
          {
            id: "1",
            message: null,
            function: "continue",
            args: JSON.stringify({
              summary: "User wants to generate project inventory",
              suggestedPhase: "EXECUTE",
              confidence: 95,
              reasoning: "This is a straightforward task that can be executed immediately",
            }),
          },
        ],
      },
      priority: 10,
    },

    // EXECUTE phase - Executor generates inventory
    {
      trigger: {
        agentName: "Executor",
        phase: "EXECUTE",
        systemPrompt: /inventory|analyze.*codebase/i,
      },
      response: {
        content:
          "I'll now generate a comprehensive inventory of your project using our inventory analysis tool.",
        toolCalls: [
          {
            id: "2",
            message: null,
            function: "generate_inventory",
            args: JSON.stringify({}),
          },
        ],
      },
      priority: 10,
    },

    // Handle inventory generation completion
    {
      trigger: {
        agentName: "Executor",
        phase: "EXECUTE",
        previousToolCalls: ["generate_inventory"],
      },
      response: {
        content: `Great! I've successfully generated a comprehensive inventory of your project. Here's what was created:

üìã **Main Inventory**: Saved to \`context/INVENTORY.md\`
- Complete project structure analysis
- Key architectural patterns identified
- Dependencies and their relationships mapped
- Critical code paths documented

üìö **Complex Module Guides**: Individual guides created for complex modules
- Detailed documentation for intricate components
- Usage examples and best practices
- Integration points highlighted

The inventory provides a thorough understanding of your codebase architecture, making it easier to navigate and work with the project.`,
        toolCalls: [
          {
            id: "3",
            message: null,
            function: "complete",
            args: JSON.stringify({
              phaseComplete: true,
              readyForNext: true,
              suggestedNextPhase: "VERIFICATION",
              summary: "Project inventory generated successfully",
            }),
          },
        ],
      },
      priority: 9,
    },

    // Orchestrator handles completion
    {
      trigger: {
        agentName: "Orchestrator",
        phase: "EXECUTE",
        previousToolCalls: ["complete"],
      },
      response: {
        toolCalls: [
          {
            id: "4",
            message: null,
            function: "continue",
            args: JSON.stringify({
              summary: "Inventory generation completed successfully",
              suggestedPhase: "VERIFICATION",
              confidence: 100,
              reasoning: "Task completed, moving to verification",
            }),
          },
        ],
      },
      priority: 9,
    },

    // VERIFICATION phase - confirm inventory was created
    {
      trigger: {
        agentName: "Executor",
        phase: "VERIFICATION",
        systemPrompt: /inventory.*generated/i,
      },
      response: {
        content: "Let me verify the inventory generation was successful.",
        toolCalls: [
          {
            id: "5",
            message: null,
            function: "readPath",
            args: JSON.stringify({
              path: "context/INVENTORY.md",
            }),
          },
        ],
      },
      priority: 10,
    },

    // Verification complete
    {
      trigger: {
        agentName: "Executor",
        phase: "VERIFICATION",
        previousToolCalls: ["readPath"],
      },
      response: {
        content: `‚úÖ Verification complete! The inventory has been successfully generated and contains:

- Project overview and structure
- Architectural patterns and conventions
- Key components and their relationships
- Dependencies analysis
- Development guidelines

The inventory is ready to use for understanding and navigating your codebase.`,
        toolCalls: [
          {
            id: "6",
            message: null,
            function: "complete",
            args: JSON.stringify({
              phaseComplete: true,
              readyForNext: false,
              summary: "Inventory generation verified - task completed successfully",
            }),
          },
        ],
      },
      priority: 9,
    },

    // Alternative flow: Inventory already exists
    {
      trigger: {
        agentName: "Executor",
        phase: "EXECUTE",
        messageContains: /inventory.*regenerated/i,
      },
      response: {
        content: `I've successfully regenerated your project inventory. The existing inventory has been updated with:

üìã **Updated Main Inventory**: \`context/INVENTORY.md\` 
- Refreshed with latest code changes
- New components and patterns identified
- Updated dependency analysis

The regenerated inventory reflects the current state of your codebase.`,
        toolCalls: [
          {
            id: "7",
            message: null,
            function: "complete",
            args: JSON.stringify({
              phaseComplete: true,
              readyForNext: true,
              suggestedNextPhase: "VERIFICATION",
              summary: "Project inventory regenerated with latest changes",
            }),
          },
        ],
      },
      priority: 8,
    },

    // Error handling: Inventory generation fails
    {
      trigger: {
        agentName: "Executor",
        phase: "EXECUTE",
        messageContains: /error.*inventory|failed.*generate/i,
      },
      response: {
        content:
          "I encountered an issue while generating the inventory. Let me try an alternative approach.",
        toolCalls: [
          {
            id: "8",
            message: null,
            function: "shell",
            args: JSON.stringify({
              command: "ls -la context/",
              purpose: "Check if context directory exists",
            }),
          },
        ],
      },
      priority: 8,
    },
  ],
};
</file>

<file path="src/test-utils/mock-llm/index.ts">
export * from "./MockLLMService";
export * from "./scenarios";
export * from "./types";

import type { ToolCall } from "@/llm/types";
import { MockLLMService } from "./MockLLMService";
import { allScenarios } from "./scenarios";
import type { MockLLMConfig, MockLLMScenario } from "./types";

/**
 * Create a mock LLM service with predefined scenarios
 */
export function createMockLLMService(
  scenarios?: string[] | MockLLMScenario[],
  config?: Partial<MockLLMConfig>
): MockLLMService {
  const loadedScenarios: MockLLMScenario[] = [];

  if (scenarios) {
    for (const scenario of scenarios) {
      if (typeof scenario === "string") {
        // Load by name
        const found = allScenarios.find((s) => s.name === scenario);
        if (found) {
          loadedScenarios.push(found);
        }
      } else {
        // Direct scenario object
        loadedScenarios.push(scenario);
      }
    }
  }

  return new MockLLMService({
    ...config,
    scenarios: loadedScenarios,
    defaultResponse: config?.defaultResponse || {
      content: "Mock LLM: No matching response found",
      toolCalls: [],
    },
  });
}

/**
 * Create a simple mock that always returns the same response
 */
export function createSimpleMock(content: string, toolCalls?: ToolCall[]): MockLLMService {
  return new MockLLMService({
    defaultResponse: { content, toolCalls },
  });
}

/**
 * Create a mock that simulates errors
 */
export function createErrorMock(error: Error): MockLLMService {
  return new MockLLMService({
    defaultResponse: { error },
  });
}
</file>

<file path="src/test-utils/mock-llm/types.ts">
import type { ToolCall } from "@/llm/types";

export interface MockLLMResponse {
  /** The messages that should trigger this response */
  trigger: {
    /** Match system prompt content */
    systemPrompt?: string | RegExp;
    /** Match user message content */
    userMessage?: string | RegExp;
    /** Match specific tool calls in the conversation */
    previousToolCalls?: string[];
    /** Match agent name */
    agentName?: string | RegExp;
    /** Match conversation phase */
    phase?: string;
    /** Match if message contains text */
    messageContains?: string | RegExp;
    /** Which iteration for this agent (1st, 2nd, etc) */
    iterationCount?: number;
    /** Who called continue last */
    previousAgent?: string;
    /** Respond differently after specific agent */
    afterAgent?: string;
    /** Match when continue tool specifies a phase */
    continueToPhase?: string;
  };
  /** The response to return when triggered */
  response: {
    /** Text content of the response */
    content?: string;
    /** Tool calls to make */
    toolCalls?: ToolCall[];
    /** Simulate streaming delay in ms */
    streamDelay?: number;
    /** Simulate an error */
    error?: Error;
  };
  /** Priority for matching (higher = checked first) */
  priority?: number;
}

export interface MockLLMScenario {
  name: string;
  description: string;
  responses: MockLLMResponse[];
}

export interface MockLLMConfig {
  /** Default response if no triggers match */
  defaultResponse?: MockLLMResponse["response"];
  /** Log all requests for debugging */
  debug?: boolean;
  /** Scenarios to load */
  scenarios?: MockLLMScenario[];
  /** Custom responses for matching specific patterns */
  responses?: Array<{
    match: RegExp | string;
    response: MockLLMResponse["response"];
  }>;
}
</file>

<file path="src/test-utils/e2e-assertions.ts">
import { expect } from "bun:test";
import type { ExecutionTrace } from "./e2e-types";

/**
 * Assert that agents execute in the expected sequence
 */
export function assertAgentSequence(trace: ExecutionTrace, ...expectedAgents: string[]) {
    const executedAgents = trace.executions.map(e => e.agent);
    expect(executedAgents).toEqual(expectedAgents);
}

/**
 * Assert that phase transitions occur in the expected order
 */
export function assertPhaseTransitions(trace: ExecutionTrace, ...expectedPhases: string[]) {
    // Extract phases from executions where phase changed
    const phases = trace.executions
        .filter(e => e.message?.includes("Phase changed"))
        .map(e => e.phase);
    expect(phases).toEqual(expectedPhases);
}

/**
 * Assert that specific tools are called by an agent
 */
export function assertToolCalls(trace: ExecutionTrace, agent: string, ...expectedTools: string[]) {
    const agentTools = trace.toolCalls
        .filter(tc => tc.agent === agent)
        .map(tc => tc.tool);
    expect(agentTools).toEqual(expectedTools);
}

/**
 * Check if feedback was propagated from one agent to another
 */
export function assertFeedbackPropagated(trace: ExecutionTrace, fromAgent: string, toAgent: string, keyword: string): boolean {
    // Find message from fromAgent
    const fromExecution = trace.executions.find(e => 
        e.agent === fromAgent && e.message?.includes(keyword)
    );
    if (!fromExecution) return false;
    
    // Find subsequent execution of toAgent
    const fromIndex = trace.executions.indexOf(fromExecution);
    const toExecution = trace.executions
        .slice(fromIndex + 1)
        .find(e => e.agent === toAgent);
    
    return toExecution !== undefined;
}
</file>

<file path="src/test-utils/e2e-types.ts">
import type { AgentInstance } from "@/agents/types";
import type { ConversationCoordinator } from "@/conversations";
import type { AgentConversationContext } from "@/conversations/AgentConversationContext";
import type { ConversationMessageRepository } from "@/conversations/ConversationMessageRepository";
import type { MockLLMService } from "@/llm/__tests__/MockLLMService";
import type { AgentRegistry } from "@/agents/AgentRegistry";
import type { ProjectContext } from "@/services/ProjectContext";
import type { NDKEvent } from "@nostr-dev-kit/ndk";

export interface E2ETestContext {
    mockLLM: MockLLMService;
    conversationCoordinator: ConversationCoordinator;
    agentContext: AgentConversationContext;
    messageRepo: ConversationMessageRepository;
    agentRegistry: AgentRegistry;
    projectContext: ProjectContext;
    testAgents: AgentInstance[];
    cleanup: () => Promise<void>;
}

export interface ExecutionTrace {
    conversationId: string;
    executions: AgentExecutionRecord[];
    toolCalls: ToolCallRecord[];
    routingDecisions: any[];
    agentInteractions: AgentExecutionRecord[];
}

export interface AgentExecutionRecord {
    agent: string;
    phase: string;
    timestamp: Date;
    message?: string;
    toolCalls?: any[];
}


export interface ToolCallRecord {
    agent: string;
    tool: string;
    arguments: any;
    timestamp: Date;
}

export interface ToolCall {
    id?: string;
    type?: string;
    function?: {
        name: string;
        arguments: string;
    };
    name?: string;
    params?: any;
}

export interface AgentExecutionResult {
    message: string;
    toolCalls: ToolCall[];
}

export interface RoutingDecision {
    agents: string[];
    phase?: string;
    reason: string;
}
</file>

<file path="src/test-utils/mock-setup.ts">
import { mock } from "bun:test";

/**
 * Common mock setup for services module used across many tests
 */
export function setupServicesMock(projectPath = "/test/project"): void {
  mock.module("@/services", () => ({
    getProjectContext: () => ({
      projectPath,
      configService: {
        getProjectPath: () => projectPath,
        getProject: () => ({
          name: "test-project",
          description: "Test project",
          agents: [],
        }),
        getMCPServices: () => [],
      },
    }),
  }));
}

/**
 * Common mock setup for execution time tracking
 */
export function setupExecutionTimeMock(): void {
  mock.module("@/conversations/executionTime", () => ({
    startExecutionTime: mock(() => {}),
    stopExecutionTime: mock(() => {}),
  }));
}

/**
 * Common mock setup for execution logger
 */
export function setupExecutionLoggerMock(): void {
  mock.module("@/logging/ExecutionLogger", () => ({
    createExecutionLogger: () => ({
      logToolCall: () => {},
      logToolResult: () => {},
      logStream: () => {},
      logComplete: () => {},
      logError: () => {},
      logEvent: () => {},
      routingDecision: () => {},
      agentThinking: () => {},
    }),
  }));
}

/**
 * Common mock setup for tracing
 */
export function setupTracingMock(): void {
  mock.module("@/tracing", () => ({
    createTracingContext: () => ({ id: "trace-id" }),
    createAgentExecutionContext: (parent: unknown, agentName: string) => ({
      id: `trace-${agentName}`,
      parent,
    }),
  }));
}

/**
 * Common mock setup for agent utils
 */
export function setupAgentUtilsMock(tools: unknown[] = []): void {
  mock.module("@/agents/utils", () => ({
    getAvailableTools: () => tools,
    createAgentPrompt: () => "Test agent prompt",
  }));
}

/**
 * Common mock setup for tool registry
 */
export function setupToolRegistryMock(): void {
  mock.module("@/tools/registry", () => ({
    toolRegistry: {
      getTool: (name: string) => ({
        name,
        description: `Mock ${name} tool`,
        execute: async () => ({ success: true }),
      }),
    },
  }));
}

/**
 * Setup all common mocks at once
 */
export function setupCommonTestMocks(projectPath = "/test/project"): void {
  setupServicesMock(projectPath);
  setupExecutionTimeMock();
  setupExecutionLoggerMock();
  setupTracingMock();
  setupAgentUtilsMock();
  setupToolRegistryMock();
}
</file>

<file path="src/test-utils/ndk-test-helpers.ts">
/**
 * NDK Test Utilities Integration
 * 
 * This module provides access to NDK's comprehensive testing utilities
 * for more robust testing of Nostr protocol interactions.
 */

import {
  RelayMock,
  RelayPoolMock,
  EventGenerator,
  TestFixture,
  TestEventFactory,
  UserGenerator,
  SignerGenerator,
  TimeController,
  withTimeControl,
  mockNutzap,
  mockProof,
  type Proof
} from "@nostr-dev-kit/ndk/test";

import { NDK } from "@nostr-dev-kit/ndk";
import type { NDKEvent, NDKUser } from "@nostr-dev-kit/ndk";

/**
 * Test user names available from NDK's deterministic user generator
 */
export type TestUserName = "alice" | "bob" | "carol" | "dave" | "eve";

/**
 * Extended test fixture for TENEX that combines NDK's testing utilities
 * with TENEX-specific testing needs
 */
export class TENEXTestFixture extends TestFixture {
  private relayMocks: Map<string, RelayMock> = new Map();
  
  constructor() {
    super();
    // Initialize NDK with test configuration
    this.ndk.explicitRelayUrls = ["wss://test.relay"];
  }

  /**
   * Create a mock relay with configurable behavior
   */
  createMockRelay(url = "wss://test.relay", options?: {
    simulateDisconnect?: boolean;
    disconnectAfter?: number;
    connectionDelay?: number;
    autoConnect?: boolean;
    failNextPublish?: boolean;
  }): RelayMock {
    const relay = new RelayMock(url, options);
    this.relayMocks.set(url, relay);
    return relay;
  }

  /**
   * Get or create a mock relay
   */
  getMockRelay(url = "wss://test.relay"): RelayMock {
    if (!this.relayMocks.has(url)) {
      return this.createMockRelay(url);
    }
    const relay = this.relayMocks.get(url);
    if (!relay) {
      throw new Error(`Relay not found for URL: ${url}`);
    }
    return relay;
  }

  /**
   * Create an agent event for testing
   */
  async createAgentEvent(
    agent: TestUserName | NDKUser,
    content: string,
    kind = 8000, // Agent-specific kind
    tags: string[][] = []
  ): Promise<NDKEvent> {
    const event = await this.eventFactory.createSignedTextNote(
      content,
      agent,
      kind
    );
    
    // Add agent-specific tags
    event.tags = [
      ...event.tags,
      ...tags,
      ["client", "tenex"],
      ["version", "1.0.0"]
    ];
    
    return event;
  }

  /**
   * Create a conversation thread between users and agents
   */
  async createConversationThread(
    initialMessage: { author: TestUserName; content: string },
    replies: Array<{ author: TestUserName; content: string; isAgent?: boolean }>
  ): Promise<NDKEvent[]> {
    const events: NDKEvent[] = [];
    
    // Create initial message
    const initialEvent = await this.eventFactory.createSignedTextNote(
      initialMessage.content,
      initialMessage.author
    );
    events.push(initialEvent);
    
    // Create replies
    let parentEvent = initialEvent;
    for (const reply of replies) {
      const replyEvent = reply.isAgent
        ? await this.createAgentEvent(reply.author, reply.content, 8001, [
            ["e", parentEvent.id ?? "", "", "reply"],
            ["p", parentEvent.pubkey]
          ])
        : await this.eventFactory.createReply(
            parentEvent,
            reply.content,
            reply.author
          );
      
      events.push(replyEvent);
      parentEvent = replyEvent;
    }
    
    return events;
  }

  /**
   * Simulate relay communication for an event
   */
  async simulateRelayInteraction(
    event: NDKEvent,
    relayUrl = "wss://test.relay"
  ): Promise<void> {
    const relay = this.getMockRelay(relayUrl);
    
    // Simulate publishing
    await relay.publish(event);
    
    // Simulate receiving the event back
    await relay.simulateEvent(event);
    
    // Simulate EOSE
    relay.simulateEOSE("test-sub");
  }

  /**
   * Clean up test resources
   */
  cleanup(): void {
    // Reset all mock relays
    this.relayMocks.forEach(relay => relay.reset());
    this.relayMocks.clear();
  }
}

/**
 * Helper to create a test environment with time control
 */
export async function withTestEnvironment<T>(
  testFn: (fixture: TENEXTestFixture, timeControl: TimeController) => Promise<T>
): Promise<T> {
  return withTimeControl(async (timeControl) => {
    const fixture = new TENEXTestFixture();
    try {
      return await testFn(fixture, timeControl);
    } finally {
      fixture.cleanup();
    }
  });
}

/**
 * Quick helper to get a test user with signer
 */
export async function getTestUserWithSigner(
  name: TestUserName,
  ndk?: NDK
): Promise<{ user: NDKUser; signer: unknown }> {
  const user = await UserGenerator.getUser(name, ndk);
  const signer = SignerGenerator.getSigner(name);
  return { user, signer };
}

/**
 * Create a mock agent configuration for testing
 */
interface MockAgentConfig {
  name?: string;
  slug?: string;
  role?: string;
  backend?: string;
  tools?: string[];
  capabilities?: {
    canRead?: boolean;
    canWrite?: boolean;
    canExecute?: boolean;
  };
  rateLimits?: {
    messagesPerMinute?: number;
    tokensPerDay?: number;
  };
  [key: string]: unknown;
}

export function createMockAgentConfig(overrides: MockAgentConfig = {}): MockAgentConfig {
  return {
    name: overrides.name || "TestAgent",
    slug: overrides.slug || "test-agent",
    role: overrides.role || "Test agent for unit testing",
    backend: overrides.backend || "reason-act-loop",
    tools: overrides.tools || ["test-tool"],
    capabilities: overrides.capabilities || {
      canRead: true,
      canWrite: false,
      canExecute: false
    },
    rateLimits: overrides.rateLimits || {
      messagesPerMinute: 10,
      tokensPerDay: 100000
    },
    ...overrides
  };
}

// Re-export commonly used utilities
export {
  RelayMock,
  RelayPoolMock,
  EventGenerator,
  TestEventFactory,
  UserGenerator,
  SignerGenerator,
  TimeController,
  withTimeControl,
  mockNutzap,
  mockProof,
  type Proof
};
</file>

<file path="src/utils/agentFetcher.ts">
import type NDK from "@nostr-dev-kit/ndk";
import { logger } from "./logger";

/**
 * Fetches an agent definition from a Nostr event
 * @param eventId - The ID of the event containing the agent definition
 * @param ndk - The NDK instance to use for fetching
 * @returns The agent definition or null if not found
 */
export async function fetchAgentDefinition(
  eventId: string,
  ndk: NDK
): Promise<{
  id: string;
  title: string;
  description: string;
  role: string;
  instructions: string;
  useCriteria: string;
  version: string;
  created_at: number | undefined;
  pubkey: string;
} | null> {
  try {
    // Strip "nostr:" prefix if present
    const cleanEventId = eventId.startsWith("nostr:") ? eventId.substring(6) : eventId;
    
    const event = await ndk.fetchEvent(cleanEventId, { groupable: false });

    if (!event) {
      logger.warning(`Agent event not found: ${cleanEventId}`);
      return null;
    }

    return {
      id: event.id,
      title: event.tagValue("title") || "Unnamed Agent",
      description: event.tagValue("description") || "",
      role: event.tagValue("role") || "assistant",
      instructions: event.content || "",
      useCriteria: event.tagValue("use-criteria") || "",
      version: event.tagValue("ver") || "1.0.0",
      created_at: event.created_at,
      pubkey: event.pubkey,
    };
  } catch (error) {
    logger.error(`Failed to fetch agent event: ${eventId}`, error);
    return null;
  }
}
</file>

<file path="src/utils/cli-config-scope.ts">
import { configService } from "@/services/ConfigService";

export interface ConfigScope {
  basePath: string;
  isGlobal: boolean;
  isProject: boolean;
  error?: string;
}

/**
 * Resolves the configuration scope for CLI commands
 * Consolidates the logic for determining whether to use global or project config
 *
 * @param options Command line options with optional project/global flags
 * @param currentPath The current working directory path
 * @returns ConfigScope object with resolved path and scope information
 */
export async function resolveConfigScope(
  options: { project?: boolean; global?: boolean },
  currentPath: string = process.cwd()
): Promise<ConfigScope> {
  // Check for conflicting flags
  if (options.project && options.global) {
    return {
      basePath: "",
      isGlobal: false,
      isProject: false,
      error: "Cannot use both --project and --global flags",
    };
  }

  // Determine if we're in a project directory (check for main config file)
  const projectConfigExists = await configService.projectConfigExists(currentPath, "config.json");

  // Handle explicit flags
  if (options.global) {
    return {
      basePath: configService.getGlobalPath(),
      isGlobal: true,
      isProject: false,
    };
  }

  if (options.project) {
    if (!projectConfigExists) {
      return {
        basePath: "",
        isGlobal: false,
        isProject: false,
        error: "Not in a TENEX project directory. Run 'tenex project init' first.",
      };
    }
    return {
      basePath: currentPath,
      isGlobal: false,
      isProject: true,
    };
  }

  // Default behavior: use project config if available, otherwise global
  if (projectConfigExists) {
    return {
      basePath: currentPath,
      isGlobal: false,
      isProject: true,
    };
  }

  return {
    basePath: configService.getGlobalPath(),
    isGlobal: true,
    isProject: false,
  };
}

/**
 * Helper to format config scope for display
 */
export function formatConfigScope(scope: ConfigScope): string {
  if (scope.error) {
    return scope.error;
  }

  if (scope.isGlobal) {
    return "global configuration";
  }

  if (scope.isProject) {
    return `project configuration at ${scope.basePath}`;
  }

  return "configuration";
}

/**
 * Check if the current directory is a TENEX project
 * @param projectPath - The path to check (defaults to current working directory)
 * @returns True if the directory contains a TENEX project configuration
 */
export async function isProjectDirectory(projectPath: string = process.cwd()): Promise<boolean> {
  return await configService.projectConfigExists(projectPath, "config.json");
}

/**
 * Get the appropriate configuration path based on project detection
 * @param projectPath - The path to check (defaults to current working directory)
 * @returns The configuration path (project path if in a project, global path otherwise)
 */
export async function getConfigPath(projectPath: string = process.cwd()): Promise<string> {
  const isProject = await isProjectDirectory(projectPath);
  return isProject ? configService.getProjectPath(projectPath) : configService.getGlobalPath();
}
</file>

<file path="src/utils/error-formatter.ts">
// ToolError removed - define it locally if needed
interface ToolError {
  kind: 'validation' | 'execution' | 'system';
  message: string;
  field?: string;
  tool?: string;
}

/**
 * Comprehensive error formatter that handles all error types in the codebase
 * Consolidates error formatting logic from various parts of the system
 */
export function formatAnyError(error: unknown): string {
  // Handle null/undefined
  if (error == null) {
    return "Unknown error";
  }

  // Handle strings
  if (typeof error === "string") {
    return error;
  }

  // Handle Error instances
  if (error instanceof Error) {
    return error.message;
  }

  // Handle objects
  if (typeof error === "object") {
    const errorObj = error as Record<string, unknown>;

    // Check for ToolError structure (with type guard)
    if ("kind" in errorObj && "message" in errorObj) {
      const kind = errorObj.kind;
      if (kind === "validation" || kind === "execution" || kind === "system") {
        return formatToolError(errorObj as unknown as ToolError);
      }
    }

    // Check for simple message property
    if ("message" in errorObj && typeof errorObj.message === "string") {
      return errorObj.message;
    }

    // Try to extract meaningful properties from the error object
    const parts: string[] = [];

    // Common error properties
    if ("kind" in errorObj) parts.push(`kind: ${errorObj.kind}`);
    if ("field" in errorObj) parts.push(`field: ${errorObj.field}`);
    if ("tool" in errorObj) parts.push(`tool: ${errorObj.tool}`);
    if ("code" in errorObj) parts.push(`code: ${errorObj.code}`);
    if ("statusCode" in errorObj) parts.push(`statusCode: ${errorObj.statusCode}`);
    if ("errno" in errorObj) parts.push(`errno: ${errorObj.errno}`);
    if ("syscall" in errorObj) parts.push(`syscall: ${errorObj.syscall}`);

    // If we found specific properties, use them
    if (parts.length > 0) {
      return parts.join(", ");
    }

    // Otherwise, try to stringify the object
    try {
      const str = JSON.stringify(error);
      // Don't return huge JSON strings
      if (str.length > 200) {
        return "[Complex Error Object]";
      }
      return str;
    } catch {
      return "[Complex Error Object]";
    }
  }

  // Fallback to String conversion
  return String(error);
}

/**
 * Format ToolError objects into human-readable strings
 */
export function formatToolError(error: ToolError): string {
  switch (error.kind) {
    case "validation":
      // If the field is empty and message is just "Required", make it clearer
      if (error.field === "" && error.message === "Required") {
        return "Validation error: Missing required parameter";
      }
      return error.field
        ? `Validation error in ${error.field}: ${error.message}`
        : `Validation error: ${error.message}`;
    case "execution":
      return error.tool
        ? `Execution error in ${error.tool}: ${error.message}`
        : `Execution error: ${error.message}`;
    case "system":
      return `System error: ${error.message}`;
    default: {
      // This should never happen with proper ToolError types
      const unknownError = error as Record<string, unknown>;
      return (
        (typeof unknownError.message === "string" ? unknownError.message : null) || "Unknown error"
      );
    }
  }
}
</file>

<file path="src/utils/lessonFormatter.ts">
import type { NDKAgentLesson } from "@/events/NDKAgentLesson";
import { logger } from "@/utils/logger";

/**
 * Format agent lessons into a concise string without using LLM
 * This is a simple concatenation with minimal formatting
 */
export function formatLessonsForAgent(lessons: NDKAgentLesson[]): string {
  if (lessons.length === 0) {
    return "";
  }

  logger.debug("Formatting lessons for agent", {
    lessonsCount: lessons.length,
  });

  // Format each lesson concisely - ALL OF THEM!
const formattedLessons = lessons
    .map((lesson, index) => {
        const title = lesson.title || "Untitled Lesson";
        const content = lesson.lesson;
        const category = lesson.category;
        const hashtags = lesson.hashtags;
        const hasDetailed = !!lesson.detailed;

        // Build metadata line
        let metadata = "";
        if (category) metadata += ` [${category}]`;
        if (hasDetailed) metadata += " [detailed available]";
        if (hashtags && hashtags.length > 0) metadata += ` #${hashtags.join(" #")}`;

        // Create a concise format for each lesson
        return `#${index + 1}: ${title} ${metadata}\n${content}${hasDetailed ? `\n‚Ü≥ Use lesson_get("${title}") for detailed version` : ""}`;
    })
    .join("\n\n");

  // Add header for context
  const header = `## Lessons Learned (${lessons.length} total)\n\n`;

  return header + formattedLessons;
}
</file>

<file path="src/utils/logger.ts">
import chalk from "chalk";

const levels: Record<string, number> = {
  silent: 0,
  error: 1,
  warn: 2,
  info: 3,
  debug: 4,
};

// Helper to get current log level dynamically
function getCurrentLevel(): number {
  const LOG_LEVEL = process.env.LOG_LEVEL || "info";
  return levels[LOG_LEVEL] || levels.info;
}

// Helper to check if debug is enabled
function isDebugEnabled(): boolean {
  return process.env.DEBUG === "true";
}

// Color configuration for consistent output
const colors = {
  error: chalk.red,
  warn: chalk.yellow,
  info: chalk.blue,
  success: chalk.green,
  debug: chalk.gray,
};

const emojis = {
  error: "‚ùå",
  warn: "‚ö†Ô∏è",
  info: "‚ÑπÔ∏è",
  success: "‚úÖ",
  debug: "üîç",
};

// Main logger object
export const logger = {
  error: (message: string, error?: unknown) => {
    if (getCurrentLevel() >= levels.error) {
      console.error(colors.error(`${emojis.error} ${message}`), error || "");
    }
  },

  warn: (message: string, ...args: unknown[]) => {
    if (getCurrentLevel() >= levels.warn) {
      console.warn(colors.warn(`${emojis.warn} ${message}`), ...args);
    }
  },

  warning: (message: string, ...args: unknown[]) => {
    logger.warn(message, ...args);
  },

  info: (message: string, ...args: unknown[]) => {
    if (getCurrentLevel() >= levels.info) {
      console.log(colors.info(`${emojis.info} ${message}`), ...args);
    }
  },

  success: (message: string, ...args: unknown[]) => {
    if (getCurrentLevel() >= levels.info) {
      console.log(colors.success(`${emojis.success} ${message}`), ...args);
    }
  },

  debug: (message: string, ...args: unknown[]) => {
    if (isDebugEnabled() && getCurrentLevel() >= levels.debug) {
      console.log(colors.debug(`${emojis.debug} ${message}`), ...args);
    }
  },
};
</file>

<file path="src/utils/nostr-entity-parser.ts">
import NDK, { NDKEvent, NDKUser } from '@nostr-dev-kit/ndk';

/**
 * Parses various Nostr user identifier formats into a pubkey
 * Handles: npub, nprofile, hex pubkey, with or without "nostr:" prefix
 * 
 * @param input - The user identifier in various formats
 * @param ndk - NDK instance for validation
 * @returns The parsed pubkey or null if invalid
 */
export function parseNostrUser(input: string | undefined): string | null {
    if (!input) return null;
    
    try {
        // Strip nostr: prefix if present
        let cleaned = input.trim();
        if (cleaned.startsWith('nostr:')) {
            cleaned = cleaned.substring(6);
        }
        
        // Handle npub format
        if (cleaned.startsWith('npub1')) {
            const user = new NDKUser({ npub: cleaned });
            return user.pubkey;
        }
        
        // Handle nprofile format
        if (cleaned.startsWith('nprofile1')) {
            const user = new NDKUser({ nprofile: cleaned });
            return user.pubkey;
        }
        
        // Assume it's a hex pubkey - validate format
        if (/^[0-9a-fA-F]{64}$/.test(cleaned)) {
            return cleaned.toLowerCase();
        }
        
        // Try to create user anyway in case it's a valid format we didn't check
        try {
            const user = new NDKUser({ pubkey: cleaned });
            if (user.pubkey && /^[0-9a-fA-F]{64}$/.test(user.pubkey)) {
                return user.pubkey;
            }
        } catch {
            // Ignore and return null
        }
        
        return null;
    } catch (error) {
        console.debug('Failed to parse Nostr user identifier:', input, error);
        return null;
    }
}

/**
 * Parses various Nostr event identifier formats and fetches the event
 * Handles: nevent, note, naddr, hex event id, with or without "nostr:" prefix
 * 
 * @param input - The event identifier in various formats
 * @param ndk - NDK instance for fetching
 * @returns The fetched event or null if not found/invalid
 */
export async function parseNostrEvent(input: string | undefined, ndk: NDK): Promise<NDKEvent | null> {
    if (!input) return null;
    
    try {
        // Strip nostr: prefix if present
        let cleaned = input.trim();
        if (cleaned.startsWith('nostr:')) {
            cleaned = cleaned.substring(6);
        }
        
        // Try to fetch directly - NDK handles various formats
        if (cleaned.startsWith('nevent1') || cleaned.startsWith('note1') || cleaned.startsWith('naddr1')) {
            const event = await ndk.fetchEvent(cleaned);
            return event;
        }
        
        // Try as hex event ID
        if (/^[0-9a-fA-F]{64}$/.test(cleaned)) {
            const event = await ndk.fetchEvent(cleaned);
            return event;
        }
        
        // Last attempt - try to fetch as-is
        const event = await ndk.fetchEvent(cleaned);
        return event;
    } catch (error) {
        console.debug('Failed to parse/fetch Nostr event:', input, error);
        return null;
    }
}

/**
 * Validates and normalizes a Nostr identifier, removing prefixes
 * Returns the cleaned identifier or null if invalid
 */
export function normalizeNostrIdentifier(input: string | undefined): string | null {
    if (!input) return null;
    
    let cleaned = input.trim();
    if (cleaned.startsWith('nostr:')) {
        cleaned = cleaned.substring(6);
    }
    
    // Basic validation - should be bech32 or hex
    if (cleaned.match(/^(npub1|nprofile1|nevent1|note1|nsec1|naddr1)[0-9a-z]+$/i) ||
        cleaned.match(/^[0-9a-fA-F]{64}$/)) {
        return cleaned;
    }
    
    return null;
}
</file>

<file path="src/utils/projectInitialization.ts">
import { ProjectManager } from "@/daemon/ProjectManager";
import { getNDK, initNDK } from "@/nostr/ndkClient";
import { isProjectContextInitialized } from "@/services";
import { handleCliError } from "@/utils/cli-error";
import { logger } from "@/utils/logger";

/**
 * Initialize project context if not already initialized
 * This includes NDK setup and ProjectManager initialization
 *
 * Used by commands that need full project context:
 * - tenex project run
 * - tenex debug chat
 * - tenex debug system-prompt
 * - tenex inventory generate
 */
export async function ensureProjectInitialized(projectPath: string): Promise<void> {
  if (isProjectContextInitialized()) {
    logger.debug("Project context already initialized");
    return;
  }

  try {
    // Step 1: Initialize NDK connection
    await initNDK();
    const ndk = getNDK();

    // Step 2: Initialize ProjectContext using ProjectManager
    const projectManager = new ProjectManager();
    await projectManager.loadAndInitializeProjectContext(projectPath, ndk);
  } catch (error) {
    // Check if this is a missing project configuration error
    const errorMessage = error instanceof Error ? error.message : String(error);
    if (errorMessage.includes("Project configuration missing projectNaddr")) {
      const message = [
        "\n‚ùå Not in a TENEX project directory\n",
        "This command must be run from within a TENEX project.",
        "\nTo initialize a new project, run:",
        "  tenex init\n",
        "Or navigate to an existing TENEX project directory.\n",
      ].join("\n");
      handleCliError(new Error(message));
    }
    throw error;
  }
}
</file>

<file path="src/utils/tool-result-formatter.ts">
// ToolExecutionResult removed - using AI SDK tools only

/**
 * Format a tool result as a string for inclusion in the conversation
 */
export function formatToolResultAsString(result: any): string {
  const toolInfo = result.toolName ? `[${result.toolName}]` : "[Unknown Tool]";
  const argsInfo = result.toolArgs && Object.keys(result.toolArgs).length > 0
    ? ` with args: ${JSON.stringify(result.toolArgs)}`
    : "";
  
  if (result.success) {
    // Format the output as a string
    const output = result.output;
    if (typeof output === "string") {
      return `Tool ${toolInfo}${argsInfo} completed successfully:\n${output}`;
    }
    if (output !== undefined && output !== null) {
      return `Tool ${toolInfo}${argsInfo} completed successfully:\n${JSON.stringify(output, null, 2)}`;
    }
    return `Tool ${toolInfo}${argsInfo} completed successfully`;
  }
  return `Tool ${toolInfo}${argsInfo} failed with error: ${result.error?.message || "Unknown error"}`;
}
</file>

<file path="context/conversations.md">
# Conversation Management System

## Overview

The conversation management system is the core infrastructure that maintains context, state, and continuity across multi-agent interactions in TENEX. It ensures that every agent has the complete context needed to provide coherent responses while managing the complexity of asynchronous, multi-participant conversations.

## Core Concepts

### 1. Conversation

A conversation represents a complete interaction thread initiated by a user. It maintains:
- **Unique identifier**: The ID of the initiating event
- **Title**: Human-readable description of the conversation
- **Phase**: Current operational phase (chat, brainstorm, plan, execute, verification, chores, reflection)
- **History**: Ordered sequence of all events (messages) in the conversation
- **Agent States**: Per-agent tracking of conversation position and session information
- **Metadata**: Additional context like summaries, referenced articles, and execution timing

### 2. Agent State

Each agent participating in a conversation maintains its own state:
- **lastProcessedMessageIndex**: Position in the conversation history that the agent has processed
- **claudeSessionId**: Optional session identifier for maintaining API-level continuity with Claude

### 3. Event Types

Events in a conversation can be:
- **User messages**: Direct input from the human user
- **Agent responses**: Messages from AI agents
- **System events**: Phase transitions, handoffs, and other system-level notifications

## Message Building Process

When an agent needs to respond to a conversation, the system constructs a complete message context following these principles:

### Complete History Reconstruction

The system provides the FULL conversation history to maintain perfect context continuity. This is critical for agents to:
- Answer questions about earlier parts of the conversation
- Maintain consistent understanding of the task
- Reference previous decisions and context

The history includes:
1. **All previous messages** up to (but not including) the current triggering event
2. **Proper role attribution** for each message:
   - User messages ‚Üí `user` role
   - Agent's own previous messages ‚Üí `assistant` role  
   - Other agents' messages ‚Üí `system` role with attribution
3. **Chronological ordering** to maintain conversation flow

### Message Role Assignment

The system uses standard LLM conversation roles:

- **user**: Messages from the human user
- **assistant**: The agent's own previous responses
- **system**: Messages from other agents (with attribution) and system notifications

This standard format ensures compatibility with LLM APIs and provides clear conversation structure.

### "Messages While You Were Away" Block

This special block is used ONLY when there are genuinely new messages from other participants that the agent hasn't seen yet (messages after the agent's `lastProcessedMessageIndex`). It serves to:
- Alert the agent to activity that occurred while it was inactive
- Provide handoff context when agents transition work
- Highlight important updates that need immediate attention
- Show messages from other agents that have been added since the agent last processed the conversation

The block is NOT used when:
- The agent's own messages are being provided (these are `assistant` messages)
- The agent is continuing a direct conversation with the user
- There are no new messages from others since the agent's last interaction

### END OF HISTORY Marker

The "=== END OF HISTORY ===" marker works in conjunction with the "MESSAGES WHILE YOU WERE AWAY" block to:
- Signal the end of the historical context
- Prompt the agent to respond to the most recent user message

The marker is included at the end of the "MESSAGES WHILE YOU WERE AWAY" block along with:
- A clear instruction to respond to the most recent user message
- A reminder to consider the provided context

This marker system ensures agents can distinguish between historical context they're being caught up on versus the actual message they need to respond to.

## Agent Participation Patterns

### Direct P-tagging (First Message)

When a user starts a conversation by directly addressing an agent (e.g., "@project-manager"):
- The agent is immediately added to the conversation
- No "MESSAGES WHILE YOU WERE AWAY" block (nothing happened before)
- No "NEW INTERACTION" marker (agent is directly addressed)
- The agent's state starts at index 0

### P-tagging Mid-Conversation

When a user brings a new agent into an existing conversation:
- The agent receives the complete conversation history
- All previous messages are provided in proper role format
- The agent can see everything that happened before being invited
- No "MESSAGES WHILE YOU WERE AWAY" unless there are additional unprocessed messages

### Conversation Continuation

When an agent continues an ongoing conversation:
- Full conversation history is provided
- Agent's own messages appear as `assistant` role
- User messages appear as `user` role
- Other agents' messages appear as `system` role with attribution

### Multi-Agent Interactions

When multiple agents participate:
- Each agent maintains its own state and position in the conversation
- Agents see each other's messages as system messages with clear attribution
- The full conversation context is maintained for all participants
- Handoff summaries can be provided for context during phase transitions

## State Management

### Agent State Initialization

When an agent first joins a conversation:
1. Check if the agent is being directly addressed in the triggering event
2. If it's the first message and the agent is p-tagged, start at index 0
3. If joining mid-conversation, start at index 0 to see full history
4. Store the initial state in the conversation's agent states map

### State Updates

After each agent interaction:
1. Update `lastProcessedMessageIndex` to current history length
2. Preserve any session IDs from the triggering event
3. Save the updated state for future continuity

### Session Management

Claude session IDs are:
- Extracted from triggering events when present
- Stored in the agent's state
- Preserved across multiple interactions
- Updated when new session IDs are provided
- Used to maintain API-level conversation continuity

## Critical Requirements

### Context Completeness

**Every agent must receive the complete conversation history** to maintain coherent context. This is non-negotiable because:
- Agents may be asked about any part of the conversation
- Context loss leads to confusion and incorrect responses
- Full history enables proper reasoning and decision-making

### Message Ordering

Messages must be provided in strict chronological order to maintain conversation flow. The system:
- Preserves the exact sequence of events
- Maintains proper alternation between participants
- Ensures cause-and-effect relationships are clear

### Role Consistency

Message roles must follow standard LLM conventions:
- `user` for human input
- `assistant` for the agent's own messages
- `system` for other agents and system notifications

### Attribution Clarity

When multiple agents participate, clear attribution is essential:
- Other agents' messages include their name in brackets
- System messages are clearly marked
- Handoff context is explicitly provided

## Error Prevention

### Common Pitfalls to Avoid

1. **Never provide only recent messages** - Always include full history
2. **Never mix message roles** - Maintain clear role distinctions
3. **Never duplicate the triggering event** - It should appear only once as the primary message
4. **Never show "MESSAGES WHILE YOU WERE AWAY" for the agent's own messages**
5. **Never lose session IDs** - Preserve them across interactions

### Validation Requirements

The system must ensure:
- All messages have content and proper roles
- Agent states are properly initialized before use
- History is complete and properly ordered
- Session IDs are preserved when present
- Attribution is clear for all participants

## Phase Transitions and Handoffs

When agents hand off work or transition phases:
- The receiving agent gets full conversation context
- Handoff summaries provide transition context
- Phase metadata is updated appropriately
- All participants maintain their individual states

## Testing Considerations

Critical scenarios that must be tested:
1. **Single agent conversations** with multiple exchanges
2. **P-tagging agents** at conversation start vs mid-conversation
3. **Multi-agent interactions** with proper attribution
4. **Session ID management** across interactions
5. **Phase transitions** with context preservation
6. **Agent handoffs** with summary context
7. **NEW INTERACTION marker** appearing only when MESSAGES WHILE YOU WERE AWAY is present
8. **Complete history preservation** across all scenarios

## Implementation Notes

### Message Building Logic

The `buildAgentMessages` function follows this sequence:
1. **Build complete conversation history** - All messages up to but not including the triggering event
2. **Check for messages while away** - Messages from others after `lastProcessedMessageIndex`
3. **Add MESSAGES WHILE YOU WERE AWAY block** - Only if there are new messages from others
4. **Add END OF HISTORY marker** - Included at the end of the "while away" block with instructions
5. **Add the triggering event** - The actual message to respond to

Key implementation details:
- Messages from others after `lastProcessedMessageIndex` are included in "MESSAGES WHILE YOU WERE AWAY"
- The END OF HISTORY marker includes an instruction to respond to the most recent user message
- The system ensures agents have full context while clearly delineating historical vs current messages

Key functions involved in the conversation management:
- `buildAgentMessages`: Constructs the complete message context for an agent
- `addEvent`: Adds new events to conversation history
- `updatePhase`: Manages phase transitions
- `updateAgentState`: Updates agent-specific state information
- `getEventSender`/`getEventSenderForHistory`: Determines message attribution

The system maintains conversation state through:
- In-memory conversation map
- Persistent storage via FileSystemAdapter
- Agent state tracking per conversation
- Session ID management for API continuity

## Performance Considerations

While providing full history is essential for context:
- History is built efficiently in a single pass
- Messages are constructed in order without redundant processing
- Agent states prevent unnecessary reprocessing
- Persistence is handled asynchronously where possible

## Key Components

- **`ConversationStore.ts`**: Manages the storage and retrieval of conversations in memory and coordinates with persistence layer.

- **`ConversationCoordinator.ts`**: Coordinates conversation flow and manages agent interactions within conversations.

- **`MessageBuilder.ts`**: Constructs properly formatted messages for agent consumption with full context.

- **`AgentConversationContext.ts`**: Manages agent-specific context within conversations including state tracking.

- **`services/`**: Directory containing core conversation services:
    - **`ConversationEventProcessor.ts`**: Processes incoming events and updates conversation state.
    - **`PhaseManager.ts`**: Manages phase transitions and phase-specific logic.
    - **`AgentResolver.ts`**: Resolves agents referenced in conversations.
    - **`ConversationPersistenceService.ts`**: Handles conversation persistence coordination.

- **`persistence/`**: Contains persistence logic for saving conversations:
    - **`FileSystemAdapter.ts`**: Saves conversations to the local filesystem.
    - **`schemas.ts`**: Defines validation schemas for persisted data.

- **`executionQueue/`**: Manages execution queue for preventing concurrent executions:
    - **`ExecutionQueueManager.ts`**: Main queue management orchestrator.
    - **`LockManager.ts`**: Handles execution lock acquisition and release.
    - **`QueueManager.ts`**: Manages the FIFO queue of waiting conversations.
    - **`TimeoutManager.ts`**: Handles execution timeouts and warnings.

- **`types.ts`**: Defines data structures and types like `Conversation`, `Message`, and `AgentState`.

- **`phases.ts`**: Defines conversation phases (`CHAT`, `BRAINSTORM`, `PLAN`, `EXECUTE`, `VERIFICATION`, `CHORES`, `REFLECTION`).

- **`executionTime.ts`**: Tracks execution timing for different conversation operations.
</file>

<file path="context/PROJECT.md">
# Project Name: TENEX

## 1. Core Concept

TENEX is a multi-agent development environment designed to build software through the collaboration of AI agents. It operates on the Nostr protocol, creating a decentralized and context-aware system where human developers guide high-level strategy while autonomous agents handle the low-level implementation tasks.

The fundamental shift is from traditional coding in a text editor to managing and providing context to a team of AI agents who write the code.

## 2. Key Features

*   **Multi-Agent Architecture:** The system is composed of specialized AI agents, each with a distinct role (e.g., Planner, Executor, Project Manager, human-replica).
*   **Invisible Orchestrator:** A central component that intelligently routes user requests and agent responses to the most appropriate agent, creating a seamless workflow.
*   **External Delegation:** A `delegate_external` tool allows agents to communicate and delegate tasks to agents outside the current project. This functions by sending Nostr events (`kind:11` for new messages, `kind:1111` for replies). This tool is available to all agents by default.
*   **Phase-Based Workflow:** Every development task follows a structured, cyclical process:
    1.  **CHAT:** Requirements gathering and clarification.
    2.  **BRAINSTORM:** Idea exploration and refinement.
    3.  **PLAN:** Architectural design and technical specification.
    4.  **EXECUTE:** Code implementation and review.
    5.  **VERIFICATION:** Functional testing from an end-user perspective.
    6.  **CHORES:** Cleanup, documentation, and maintenance.
    7.  **REFLECTION:** Agents learn from the completed task to improve future performance.
*   **Conversation Restart:** When a conversation reaches its natural conclusion (the `END` phase), it is not permanently closed. If the user provides a new message, a new conversation is automatically started from the `CHAT` phase, preserving the full history and context. This ensures a seamless and continuous user experience.
*   **Continuous Learning:** Agents are designed to learn from every interaction, building a persistent knowledge base that improves their effectiveness over time.
*   **Nostr-Native:** Built on the Nostr protocol, ensuring communication is decentralized, secure, and censorship-resistant.
*   **LLM Agnostic:** Supports multiple Large Language Model providers, including OpenAI, Anthropic, and Google.
*   **Agent Presence & Identification (User-defined requirement):**
    *   **Online Status:** Agent online status must be determined by querying for `kind:24010` status events with a `since` filter of one minute ago. The `a` tag of the status event must be compared with the project's tag ID to ensure the status applies to the correct project. **The 'a' tag must include the project owner's pubkey.**
    *   **Agent ID Format:** When returning agent information, the agent's `npub` must be used instead of their public key.
    *   **Agent Self-Knowledge:** Agents must be explicitly informed of their own `npub` as part of their core identity prompt.

## 3. Guiding Principles

*   **Context is King:** The primary role of the human user is to provide clear and comprehensive context. The agents' success is directly tied to the quality of this context.
*   **Human as Orchestrator:** The user acts as a high-level director, making strategic decisions and guiding the AI team, rather than writing code line-by-line.
*   **Automation of Toil:** The goal is to automate the repetitive and tedious aspects of software development, freeing up human developers to focus on creative and strategic challenges.

## 4. Technical Stack

*   **Runtime:** Bun (primary) / Node.js (>=18.0.0 compatibility)
*   **Language:** TypeScript (^5.8.3)
*   **Protocol:** Nostr (via @nostr-dev-kit/ndk)
*   **Version Control:** Git
*   **Key Libraries:**
    *   Commander - CLI framework
    *   Zod - Runtime type validation
    *   multi-llm-ts - Multi-LLM integration

## 5. Project Goals

*   To create a new paradigm for software development that is more efficient and powerful than traditional methods.
*   To leverage the power of multiple, specialized AI agents to tackle complex programming tasks.
*   To build a system that is robust, decentralized, and continuously improves itself.
</file>

<file path="src/conversations/services/ConversationStore.ts">
import { logger } from "@/utils/logger";
import type { Conversation } from "../types";

/**
 * In-memory storage for active conversations.
 * Single Responsibility: Fast lookup and retrieval of conversation objects.
 */
export class ConversationStore {
  private conversations: Map<string, Conversation> = new Map();

  /**
   * Get a conversation by ID
   */
  get(id: string): Conversation | undefined {
    return this.conversations.get(id);
  }

  /**
   * Store a conversation
   */
  set(id: string, conversation: Conversation): void {
    // Debug logging for session tracking
    if (conversation.agentStates) {
      for (const [agentSlug, state] of conversation.agentStates.entries()) {
        if (state.claudeSessionsByPhase) {
          logger.debug(`[ConversationStore] Storing conversation ${id.substring(0, 8)} with existing sessions for agent ${agentSlug}:`, {
            conversationId: id,
            agentSlug,
            sessions: state.claudeSessionsByPhase,
          });
        }
      }
    }
    
    this.conversations.set(id, conversation);
    logger.debug(`[ConversationStore] Stored conversation ${id}`);
  }

  /**
   * Delete a conversation
   */
  delete(id: string): void {
    this.conversations.delete(id);
    logger.debug(`[ConversationStore] Deleted conversation ${id}`);
  }

  /**
   * Check if a conversation exists
   */
  exists(id: string): boolean {
    return this.conversations.has(id);
  }

  /**
   * Check if a conversation exists
   */
  has(id: string): boolean {
    return this.conversations.has(id);
  }

  /**
   * Get all conversations
   */
  getAll(): Conversation[] {
    return Array.from(this.conversations.values());
  }

  /**
   * Find a conversation by event ID
   */
  findByEvent(eventId: string): Conversation | undefined {
    for (const conversation of this.conversations.values()) {
      if (conversation.history.some((e) => e.id === eventId)) {
        return conversation;
      }
    }
    return undefined;
  }

  /**
   * Clear all conversations
   */
  clear(): void {
    this.conversations.clear();
    logger.debug("[ConversationStore] Cleared all conversations");
  }

  /**
   * Get the number of stored conversations
   */
  size(): number {
    return this.conversations.size;
  }
}
</file>

<file path="src/conversations/services/index.ts">
export {
  type IAgentResolver,
  MockAgentResolver,
  ProjectAgentResolver,
  StandaloneAgentResolver,
} from "./AgentResolver";
export { ConversationCoordinator } from "./ConversationCoordinator";
export { ConversationEventProcessor } from "./ConversationEventProcessor";
export {
  ConversationPersistenceService,
  createFileSystemPersistenceService,
  type IConversationPersistenceService,
  InMemoryPersistenceAdapter,
} from "./ConversationPersistenceService";
export { ConversationStore } from "./ConversationStore";
</file>

<file path="src/lib/fs/filesystem.ts">
import type { Stats } from "node:fs";
import * as fs from "node:fs";
import * as fsPromises from "node:fs/promises";
import * as os from "node:os";
import * as path from "node:path";
import { formatAnyError } from "@/utils/error-formatter";
import { logger } from "@/utils/logger";

/**
 * Unified file system utilities combining patterns from CLI and shared packages
 * Provides both sync and async operations with consistent error handling
 *
 * @module filesystem
 * @description
 * This module provides a comprehensive set of file system utilities with:
 * - Path resolution and expansion (home directory ~)
 * - Directory and file existence checks
 * - JSON file read/write operations
 * - Text file operations
 * - Directory listing and management
 * - File copying and deletion
 * - Consistent error handling across all operations
 */

// File operations
export async function readFile(filePath: string, encoding?: BufferEncoding): Promise<string>;
export async function readFile(filePath: string, encoding: null): Promise<Buffer>;
export async function readFile(
  filePath: string,
  encoding?: BufferEncoding | null
): Promise<string | Buffer> {
  return await fsPromises.readFile(filePath, encoding as BufferEncoding | null | undefined);
}

export function expandHome(filePath: string): string {
  if (filePath.startsWith("~")) {
    return path.join(os.homedir(), filePath.slice(1));
  }
  return filePath;
}

export function resolvePath(filePath: string): string {
  return path.resolve(expandHome(filePath));
}

// Directory operations
export async function ensureDirectory(dirPath: string): Promise<void> {
  try {
    await fsPromises.access(dirPath);
  } catch (err: unknown) {
    if (err instanceof Error && "code" in err && err.code === "ENOENT") {
      await fsPromises.mkdir(dirPath, { recursive: true });
    } else {
      throw err;
    }
  }
}

export function ensureDirectorySync(dirPath: string): void {
  if (!fs.existsSync(dirPath)) {
    fs.mkdirSync(dirPath, { recursive: true });
  }
}

export async function directoryExists(dirPath: string): Promise<boolean> {
  try {
    const stat = await fsPromises.stat(dirPath);
    return stat.isDirectory();
  } catch (err: unknown) {
    if (err instanceof Error && "code" in err && err.code === "ENOENT") {
      return false;
    }
    throw err;
  }
}

export function directoryExistsSync(dirPath: string): boolean {
  try {
    const stat = fs.statSync(dirPath);
    return stat.isDirectory();
  } catch (err: unknown) {
    if (err instanceof Error && "code" in err && err.code === "ENOENT") {
      return false;
    }
    throw err;
  }
}

// Path existence check (works for both files and directories)
export async function pathExists(filePath: string): Promise<boolean> {
  try {
    await fsPromises.access(filePath);
    return true;
  } catch {
    return false;
  }
}

// File operations
export async function fileExists(filePath: string): Promise<boolean> {
  try {
    const stat = await fsPromises.stat(filePath);
    return stat.isFile();
  } catch (err: unknown) {
    if (err instanceof Error && "code" in err && err.code === "ENOENT") {
      return false;
    }
    throw err;
  }
}

export function fileExistsSync(filePath: string): boolean {
  try {
    const stat = fs.statSync(filePath);
    return stat.isFile();
  } catch (err: unknown) {
    if (err instanceof Error && "code" in err && err.code === "ENOENT") {
      return false;
    }
    throw err;
  }
}

// JSON operations with error handling
export async function readJsonFile<T>(filePath: string): Promise<T | null> {
  try {
    const content = await fsPromises.readFile(resolvePath(filePath), "utf-8");
    return JSON.parse(content) as T;
  } catch (err: unknown) {
    if (err instanceof Error && "code" in err && err.code === "ENOENT") {
      return null;
    }
    logger.error(`Failed to read JSON file ${filePath}: ${formatAnyError(err)}`);
    throw err;
  }
}

export function readJsonFileSync<T>(filePath: string): T | null {
  try {
    const content = fs.readFileSync(resolvePath(filePath), "utf-8");
    return JSON.parse(content) as T;
  } catch (err: unknown) {
    if (err instanceof Error && "code" in err && err.code === "ENOENT") {
      return null;
    }
    logger.error(`Failed to read JSON file ${filePath}: ${formatAnyError(err)}`);
    throw err;
  }
}

export async function writeJsonFile<T>(
  filePath: string,
  data: T,
  options?: { spaces?: number }
): Promise<void> {
  const resolvedPath = resolvePath(filePath);
  await ensureDirectory(path.dirname(resolvedPath));
  const spaces = options?.spaces ?? 2;
  await fsPromises.writeFile(resolvedPath, JSON.stringify(data, null, spaces));
}

export function writeJsonFileSync<T>(
  filePath: string,
  data: T,
  options?: { spaces?: number }
): void {
  const resolvedPath = resolvePath(filePath);
  ensureDirectorySync(path.dirname(resolvedPath));
  const spaces = options?.spaces ?? 2;
  fs.writeFileSync(resolvedPath, JSON.stringify(data, null, spaces));
}

// Text file operations
export async function readTextFile(filePath: string): Promise<string | null> {
  try {
    return await fsPromises.readFile(resolvePath(filePath), "utf-8");
  } catch (err: unknown) {
    if (err instanceof Error && "code" in err && err.code === "ENOENT") {
      return null;
    }
    logger.error(`Failed to read text file ${filePath}: ${formatAnyError(err)}`);
    throw err;
  }
}

export function readTextFileSync(filePath: string): string | null {
  try {
    return fs.readFileSync(resolvePath(filePath), "utf-8");
  } catch (err: unknown) {
    if (err instanceof Error && "code" in err && err.code === "ENOENT") {
      return null;
    }
    logger.error(`Failed to read text file ${filePath}: ${formatAnyError(err)}`);
    throw err;
  }
}

export async function writeTextFile(filePath: string, content: string): Promise<void> {
  const resolvedPath = resolvePath(filePath);
  await ensureDirectory(path.dirname(resolvedPath));
  await fsPromises.writeFile(resolvedPath, content, "utf-8");
}

export function writeTextFileSync(filePath: string, content: string): void {
  const resolvedPath = resolvePath(filePath);
  ensureDirectorySync(path.dirname(resolvedPath));
  fs.writeFileSync(resolvedPath, content, "utf-8");
}

// Directory listing
export async function listDirectory(dirPath: string): Promise<string[]> {
  try {
    return await fsPromises.readdir(resolvePath(dirPath));
  } catch (err: unknown) {
    if (err instanceof Error && "code" in err && err.code === "ENOENT") {
      return [];
    }
    throw err;
  }
}

export function listDirectorySync(dirPath: string): string[] {
  try {
    return fs.readdirSync(resolvePath(dirPath));
  } catch (err: unknown) {
    if (err instanceof Error && "code" in err && err.code === "ENOENT") {
      return [];
    }
    throw err;
  }
}

// File copying
export async function copyFile(src: string, dest: string): Promise<void> {
  const resolvedDest = resolvePath(dest);
  await ensureDirectory(path.dirname(resolvedDest));
  await fsPromises.copyFile(resolvePath(src), resolvedDest);
}

export function copyFileSync(src: string, dest: string): void {
  const resolvedDest = resolvePath(dest);
  ensureDirectorySync(path.dirname(resolvedDest));
  fs.copyFileSync(resolvePath(src), resolvedDest);
}

// File deletion
export async function deleteFile(filePath: string): Promise<void> {
  try {
    await fsPromises.unlink(resolvePath(filePath));
  } catch (err: unknown) {
    if (err instanceof Error && "code" in err && err.code === "ENOENT") {
      // File doesn't exist, that's fine
      return;
    }
    throw err;
  }
}

export function deleteFileSync(filePath: string): void {
  try {
    fs.unlinkSync(resolvePath(filePath));
  } catch (err: unknown) {
    if (err instanceof Error && "code" in err && err.code === "ENOENT") {
      // File doesn't exist, that's fine
      return;
    }
    throw err;
  }
}

// Directory deletion
export async function deleteDirectory(
  dirPath: string,
  options?: { recursive?: boolean }
): Promise<void> {
  try {
    await fsPromises.rm(resolvePath(dirPath), { recursive: options?.recursive ?? true });
  } catch (err: unknown) {
    if (err instanceof Error && "code" in err && err.code === "ENOENT") {
      // Directory doesn't exist, that's fine
      return;
    }
    throw err;
  }
}

export function deleteDirectorySync(dirPath: string, options?: { recursive?: boolean }): void {
  try {
    fs.rmSync(resolvePath(dirPath), { recursive: options?.recursive ?? true });
  } catch (err: unknown) {
    if (err instanceof Error && "code" in err && err.code === "ENOENT") {
      // Directory doesn't exist, that's fine
      return;
    }
    throw err;
  }
}

// File stats
export async function getFileStats(filePath: string): Promise<Stats | null> {
  try {
    return await fsPromises.stat(resolvePath(filePath));
  } catch (err: unknown) {
    if (err instanceof Error && "code" in err && err.code === "ENOENT") {
      return null;
    }
    throw err;
  }
}

export function getFileStatsSync(filePath: string): Stats | null {
  try {
    return fs.statSync(resolvePath(filePath));
  } catch (err: unknown) {
    if (err instanceof Error && "code" in err && err.code === "ENOENT") {
      return null;
    }
    throw err;
  }
}
</file>

<file path="src/llm/providers/MockProvider.ts">
import type { MockLLMConfig } from "@/test-utils/mock-llm/types";
import { MockLLMService } from "@/test-utils/mock-llm/MockLLMService";
import { logger } from "@/utils/logger";
import { MockLanguageModelV2 } from "ai/test";
import type { LanguageModelV2 } from "@ai-sdk/provider";
import type { Provider } from "ai";

/**
 * Creates a mock provider that integrates MockLLMService with AI SDK
 * This allows us to use the mock service through the standard LLMServiceFactory
 */
export function createMockProvider(config?: MockLLMConfig): Provider {
    const mockService = new MockLLMService(config);
    
    // Create a factory function that returns a language model
    const createLanguageModel = (modelId: string): LanguageModelV2 => {
        logger.info(`[MockProvider] Creating language model for: ${modelId}`);
        
        return new MockLanguageModelV2({
            provider: "mock",
            modelId: modelId || "mock-model",
            
            doGenerate: async (options) => {
                // Extract messages - the prompt can be either an array or an object with messages
                const messages = Array.isArray(options?.prompt) 
                    ? options.prompt 
                    : options?.prompt?.messages;
                
                logger.debug("[MockProvider] doGenerate called", {
                    hasPrompt: !!options?.prompt,
                    messageCount: messages?.length || 0,
                    toolCount: Object.keys(options?.tools || {}).length,
                });
                
                if (!messages || messages.length === 0) {
                    logger.warn("[MockProvider] doGenerate called with no messages");
                    return {
                        finishReason: "stop" as const,
                        usage: { inputTokens: 0, outputTokens: 0 },
                        text: "Mock response: no messages provided",
                        toolCalls: [],
                        warnings: [],
                        logprobs: undefined,
                        response: {
                            id: `mock-${Date.now()}`,
                            timestamp: new Date(),
                            modelId,
                        },
                    };
                }

                // Convert AI SDK messages to our Message format
                const convertedMessages = messages.map(msg => ({
                    role: msg.role,
                    content: Array.isArray(msg.content) 
                        ? msg.content.map(part => {
                            if (part.type === "text") return part.text;
                            return "[non-text content]";
                        }).join(" ")
                        : typeof msg.content === "string" ? msg.content : "",
                }));

                // Call MockLLMService
                const response = await mockService.complete({
                    messages: convertedMessages,
                    options: {
                        configName: modelId,
                    },
                });

                // Convert response to AI SDK v2 format
                const text = response.content || "";
                const toolCalls = response.toolCalls?.map((tc, index) => ({
                    toolCallType: "function" as const,
                    toolCallId: `call_${index}`,
                    toolName: tc.name,
                    arguments: tc.params || {},
                })) || [];

                return {
                    finishReason: "stop" as const,
                    usage: {
                        inputTokens: response.usage?.prompt_tokens || 100,
                        outputTokens: response.usage?.completion_tokens || 50,
                    },
                    text,
                    toolCalls,
                    warnings: [],
                    logprobs: undefined,
                    response: {
                        id: `mock-${Date.now()}`,
                        timestamp: new Date(),
                        modelId,
                    },
                };
            },
            
            doStream: async (options) => {
                // Extract messages - the prompt can be either an array or an object with messages
                const messages = Array.isArray(options?.prompt) 
                    ? options.prompt 
                    : options?.prompt?.messages;
                
                logger.debug("[MockProvider] doStream called", {
                    hasPrompt: !!options?.prompt,
                    messageCount: messages?.length || 0,
                    toolCount: Object.keys(options?.tools || {}).length,
                });
                
                if (!messages || messages.length === 0) {
                    logger.warn("[MockProvider] doStream called with no messages");
                    const stream = new ReadableStream({
                        start(controller) {
                            controller.enqueue({
                                type: "text-delta",
                                delta: "Mock response: no messages provided",
                            });
                            controller.enqueue({
                                type: "finish",
                                finishReason: "stop",
                                usage: { inputTokens: 0, outputTokens: 0 },
                                logprobs: undefined,
                            });
                            controller.close();
                        },
                    });
                    return {
                        stream,
                        warnings: [],
                        response: {
                            id: `mock-stream-${Date.now()}`,
                            timestamp: new Date(),
                            modelId,
                        },
                    };
                }

                // Convert messages
                const convertedMessages = messages.map(msg => ({
                    role: msg.role,
                    content: Array.isArray(msg.content) 
                        ? msg.content.map(part => {
                            if (part.type === "text") return part.text;
                            return "[non-text content]";
                        }).join(" ")
                        : typeof msg.content === "string" ? msg.content : "",
                }));

                // Get the mock service's stream
                const streamEvents = mockService.stream({
                    messages: convertedMessages,
                    options: {
                        configName: modelId,
                    },
                });

                // Create a ReadableStream that emits AI SDK v2 stream parts
                const stream = new ReadableStream({
                    async start(controller) {
                        try {
                            const toolCalls: Array<{
                                toolCallId: string;
                                toolName: string;
                                arguments: unknown;
                            }> = [];

                            for await (const event of streamEvents) {
                                switch (event.type) {
                                    case "content":
                                        controller.enqueue({
                                            type: "text-delta",
                                            delta: event.content,
                                        });
                                        break;

                                    case "tool_start": {
                                        const toolCallId = `call_${toolCalls.length}`;
                                        const toolCall = {
                                            toolCallId,
                                            toolName: event.tool,
                                            arguments: event.args,
                                        };
                                        toolCalls.push(toolCall);
                                        
                                        controller.enqueue({
                                            type: "tool-call-delta",
                                            toolCallType: "function" as const,
                                            toolCallId,
                                            toolName: event.tool,
                                            argsTextDelta: JSON.stringify(event.args),
                                        });
                                        break;
                                    }

                                    case "done": {
                                        controller.enqueue({
                                            type: "finish",
                                            finishReason: "stop",
                                            usage: {
                                                inputTokens: event.response?.usage?.prompt_tokens || 100,
                                                outputTokens: event.response?.usage?.completion_tokens || 50,
                                            },
                                            logprobs: undefined,
                                        });
                                        break;
                                    }

                                    case "error": {
                                        controller.enqueue({
                                            type: "error",
                                            error: new Error(event.error),
                                        });
                                        break;
                                    }
                                }
                            }
                            
                            controller.close();
                        } catch (error) {
                            controller.error(error);
                        }
                    },
                });

                return {
                    stream,
                    warnings: [],
                    response: {
                        id: `mock-stream-${Date.now()}`,
                        timestamp: new Date(),
                        modelId,
                    },
                };
            },
        });
    };
    
    // Create a custom provider that can handle any model ID
    const provider: Provider = {
        languageModel: (modelId: string) => {
            return createLanguageModel(modelId);
        },
        textEmbeddingModel: () => {
            throw new Error("Mock provider does not support embedding models");
        },
        // Provider type from 'ai' package may have slightly different interface
        // Cast as needed
    } as Provider;
    
    return provider;
}

/**
 * Global mock service instance for test configuration
 */
let globalMockService: MockLLMService | null = null;

/**
 * Get or create the global mock service
 */
export function getGlobalMockService(config?: MockLLMConfig): MockLLMService {
    if (!globalMockService) {
        globalMockService = new MockLLMService(config);
    }
    return globalMockService;
}

/**
 * Reset the global mock service
 */
export function resetGlobalMockService(): void {
    globalMockService = null;
}
</file>

<file path="src/prompts/fragments/30-project-inventory.ts">
import * as fs from "node:fs";
import * as path from "node:path";
import { logger } from "@/utils/logger";
import { countTotalFiles } from "../utils/projectUtils";
import { fragmentRegistry } from "../core/FragmentRegistry";
import type { PromptFragment } from "../core/types";

// Project inventory context fragment
interface InventoryContextArgs {}

// Helper function to get project files (excluding dot files/dirs)
function getProjectFiles(): { files: string[]; isEmpty: boolean; tree: string } {
  const projectFiles: string[] = [];
  let isEmpty = true;
  let totalFileCount = 0;

  // Helper function to count files in a directory (non-recursive, only direct children)
  function countDirectFiles(dir: string): number {
    let count = 0;
    try {
      const entries = fs.readdirSync(dir, { withFileTypes: true });
      for (const entry of entries) {
        if (!entry.name.startsWith(".") && entry.name !== "node_modules" && !entry.isDirectory()) {
          count += 1;
        }
      }
    } catch (error) {
      logger.debug(`Could not count files in ${dir}`, { error });
    }
    return count;
  }

  // Helper function to build tree structure recursively
  function buildTree(dir: string, prefix = "", _isLast = true, showFiles = true): string[] {
    const treeLines: string[] = [];

    try {
      const entries = fs.readdirSync(dir, { withFileTypes: true });

      // Filter and sort entries
      const filteredEntries = entries.filter((entry) => {
        // Skip dot files/dirs and node_modules
        return !entry.name.startsWith(".") && entry.name !== "node_modules";
      });

      // Sort directories first, then files
      filteredEntries.sort((a, b) => {
        if (a.isDirectory() && !b.isDirectory()) return -1;
        if (!a.isDirectory() && b.isDirectory()) return 1;
        return a.name.localeCompare(b.name);
      });

      filteredEntries.forEach((entry, index) => {
        const isLastEntry = index === filteredEntries.length - 1;
        const connector = isLastEntry ? "‚îî‚îÄ‚îÄ " : "‚îú‚îÄ‚îÄ ";
        const extension = isLastEntry ? "    " : "‚îÇ   ";

        if (entry.isDirectory()) {
          const subDir = path.join(dir, entry.name);
          // Always show directories and recurse
          if (showFiles) {
            treeLines.push(`${prefix}${connector}${entry.name}/`);
          } else {
            // Count only direct files in this directory
            const fileCount = countDirectFiles(subDir);
            const fileLabel =
              fileCount === 0 ? "" : fileCount === 1 ? " (1 file)" : ` (${fileCount} files)`;
            treeLines.push(`${prefix}${connector}${entry.name}/${fileLabel}`);
          }
          // Always recurse into subdirectories
          const subTree = buildTree(subDir, prefix + extension, isLastEntry, showFiles);
          treeLines.push(...subTree);
        } else if (showFiles) {
          treeLines.push(`${prefix}${connector}${entry.name}`);
        }
      });
    } catch (error) {
      logger.debug(`Could not read directory ${dir}`, { error });
    }

    return treeLines;
  }

  try {
    const projectDir = process.cwd();
    const entries = fs.readdirSync(projectDir, { withFileTypes: true });

    for (const entry of entries) {
      // Skip dot files/dirs and node_modules
      if (entry.name.startsWith(".") || entry.name === "node_modules") {
        continue;
      }

      isEmpty = false;

      if (entry.isDirectory()) {
        projectFiles.push(`${entry.name}/`);
      } else {
        projectFiles.push(entry.name);
      }
    }

    // Sort directories first, then files
    projectFiles.sort((a, b) => {
      const aIsDir = a.endsWith("/");
      const bIsDir = b.endsWith("/");
      if (aIsDir && !bIsDir) return -1;
      if (!aIsDir && bIsDir) return 1;
      return a.localeCompare(b);
    });
  } catch (error) {
    logger.debug("Could not read project directory", { error });
  }

  // Count total files to decide whether to show individual files
  totalFileCount = countTotalFiles(process.cwd());
  const showFiles = totalFileCount < 200;

  // Build the tree structure
  const treeLines = buildTree(process.cwd(), "", true, showFiles);

  // If not showing files and there are files in the root directory, add a count
  if (!showFiles) {
    const rootFileCount = countDirectFiles(process.cwd());
    if (rootFileCount > 0) {
      const fileLabel = rootFileCount === 1 ? "1 file in root" : `${rootFileCount} files in root`;
      treeLines.push(`\n(${fileLabel})`);
    }
  }

  const tree = treeLines.join("\n");

  return { files: projectFiles, isEmpty, tree };
}

// Helper function to load inventory and context synchronously
function loadProjectContextSync(): {
  inventoryContent: string | null;
  projectContent: string | null;
  contextFiles: string[];
} {
  let inventoryContent: string | null = null;
  let contextFiles: string[] = [];

  try {
    const inventoryPath = path.join(process.cwd(), "context", "INVENTORY.md");
    if (fs.existsSync(inventoryPath)) {
      inventoryContent = fs.readFileSync(inventoryPath, "utf8");
    }
  } catch (error) {
    logger.debug("Could not load inventory content", { error });
  }

  // Get list of context files
  try {
    const contextDir = path.join(process.cwd(), "context");
    if (fs.existsSync(contextDir)) {
      const files = fs.readdirSync(contextDir);
      contextFiles = files.filter(
        (f) => f.endsWith(".md") && f !== "INVENTORY.md" && f !== "PROJECT.md"
      );
    }
  } catch (error) {
    // Context directory may not exist
    logger.debug("Could not read context directory", { error });
  }

  return { inventoryContent, projectContent: null, contextFiles };
}

export const inventoryContextFragment: PromptFragment<InventoryContextArgs> = {
  id: "project-inventory-context",
  priority: 25,
  template: () => {
    // If content is provided directly, use it; otherwise load from file
    const loaded = loadProjectContextSync();
    const { inventoryContent, contextFiles } = loaded;

    const parts: string[] = [];

    parts.push(`<project_inventory>
Project Path: ${process.cwd()}

The project inventory provides comprehensive information about this codebase:
`);

    if (inventoryContent) {
      parts.push(`${inventoryContent}

This inventory helps you understand the project structure, significant files, and architectural patterns when working with the codebase.

This is just a map for you to be quickly situated.
`);
    } else {
      // Get project files to determine if this is a fresh project
      const { isEmpty, tree } = getProjectFiles();

      if (isEmpty) {
        parts.push(`## Project Context
This is a fresh project with no files yet.`);
      } else {
        // Count total files to determine if we should strongly recommend inventory generation
        const totalFileCount = countTotalFiles(process.cwd());

        if (totalFileCount > 15) {
          parts.push(`## Project Context

‚ö†Ô∏è **IMPORTANT: Project Inventory Recommended**

This project contains ${totalFileCount} files but lacks a proper inventory. For optimal results, we strongly recommend having the @project-manager agent explore and familiarize itself with the codebase first.

**To generate an inventory, ask:** "@project-manager please explore this project and generate an initial inventory"

This will help all agents better understand:
- Project structure and architecture
- Key files and their purposes
- Technology stack and dependencies
- Coding patterns and conventions

**Current file structure:**

\`\`\`
${tree}
\`\`\`
`);
        } else {
          parts.push(`## Project Context

A proper project inventory does not exist yet. The @project-manager agent can generate a comprehensive inventory to improve results.

Here is a basic file structure we created for you:

\`\`\`
${tree}
\`\`\`
`);
        }
      }
    }

    // Add context files listing if available
    if (contextFiles && contextFiles.length > 0) {
      parts.push(`### Additional Context Files
The following documentation files are available in the context/ directory and can be read using the read_path tool:
${contextFiles.map((f) => `- context/${f}`).join("\n")}`);
    }

    parts.push("</project_inventory>\n");

    return parts.join("\n\n");
  },
};

// Register fragments
fragmentRegistry.register(inventoryContextFragment);
</file>

<file path="src/prompts/fragments/delegated-task-context.ts">
import { fragmentRegistry } from "../core/FragmentRegistry";
import type { PromptFragment } from "../core/types";

/**
 * Context fragment for delegated tasks (NDKTask kind 1934)
 */
interface DelegatedTaskContextArgs {
  taskDescription: string;
}

export const delegatedTaskContextFragment: PromptFragment<DelegatedTaskContextArgs> = {
  id: "delegated-task-context",
  priority: 5, // Early priority to set context
  template: ({ taskDescription }) => {
    return `## Delegated Task Context

You have been assigned a specific task to complete:

**Task:** ${taskDescription}

Focus on completing this specific task efficiently and effectively.`;
  },
  validateArgs: (args): args is DelegatedTaskContextArgs => {
    return typeof (args as any).taskDescription === "string";
  },
  expectedArgs: "{ taskDescription: string }",
};

// Register the fragment
fragmentRegistry.register(delegatedTaskContextFragment);
</file>

<file path="src/prompts/fragments/index.ts">
/**
 * Fragment registration manifest
 * Explicitly registers all prompt fragments in the system
 * This replaces the implicit import side-effects pattern
 */

import { fragmentRegistry } from "../core/FragmentRegistry";

// Import all fragment definitions
import { agentIdentityFragment } from "./01-agent-identity";
// 10-referenced-article uses inline registration, no named export
import "./10-referenced-article";
import { availableAgentsFragment } from "./15-available-agents";
// 20-voice-mode doesn't export the fragment, it's registered inline
import "./20-voice-mode";
import { phaseContextFragment } from "./20-phase-context";
import { retrievedLessonsFragment } from "./24-retrieved-lessons";
import { projectMdFragment } from "./30-project-md";
import { inventoryContextFragment } from "./30-project-inventory";
import { mainInventoryPromptFragment } from "./90-inventory-generation";
import { delegatedTaskContextFragment } from "./delegated-task-context";

/**
 * Register all fragments explicitly
 * This provides a clear view of all available fragments
 */
export function registerAllFragments(): void {
  // Core identity and context
  fragmentRegistry.register(agentIdentityFragment);
  fragmentRegistry.register(delegatedTaskContextFragment);
  
  // Phase-related fragments
  fragmentRegistry.register(phaseContextFragment);
  
  // Agent collaboration
  fragmentRegistry.register(availableAgentsFragment);
  
  // Behavioral guidance
  // voice-mode and referenced-article are registered via side effects
  
  // Context and learning
  fragmentRegistry.register(retrievedLessonsFragment);
  
  // Project-specific
  fragmentRegistry.register(projectMdFragment);
  fragmentRegistry.register(inventoryContextFragment);
  fragmentRegistry.register(mainInventoryPromptFragment);
}

// Auto-register all fragments on import
registerAllFragments();
</file>

<file path="src/services/mcp/MCPManager.ts">
/**
 * MCPManager - AI SDK Native MCP Integration
 * 
 * Uses AI SDK's experimental MCP client for cleaner, more maintainable integration
 */

import * as path from "node:path";
import { experimental_createMCPClient, type experimental_MCPClient } from 'ai';
import { Experimental_StdioMCPTransport } from 'ai/mcp-stdio';
import type { CoreTool } from 'ai';
import { configService } from "@/services/ConfigService";
import type { MCPServerConfig, TenexMCP } from "@/services/config/types";
import { formatAnyError } from "@/utils/error-formatter";
import { logger } from "@/utils/logger";

interface MCPClientEntry {
  client: experimental_MCPClient;
  transport: Experimental_StdioMCPTransport;
  serverName: string;
  config: MCPServerConfig;
}


export class MCPManager {
  private static instance: MCPManager;
  private clients: Map<string, MCPClientEntry> = new Map();
  private isInitialized = false;
  private projectPath?: string;
  private cachedTools: Record<string, CoreTool<unknown, unknown>> = {};

  private constructor() {}

  static getInstance(): MCPManager {
    if (!MCPManager.instance) {
      MCPManager.instance = new MCPManager();
    }
    return MCPManager.instance;
  }

  async initialize(projectPath?: string): Promise<void> {
    if (this.isInitialized) {
      return;
    }

    try {
      this.projectPath = projectPath;
      const config = await configService.loadConfig(projectPath);

      if (!config.mcp || !config.mcp.enabled) {
        logger.info("MCP is disabled");
        return;
      }

      await this.startServers(config.mcp);
      await this.refreshToolCache();
      this.isInitialized = true;
    } catch (error) {
      logger.error("Failed to initialize MCP manager:", error);
      // Don't throw - allow the system to continue without MCP
    }
  }

  private async startServers(mcpConfig: TenexMCP): Promise<void> {
    const startPromises = Object.entries(mcpConfig.servers).map(([name, config]) =>
      this.startServer(name, config).catch((error) => {
        logger.error(`Failed to start MCP server '${name}':`, error);
        // Continue with other servers
      })
    );

    await Promise.all(startPromises);
  }

  private async startServer(name: string, config: MCPServerConfig): Promise<void> {
    if (this.clients.has(name)) {
      logger.warn(`MCP server '${name}' is already running`);
      return;
    }

    // SECURITY CHECK: Enforce allowedPaths
    if (config.allowedPaths && config.allowedPaths.length > 0 && this.projectPath) {
      const resolvedProjectPath = path.resolve(this.projectPath);
      const isAllowed = config.allowedPaths.some((allowedPath) => {
        const resolvedAllowedPath = path.resolve(allowedPath);
        return (
          resolvedProjectPath.startsWith(resolvedAllowedPath) ||
          resolvedAllowedPath.startsWith(resolvedProjectPath)
        );
      });

      if (!isAllowed) {
        logger.warn(
          `Skipping MCP server '${name}' due to path restrictions. Project path '${this.projectPath}' is not in allowedPaths: ${config.allowedPaths.join(", ")}`
        );
        return;
      }
    }

    const mergedEnv: Record<string, string> = {};
    // Only include defined environment variables
    for (const [key, value] of Object.entries(process.env)) {
      if (value !== undefined) {
        mergedEnv[key] = value;
      }
    }
    // Override with config env
    if (config.env) {
      Object.assign(mergedEnv, config.env);
    }

    logger.debug(
      `Starting MCP server '${name}' with command: ${config.command} ${config.args.join(" ")}`
    );

    const transport = new Experimental_StdioMCPTransport({
      command: config.command,
      args: config.args,
      env: mergedEnv,
      cwd: this.projectPath,
    });

    try {
      const client = await experimental_createMCPClient({
        transport,
        name: `tenex-${name}`,
        version: "1.0.0",
      });

      // Perform health check - try to get tools
      const timeoutPromise = new Promise((_, reject) =>
        setTimeout(() => reject(new Error("Health check timeout")), 5000)
      );

      try {
        await Promise.race([
          client.tools(),
          timeoutPromise
        ]);
      } catch (error) {
        logger.error(`MCP server '${name}' failed health check:`, error);
        await transport.close();
        return;
      }

      this.clients.set(name, {
        client,
        transport,
        serverName: name,
        config,
      });

      logger.info(`Started MCP server '${name}'`);
    } catch (error) {
      logger.error(`Failed to create MCP client for '${name}':`, formatAnyError(error));
      try {
        await transport.close();
      } catch {
        // Ignore close errors
      }
    }
  }

  private async refreshToolCache(): Promise<void> {
    const tools: Record<string, CoreTool<unknown, unknown>> = {};

    for (const [serverName, entry] of this.clients) {
      try {
        const serverTools = await entry.client.tools();
        
        // Namespace the tools with server name
        for (const [toolName, tool] of Object.entries(serverTools)) {
          const namespacedName = `mcp__${serverName}__${toolName}`;
          
          // The tools from experimental_MCPClient are already CoreTool instances
          // We just need to ensure they have the correct structure
          // CoreTool should have: description, parameters (as zod schema), and execute function
          
          // Store the tool directly - it's already a proper CoreTool
          tools[namespacedName] = tool;
          
          // Log the tool structure for debugging
          logger.debug(`MCP tool '${namespacedName}' registered`, {
            hasDescription: !!tool.description,
            hasParameters: !!tool.parameters,
            hasExecute: typeof tool.execute === 'function',
            parametersType: tool.parameters ? typeof tool.parameters : 'undefined'
          });
        }

        logger.debug(`Discovered ${Object.keys(serverTools).length} tools from MCP server '${serverName}'`);
      } catch (error) {
        logger.error(`Failed to get tools from MCP server '${serverName}':`, formatAnyError(error));
      }
    }

    this.cachedTools = tools;
    logger.info(`Cached ${Object.keys(tools).length} MCP tools from ${this.clients.size} servers`);
  }

  /**
   * Get all cached MCP tools as an object keyed by tool name
   */
  getCachedTools(): Record<string, CoreTool<unknown, unknown>> {
    return this.cachedTools;
  }

  /**
   * Get tools for a specific agent based on their configuration
   * @param requestedTools - Array of tool names the agent wants
   * @param mcpEnabled - Whether the agent has MCP access
   */
  async getToolsForAgent(
    requestedTools: string[],
    mcpEnabled = true
  ): Promise<Record<string, CoreTool<unknown, unknown>>> {
    const tools: Record<string, CoreTool<unknown, unknown>> = {};

    if (!mcpEnabled) {
      return tools;
    }

    // Filter requested MCP tools
    const requestedMcpTools = requestedTools.filter(name => name.startsWith('mcp__'));

    if (requestedMcpTools.length > 0) {
      // Return only requested MCP tools
      for (const toolName of requestedMcpTools) {
        if (this.cachedTools[toolName]) {
          tools[toolName] = this.cachedTools[toolName];
        } else {
          logger.debug(`Requested MCP tool '${toolName}' not found`);
        }
      }
    } else if (mcpEnabled) {
      // Return all MCP tools if none specifically requested but MCP is enabled
      Object.assign(tools, this.cachedTools);
    }

    return tools;
  }

  async shutdown(): Promise<void> {
    const shutdownPromises: Promise<void>[] = [];

    for (const [name, entry] of this.clients) {
      shutdownPromises.push(this.shutdownServer(name, entry));
    }

    await Promise.all(shutdownPromises);
    this.clients.clear();
    this.cachedTools = {};
    this.isInitialized = false;
  }

  private async shutdownServer(name: string, entry: MCPClientEntry): Promise<void> {
    try {
      await entry.transport.close();
      logger.info(`Shut down MCP server '${name}'`);
    } catch (error) {
      logger.error(`Error shutting down MCP server '${name}':`, formatAnyError(error));
    }
  }

  /**
   * Check if a server is running
   */
  isServerRunning(name: string): boolean {
    return this.clients.has(name);
  }

  /**
   * Get list of running servers
   */
  getRunningServers(): string[] {
    return Array.from(this.clients.keys());
  }

  /**
   * Reload MCP service configuration and restart servers
   */
  async reload(projectPath?: string): Promise<void> {
    logger.info("Reloading MCP manager configuration");

    // Shutdown existing servers
    await this.shutdown();

    // Re-initialize with the new configuration
    await this.initialize(projectPath || this.projectPath);

    logger.info("MCP manager reloaded successfully", {
      runningServers: this.getRunningServers(),
      availableTools: Object.keys(this.cachedTools).length,
    });
  }
}

export const mcpManager = MCPManager.getInstance();
// Export as mcpService for compatibility with existing code
export const mcpService = mcpManager;
</file>

<file path="src/services/ReportManager.ts">
import type { AgentInstance } from "@/agents/types";
import { getNDK } from "@/nostr";
import { getProjectContext } from "@/services/ProjectContext";
import { logger } from "@/utils/logger";
import NDK, { NDKArticle } from "@nostr-dev-kit/ndk";
import { nip19 } from "nostr-tools";

export interface ReportData {
  slug: string;
  title: string;
  summary: string;
  content: string;
  hashtags?: string[];
}

export interface ReportInfo {
  id: string;
  slug: string;
  title?: string;
  summary?: string;
  content?: string;
  author: string;
  publishedAt?: number;
  hashtags?: string[];
  projectReference?: string;
  isDeleted?: boolean;
}

export interface ReportSummary {
  id: string;
  slug: string;
  title?: string;
  summary?: string;
  author: string;
  publishedAt?: number;
  hashtags?: string[];
}

/**
 * Centralized service for managing NDKArticle reports
 * Handles creation, reading, listing, and deletion of reports
 */
export class ReportManager {
  private ndk: NDK;

  constructor(ndk?: NDK) {
    const ndkInstance = ndk || getNDK();
    if (!ndkInstance) {
      throw new Error("NDK instance not available");
    }
    this.ndk = ndkInstance;
  }

  /**
   * Write or update a report
   */
  async writeReport(data: ReportData, agent: AgentInstance): Promise<string> {
    const projectCtx = getProjectContext();
    if (!projectCtx?.project) {
      throw new Error("No project context available");
    }

    if (!agent.signer) {
      throw new Error("Agent signer required to publish reports");
    }

    const article = new NDKArticle(this.ndk);
    
    // Set the d-tag explicitly to the provided slug
    article.dTag = data.slug;
    
    // Set article properties
    article.title = data.title;
    article.summary = data.summary;
    article.content = data.content;
    article.published_at = Math.floor(Date.now() / 1000);
    
    // Add hashtags if provided
    if (data.hashtags && data.hashtags.length > 0) {
      article.tags.push(...data.hashtags.map(tag => ["t", tag]));
    }
    
    // Tag the current project using a-tag
    const projectTagId = projectCtx.project.tagId();
    article.tags.push(["a", projectTagId]);
    
    // Add author tag for the agent
    article.tags.push(["p", agent.pubkey, "", "author"]);
    
    // Sign and publish the article
    await article.sign(agent.signer);
    await article.publish();
    
    // Return the encoded article ID
    return article.encode();
  }

  /**
   * Read a report by slug or naddr
   */
  async readReport(identifier: string, agentPubkey?: string): Promise<ReportInfo | null> {
    let article: NDKArticle | null = null;

    // Check if identifier is an naddr
    if (identifier.startsWith("naddr1")) {
      // Decode the naddr to get the event
      const decoded = nip19.decode(identifier);
      if (decoded.type === "naddr" && decoded.data.kind === 30023) {
        // Fetch the specific article
        const filter = {
          kinds: [30023],
          authors: [decoded.data.pubkey],
          "#d": [decoded.data.identifier],
        };
        
        const events = await this.ndk.fetchEvents(filter);
        if (events.size > 0) {
          const event = Array.from(events)[0];
          article = NDKArticle.from(event);
        }
      }
    } else if (agentPubkey) {
      // Treat as a slug - search for articles with this d-tag from specific agent
      const filter = {
        kinds: [30023],
        authors: [agentPubkey],
        "#d": [identifier],
      };
      
      const events = await this.ndk.fetchEvents(filter);
      if (events.size > 0) {
        const event = Array.from(events)[0];
        article = NDKArticle.from(event);
      }
    }

    if (!article) {
      return null;
    }

    return this.articleToReportInfo(article);
  }

  /**
   * List reports from project agents
   */
  async listReports(agentPubkeys?: string[]): Promise<ReportSummary[]> {
    const projectCtx = getProjectContext();
    if (!projectCtx?.project) {
      throw new Error("No project context available");
    }

    // Get the project's tag ID to filter articles
    const projectTagId = projectCtx.project.tagId();
    
    // Build the filter for fetching articles
    interface ArticleFilter {
      kinds: number[];
      "#a": string[];
      authors?: string[];
    }
    
    const filter: ArticleFilter = {
      kinds: [30023],
      "#a": [projectTagId], // Articles that tag this project
    };

    // If agent pubkeys provided, filter by them
    if (agentPubkeys && agentPubkeys.length > 0) {
      filter.authors = agentPubkeys;
    }

    // Fetch the articles
    const events = await this.ndk.fetchEvents(filter);
    
    // Process the articles
    const reports: ReportSummary[] = [];
    
    for (const event of events) {
      const article = NDKArticle.from(event);
      
      // Check if article is deleted
      const isDeleted = article.tags.some(tag => tag[0] === "deleted");
      if (isDeleted) {
        continue; // Skip deleted articles
      }
      
      // Extract hashtags
      const hashtags = article.tags
        .filter(tag => tag[0] === "t")
        .map(tag => tag[1]);
      
      // Get author npub
      const authorNpub = article.author.npub;
      
      reports.push({
        id: `nostr:${article.encode()}`,
        slug: article.dTag || "",
        title: article.title,
        summary: article.summary,
        author: authorNpub,
        publishedAt: article.published_at,
        hashtags: hashtags.length > 0 ? hashtags : undefined,
      });
    }
    
    // Sort reports by published date (newest first)
    reports.sort((a, b) => (b.publishedAt || 0) - (a.publishedAt || 0));

    return reports;
  }

  /**
   * Delete a report by marking it as deleted
   */
  async deleteReport(slug: string, agent: AgentInstance): Promise<string> {
    const projectCtx = getProjectContext();
    if (!projectCtx?.project) {
      throw new Error("No project context available");
    }

    if (!agent.signer) {
      throw new Error("Agent signer required to delete reports");
    }

    // First, find the existing article
    const filter = {
      kinds: [30023],
      authors: [agent.pubkey],
      "#d": [slug],
    };
    
    const events = await this.ndk.fetchEvents(filter);
    if (events.size === 0) {
      throw new Error(`No report found with slug: ${slug}`);
    }

    const event = Array.from(events)[0];
    const article = NDKArticle.from(event);
    
    // Create a new version with empty content and deleted tag
    const deletedArticle = new NDKArticle(this.ndk);
    
    // Preserve the d-tag
    deletedArticle.dTag = slug;
    
    // Set minimal properties
    deletedArticle.title = article.title || "Deleted Report";
    deletedArticle.summary = "This report has been deleted";
    deletedArticle.content = "";
    deletedArticle.published_at = Math.floor(Date.now() / 1000);
    
    // Add the deleted tag
    deletedArticle.tags.push(["deleted"]);
    
    // Preserve the project tag
    const projectTagId = projectCtx.project.tagId();
    deletedArticle.tags.push(["a", projectTagId]);
    
    // Add author tag
    deletedArticle.tags.push(["p", agent.pubkey, "", "author"]);
    
    // Sign and publish the updated article
    await deletedArticle.sign(agent.signer);
    await deletedArticle.publish();
    
    logger.info("üóëÔ∏è Report marked as deleted", {
      slug,
      articleId: deletedArticle.encode(),
    });
    
    return deletedArticle.encode();
  }

  /**
   * Get all agent pubkeys from the project context
   */
  getAllProjectAgentPubkeys(): string[] {
    const projectCtx = getProjectContext();
    if (!projectCtx) {
      return [];
    }

    const agentPubkeys: string[] = [];
    
    // Add project manager pubkey
    if (projectCtx.projectManager) {
      agentPubkeys.push(projectCtx.projectManager.pubkey);
    }
    
    // Add all other agents
    if (projectCtx.agents) {
      for (const agent of projectCtx.agents.values()) {
        if (!agentPubkeys.includes(agent.pubkey)) {
          agentPubkeys.push(agent.pubkey);
        }
      }
    }
    
    return agentPubkeys;
  }

  /**
   * Convert an NDKArticle to ReportInfo
   */
  private articleToReportInfo(article: NDKArticle): ReportInfo {
    // Extract hashtags from tags
    const hashtags = article.tags
      .filter(tag => tag[0] === "t")
      .map(tag => tag[1]);

    // Extract project reference if present
    const projectTag = article.tags.find(tag => tag[0] === "a" && tag[1]?.includes(":31933:"));
    const projectReference = projectTag ? projectTag[1] : undefined;

    // Check if deleted
    const isDeleted = article.tags.some(tag => tag[0] === "deleted");

    // Get author npub
    const authorNpub = article.author.npub;

    return {
      id: `nostr:${article.encode()}`,
      slug: article.dTag || "",
      title: article.title,
      summary: article.summary,
      content: article.content,
      author: authorNpub,
      publishedAt: article.published_at,
      hashtags: hashtags.length > 0 ? hashtags : undefined,
      projectReference,
      isDeleted,
    };
  }
}
</file>

<file path="src/test-utils/bun-mocks.ts">
import { mock } from "bun:test";
import type { NDKEvent } from "@nostr-dev-kit/ndk";
import type { Conversation, AgentState } from "@/conversations/types";
import type { AgentInstance } from "@/agents/types";

/**
 * Create a mock NDKEvent for testing
 */
export function createMockNDKEvent(overrides: Partial<NDKEvent> = {}): NDKEvent {
  const event = {
    id: "test-event-id",
    kind: 1,
    pubkey: "test-pubkey",
    created_at: Math.floor(Date.now() / 1000),
    content: "test content",
    tags: [],
    sig: "test-sig",
    relay: undefined,
    tag: mock((tag: string[]): void => {
      (event as NDKEvent).tags.push(tag);
    }),
    tagValue: mock((tagName: string): string | undefined => {
      const tag = (event as NDKEvent).tags.find((t: string[]) => t[0] === tagName);
      return tag ? tag[1] : undefined;
    }),
    getMatchingTags: mock((tagName: string): string[][] => {
      return (event as NDKEvent).tags.filter((t: string[]) => t[0] === tagName);
    }),
    tagReference: mock((): string[] => ["e", "test-event-id"]),
    publish: mock((): Promise<void> => Promise.resolve()),
    reply: mock((): NDKEvent => {
      const replyEvent = createMockNDKEvent();
      replyEvent.tags = [["e", "test-event-id", "", "reply"]];
      return replyEvent;
    }),
    ...overrides,
  };
  
  // Override tags if provided
  if (overrides.tags) {
    event.tags = overrides.tags;
  }
  
  return event as unknown as NDKEvent;
}

interface MockNDK {
  fetchEvent: ReturnType<typeof mock>;
  fetchEvents: ReturnType<typeof mock>;
  publish: ReturnType<typeof mock>;
  connect: ReturnType<typeof mock>;
  signer: {
    sign: ReturnType<typeof mock>;
    pubkey: ReturnType<typeof mock>;
  };
  [key: string]: unknown;
}

/**
 * Create a mock NDK instance
 */
export function createMockNDK(overrides: Partial<MockNDK> = {}): MockNDK {
  return {
    fetchEvent: mock((): Promise<NDKEvent | null> => Promise.resolve(null)),
    fetchEvents: mock((): Promise<Set<NDKEvent>> => Promise.resolve(new Set())),
    publish: mock((): Promise<void> => Promise.resolve()),
    connect: mock((): Promise<void> => Promise.resolve()),
    signer: {
      sign: mock((): Promise<string> => Promise.resolve("signature")),
      pubkey: mock((): string => "test-pubkey"),
    },
    ...overrides,
  };
}

/**
 * Create a mock Conversation
 */
export function createMockConversation(overrides: Partial<Conversation> = {}): Conversation {
  return {
    id: "test-conversation-id",
    title: "Test Conversation",
    phase: "CHAT",
    history: [],
    agentStates: new Map<string, AgentState>(),
    metadata: {},
    executionTime: {
      totalSeconds: 0,
      isActive: false,
      lastUpdated: Date.now(),
    },
    ...overrides,
  };
}

/**
 * Create a mock Agent
 */
export function createMockAgent(overrides: Partial<AgentInstance> = {}): Partial<AgentInstance> {
  return {
    name: "test-agent",
    slug: "test-agent",
    pubkey: "test-agent-pubkey",
    role: "Test role",
    backend: "reason-act-loop",
    tools: [],
    ...overrides,
  };
}

interface MockFSOptions {
  recursive?: boolean;
  [key: string]: unknown;
}

interface MockFSStats {
  isFile(): boolean;
  isDirectory(): boolean;
  size: number;
}

interface MockFS {
  readFile(path: string): Promise<string>;
  writeFile(path: string, content: string): Promise<void>;
  mkdir(path: string, options?: MockFSOptions): Promise<void>;
  readdir(path: string): Promise<string[]>;
  stat(path: string): Promise<MockFSStats>;
  unlink(path: string): Promise<void>;
  _setFile(path: string, content: string): void;
  _setDirectory(path: string): void;
  _clear(): void;
  _getFiles(): Map<string, string>;
  _getDirectories(): Set<string>;
}

/**
 * Create mock file system operations
 */
export function createMockFS(): MockFS {
  const files = new Map<string, string>();
  const directories = new Set<string>(["/", "/tmp"]);

  return {
    readFile: mock((path: string): Promise<string> => {
      if (!files.has(path)) {
        throw new Error(`ENOENT: no such file or directory, open '${path}'`);
      }
      const content = files.get(path);
      if (content === undefined) {
        throw new Error(`File content is undefined for path: ${path}`);
      }
      return Promise.resolve(content);
    }),
    writeFile: mock((path: string, content: string): Promise<void> => {
      // Ensure parent directory exists
      const dir = path.substring(0, path.lastIndexOf("/"));
      if (dir && !directories.has(dir)) {
        throw new Error(`ENOENT: no such file or directory, open '${path}'`);
      }
      files.set(path, content);
      return Promise.resolve();
    }),
    mkdir: mock((path: string, options?: MockFSOptions): Promise<void> => {
      directories.add(path);
      // Add parent directories if recursive
      if (options?.recursive) {
        let currentPath = "";
        for (const part of path.split("/").filter(Boolean)) {
          currentPath += "/" + part;
          directories.add(currentPath);
        }
      }
      return Promise.resolve();
    }),
    readdir: mock((path: string): Promise<string[]> => {
      if (!directories.has(path)) {
        throw new Error(`ENOENT: no such file or directory, scandir '${path}'`);
      }
      const entries: string[] = [];
      const prefix = path.endsWith("/") ? path : path + "/";
      
      // Find files in this directory
      for (const filePath of files.keys()) {
        if (filePath.startsWith(prefix)) {
          const relative = filePath.substring(prefix.length);
          if (!relative.includes("/")) {
            entries.push(relative);
          }
        }
      }
      
      // Find subdirectories
      for (const dir of directories) {
        if (dir.startsWith(prefix) && dir !== path) {
          const relative = dir.substring(prefix.length);
          const firstPart = relative.split("/")[0];
          if (firstPart && !entries.includes(firstPart)) {
            entries.push(firstPart);
          }
        }
      }
      
      return Promise.resolve(entries);
    }),
    stat: mock((path: string): Promise<MockFSStats> => {
      if (files.has(path)) {
        return Promise.resolve({
          isFile: () => true,
          isDirectory: () => false,
          size: files.get(path)?.length ?? 0,
        });
      }
      if (directories.has(path)) {
        return Promise.resolve({
          isFile: () => false,
          isDirectory: () => true,
          size: 0,
        });
      }
      throw new Error(`ENOENT: no such file or directory, stat '${path}'`);
    }),
    unlink: mock((path: string): Promise<void> => {
      if (!files.has(path)) {
        throw new Error(`ENOENT: no such file or directory, unlink '${path}'`);
      }
      files.delete(path);
      return Promise.resolve();
    }),
    // Helper methods for testing
    _setFile: (path: string, content: string): void => {
      files.set(path, content);
    },
    _setDirectory: (path: string): void => {
      directories.add(path);
    },
    _clear: (): void => {
      files.clear();
      directories.clear();
      directories.add("/");
      directories.add("/tmp");
    },
    _getFiles: (): Map<string, string> => files,
    _getDirectories: (): Set<string> => directories,
  };
}
</file>

<file path="src/test-utils/conversational-logger.ts">
/**
 * Conversational logger that formats test output as a natural dialog
 * showing phase transitions and agent interactions
 */

import type { MockLLMResponse } from "./mock-llm/types";

interface ToolCall {
  function?: string | {
    name?: string;
    arguments?: string;
  };
  name?: string;
  args?: string;
}

export class ConversationalLogger {
  private static instance: ConversationalLogger;
  private conversationStartTime: Date = new Date();
  private lastPhase = "CHAT";
  private currentAgent: string | null = null;

  static getInstance(): ConversationalLogger {
    if (!ConversationalLogger.instance) {
      ConversationalLogger.instance = new ConversationalLogger();
    }
    return ConversationalLogger.instance;
  }

  private formatTime(): string {
    const elapsed = Date.now() - this.conversationStartTime.getTime();
    const seconds = Math.floor(elapsed / 1000);
    const minutes = Math.floor(seconds / 60);
    if (minutes > 0) {
      return `${minutes}m ${seconds % 60}s`;
    }
    return `${seconds}s`;
  }

  private formatAgentName(agentName: string): string {
    // Capitalize and format agent names nicely
    return agentName
      .replace(/([a-z])([A-Z])/g, "$1 $2") // Add space before capitals
      .replace(/^\w/, (c) => c.toUpperCase()) // Capitalize first letter
      .replace(/-/g, " "); // Replace hyphens with spaces
  }

  private getAgentSlug(agentName: string): string {
    // Convert to lowercase slug format
    return agentName.toLowerCase().replace(/\s+/g, "-");
  }

  private formatLogLine(
    agentName: string | null,
    emoji: string,
    timeStamp: string,
    message: string
  ): string {
    const agentPrefix = agentName ? `[${this.getAgentSlug(agentName)}] ` : "";
    return `${emoji} [${timeStamp}] ${agentPrefix}${message}`;
  }

  logAgentThinking(
    agentName: string,
    context: {
      phase?: string;
      userMessage?: string;
      iteration?: number;
      agentIteration?: number;
    }
  ): void {
    this.currentAgent = agentName;
    const formattedAgent = this.formatAgentName(agentName);
    const timeStamp = this.formatTime();

    // Check if phase changed
    if (context.phase && context.phase !== this.lastPhase) {
      this.logPhaseTransition(this.lastPhase, context.phase);
      this.lastPhase = context.phase;
    }

    if (context.userMessage) {
      const message = `${formattedAgent} received: "${context.userMessage.substring(0, 60)}${context.userMessage.length > 60 ? "..." : ""}"`;
      console.log(`\n${this.formatLogLine(agentName, "üéØ", timeStamp, message)}`);
    }

    const message = `${formattedAgent} is thinking...`;
    console.log(this.formatLogLine(agentName, "ü§î", timeStamp, message));
  }

  logAgentResponse(
    agentName: string,
    response: {
      content?: string;
      toolCalls?: ToolCall[];
      phase?: string;
      reason?: string;
    }
  ): void {
    const formattedAgent = this.formatAgentName(agentName);
    const timeStamp = this.formatTime();

    if (response.content) {
      // Format routing decisions nicely
      if (agentName.toLowerCase() === "orchestrator") {
        try {
          const routing = JSON.parse(response.content);
          if (routing.agents && routing.phase && routing.reason) {
            const message = `${formattedAgent}: "I'll route this to ${routing.agents.join(", ")} in ${routing.phase} phase - ${routing.reason}"`;
            console.log(this.formatLogLine(agentName, "üéØ", timeStamp, message));
            return;
          }
        } catch {
          // Not a JSON routing response, handle normally
        }
      }

      const truncatedContent =
        response.content.length > 80 ? `${response.content.substring(0, 80)}...` : response.content;
      const message = `${formattedAgent}: "${truncatedContent}"`;
      console.log(this.formatLogLine(agentName, "üí¨", timeStamp, message));
    }

    if (response.toolCalls && response.toolCalls.length > 0) {
      for (const toolCall of response.toolCalls) {
        const toolName =
          typeof toolCall.function === "string"
            ? toolCall.function
            : toolCall.function?.name || toolCall.name || "unknown";

        this.logToolExecution(agentName, toolName, toolCall);
      }
    }
  }

  logToolExecution(agentName: string, toolName: string, toolCall: ToolCall): void {
    const formattedAgent = this.formatAgentName(agentName);
    const timeStamp = this.formatTime();

    switch (toolName) {
      case "continue":
        try {
          const args =
            typeof toolCall.function === "string"
              ? JSON.parse(toolCall.args || "{}")
              : JSON.parse(toolCall.function?.arguments || "{}");

          if (args.agents) {
            const message = `${formattedAgent}: "Passing control to ${args.agents.join(", ")} - ${args.reason || "continuing workflow"}"`;
            console.log(this.formatLogLine(agentName, "üîÑ", timeStamp, message));
          } else {
            const message = `${formattedAgent}: "Continuing with next phase - ${args.summary || args.reason || "proceeding"}"`;
            console.log(this.formatLogLine(agentName, "üîÑ", timeStamp, message));
          }
        } catch {
          const message = `${formattedAgent}: "Continuing workflow..."`;
          console.log(this.formatLogLine(agentName, "üîÑ", timeStamp, message));
        }
        break;

      case "complete":
        try {
          const args =
            typeof toolCall.function === "string"
              ? JSON.parse(toolCall.args || "{}")
              : JSON.parse(toolCall.function?.arguments || "{}");
          const message = `${formattedAgent}: "Task completed - ${args.finalResponse || args.summary || "done"}"`;
          console.log(this.formatLogLine(agentName, "‚úÖ", timeStamp, message));
        } catch {
          const message = `${formattedAgent}: "Task completed successfully"`;
          console.log(this.formatLogLine(agentName, "‚úÖ", timeStamp, message));
        }
        break;

      case "shell":
        try {
          const args =
            typeof toolCall.function === "string"
              ? JSON.parse(toolCall.args || "{}")
              : JSON.parse(toolCall.function?.arguments || "{}");
          const message = `${formattedAgent}: "Executing: ${args.command}"`;
          console.log(this.formatLogLine(agentName, "‚ö°", timeStamp, message));
        } catch {
          const message = `${formattedAgent}: "Executing shell command..."`;
          console.log(this.formatLogLine(agentName, "‚ö°", timeStamp, message));
        }
        break;

      case "generateInventory":
        try {
          const args =
            typeof toolCall.function === "string"
              ? JSON.parse(toolCall.args || "{}")
              : JSON.parse(toolCall.function?.arguments || "{}");
          const message = `${formattedAgent}: "Analyzing project structure in ${args.paths?.join(", ") || "current directory"}"`;
          console.log(this.formatLogLine(agentName, "üìã", timeStamp, message));
        } catch {
          const message = `${formattedAgent}: "Generating project inventory..."`;
          console.log(this.formatLogLine(agentName, "üìã", timeStamp, message));
        }
        break;

      case "writeFile":
      case "writeContextFile":
        try {
          const args =
            typeof toolCall.function === "string"
              ? JSON.parse(toolCall.args || "{}")
              : JSON.parse(toolCall.function?.arguments || "{}");
          const message = `${formattedAgent}: "Writing to ${args.path || args.filename || "file"}"`;
          console.log(this.formatLogLine(agentName, "üìù", timeStamp, message));
        } catch {
          const message = `${formattedAgent}: "Writing file..."`;
          console.log(this.formatLogLine(agentName, "üìù", timeStamp, message));
        }
        break;

      default: {
        const message = `${formattedAgent}: "Using ${toolName} tool"`;
        console.log(this.formatLogLine(agentName, "üîß", timeStamp, message));
      }
    }
  }

  logPhaseTransition(fromPhase: string, toPhase: string): void {
    const timeStamp = this.formatTime();
    console.log(`\nüìç [${timeStamp}] Phase transition: ${fromPhase} ‚Üí ${toPhase}`);
  }

  logError(agentName: string, error: string): void {
    const formattedAgent = this.formatAgentName(agentName);
    const timeStamp = this.formatTime();
    const message = `${formattedAgent}: "Error occurred - ${error}"`;
    console.log(this.formatLogLine(agentName, "‚ùå", timeStamp, message));
  }

  logTestStart(testName: string): void {
    this.conversationStartTime = new Date();
    this.lastPhase = "CHAT";
    console.log(`\nüé¨ Starting test: ${testName}`);
    console.log(`üìÖ ${this.conversationStartTime.toISOString()}`);
    console.log(`${"=".repeat(60)}\n`);
  }

  logTestEnd(success: boolean, testName?: string): void {
    const timeStamp = this.formatTime();
    const status = success ? "‚úÖ PASSED" : "‚ùå FAILED";
    console.log(`\n${"=".repeat(60)}`);
    console.log(`üèÅ [${timeStamp}] Test completed: ${status} ${testName || ""}`);
  }

  logMatchedResponse(mockResponse: MockLLMResponse): void {
    const timeStamp = this.formatTime();
    const trigger = mockResponse.trigger;
    const agentName = typeof trigger.agentName === 'string' 
      ? trigger.agentName 
      : (trigger.agentName?.toString() || this.currentAgent);

    let triggerDescription = "";
    if (trigger.agentName) {
      const agentNameStr = typeof trigger.agentName === 'string' ? trigger.agentName : trigger.agentName.toString();
      triggerDescription += `Agent: ${this.formatAgentName(agentNameStr)}`;
    }
    if (trigger.phase) {
      triggerDescription += `, Phase: ${trigger.phase}`;
    }
    if (trigger.userMessage) {
      const msgPreview = trigger.userMessage.toString().substring(0, 30);
      triggerDescription += `, Message: "${msgPreview}..."`;
    }

    const message = `Mock matched (${triggerDescription})`;
    console.log(this.formatLogLine(agentName, "üéØ", timeStamp, message));

    if (mockResponse.response.content) {
      const preview = mockResponse.response.content.substring(0, 50);
      console.log(
        `   ‚Üí Response: "${preview}${mockResponse.response.content.length > 50 ? "..." : ""}"`
      );
    }

    // Log tool calls if present
    if (mockResponse.response.toolCalls && mockResponse.response.toolCalls.length > 0) {
      const toolNames = mockResponse.response.toolCalls.map((tc) => {
        const toolName = tc.function?.name || tc.name || "unknown";
        return toolName;
      });
      console.log(`   ‚Üí Tools: [${toolNames.join(", ")}]`);
    }
  }

  reset(): void {
    this.conversationStartTime = new Date();
    this.lastPhase = "CHAT";
    this.currentAgent = null;
  }
}

// Export singleton instance
export const conversationalLogger = ConversationalLogger.getInstance();
</file>

<file path="src/test-utils/index.ts">
/**
 * Test utilities for TENEX backend
 *
 * This module provides comprehensive testing utilities including:
 * - Mock LLM service for deterministic E2E testing
 * - Mock factories for common objects
 * - Test environment helpers
 * - Assertion utilities
 */

export * from "./conversational-logger";
export * from "./e2e-conversational-setup";
export * from "./mock-factories";
export * from "./mock-llm";
export * from "./mock-setup";

import { expect, mock } from "bun:test";
import * as fs from "node:fs/promises";
import { tmpdir } from "node:os";
import * as path from "node:path";

/**
 * Create a temporary directory for testing
 */
export async function createTempDir(prefix = "tenex-test-"): Promise<string> {
  const tempPath = path.join(tmpdir(), prefix + Math.random().toString(36).substr(2, 9));
  await fs.mkdir(tempPath, { recursive: true });
  return tempPath;
}

/**
 * Clean up a temporary directory
 */
export async function cleanupTempDir(dirPath: string): Promise<void> {
  try {
    await fs.rm(dirPath, { recursive: true, force: true });
  } catch {
    // Ignore errors during cleanup
  }
}

/**
 * Reset all mocks and singletons
 */
export function resetAllMocks(): void {
  mock.restore();

  // Reset singletons
  const modules = [
    "@/services/mcp/MCPService",
    "@/services/ConfigService",
    "@/services/ProjectContext",
  ];

  for (const module of modules) {
    try {
      // eslint-disable-next-line @typescript-eslint/no-require-imports
      const mod = require(module);
      if (mod.instance) {
        mod.instance = undefined;
      }
      if (mod.getInstance?.cache) {
        mod.getInstance.cache = undefined;
      }
    } catch {
      // Module might not be loaded
    }
  }
}

/**
 * Wait for a condition to be true
 */
export async function waitFor(
  condition: () => boolean | Promise<boolean>,
  timeout = 5000,
  interval = 100
): Promise<void> {
  const start = Date.now();

  while (Date.now() - start < timeout) {
    if (await condition()) {
      return;
    }
    await new Promise((resolve) => setTimeout(resolve, interval));
  }

  throw new Error(`Timeout waiting for condition after ${timeout}ms`);
}

/**
 * Mock file system operations
 */
export function mockFileSystem(files: Map<string, string>): Map<string, string> {
  mock.module("@/lib/fs", () => ({
    fileExists: mock((path: string) => files.has(path)),
    readFile: mock((path: string) => {
      const content = files.get(path);
      if (!content) throw new Error(`File not found: ${path}`);
      return content;
    }),
    writeFile: mock((path: string, content: string) => {
      files.set(path, content);
    }),
    ensureDirectory: mock(() => {}),
    writeJsonFile: mock((path: string, data: unknown) => {
      files.set(path, JSON.stringify(data, null, 2));
    }),
  }));

  return files;
}

/**
 * Capture console output during tests
 */
export class ConsoleCapture {
  private logs: string[] = [];
  private errors: string[] = [];
  private originalLog: typeof console.log = console.log;
  private originalError: typeof console.error = console.error;

  start(): void {
    this.originalLog = console.log;
    this.originalError = console.error;

    console.log = (...args: unknown[]) => {
      this.logs.push(args.map(String).join(" "));
    };

    console.error = (...args: unknown[]) => {
      this.errors.push(args.map(String).join(" "));
    };
  }

  stop(): void {
    console.log = this.originalLog;
    console.error = this.originalError;
  }

  getLogs(): string[] {
    return this.logs;
  }

  getErrors(): string[] {
    return this.errors;
  }

  clear(): void {
    this.logs = [];
    this.errors = [];
  }
}

/**
 * Custom assertions
 */
export const assertions = {
  /**
   * Assert that an async function throws an error
   */
  async toThrowAsync(
    fn: () => Promise<unknown>,
    expectedError?: string | RegExp | Error
  ): Promise<void> {
    try {
      await fn();
      throw new Error("Expected function to throw, but it didn't");
    } catch (error) {
      if (expectedError) {
        if (typeof expectedError === "string") {
          expect((error as Error).message).toContain(expectedError);
        } else if (expectedError instanceof RegExp) {
          expect((error as Error).message).toMatch(expectedError);
        } else {
          expect(error).toBe(expectedError);
        }
      }
    }
  },

  /**
   * Assert that an array contains an object matching partial properties
   */
  toContainObjectMatching<T>(array: T[], partial: Partial<T>): void {
    const found = array.some((item) => {
      return Object.entries(partial).every(([key, value]) => {
        return (item as Record<string, unknown>)[key] === value;
      });
    });

    if (!found) {
      throw new Error(`Array does not contain object matching ${JSON.stringify(partial)}`);
    }
  },
};
</file>

<file path="src/tools/implementations/agents_discover.ts">
import { tool } from 'ai';
import { getNDK } from "@/nostr";
import { NDKAgentDiscovery } from "@/services/NDKAgentDiscovery";
import { logger } from "@/utils/logger";
import { z } from "zod";
const agentsDiscoverSchema = z.object({
  searchText: z.string().nullable().describe("Text to search for in agent name/description/role"),
  limit: z.coerce.number().default(50).describe("Maximum number of agents to return"),
});

type AgentsDiscoverInput = z.infer<typeof agentsDiscoverSchema>;
type AgentsDiscoverOutput = {
  markdown: string;
  agentsFound: number;
};

/**
 * Format discovered agents as markdown
 */
function formatAgentsAsMarkdown(
  agents: Array<{
    id: string;
    title: string;
    role: string;
    description?: string;
    useCriteria?: string;
    authorPubkey: string;
    createdAt?: number;
  }>
): string {
  if (agents.length === 0) {
    return "## No agents found\n\nNo agents match your search criteria. Try broadening your search or check back later.";
  }

  const lines: string[] = [];
  lines.push("# Agent Discovery Results");
  lines.push(`\nFound **${agents.length}** available agent${agents.length === 1 ? "" : "s"}:\n`);

  agents.forEach((agent, index) => {
    lines.push(`## ${index + 1}. ${agent.title}`);
    lines.push(`nostr:${agent.id}`);
    lines.push("");

    lines.push("---");
    lines.push("");
  });

  return lines.join("\n");
}

/**
 * Core implementation of the agents_discover functionality
 * Shared between AI SDK and legacy Tool interfaces
 */
async function executeAgentsDiscover(
  input: AgentsDiscoverInput
): Promise<AgentsDiscoverOutput> {
  const { searchText, limit = 50 } = input;

  const ndk = getNDK();
  const discovery = new NDKAgentDiscovery(ndk);

  // Discover agents with specified filters
  const agents = await discovery.discoverAgents({
    searchText,
  });

  // Format results with bech32 encoded IDs
  let results = agents.map((agent) => {
    // Get bech32 encoded ID from the NDKAgentDefinition event
    const bech32Id = agent.encode();

    return {
      id: bech32Id,
      title: agent.title || "Unnamed Agent",
      role: agent.role || "assistant",
      description: agent.description,
      useCriteria: agent.useCriteria,
      authorPubkey: agent.pubkey,
      createdAt: agent.created_at,
    };
  });

  // Apply limit if specified
  if (limit && results.length > limit) {
    results = results.slice(0, limit);
  }

  logger.info(`Returning ${results.length} AgentDefinition events after limiting`);

  // Format as markdown
  const markdown = formatAgentsAsMarkdown(results);

  return {
    markdown,
    agentsFound: results.length,
  };
}

/**
 * Create an AI SDK tool for discovering agents
 * This is the primary implementation
 */
export function createAgentsDiscoverTool(): ReturnType<typeof tool> {
  return tool({
    description: "Discover agent definition events; these are agent definitions that can be useful to be installed in the project. Use this when trying to discover NEW possible agents to add to the project NOT to see the list of current agents in the project.",
    inputSchema: agentsDiscoverSchema,
    execute: async (input: AgentsDiscoverInput) => {
      try {
        return await executeAgentsDiscover(input);
      } catch (error) {
        logger.error("Failed to discover agents", { error });
        throw new Error(`Failed to discover agents: ${error instanceof Error ? error.message : String(error)}`);
      }
    },
  });
}
</file>

<file path="src/tools/implementations/agents_list.ts">
import { tool } from 'ai';
import { fileExists, readFile } from "@/lib/fs";
import { logger } from "@/utils/logger";
import * as path from "node:path";
import { z } from "zod";
const agentsListSchema = z.object({
  includeGlobal: z
    .boolean()
    .nullable()
    .describe("Whether to include global agents in the list (default: true)"),
  verbose: z
    .boolean()
    .nullable()
    .describe("Whether to include full instructions and details (default: false)"),
});

type AgentsListInput = z.infer<typeof agentsListSchema>;

type AgentInfo = {
  slug: string;
  name: string;
  role: string;
  description?: string;
  instructions?: string;
  useCriteria?: string;
  tools?: string[];
  mcp?: boolean;
  isGlobal?: boolean;
  eventId?: string;
};

type AgentsListOutput = {
  success: boolean;
  message?: string;
  error?: string;
  agents: AgentInfo[];
  summary?: {
    total: number;
    project: number;
    global: number;
  };
};

/**
 * Core implementation of the agents_list functionality
 * Shared between AI SDK and legacy Tool interfaces
 */
async function executeAgentsList(
  input: AgentsListInput
): Promise<AgentsListOutput> {
  const { includeGlobal = true, verbose = false } = input;

      const projectPath = process.cwd();
      const agents: AgentInfo[] = [];
      
      // Load project agents
      const projectAgentsDir = path.join(projectPath, ".tenex", "agents");
      const projectRegistryPath = path.join(projectPath, ".tenex", "agents.json");
      
      let projectAgents = 0;
      let globalAgents = 0;

      // Read project registry
      if (await fileExists(projectRegistryPath)) {
        try {
          const registryContent = await readFile(projectRegistryPath);
          const registry = JSON.parse(registryContent);
          
          for (const [slug, entry] of Object.entries(registry as Record<string, { file: string; eventId?: string }>)) {
            const agentFilePath = path.join(projectAgentsDir, entry.file);
            
            if (await fileExists(agentFilePath)) {
              try {
                const agentContent = await readFile(agentFilePath);
                const agentDef = JSON.parse(agentContent);
                
                agents.push({
                  slug,
                  name: agentDef.name,
                  role: agentDef.role,
                  description: agentDef.description,
                  instructions: verbose ? agentDef.instructions : undefined,
                  useCriteria: agentDef.useCriteria,
                  tools: agentDef.tools,
                  mcp: agentDef.mcp,
                  isGlobal: false,
                  eventId: entry.eventId,
                });
                projectAgents++;
              } catch (error) {
                logger.warn(`Failed to read agent file: ${agentFilePath}`, { error });
              }
            }
          }
        } catch (error) {
          logger.debug("Failed to read project agents registry", { error });
        }
      }

      // Load global agents if requested
      if (includeGlobal) {
        const homedir = process.env.HOME || process.env.USERPROFILE || "";
        const globalAgentsDir = path.join(homedir, ".tenex", "agents");
        const globalRegistryPath = path.join(homedir, ".tenex", "agents.json");
        
        if (await fileExists(globalRegistryPath)) {
          try {
            const registryContent = await readFile(globalRegistryPath);
            const registry = JSON.parse(registryContent);
            
            for (const [slug, entry] of Object.entries(registry as Record<string, { file: string; eventId?: string }>)) {
              // Skip if already loaded from project
              if (agents.some(a => a.slug === slug)) {
                continue;
              }
              
              const agentFilePath = path.join(globalAgentsDir, entry.file);
              
              if (await fileExists(agentFilePath)) {
                try {
                  const agentContent = await readFile(agentFilePath);
                  const agentDef = JSON.parse(agentContent);
                  
                  agents.push({
                    slug,
                    name: agentDef.name,
                    role: agentDef.role,
                    description: agentDef.description,
                    instructions: verbose ? agentDef.instructions : undefined,
                    useCriteria: agentDef.useCriteria,
                    tools: agentDef.tools,
                    mcp: agentDef.mcp,
                    isGlobal: true,
                    eventId: entry.eventId,
                  });
                  globalAgents++;
                } catch (error) {
                  logger.warn(`Failed to read global agent file: ${agentFilePath}`, { error });
                }
              }
            }
          } catch (error) {
            logger.debug("Failed to read global agents registry", { error });
          }
        }
      }


      // Sort agents by type (project first, then global) and name
      agents.sort((a, b) => {
        if (a.isGlobal !== b.isGlobal) return a.isGlobal ? 1 : -1;
        return a.name.localeCompare(b.name);
      });

      logger.info(`Listed ${agents.length} agents`);
      logger.info(`  Project: ${projectAgents}`);
      logger.info(`  Global: ${globalAgents}`);

  return {
    success: true,
    message: `Found ${agents.length} agents`,
    agents,
    summary: {
      total: agents.length,
      project: projectAgents,
      global: globalAgents,
    },
  };
}

/**
 * Create an AI SDK tool for listing agents
 * This is the primary implementation
 */
export function createAgentsListTool(): ReturnType<typeof tool> {
  return tool({
    description: "List all available agents in the project, including their system prompts and configurations",
    inputSchema: agentsListSchema,
    execute: async (input: AgentsListInput) => {
      try {
        return await executeAgentsList(input);
      } catch (error) {
        logger.error("Failed to list agents", { error });
        throw new Error(`Failed to list agents: ${error instanceof Error ? error.message : String(error)}`);
      }
    },
  });
}
</file>

<file path="src/tools/implementations/agents_read.ts">
import { tool } from 'ai';
import { fileExists, readFile } from "@/lib/fs";
import type { ExecutionContext } from "@/agents/execution/types";
import { logger } from "@/utils/logger";
import * as path from "node:path";
import { z } from "zod";
// Define the input schema
const agentsReadSchema = z.object({
  slug: z.string().describe("The slug identifier of the agent to read"),
});

type AgentsReadInput = z.infer<typeof agentsReadSchema>;

// Define the output type
interface AgentsReadOutput {
  success: boolean;
  message?: string;
  error?: string;
  agent?: {
    slug: string;
    name: string;
    role: string;
    description?: string;
    instructions?: string;
    useCriteria?: string;
    llmConfig?: string;
    tools?: string[];
    mcp?: boolean;
    filePath?: string;
    isGlobal?: boolean;
  };
}

/**
 * Tool: agents_read
 * Read a local agent definition from JSON file
 */
/**
 * Core implementation of reading agents
 * Shared between AI SDK and legacy Tool interfaces
 */
async function executeAgentsRead(
  input: AgentsReadInput,
  _context: ExecutionContext
): Promise<AgentsReadOutput> {
  const { slug } = input;

  if (!slug) {
    throw new Error("Agent slug is required");
  }

  // Get project context
  const projectPath = process.cwd();
  
  // Try to read from project agents first
  let agentsDir = path.join(projectPath, ".tenex", "agents");
  const fileName = `${slug}.json`;
  let filePath = path.join(agentsDir, fileName);
  let isGlobal = false;

  // Check if the file exists in project directory
  if (!(await fileExists(filePath))) {
    // Try global agents directory
    const homedir = process.env.HOME || process.env.USERPROFILE || "";
    agentsDir = path.join(homedir, ".tenex", "agents");
    filePath = path.join(agentsDir, fileName);
    isGlobal = true;

    if (!(await fileExists(filePath))) {
      throw new Error(`Agent definition for slug "${slug}" not found in project or global agents`);
    }
  }

  // Read the agent definition file
  let agentDefinition: {
    name: string;
    role: string;
    description?: string;
    instructions?: string;
    useCriteria?: string;
    llmConfig?: string;
    tools?: string[];
    mcp?: boolean;
  };
  try {
    const content = await readFile(filePath);
    agentDefinition = JSON.parse(content);
  } catch (error) {
    throw new Error(`Failed to read or parse agent definition file: ${error}`);
  }

  // Also check if agent is in registry to get additional metadata
  const registryPath = isGlobal
    ? path.join(path.dirname(agentsDir), "agents.json")
    : path.join(projectPath, ".tenex", "agents.json");
  
  if (await fileExists(registryPath)) {
    try {
      const content = await readFile(registryPath);
      const registry = JSON.parse(content);
      // Check if agent exists in registry
      if (registry[slug]) {
        logger.debug("Agent found in registry", { slug });
      }
    } catch (error) {
      logger.debug("Failed to read agents registry", { error });
    }
  }

  logger.info(`Successfully read agent definition for "${agentDefinition.name}" (${slug})`);
  logger.info(`  Location: ${isGlobal ? "Global" : "Project"}`);
  logger.info(`  File: ${filePath}`);

  return {
    success: true,
    message: `Successfully read agent definition for "${agentDefinition.name}"`,
    agent: {
      slug,
      name: agentDefinition.name,
      role: agentDefinition.role,
      description: agentDefinition.description,
      instructions: agentDefinition.instructions,
      useCriteria: agentDefinition.useCriteria,
      llmConfig: agentDefinition.llmConfig,
      tools: agentDefinition.tools,
      mcp: agentDefinition.mcp,
      filePath,
      isGlobal,
    },
  };
}

/**
 * Create an AI SDK tool for reading agents
 * This is the primary implementation
 */
export function createAgentsReadTool(context: ExecutionContext): ReturnType<typeof tool> {
  return tool({
    description: "Read a local agent definition from its JSON file",
    inputSchema: agentsReadSchema,
    execute: async (input: AgentsReadInput) => {
      try {
        return await executeAgentsRead(input, context);
      } catch (error) {
        logger.error("Failed to read agent definition", { error });
        throw new Error(`Failed to read agent definition: ${error instanceof Error ? error.message : String(error)}`);
      }
    },
  });
}
</file>

<file path="src/tools/implementations/generate_inventory.ts">
import { tool } from 'ai';
import { exec } from "node:child_process";
import { promisify } from "node:util";
import { generateInventory, inventoryExists } from "@/utils/inventory";
import { logger } from "@/utils/logger";
import { z } from "zod";
import type { ExecutionContext } from "@/agents/execution/types";

const execAsync = promisify(exec);

const generateInventorySchema = z.object({});

type GenerateInventoryInput = z.infer<typeof generateInventorySchema>;
type GenerateInventoryOutput = {
  message: string;
  inventoryExists: boolean;
  regenerated: boolean;
};

// Core implementation - extracted from existing execute function
async function executeGenerateInventory(input: GenerateInventoryInput, context: ExecutionContext): Promise<GenerateInventoryOutput> {
  logger.info("Agent requesting inventory generation", {
    projectPath: context.projectPath,
  });

  // Check if inventory already exists
  const exists = await inventoryExists(context.projectPath);

  // Check for recently modified files using git status
  let focusFiles: Array<{ path: string; status: string }> | undefined;
  try {
    const { stdout } = await execAsync("git status --porcelain", {
      cwd: context.projectPath,
    });
    if (stdout.trim()) {
      focusFiles = stdout
        .trim()
        .split("\n")
        .filter((line) => line.length > 0)
        .map((line) => ({
          status: line.substring(0, 2).trim(),
          path: line.substring(3),
        }));

      logger.info("Detected modified files for inventory focus", {
        count: focusFiles.length,
        files: focusFiles.slice(0, 10), // Log first 10 files
      });
    }
  } catch (error) {
    logger.warn("Failed to get git status for focus files", { error });
    // Continue without focus files
  }

  // Prepare options if agent context is available
  const options = {
    focusFiles,
    agent: context.agent,
    conversationRootEventId: context.conversationId,
  };

  // Generate the inventory
  await generateInventory(context.projectPath, options);

  const statusMessage = exists
    ? "‚úÖ Project inventory regenerated successfully!"
    : "‚úÖ Project inventory generated successfully!";

  const message = `${statusMessage}

üìã Main inventory saved to context/INVENTORY.md
üìö Complex module guides (if any) saved to context/ directory

The inventory provides comprehensive information about the codebase structure, significant files, and architectural patterns to help with development tasks.`;

  return {
    message,
    inventoryExists: true,
    regenerated: exists,
  };
}

// AI SDK tool factory
export function createGenerateInventoryTool(context: ExecutionContext): ReturnType<typeof tool> {
  return tool({
    description: "Generate a comprehensive project inventory using repomix + LLM analysis",
    inputSchema: generateInventorySchema,
    execute: async (input: GenerateInventoryInput) => {
      return await executeGenerateInventory(input, context);
    },
  });
}
</file>

<file path="src/tools/implementations/mcp_discover.ts">
import { tool } from 'ai';
import { NDKMCPTool } from "@/events/NDKMCPTool";
import { getNDK } from "@/nostr";
import type { ExecutionContext } from "@/agents/execution/types";
import { logger } from "@/utils/logger";
import type { NDKFilter } from "@nostr-dev-kit/ndk";
import { z } from "zod";
// Define the input schema
const mcpDiscoverSchema = z.object({
  searchText: z.string().nullable().describe("Text to search for in tool name/description"),
  limit: z.coerce.number().default(50).describe("Maximum number of tools to return"),
});

type McpDiscoverInput = z.infer<typeof mcpDiscoverSchema>;
type McpDiscoverOutput = {
  markdown: string;
  toolsFound: number;
};

// Core implementation - extracted from existing execute function
async function executeMcpDiscover(input: McpDiscoverInput, _context: ExecutionContext): Promise<McpDiscoverOutput> {
  const { searchText, limit = 50 } = input;
  const ndk = getNDK();

  // Build filter for kind:4200 (NDKMCPTool)
  const filter: NDKFilter = {
    kinds: NDKMCPTool.kinds,
  };

  logger.debug("Discovering NDKMCPTool events", { filter });

  // Fetch events from network
  const events = await ndk.fetchEvents(filter, {
    closeOnEose: true,
    groupable: false,
  });

  logger.info(`Found ${events.size} NDKMCPTool events`);

  // Convert to NDKMCPTool instances and extract metadata
  const discoveredTools: Array<{
    id: string;
    name: string;
    description?: string;
    command?: string;
    image?: string;
    slug: string;
    authorPubkey: string;
    createdAt?: number;
  }> = [];

  for (const event of Array.from(events)) {
    const mcpTool = NDKMCPTool.from(event);

    // Get bech32 encoded ID
    const bech32Id = mcpTool.encode();

    const discovered = {
      id: bech32Id,
      name: mcpTool.name || "Unnamed Tool",
      description: mcpTool.description,
      command: mcpTool.command,
      image: mcpTool.image,
      slug: mcpTool.slug,
      authorPubkey: mcpTool.pubkey,
      createdAt: mcpTool.created_at,
    };

    discoveredTools.push(discovered);
  }

  // Apply local filtering if specified
  let filtered = discoveredTools;

  if (searchText) {
    const searchLower = searchText.toLowerCase();
    filtered = discoveredTools.filter((tool) => {
      const searchableText = [tool.name, tool.description || "", tool.command || ""]
        .join(" ")
        .toLowerCase();

      return searchableText.includes(searchLower);
    });
  }

  // Sort by creation time (newest first)
  filtered.sort((a, b) => (b.createdAt || 0) - (a.createdAt || 0));

  // Limit results
  if (limit && filtered.length > limit) {
    filtered = filtered.slice(0, limit);
  }

  logger.info(`Returning ${filtered.length} MCP tools after filtering`);

  // Format as markdown
  const markdown = formatToolsAsMarkdown(filtered);

  return {
    markdown,
    toolsFound: filtered.length,
  };
}

// AI SDK tool factory
export function createMcpDiscoverTool(context: ExecutionContext): ReturnType<typeof tool> {
  return tool({
    description: "Discover MCP tool definitions from the Nostr network that can be installed and used to extend your capabilities",
    inputSchema: mcpDiscoverSchema,
    execute: async (input: McpDiscoverInput) => {
      return await executeMcpDiscover(input, context);
    },
  });
}

/**
 * Format discovered tools as markdown
 */
function formatToolsAsMarkdown(
  tools: Array<{
    id: string;
    name: string;
    description?: string;
    command?: string;
    image?: string;
    slug: string;
    authorPubkey: string;
    createdAt?: number;
  }>
): string {
  if (tools.length === 0) {
    return "## No MCP tools found\n\nNo tools match your search criteria. Try broadening your search or check back later.";
  }

  const lines: string[] = [];
  lines.push("# MCP Tool Discovery Results");
  lines.push(`\nFound **${tools.length}** available tool${tools.length === 1 ? "" : "s"}:\n`);

  tools.forEach((tool, index) => {
    lines.push(`## ${index + 1}. ${tool.name}`);
    lines.push(`nostr:${tool.id}`);
    lines.push("");

    lines.push("---");
    lines.push("");
  });

  return lines.join("\n");
}
</file>

<file path="src/tools/implementations/report_delete.ts">
import { tool } from 'ai';
import { ReportManager } from "@/services/ReportManager";
import { logger } from "@/utils/logger";
import { z } from "zod";
import type { ExecutionContext } from "@/agents/execution/types";

const reportDeleteSchema = z.object({
  slug: z.string().describe("The slug identifier (d-tag) of the report to delete"),
});

type ReportDeleteInput = z.infer<typeof reportDeleteSchema>;

interface ReportDeleteOutput {
  success: boolean;
  articleId: string;
  slug: string;
  message: string;
}

/**
 * Core implementation of report deletion functionality
 */
async function executeReportDelete(
  input: ReportDeleteInput,
  context: ExecutionContext
): Promise<ReportDeleteOutput> {
  const { slug } = input;

  logger.info("üóëÔ∏è Deleting report", {
    slug,
    agent: context.agent.name,
    phase: context.phase,
  });

  const reportManager = new ReportManager();
  
  const articleId = await reportManager.deleteReport(slug, context.agent);
  
  logger.info("‚úÖ Report deleted successfully", {
    slug,
    articleId,
    agent: context.agent.name,
  });

  return {
    success: true,
    articleId: `nostr:${articleId}`,
    slug,
    message: `Report "${slug}" marked as deleted`,
  };
}

/**
 * Create an AI SDK tool for deleting reports
 */
export function createReportDeleteTool(context: ExecutionContext): ReturnType<typeof tool> {
  return tool({
    description: "Mark an NDKArticle report as deleted",
    
    inputSchema: reportDeleteSchema,
    
    execute: async (input: ReportDeleteInput) => {
      return await executeReportDelete(input, context);
    },
  });
}
</file>

<file path="src/tools/implementations/report_read.ts">
import { tool } from 'ai';
import { ReportManager } from "@/services/ReportManager";
import { logger } from "@/utils/logger";
import { z } from "zod";
import type { ExecutionContext } from "@/agents/execution/types";

const reportReadSchema = z.object({
  identifier: z
    .string()
    .describe("The slug (d-tag) or naddr1... identifier of the article to read"),
});

type ReportReadInput = z.infer<typeof reportReadSchema>;

interface ReportReadOutput {
  success: boolean;
  article?: {
    id: string;
    slug: string;
    title?: string;
    summary?: string;
    content?: string;
    author?: string;
    publishedAt?: number;
    hashtags?: string[];
    projectReference?: string;
  };
  message?: string;
}

/**
 * Core implementation of report reading functionality
 */
async function executeReportRead(
  input: ReportReadInput,
  context: ExecutionContext
): Promise<ReportReadOutput> {
  const { identifier } = input;

  logger.info("üìñ Reading report", {
    identifier,
    agent: context.agent.name,
    phase: context.phase,
  });

  const reportManager = new ReportManager();
  
  // Use agent pubkey for slug lookups
  const report = await reportManager.readReport(identifier, context.agent.pubkey);

  if (!report) {
    logger.info("üì≠ No report found", {
      identifier,
      agent: context.agent.name,
    });

    return {
      success: false,
      message: `No report found with identifier: ${identifier}`,
    };
  }

  // Check if the report is deleted
  if (report.isDeleted) {
    logger.info("üóëÔ∏è Report is deleted", {
      identifier,
      agent: context.agent.name,
    });

    return {
      success: false,
      message: `Report "${identifier}" has been deleted`,
    };
  }

  logger.info("‚úÖ Report read successfully", {
    slug: report.slug,
    title: report.title,
    agent: context.agent.name,
  });

  return {
    success: true,
    article: {
      id: report.id,
      slug: report.slug,
      title: report.title,
      summary: report.summary,
      content: report.content,
      author: report.author,
      publishedAt: report.publishedAt,
      hashtags: report.hashtags,
      projectReference: report.projectReference,
    },
  };
}

/**
 * Create an AI SDK tool for reading reports
 */
export function createReportReadTool(context: ExecutionContext): ReturnType<typeof tool> {
  return tool({
    description: "Read an NDKArticle report by slug or naddr identifier",
    
    inputSchema: reportReadSchema,
    
    execute: async (input: ReportReadInput) => {
      return await executeReportRead(input, context);
    },
  });
}
</file>

<file path="src/tools/implementations/reports_list.ts">
import { tool } from 'ai';
import { ReportManager } from "@/services/ReportManager";
import { logger } from "@/utils/logger";
import { z } from "zod";
import type { ExecutionContext } from "@/agents/execution/types";

const reportsListSchema = z.object({
  allAgents: z
    .boolean()
    .nullable()
    .default(false)
    .describe("If true, get articles from all agents in the project. If false, only from current agent"),
});

type ReportsListInput = z.infer<typeof reportsListSchema>;

type ReportSummary = {
  id: string;
  slug: string;
  title?: string;
  summary?: string;
  author: string;
  publishedAt?: number;
  hashtags?: string[];
};

type ReportsListOutput = {
  success: boolean;
  reports: ReportSummary[];
  summary: {
    total: number;
    byAgent: Record<string, number>;
  };
  message?: string;
};

// Core implementation - extracted from existing execute function
async function executeReportsList(input: ReportsListInput, context: ExecutionContext): Promise<ReportsListOutput> {
  const { allAgents = false } = input;

  logger.info("üìö Listing reports", {
    allAgents,
    agent: context.agent.name,
    phase: context.phase,
  });

  const reportManager = new ReportManager();
  
  // Determine which agent pubkeys to use
  let agentPubkeys: string[] | undefined;
  
  if (!allAgents) {
    // Only current agent
    agentPubkeys = [context.agent.pubkey];
  } else {
    // Get all project agent pubkeys
    agentPubkeys = reportManager.getAllProjectAgentPubkeys();
  }

  // Fetch the reports
  const reports = await reportManager.listReports(agentPubkeys);
  
  // Calculate summary statistics
  const byAgent: Record<string, number> = {};
  for (const report of reports) {
    byAgent[report.author] = (byAgent[report.author] || 0) + 1;
  }

  logger.info("‚úÖ Reports listed successfully", {
    total: reports.length,
    allAgents,
    agent: context.agent.name,
  });

  return {
    success: true,
    reports,
    summary: {
      total: reports.length,
      byAgent,
    },
    message: `Found ${reports.length} report${reports.length !== 1 ? 's' : ''}`,
  };
}

// AI SDK tool factory
export function createReportsListTool(context: ExecutionContext): ReturnType<typeof tool> {
  return tool({
    description: "List NDKArticle reports from agents in the project",
    inputSchema: reportsListSchema,
    execute: async (input: ReportsListInput) => {
      return await executeReportsList(input, context);
    },
  });
}
</file>

<file path="src/cli.ts">
// CLI entry point for TENEX - Node.js compatible
import { main } from "./tenex.js";
import { handleCliError } from "./utils/cli-error.js";

main().catch((error) => {
  handleCliError(error, "Fatal error in TENEX CLI");
});
</file>

<file path="context/claude-code-integration.md">
# Claude Code Integration

## Overview

TENEX integrates Claude Code (Anthropic's code generation and execution model) through two distinct patterns, each serving different use cases and optimizing for different goals.

## Two Patterns of Claude Code Usage

### 1. ClaudeBackend Pattern (Direct Execution)

**Purpose:** Enables direct, efficient execution of Claude Code when the orchestrator determines that an entire agent turn should be handled by Claude.

**How it works:**
- Agents configured with `backend: "claude"` (e.g., Executor, Planner)
- Orchestrator routes directly to the agent
- Agent's entire execution is handled by ClaudeBackend
- No intermediate LLM call needed - the prompt passes through directly to Claude Code

**Benefits:**
- **No extra LLM calls** - Direct pass-through from orchestrator to Claude
- **No translation risk** - The original prompt is preserved exactly
- **Lower cost** - Eliminates redundant LLM invocations
- **Faster execution** - Direct path without intermediary reasoning

**Use cases:**
- When the orchestrator wants Claude to handle a complete task
- For agents whose primary purpose is Claude Code execution (Executor, Planner)
- When the entire agent turn IS the Claude Code execution

### 2. claude_code Tool Pattern (Deliberate Invocation)

**Purpose:** Allows agents using the `reason-act-loop` backend to invoke Claude Code as one step in a multi-step reasoning process.

**How it works:**
- Available as a tool in the tool registry
- **Automatically added to ALL agents using `reason-act-loop` backend** (as of latest update)
- Agents can also explicitly include `"claude_code"` in their tools array
- Agent makes an LLM call to decide when/how to use the tool
- Tool wraps ClaudeTaskExecutor for consistent behavior

**Benefits:**
- **Composability** - Claude Code becomes one capability among many
- **Flexibility** - Agents can combine Claude with other tools
- **Deliberate invocation** - The "extra" LLM call is intentional, part of the agent's reasoning
- **Session continuity** - Maintains claudeSessionId across invocations

**Use cases:**
- Specialist agents that need Claude for specific subtasks
- Multi-step workflows where Claude is one component
- When an agent needs to:
  1. Analyze existing code
  2. Use Claude to generate a solution
  3. Validate and integrate the result
  4. Report findings

## Implementation Details

### Shared Core: ClaudeTaskExecutor

Both patterns share the same underlying implementation:
- `ClaudeTaskExecutor` handles the actual Claude Code execution
- Manages NDKTask lifecycle for auditing and progress tracking
- Tracks execution time for metrics
- Publishes task events to Nostr

### Session Management

Both patterns support session continuity:
- `claudeSessionId` is stored in ConversationManager's agent state
- Sessions can be resumed for iterative development
- Each agent maintains its own session state

### Tool Configuration

The `claude_code` tool accepts:
- `prompt` (required): The prompt for Claude Code
- `systemPrompt` (optional): Additional context or constraints
- `title` (optional): Task title for tracking

## When to Use Each Pattern

### Use ClaudeBackend when:
- The agent's primary purpose is Claude Code execution
- You want to minimize LLM calls and costs
- The orchestrator's instructions should pass directly to Claude
- The entire agent turn is dedicated to Claude Code

### Use claude_code Tool when:
- The agent needs Claude as part of a larger workflow
- Multiple tools need to be coordinated
- The agent needs to make decisions about when/how to use Claude
- You're building specialist agents with diverse capabilities

## Example Configurations

### Agent with ClaudeBackend
```typescript
export const EXECUTOR_AGENT = {
    name: "Executor",
    backend: "claude",  // Direct Claude execution
    // ... other configuration
};
```

### Agent with claude_code Tool (Automatic)
```typescript
export const SPECIALIST_AGENT = {
    name: "Code Reviewer",
    backend: "reason-act-loop",  // Default reasoning backend
    tools: [
        "analyze",
        "read_path",
        // claude_code is automatically added for all reason-act-loop agents
        "complete"
    ],
    // ... other configuration
};
```

### Note on Automatic Availability
As of the latest update, the `claude_code` tool is **automatically available** to all agents using the `reason-act-loop` backend. This means:
- Project Manager can use Claude Code for complex analysis
- Specialist agents can leverage Claude Code without explicit configuration
- Any dynamically hired agent with `reason-act-loop` backend gets Claude Code access
- Agents with `backend: "claude"` continue to use the direct ClaudeBackend pattern

## Architecture Benefits

This dual-pattern approach provides:
- **Efficiency** for direct Claude execution scenarios
- **Flexibility** for complex, multi-tool workflows
- **Clear separation of concerns** in the execution model
- **Optimal cost** by avoiding unnecessary LLM calls where not needed
- **Progressive capability** - agents can be configured for either pattern based on their role
</file>

<file path="src/events/NDKAgentDefinition.ts">
import type NDK from "@nostr-dev-kit/ndk";
import { NDKEvent, type NDKRawEvent } from "@nostr-dev-kit/ndk";

export class NDKAgentDefinition extends NDKEvent {
  static kind = 4199;
  static kinds = [4199];

  constructor(ndk?: NDK, event?: NDKEvent | NDKRawEvent) {
    super(ndk, event);
    this.kind ??= 4199;
  }

  static from(event: NDKEvent): NDKAgentDefinition {
    return new NDKAgentDefinition(event.ndk, event);
  }

  get name(): string | undefined {
    return this.tagValue("title");
  }

  set name(value: string | undefined) {
    this.removeTag("title");
    if (value) this.tags.push(["title", value]);
  }

  get title(): string | undefined {
    return this.tagValue("title");
  }

  set title(value: string | undefined) {
    this.removeTag("title");
    if (value) this.tags.push(["title", value]);
  }

  get description(): string | undefined {
    return this.tagValue("description");
  }

  /**
   * A one-liner description of the agent's purpose or functionality.
   */
  set description(value: string | undefined) {
    this.removeTag("description");
    if (value) this.tags.push(["description", value]);
  }

  get role(): string | undefined {
    return this.tagValue("role");
  }

  /**
   * The expertise and personality for this agent.
   * This shapes how the agent interacts with users and other agents.
   */
  set role(value: string | undefined) {
    this.removeTag("role");
    if (value) this.tags.push(["role", value]);
  }

  get instructions(): string | undefined {
    return this.tagValue("instructions");
  }

  /**
   * Detailed instructions or guidelines for the agent's operation.
   */
  set instructions(value: string | undefined) {
    this.removeTag("instructions");
    if (value) this.tags.push(["instructions", value]);
  }

  get version(): number {
    const val = this.tagValue("ver");
    if (val === undefined) return 1; // Default version if not specified
    return Number.parseInt(val, 10);
  }

  set version(value: number) {
    this.removeTag("ver");
    this.tags.push(["ver", value.toString()]);
  }

  get useCriteria(): string | undefined {
    return this.tagValue("use-criteria");
  }

  /**
   * Criteria for when this agent should be selected or used.
   * This helps with agent routing and selection.
   */
  set useCriteria(value: string | undefined) {
    this.removeTag("use-criteria");
    if (value) this.tags.push(["use-criteria", value]);
  }

  get phase(): string | undefined {
    return this.tagValue("phase");
  }

  /**
   * The project phase this agent definition is associated with.
   * When set, this agent definition only applies to this specific phase.
   */
  set phase(value: string | undefined) {
    this.removeTag("phase");
    if (value) this.tags.push(["phase", value]);
  }
}
</file>

<file path="src/events/NDKProjectStatus.ts">
import type NDK from "@nostr-dev-kit/ndk";
import { NDKEvent, type NDKRawEvent } from "@nostr-dev-kit/ndk";

/**
 * NDKProjectStatus represents a kind 24010 event
 * Used to indicate project status including online agents and model configurations
 */
export class NDKProjectStatus extends NDKEvent {
  static kind = 24010;
  static kinds = [24010];

  constructor(ndk?: NDK, event?: NDKEvent | NDKRawEvent) {
    super(ndk, event);
    this.kind ??= 24010;
  }

  static from(event: NDKEvent): NDKProjectStatus {
    return new NDKProjectStatus(event.ndk, event);
  }

  /**
   * Get the project this status refers to
   * Returns the value of the "a" tag (replaceable event reference)
   */
  get projectReference(): string | undefined {
    return this.tagValue("a");
  }

  /**
   * Set the project this status refers to
   * @param projectTagId The tag ID of the NDKProject event (format: kind:pubkey:dTag)
   */
  set projectReference(projectTagId: string | undefined) {
    this.removeTag("a");
    if (projectTagId) {
      this.tags.push(["a", projectTagId]);
    }
  }

  /**
   * Get all agent entries from this status event
   * Returns an array of {pubkey, slug} objects
   */
  get agents(): Array<{ pubkey: string; slug: string }> {
    const agentTags = this.tags.filter((tag) => tag[0] === "agent" && tag[1] && tag[2]);
    return agentTags.map((tag) => ({
      pubkey: tag[1],
      slug: tag[2],
    }));
  }

  /**
   * Add an agent to the status
   * @param pubkey The agent's public key
   * @param slug The agent's slug/identifier
   */
  addAgent(pubkey: string, slug: string): void {
    this.tags.push(["agent", pubkey, slug]);
  }

  /**
   * Remove an agent from the status
   * @param pubkey The agent's public key to remove
   */
  removeAgent(pubkey: string): void {
    this.tags = this.tags.filter((tag) => !(tag[0] === "agent" && tag[1] === pubkey));
  }

  /**
   * Clear all agents from the status
   */
  clearAgents(): void {
    this.tags = this.tags.filter((tag) => tag[0] !== "agent");
  }

  /**
   * Check if a specific agent is in the status
   * @param pubkey The agent's public key
   */
  hasAgent(pubkey: string): boolean {
    return this.tags.some((tag) => tag[0] === "agent" && tag[1] === pubkey);
  }

  /**
   * Get all model configurations from this status event
   * Returns an array of {modelSlug, agents} objects where agents is an array of agent slugs
   */
  get models(): Array<{ modelSlug: string; agents: string[] }> {
    const modelTags = this.tags.filter((tag) => tag[0] === "model" && tag[1]);
    return modelTags.map((tag) => ({
      modelSlug: tag[1],
      agents: tag.slice(2).filter((a) => a), // Get all agent slugs from index 2 onwards
    }));
  }

  /**
   * Add a model with its agent access list
   * @param modelSlug The model slug identifier (e.g., "gpt-4", "claude-3")
   * @param agentSlugs Array of agent slugs that use this model
   */
  addModel(modelSlug: string, agentSlugs: string[]): void {
    // Remove existing model tag if it exists
    this.removeModel(modelSlug);
    // Add new model tag with all agent slugs
    this.tags.push(["model", modelSlug, ...agentSlugs]);
  }

  /**
   * Remove a model from the status
   * @param modelSlug The model slug to remove
   */
  removeModel(modelSlug: string): void {
    this.tags = this.tags.filter((tag) => !(tag[0] === "model" && tag[1] === modelSlug));
  }

  /**
   * Clear all model configurations from the status
   */
  clearModels(): void {
    this.tags = this.tags.filter((tag) => tag[0] !== "model");
  }

  /**
   * Check if a specific model exists
   * @param modelSlug The model slug
   */
  hasModel(modelSlug: string): boolean {
    return this.tags.some((tag) => tag[0] === "model" && tag[1] === modelSlug);
  }

  /**
   * Get agents that use a specific model
   * @param modelSlug The model slug
   * @returns Array of agent slugs that use this model
   */
  getModelAgents(modelSlug: string): string[] {
    const modelTag = this.tags.find((tag) => tag[0] === "model" && tag[1] === modelSlug);
    return modelTag ? modelTag.slice(2).filter((a) => a) : [];
  }

  /**
   * Check if a specific agent uses a model
   * @param modelSlug The model slug
   * @param agentSlug The agent slug
   */
  agentUsesModel(modelSlug: string, agentSlug: string): boolean {
    const agents = this.getModelAgents(modelSlug);
    return agents.includes(agentSlug);
  }

  /**
   * Get all models used by a specific agent
   * @param agentSlug The agent slug
   * @returns Array of model slugs used by this agent
   */
  getAgentModels(agentSlug: string): string[] {
    return this.models
      .filter((model) => model.agents.includes(agentSlug))
      .map((model) => model.modelSlug);
  }

  /**
   * Get the status message/content
   */
  get status(): string {
    return this.content;
  }

  /**
   * Set the status message/content
   */
  set status(value: string) {
    this.content = value;
  }

  /**
   * Get all tools with their agent access information
   * Returns an array of {toolName, agents} objects where agents is an array of agent slugs
   */
  get tools(): Array<{ toolName: string; agents: string[] }> {
    const toolTags = this.tags.filter((tag) => tag[0] === "tool" && tag[1]);
    return toolTags.map((tag) => ({
      toolName: tag[1],
      agents: tag.slice(2).filter((a) => a), // Get all agent slugs from index 2 onwards
    }));
  }

  /**
   * Add a tool with its agent access list
   * @param toolName The name of the tool
   * @param agentSlugs Array of agent slugs that have access to this tool
   */
  addTool(toolName: string, agentSlugs: string[]): void {
    // Remove existing tool tag if it exists
    this.removeTool(toolName);
    // Add new tool tag with all agent slugs
    this.tags.push(["tool", toolName, ...agentSlugs]);
  }

  /**
   * Remove a tool from the status
   * @param toolName The tool name to remove
   */
  removeTool(toolName: string): void {
    this.tags = this.tags.filter((tag) => !(tag[0] === "tool" && tag[1] === toolName));
  }

  /**
   * Clear all tools from the status
   */
  clearTools(): void {
    this.tags = this.tags.filter((tag) => tag[0] !== "tool");
  }

  /**
   * Check if a specific tool exists
   * @param toolName The tool name
   */
  hasTool(toolName: string): boolean {
    return this.tags.some((tag) => tag[0] === "tool" && tag[1] === toolName);
  }

  /**
   * Get agents that have access to a specific tool
   * @param toolName The tool name
   * @returns Array of agent slugs that have access to this tool
   */
  getToolAgents(toolName: string): string[] {
    const toolTag = this.tags.find((tag) => tag[0] === "tool" && tag[1] === toolName);
    return toolTag ? toolTag.slice(2).filter((a) => a) : [];
  }

  /**
   * Check if a specific agent has access to a tool
   * @param toolName The tool name
   * @param agentSlug The agent slug
   */
  agentHasTool(toolName: string, agentSlug: string): boolean {
    const agents = this.getToolAgents(toolName);
    return agents.includes(agentSlug);
  }

  /**
   * Get all tools accessible by a specific agent
   * @param agentSlug The agent slug
   * @returns Array of tool names accessible by this agent
   */
  getAgentTools(agentSlug: string): string[] {
    return this.tools
      .filter((tool) => tool.agents.includes(agentSlug))
      .map((tool) => tool.toolName);
  }
}
</file>

<file path="src/llm/index.ts">
// Export service
export { LLMService } from "./service";

// Export factory
export { LLMServiceFactory, llmServiceFactory } from "./LLMServiceFactory";

// Export types
export * from "./types";
</file>

<file path="src/llm/LLMServiceFactory.ts">
import type { LLMLogger } from "@/logging/LLMLogger";
import type { LLMConfiguration } from "@/services/config/types";
import { logger } from "@/utils/logger";
import { createAnthropic } from "@ai-sdk/anthropic";
import { createOpenAI } from "@ai-sdk/openai";
import { createOpenRouter } from "@openrouter/ai-sdk-provider";
import { createOllama } from "ollama-ai-provider-v2";
import { createProviderRegistry, type Provider, type ProviderRegistry } from "ai";
import { LLMService } from "./service";
import { createMockProvider } from "./providers/MockProvider";

/**
 * Factory for creating LLM services with proper provider initialization
 */
export class LLMServiceFactory {
    private providers: Map<string, Provider> = new Map();
    private registry: ProviderRegistry | null = null;
    private initialized = false;

    /**
     * Initialize providers from configuration
     */
    initializeProviders(providerConfigs: Record<string, { apiKey: string }>): void {
        this.providers.clear();
        
        // Check if mock mode is enabled
        if (process.env.USE_MOCK_LLM === 'true') {
            logger.debug("[LLMServiceFactory] Mock LLM mode enabled via USE_MOCK_LLM environment variable");
            
            // Load mock scenarios from file if specified
            const mockConfig = undefined;
            if (process.env.MOCK_LLM_SCENARIOS) {
                try {
                    // TODO: Load scenarios from file
                    logger.debug(`[LLMServiceFactory] Loading mock scenarios from: ${process.env.MOCK_LLM_SCENARIOS}`);
                } catch (error) {
                    logger.warn("[LLMServiceFactory] Failed to load mock scenarios, using defaults", {
                        error: error instanceof Error ? error.message : String(error)
                    });
                }
            }
            
            this.providers.set("mock", createMockProvider(mockConfig));
            
            // In mock mode, we only use the mock provider
            // Other providers can still be initialized but won't be used by default
        }
        
        for (const [name, config] of Object.entries(providerConfigs)) {
            if (!config?.apiKey) {
                logger.debug(`[LLMServiceFactory] Skipping provider ${name} - no API key`);
                continue;
            }
            
            try {
                switch (name) {
                    case "openrouter":
                        this.providers.set(
                            name,
                            createOpenRouter({
                                apiKey: config.apiKey,
                                usage: { include: true },
                                headers: {
                                    "X-Title": "TENEX",
                                    "HTTP-Referer": "https://github.com/tenex-chat/tenex",
                                },
                            })
                        );
                        logger.debug(`[LLMServiceFactory] Initialized OpenRouter provider`);
                        break;
                        
                    case "anthropic":
                        this.providers.set(name, createAnthropic({ 
                            apiKey: config.apiKey 
                        }));
                        logger.debug(`[LLMServiceFactory] Initialized Anthropic provider`);
                        break;
                        
                    case "openai":
                        this.providers.set(name, createOpenAI({ 
                            apiKey: config.apiKey 
                        }));
                        logger.debug(`[LLMServiceFactory] Initialized OpenAI provider`);
                        break;
                        
                    case "ollama": {
                        // For Ollama, apiKey is actually the base URL
                        // The library expects the URL to include /api path
                        let baseURL: string | undefined;
                        if (config.apiKey === "local") {
                            // Use default (library provides http://127.0.0.1:11434/api)
                            baseURL = undefined;
                        } else {
                            // Custom URL - ensure it ends with /api
                            baseURL = config.apiKey.endsWith('/api') 
                                ? config.apiKey 
                                : config.apiKey.replace(/\/$/, '') + '/api';
                        }
                        
                        // Create Ollama provider with custom base URL if provided
                        const ollamaProvider = createOllama(baseURL ? { baseURL } : undefined);
                        
                        this.providers.set(name, ollamaProvider as Provider);
                        logger.debug(`[LLMServiceFactory] Initialized Ollama provider with baseURL: ${baseURL || 'default (http://localhost:11434)'}`);
                        break;
                    }
                    
                    case "claudeCode": {
                        // Track 1: Limited claude_code provider
                        // This creates a placeholder provider that will delegate to phase-0
                        // The actual implementation happens through the existing agent/phase system
                        logger.warn(`[LLMServiceFactory] ClaudeCode provider is limited to phase-0 operations only`);
                        
                        // We don't create an actual provider here since claudeCode works through phases
                        // Instead, we'll handle this specially in the service creation
                        this.providers.set(name, {} as Provider); // Placeholder
                        logger.debug(`[LLMServiceFactory] Initialized limited ClaudeCode provider (phase-0 only)`);
                        break;
                    }
                        
                    default:
                        logger.warn(`[LLMServiceFactory] Unknown provider type: ${name}`);
                }
            } catch (error) {
                logger.error(`[LLMServiceFactory] Failed to initialize provider ${name}`, {
                    error: error instanceof Error ? error.message : String(error)
                });
            }
        }
        
        // Create the provider registry with all configured providers
        if (this.providers.size > 0) {
            const providerObject: Record<string, Provider> = {};
            for (const [name, provider] of this.providers.entries()) {
                providerObject[name] = provider;
            }
            this.registry = createProviderRegistry(providerObject);
            logger.debug(`[LLMServiceFactory] Created provider registry with ${this.providers.size} providers`);
        } else {
            logger.warn(`[LLMServiceFactory] No providers were successfully initialized`);
            // Create an empty registry to avoid null checks everywhere
            this.registry = createProviderRegistry({});
        }
        
        this.initialized = true;
    }

    /**
     * Create an LLM service from a resolved configuration
     */
    createService(
        llmLogger: LLMLogger,
        config: LLMConfiguration
    ): LLMService {
        if (!this.initialized || !this.registry) {
            throw new Error("LLMServiceFactory not initialized. Call initializeProviders first.");
        }

        // If mock mode is enabled, always use mock provider regardless of config
        const actualProvider = process.env.USE_MOCK_LLM === 'true' ? 'mock' : config.provider;
        
        // Special handling for claudeCode provider
        if (actualProvider === 'claudeCode') {
            // Track 1: Limited implementation
            // claudeCode only supports phase-0 for now
            if (config.model !== 'phase-0') {
                throw new Error(
                    `ClaudeCode provider only supports 'phase-0' model in Track 1. ` +
                    `Requested model: ${config.model}`
                );
            }
            logger.info(`[LLMServiceFactory] Creating limited ClaudeCode service for phase-0`);
            
            // For now, claudeCode will be handled through the existing phase system
            // Return a service that will delegate to the phase-0 implementation
            // This is a placeholder that will be replaced in Track 2
            return new LLMService(
                llmLogger,
                this.registry,
                actualProvider,
                config.model,
                config.temperature,
                config.maxTokens
            );
        }
        
        // Verify the provider exists
        if (!this.providers.has(actualProvider)) {
            const available = Array.from(this.providers.keys());
            throw new Error(
                `Provider "${actualProvider}" not available. ` +
                `Initialized providers: ${available.length > 0 ? available.join(", ") : "none"}`
            );
        }

        if (actualProvider === 'mock' && actualProvider !== config.provider) {
            logger.debug(`[LLMServiceFactory] Using mock provider instead of ${config.provider} due to USE_MOCK_LLM=true`);
        }

        // Use the shared registry for all services
        return new LLMService(
            llmLogger,
            this.registry,
            actualProvider,
            config.model,
            config.temperature,
            config.maxTokens
        );
    }

    /**
     * Check if a provider is available
     */
    hasProvider(providerName: string): boolean {
        return this.providers.has(providerName);
    }

    /**
     * Get list of available providers
     */
    getAvailableProviders(): string[] {
        return Array.from(this.providers.keys());
    }

    /**
     * Get the provider registry
     * Useful for direct access to language models
     */
    getRegistry(): ProviderRegistry {
        if (!this.registry) {
            throw new Error("LLMServiceFactory not initialized. Call initializeProviders first.");
        }
        return this.registry;
    }

    /**
     * Reset the factory (mainly for testing)
     */
    reset(): void {
        this.providers.clear();
        this.registry = null;
        this.initialized = false;
    }
}

// Export singleton instance
export const llmServiceFactory = new LLMServiceFactory();
</file>

<file path="src/prompts/index.ts">
// Export core functionality

export { FragmentRegistry, fragmentRegistry } from "./core/FragmentRegistry";
export { PromptBuilder } from "./core/PromptBuilder";
export type { FragmentConfig, PromptFragment } from "./core/types";

// Import all fragments to ensure they're registered when the module is imported
// Priority 01 - Identity
import "./fragments/01-agent-identity";

// Priority 02 - Delegated task context (conditional)
import "./fragments/delegated-task-context";

// Priority 10 - Early context
import "./fragments/10-referenced-article"; // Conditional

// Priority 15 - Available agents
import "./fragments/15-available-agents";

// Priority 20 - Phase and mode context
import "./fragments/20-phase-context"; // Shared
import "./fragments/20-voice-mode"; // Conditional

// Priority 24 - Lessons
import "./fragments/24-retrieved-lessons"; // Shared

// Priority 30 - Project context
import "./fragments/30-project-inventory"; // Shared
import "./fragments/30-project-md"; // Conditional (project-manager)

// Priority 90+ - Special purpose
import "./fragments/90-inventory-generation"; // Internal LLM prompts
</file>

<file path="src/test-utils/mock-llm/scenarios/concurrency-workflow.ts">
import type { MockLLMResponse, MockLLMScenario } from "../types";

const concurrencyResponses: MockLLMResponse[] = [
  // Routing decisions for orchestrator
  {
    trigger: {
      agentName: "orchestrator",
      messageContains: /routing.*decision/i,
      userMessage: /User A/,
    },
    response: {
      content: JSON.stringify({
        agents: ["orchestrator"],
        phase: "CHAT",
        reason:
          "User A wants to create an authentication system. Starting in chat phase to understand requirements.",
      }),
    },
    priority: 100,
  },
  {
    trigger: {
      agentName: "orchestrator",
      messageContains: /routing.*decision/i,
      userMessage: /User B/,
    },
    response: {
      content: JSON.stringify({
        agents: ["orchestrator"],
        phase: "CHAT",
        reason:
          "User B wants payment processing. Starting in chat phase to understand requirements.",
      }),
    },
    priority: 100,
  },
  {
    trigger: {
      agentName: "orchestrator",
      messageContains: /routing.*decision/i,
      userMessage: /User C/,
    },
    response: {
      content: JSON.stringify({
        agents: ["orchestrator"],
        phase: "CHAT",
        reason:
          "User C wants payment processing. Starting in chat phase to understand requirements.",
      }),
    },
    priority: 100,
  },

  // Orchestrator Phase 1: Initial task understanding for User A
  {
    trigger: {
      agentName: "orchestrator",
      phase: "CHAT",
      userMessage: /create.*user.*authentication.*A/i,
    },
    response: {
      content:
        "I'll help User A create an authentication system. Let me understand the requirements.",
      toolCalls: [
        {
          id: "1",
          message: null,
          function: "continue",
          args: JSON.stringify({
            summary: "Creating authentication system for User A",
            suggestedPhase: "PLAN",
          }),
        } as unknown,
      ],
    },
    priority: 10,
  },

  // Orchestrator Phase 1: Initial task understanding for User B
  {
    trigger: {
      agentName: "orchestrator",
      phase: "CHAT",
      userMessage: /implement.*payment.*processing.*B/i,
    },
    response: {
      content: "I'll help User B implement payment processing. Let me analyze the requirements.",
      toolCalls: [
        {
          id: "1",
          message: null,
          function: "continue",
          args: JSON.stringify({
            summary: "Implementing payment processing for User B",
            suggestedPhase: "PLAN",
          }),
        } as unknown,
      ],
    },
    priority: 10,
  },

  // Orchestrator Phase 2: Planning for User A
  {
    trigger: {
      agentName: "orchestrator",
      phase: "PLAN",
      messageContains: /User A/,
    },
    response: {
      content:
        "## Authentication System Plan for User A\n\n1. Create user model\n2. Implement JWT tokens\n3. Add login endpoints",
      toolCalls: [
        {
          id: "2",
          message: null,
          function: "continue",
          args: JSON.stringify({
            summary: "Authentication plan ready for User A",
            suggestedPhase: "EXECUTE",
          }),
        } as unknown,
      ],
    },
    priority: 5,
  },

  // Orchestrator Phase 2: Planning for User B
  {
    trigger: {
      agentName: "orchestrator",
      phase: "PLAN",
      messageContains: /User B/,
    },
    response: {
      content:
        "## Payment Processing Plan for User B\n\n1. Integrate payment gateway\n2. Create payment models\n3. Add webhook handlers",
      toolCalls: [
        {
          id: "2",
          message: null,
          function: "continue",
          args: JSON.stringify({
            summary: "Payment plan ready for User B",
            suggestedPhase: "EXECUTE",
          }),
        } as unknown,
      ],
    },
    priority: 5,
  },

  // Orchestrator Phase 3: Implementation delegation for User A
  {
    trigger: {
      agentName: "orchestrator",
      phase: "EXECUTE",
      messageContains: /User A/,
    },
    response: {
      content: "Delegating to Executor agent to implement authentication for User A.",
      toolCalls: [
        {
          id: "3",
          message: null,
          function: "delegate",
          args: JSON.stringify({
            toAgent: "executor",
            context: "Implement authentication system for User A as planned",
          }),
        } as unknown,
      ],
    },
    priority: 5,
  },

  // Orchestrator Phase 3: Implementation delegation for User B
  {
    trigger: {
      agentName: "orchestrator",
      phase: "EXECUTE",
      messageContains: /User B/,
    },
    response: {
      content: "Delegating to Executor agent to implement payment processing for User B.",
      toolCalls: [
        {
          id: "3",
          message: null,
          function: "delegate",
          args: JSON.stringify({
            toAgent: "executor",
            context: "Implement payment processing for User B as planned",
          }),
        } as unknown,
      ],
    },
    priority: 5,
  },

  // Executor implementation for User A
  {
    trigger: {
      agentName: "executor",
      phase: "EXECUTE",
      messageContains: /User A/,
    },
    response: {
      content:
        "Implementing authentication system for User A:\n\n1. Creating user model...\n2. Setting up JWT...\n3. Adding endpoints...\n\nAuthentication system implemented successfully!",
      toolCalls: [
        {
          id: "4",
          message: null,
          function: "delegate",
          args: JSON.stringify({
            toAgent: "orchestrator",
            context: "Authentication implementation completed for User A",
          }),
        } as unknown,
      ],
    },
    priority: 5,
  },

  // Executor implementation for User B
  {
    trigger: {
      agentName: "executor",
      phase: "EXECUTE",
      messageContains: /User B/,
    },
    response: {
      content:
        "Implementing payment processing for User B:\n\n1. Integrating payment gateway...\n2. Creating payment models...\n3. Setting up webhooks...\n\nPayment processing implemented successfully!",
      toolCalls: [
        {
          id: "4",
          message: null,
          function: "delegate",
          args: JSON.stringify({
            toAgent: "orchestrator",
            context: "Payment implementation completed for User B",
          }),
        } as unknown,
      ],
    },
    priority: 5,
  },

  // Orchestrator Phase 4: Verification for User A
  {
    trigger: {
      agentName: "orchestrator",
      phase: "EXECUTE",
      messageContains: /completed for User A/,
    },
    response: {
      content: "Authentication system has been implemented for User A. Moving to verification.",
      toolCalls: [
        {
          id: "5",
          message: null,
          function: "continue",
          args: JSON.stringify({
            summary: "Ready to verify authentication for User A",
            suggestedPhase: "VERIFICATION",
          }),
        } as unknown,
      ],
    },
    priority: 5,
  },

  // Orchestrator Phase 4: Verification for User B
  {
    trigger: {
      agentName: "orchestrator",
      phase: "EXECUTE",
      messageContains: /completed for User B/,
    },
    response: {
      content: "Payment processing has been implemented for User B. Moving to verification.",
      toolCalls: [
        {
          id: "5",
          message: null,
          function: "continue",
          args: JSON.stringify({
            summary: "Ready to verify payment processing for User B",
            suggestedPhase: "VERIFICATION",
          }),
        } as unknown,
      ],
    },
    priority: 5,
  },

  // Orchestrator Phase 5: Completion for User A
  {
    trigger: {
      agentName: "orchestrator",
      phase: "VERIFICATION",
      messageContains: /User A/,
    },
    response: {
      content:
        "‚úÖ Authentication system for User A has been successfully implemented and verified!",
      toolCalls: [
        {
          id: "6",
          message: null,
          function: "completeConversation",
          args: JSON.stringify({
            summary: "Authentication system completed for User A",
          }),
        } as unknown,
      ],
    },
    priority: 5,
  },

  // Orchestrator Phase 5: Completion for User B
  {
    trigger: {
      agentName: "orchestrator",
      phase: "VERIFICATION",
      messageContains: /User B/,
    },
    response: {
      content: "‚úÖ Payment processing for User B has been successfully implemented and verified!",
      toolCalls: [
        {
          id: "6",
          message: null,
          function: "completeConversation",
          args: JSON.stringify({
            summary: "Payment processing completed for User B",
          }),
        } as unknown,
      ],
    },
    priority: 5,
  },

  // Orchestrator Phase 1: Initial task understanding for User C
  {
    trigger: {
      agentName: "orchestrator",
      phase: "CHAT",
      userMessage: /implement.*payment.*processing.*C/i,
    },
    response: {
      content: "I'll help User C implement payment processing. Let me analyze the requirements.",
      toolCalls: [
        {
          id: "1",
          message: null,
          function: "continue",
          args: JSON.stringify({
            summary: "Implementing payment processing for User C",
            suggestedPhase: "PLAN",
          }),
        } as unknown,
      ],
    },
    priority: 10,
  },

  // Orchestrator Phase 2: Planning for User C
  {
    trigger: {
      agentName: "orchestrator",
      phase: "PLAN",
      messageContains: /User C/,
    },
    response: {
      content:
        "## Payment Processing Plan for User C\n\n1. Integrate payment gateway\n2. Create payment models\n3. Add webhook handlers",
      toolCalls: [
        {
          id: "2",
          message: null,
          function: "continue",
          args: JSON.stringify({
            summary: "Payment plan ready for User C",
            suggestedPhase: "EXECUTE",
          }),
        } as unknown,
      ],
    },
    priority: 5,
  },

  // Orchestrator Phase 3: Implementation delegation for User C
  {
    trigger: {
      agentName: "orchestrator",
      phase: "EXECUTE",
      messageContains: /User C/,
    },
    response: {
      content: "Delegating to Executor agent to implement payment processing for User C.",
      toolCalls: [
        {
          id: "3",
          message: null,
          function: "handoff",
          args: JSON.stringify({
            toAgent: "executor",
            context: "Implement payment processing for User C as planned",
          }),
        } as unknown,
      ],
    },
    priority: 5,
  },

  // Executor implementation for User C
  {
    trigger: {
      agentName: "executor",
      phase: "EXECUTE",
      messageContains: /User C/,
    },
    response: {
      content:
        "Implementing payment processing for User C:\n\n1. Integrating payment gateway...\n2. Creating payment models...\n3. Setting up webhooks...\n\nPayment processing implemented successfully!",
      toolCalls: [
        {
          id: "4",
          message: null,
          function: "delegate",
          args: JSON.stringify({
            toAgent: "orchestrator",
            context: "Payment implementation completed for User C",
          }),
        } as unknown,
      ],
    },
    priority: 5,
  },

  // Orchestrator Phase 4: Verification for User C
  {
    trigger: {
      agentName: "orchestrator",
      phase: "EXECUTE",
      messageContains: /completed for User C/,
    },
    response: {
      content: "Payment processing has been implemented for User C. Moving to verification.",
      toolCalls: [
        {
          id: "5",
          message: null,
          function: "continue",
          args: JSON.stringify({
            summary: "Ready to verify payment processing for User C",
            suggestedPhase: "VERIFICATION",
          }),
        } as unknown,
      ],
    },
    priority: 5,
  },

  // Orchestrator Phase 5: Completion for User C
  {
    trigger: {
      agentName: "orchestrator",
      phase: "VERIFICATION",
      messageContains: /User C/,
    },
    response: {
      content: "‚úÖ Payment processing for User C has been successfully implemented and verified!",
      toolCalls: [
        {
          id: "6",
          message: null,
          function: "completeConversation",
          args: JSON.stringify({
            summary: "Payment processing completed for User C",
          }),
        } as unknown,
      ],
    },
    priority: 5,
  },
];

export const concurrencyWorkflowScenarios: MockLLMScenario[] = [
  {
    name: "concurrency-workflow",
    description: "Mock responses for concurrent conversation workflow testing",
    responses: concurrencyResponses,
  },
];
</file>

<file path="src/test-utils/mock-llm/scenarios/index.ts">
export * from "./concurrency-workflow";
export * from "./error-handling";
export * from "./inventory-generation";
export * from "./network-resilience";
export * from "./performance-testing";
export * from "./state-persistence";
export * from "./threading-workflow";

import type { MockLLMScenario } from "../types";
import { concurrencyWorkflowScenarios } from "./concurrency-workflow";
import { errorHandlingScenario } from "./error-handling";
import { inventoryGenerationScenario } from "./inventory-generation";
import { networkResilienceScenario } from "./network-resilience";
import { performanceTestingScenario } from "./performance-testing";
import { statePersistenceScenario } from "./state-persistence";
import { threadingWorkflow } from "./threading-workflow";

/**
 * All available mock scenarios for testing
 */
export const allScenarios: MockLLMScenario[] = [
  errorHandlingScenario,
  statePersistenceScenario,
  performanceTestingScenario,
  inventoryGenerationScenario,
  networkResilienceScenario,
  threadingWorkflow,
];

/**
 * Concurrency testing scenarios
 */
export const concurrencyScenarios = concurrencyWorkflowScenarios;

// Add concurrency scenarios to all scenarios
allScenarios.push(...concurrencyWorkflowScenarios);

/**
 * Get a specific scenario by name
 */
export function getScenario(name: string): MockLLMScenario | undefined {
  return allScenarios.find((s) => s.name === name);
}

/**
 * Create a custom scenario for specific test cases
 */
export function createScenario(
  name: string,
  description: string,
  responses: MockLLMScenario["responses"]
): MockLLMScenario {
  return { name, description, responses };
}
</file>

<file path="src/test-utils/mock-llm/MockLLMService.ts">
import type {
  CompletionRequest,
  CompletionResponse,
  LLMService,
  Message,
  StreamEvent,
} from "@/llm/types";
import { conversationalLogger } from "../conversational-logger";
import type { MockLLMConfig, MockLLMResponse } from "./types";

export class MockLLMService implements LLMService {
  private config: MockLLMConfig;
  private responses: MockLLMResponse[] = [];
  private requestHistory: Array<{
    messages: Message[];
    model?: string;
    response: MockLLMResponse["response"];
    timestamp: Date;
  }> = [];

  // Context tracking for enhanced triggers
  private conversationContext: Map<
    string,
    {
      lastContinueCaller?: string;
      iteration: number;
      agentIterations: Map<string, number>;
      lastAgentExecuted?: string;
    }
  > = new Map();

  constructor(config: MockLLMConfig = {}) {
    this.config = config;

    // Load responses from scenarios
    if (config.scenarios) {
      for (const scenario of config.scenarios) {
        this.responses.push(...scenario.responses);
      }
    }

    // Sort by priority
    this.responses.sort((a, b) => (b.priority || 0) - (a.priority || 0));
  }

  async complete(request: CompletionRequest): Promise<CompletionResponse> {
    const messages = request.messages;
    const model = request.options?.configName || "mock-model";

    const response = this.findMatchingResponse(messages);

    this.recordRequest(messages, model, response);

    if (response.error) {
      throw response.error;
    }

    // Simulate delay if specified
    if (response.streamDelay) {
      await new Promise((resolve) => setTimeout(resolve, response.streamDelay));
    }

    // Convert to CompletionResponse format
    // toolCalls with proper structure
    const toolCallsInfo = response.toolCalls
      ? response.toolCalls.map((tc) => {
          // Convert our mock format to LlmToolCallInfo format
          let functionName: string;
          let args: Record<string, unknown> = {};

          if (typeof tc === "object" && "function" in tc) {
            // Format with function as string
            functionName = tc.function;
            try {
              args = JSON.parse(tc.args || "{}");
            } catch {
              args = {};
            }
          } else {
            functionName = "unknown";
          }

          return {
            name: functionName,
            params: args,
            result: null,
          };
        })
      : [];

    return {
      type: "text",
      content: response.content || "",
      toolCalls: toolCallsInfo.length > 0 ? toolCallsInfo : undefined,
      usage: {
        prompt_tokens: 100,
        completion_tokens: 50,
        total_tokens: 150,
      },
    } as CompletionResponse;
  }

  async *stream(request: CompletionRequest): AsyncIterable<StreamEvent> {
    const messages = request.messages;
    const model = request.options?.configName || "mock-model";

    const response = this.findMatchingResponse(messages);

    this.recordRequest(messages, model, response);

    if (response.error) {
      yield { type: "error", error: response.error.message };
      return;
    }

    // Simulate streaming content
    if (response.content) {
      const words = response.content.split(" ");
      for (const word of words) {
        yield { type: "content", content: `${word} ` };
        if (response.streamDelay) {
          await new Promise((resolve) =>
            setTimeout(resolve, (response.streamDelay || 0) / words.length)
          );
        }
      }
    }

    // Send tool calls
    if (response.toolCalls && response.toolCalls.length > 0) {
      for (const toolCall of response.toolCalls) {
        const toolName = toolCall.function;
        const toolArgs = toolCall.args || "{}";

        yield {
          type: "tool_start",
          tool: toolName,
          args: JSON.parse(toolArgs),
        };
      }
    }

    // Send completion event
    yield {
      type: "done",
      response: {
        type: "text",
        content: response.content || "",
        toolCalls: [],
        usage: {
          prompt_tokens: 100,
          completion_tokens: 50,
          total_tokens: 150,
        },
      } as CompletionResponse,
    };
  }

  private findMatchingResponse(messages: Message[]): MockLLMResponse["response"] {
    const systemMessage = messages.find((m) => m.role === "system");
    const lastUserMessage = messages.filter((m) => m.role === "user").pop();

    // Extract tool calls from messages that have them
    interface MessageWithToolCalls extends Message {
      tool_calls?: Array<{
        function: string | { name: string };
      }>;
    }

    const toolCalls = messages
      .filter((m): m is MessageWithToolCalls => {
        const msg = m as MessageWithToolCalls;
        return Boolean(
          msg.tool_calls && Array.isArray(msg.tool_calls) && msg.tool_calls.length > 0
        );
      })
      .flatMap((m) => {
        return (m.tool_calls || []).map((tc) => {
          return typeof tc.function === "string" ? tc.function : tc.function?.name;
        });
      })
      .filter((name): name is string => typeof name === "string");

    // Extract agent name and phase from system prompt
    const agentName = this.extractAgentName(systemMessage?.content || "");
    const phase = this.extractPhase(systemMessage?.content || "");

    // Get conversation context
    const conversationId = this.extractConversationId();
    const context = this.getOrCreateContext(conversationId);

    // Update agent iteration count
    if (!context.agentIterations.has(agentName)) {
      context.agentIterations.set(agentName, 0);
    }
    const currentIteration = context.agentIterations.get(agentName) || 0;
    context.agentIterations.set(agentName, currentIteration + 1);
    const agentIteration = context.agentIterations.get(agentName) || 0;

    if (this.config.debug) {
      conversationalLogger.logAgentThinking(agentName, {
        phase,
        userMessage: lastUserMessage?.content,
        iteration: context.iteration,
        agentIteration,
      });
    }

    // Find matching response
    for (const mockResponse of this.responses) {
      const trigger = mockResponse.trigger;

      // Check all trigger conditions
      if (trigger.systemPrompt && systemMessage) {
        if (!systemMessage.content) continue;
        const matches =
          trigger.systemPrompt instanceof RegExp
            ? trigger.systemPrompt.test(systemMessage.content)
            : systemMessage.content.includes(trigger.systemPrompt);
        if (!matches) continue;
      }

      if (trigger.userMessage) {
        if (!lastUserMessage || !lastUserMessage.content) {
          continue; // No user message, but trigger expects one
        }
        const matches =
          trigger.userMessage instanceof RegExp
            ? trigger.userMessage.test(lastUserMessage.content)
            : lastUserMessage.content.includes(trigger.userMessage);
        if (!matches) continue;
      }

      if (trigger.previousToolCalls) {
        const hasAllTools = trigger.previousToolCalls.every((tool) => toolCalls.includes(tool));
        if (!hasAllTools) continue;
      }

      if (trigger.agentName) {
        if (typeof trigger.agentName === "string") {
          if (trigger.agentName.toLowerCase() !== agentName.toLowerCase()) {
            continue;
          }
        } else if (trigger.agentName instanceof RegExp) {
          if (!trigger.agentName.test(agentName)) {
            continue;
          }
        }
      }

      if (trigger.phase && trigger.phase.toLowerCase() !== phase.toLowerCase()) {
        continue;
      }

      if (trigger.messageContains) {
        const allContent = messages.map((m) => m.content || "").join(" ");
        const matches =
          trigger.messageContains instanceof RegExp
            ? trigger.messageContains.test(allContent)
            : allContent.includes(trigger.messageContains);
        if (!matches) continue;
      }

      if (trigger.iterationCount !== undefined) {
        if (agentIteration !== trigger.iterationCount) continue;
      }

      if (trigger.previousAgent) {
        if (context.lastContinueCaller !== trigger.previousAgent) continue;
      }

      if (trigger.afterAgent) {
        if (context.lastAgentExecuted !== trigger.afterAgent) continue;
      }

      // All conditions matched
      if (this.config.debug) {
        conversationalLogger.logMatchedResponse(mockResponse);
      }

      // Log the response using conversational logger
      if (this.config.debug && mockResponse.response) {
        conversationalLogger.logAgentResponse(agentName, {
          content: mockResponse.response.content,
          toolCalls: mockResponse.response.toolCalls,
          phase,
          reason: "Mock response matched",
        });
      }

      return mockResponse.response;
    }

    // Return default response
    if (this.config.debug) {
      conversationalLogger.logAgentResponse("unknown", {
        content: this.config.defaultResponse?.content || "Default mock response",
        toolCalls: this.config.defaultResponse?.toolCalls,
        reason: "No matching response found, using default",
      });
    }
    return this.config.defaultResponse || { content: "Default mock response" };
  }

  private extractAgentName(systemPrompt: string): string {
    // Try multiple patterns to extract agent name
    const patterns = [
      /You are the ([\w-]+) agent/i,
      /You are ([\w-]+)[\s.]/i,
      /Agent: ([\w-]+)/i,
      /\[Agent: ([\w-]+)\]/i,
    ];

    for (const pattern of patterns) {
      const match = systemPrompt.match(pattern);
      if (match) {
        const name = match[1]?.toLowerCase();
        // Handle special cases
        if (!name || name === "the") continue; // Skip if we accidentally matched "the"
        return name;
      }
    }

    // Check for specific agent keywords
    if (systemPrompt.includes("orchestrator")) return "orchestrator";
    if (systemPrompt.includes("message router")) return "orchestrator";
    if (systemPrompt.includes("execution specialist")) return "executor";
    if (systemPrompt.includes("executor")) return "executor";
    if (systemPrompt.includes("project-manager")) return "project-manager";
    if (systemPrompt.includes("project manager")) return "project-manager";
    if (systemPrompt.includes("planning specialist")) return "planner";
    if (systemPrompt.includes("planner")) return "planner";

    return "unknown";
  }

  private extractPhase(systemPrompt: string): string {
    // Try multiple patterns to extract phase
    const patterns = [
      /Current Phase: (\w+)/i,
      /Phase: (\w+)/i,
      /\[Phase: (\w+)\]/i,
      /in (\w+) phase/i,
    ];

    for (const pattern of patterns) {
      const match = systemPrompt.match(pattern);
      if (match) {
        return match[1]?.toLowerCase() || "unknown";
      }
    }

    return "unknown";
  }

  private recordRequest(
    messages: Message[],
    model: string,
    response: MockLLMResponse["response"]
  ): void {
    this.requestHistory.push({
      messages,
      model,
      response,
      timestamp: new Date(),
    });
  }

  // Helper methods for testing

  addResponse(response: MockLLMResponse): void {
    this.responses.push(response);
    this.responses.sort((a, b) => (b.priority || 0) - (a.priority || 0));
  }

  getRequestHistory(): Array<{
    messages: Message[];
    model?: string;
    response: MockLLMResponse["response"];
  }> {
    return this.requestHistory;
  }

  clearHistory(): void {
    this.requestHistory = [];
  }

  // Method to update context (called by test harness)
  updateContext(updates: {
    conversationId?: string;
    lastContinueCaller?: string;
    iteration?: number;
    lastAgentExecuted?: string;
  }): void {
    const conversationId = updates.conversationId || "default";
    const context = this.getOrCreateContext(conversationId);

    if (updates.lastContinueCaller !== undefined) {
      context.lastContinueCaller = updates.lastContinueCaller;
    }
    if (updates.iteration !== undefined) {
      context.iteration = updates.iteration;
    }
    if (updates.lastAgentExecuted !== undefined) {
      context.lastAgentExecuted = updates.lastAgentExecuted;
    }
  }

  private getOrCreateContext(conversationId: string): {
    iteration: number;
    agentIterations: Map<string, number>;
    lastContinueCaller?: string;
    lastAgentExecuted?: string;
  } {
    if (!this.conversationContext.has(conversationId)) {
      this.conversationContext.set(conversationId, {
        iteration: 0,
        agentIterations: new Map(),
      });
    }
    const context = this.conversationContext.get(conversationId);
    if (!context) {
      throw new Error(`Conversation context not found for ${conversationId}`);
    }
    return context;
  }

  private extractConversationId(): string {
    // Try to extract conversation ID from messages
    // For now, use a default ID
    return "default";
  }
}
</file>

<file path="src/test-utils/e2e-execution.ts">
import { Message } from "@/conversations/Message";
import type { 
    E2ETestContext, 
    ExecutionTrace, 
    AgentExecutionResult, 
    RoutingDecision
} from "./e2e-types";

/**
 * Execute agent and return result (internal helper)
 */
async function executeAgentWithResult(
    context: E2ETestContext,
    agentName: string,
    conversationId: string,
    userMessage: string
): Promise<AgentExecutionResult> {
    const result: AgentExecutionResult = {
        message: "",
        toolCalls: []
    };
    
    // Find the agent
    const agent = context.agentRegistry.getAgentBySlug(agentName.toLowerCase());
    
    if (!agent) {
        console.error("Available agents:", context.agentRegistry.getAllAgents().map(a => ({ slug: a.slug, name: a.name })));
        throw new Error(`Agent not found: ${agentName}`);
    }
    
    const conversation = context.conversationCoordinator.getConversation(conversationId);
    if (!conversation) {
        throw new Error(`Conversation not found: ${conversationId}`);
    }
    
    // Execute different behavior for orchestrator vs other agents
    if (agentName.toLowerCase() === "orchestrator") {
        // Build orchestrator messages with routing prompt
        const orchestratorMessages = [
            new Message("system", `You are the orchestrator. Current phase: ${conversation.phase}. You must respond with ONLY a JSON object in this exact format:
{
    "agents": ["agent1", "agent2"],
    "phase": "currentPhase",
    "reason": "Brief explanation"
}
Select appropriate agents for the task. Use ["END"] when conversation is complete.`),
        ];
        
        // Add user message if provided
        if (userMessage) {
            orchestratorMessages.push(new Message("user", userMessage));
        }
        
        // Use the mock LLM directly to get routing decision
        const response = await context.mockLLM.complete({
            messages: orchestratorMessages,
            options: {
                configName: agent.llmConfig || "orchestrator",
                agentName: agent.name
            }
        });
        
        // Stream the response
        if (response.content) {
            result.message = response.content;
        }
    } else {
        // Execute non-orchestrator agents directly with mock LLM
        // Build simple agent messages
        const agentMessages = [
            new Message("system", `You are the ${agent.slug || agent.name} agent. Current Phase: ${conversation.phase}.`),
        ];
        
        if (userMessage) {
            agentMessages.push(new Message("user", userMessage));
        }
        
        // Get response from mock LLM
        const response = await context.mockLLM.complete({
            messages: agentMessages,
            options: {
                configName: agent.llmConfig || agent.name,
                agentName: agent.name
            }
        });
        
        // Stream the response
        if (response.content) {
            result.message = response.content;
        }
        
        // Process tool calls
        if (response.toolCalls && response.toolCalls.length > 0) {
            result.toolCalls = response.toolCalls.map(tc => ({
                id: tc.name || 'mock-tool-call',
                type: 'function' as const,
                function: {
                    name: tc.name,
                    arguments: JSON.stringify(tc.params || {})
                }
            }));
        }
    }
    
    // Result is already logged by the conversational logger in MockLLMService
    
    return result;
}

/**
 * Extract routing decision from orchestrator response
 */
function extractRoutingDecision(orchestratorResult: AgentExecutionResult): RoutingDecision | null {
    try {
        // Orchestrator with routing backend returns JSON
        const content = orchestratorResult.message;
        if (!content) return null;
        
        // Try to parse as JSON
        const parsed = JSON.parse(content);
        if (parsed.agents && Array.isArray(parsed.agents)) {
            return parsed;
        }
    } catch {
        // Not a routing decision
    }
    return null;
}

/**
 * Execute a conversation flow with multiple agents
 */
export async function executeConversationFlow(
    context: E2ETestContext,
    conversationId: string,
    initialMessage: string,
    options?: {
        maxIterations?: number;
        onAgentExecution?: (agent: string, phase: string) => void;
        onPhaseTransition?: (from: string, to: string) => void;
    }
): Promise<ExecutionTrace> {
    const maxIterations = options?.maxIterations || 20;
    let iteration = 0;
    
    const trace: ExecutionTrace = {
        conversationId,
        executions: [],
        toolCalls: [],
        routingDecisions: []
    };
    
    // Track conversation state
    const currentMessage = initialMessage;
    
    while (iteration < maxIterations) {
        iteration++;
        
        // Get current conversation state
        const state = await getConversationState(context, conversationId);
        const currentPhase = state.phase;
        
        // Always execute orchestrator for routing
        const orchestratorResult = await executeAgentWithResult(
            context,
            "orchestrator",
            conversationId,
            iteration === 1 ? currentMessage : ""
        );
        
        // Record orchestrator execution
        trace.executions.push({
            agent: "orchestrator",
            phase: currentPhase,
            timestamp: new Date(),
            message: orchestratorResult.message
        });
        
        // Extract routing decision from orchestrator response
        const routingDecision = extractRoutingDecision(orchestratorResult);
        if (!routingDecision) {
            console.error("Orchestrator response:", orchestratorResult.message);
            throw new Error("Orchestrator did not return valid routing decision");
        }
        
        // Record routing decision
        trace.routingDecisions.push({
            phase: currentPhase,
            decision: routingDecision,
            timestamp: new Date()
        });
        
        // Check for END signal
        if (routingDecision.agents.includes("END")) {
            break;
        }
        
        // Execute each target agent
        for (const targetAgent of routingDecision.agents) {
            if (targetAgent === "END") {
                // Conversation complete
                return trace;
            }
            
            // Notify callback
            if (options?.onAgentExecution) {
                options.onAgentExecution(targetAgent, routingDecision.phase || currentPhase);
            }
            
            // Execute target agent
            const agentResult = await executeAgentWithResult(
                context,
                targetAgent,
                conversationId,
                "" // No message, agent gets context from conversation
            );
            
            // Record agent execution
            trace.executions.push({
                agent: targetAgent,
                phase: routingDecision.phase || currentPhase,
                timestamp: new Date(),
                message: agentResult.message,
                toolCalls: agentResult.toolCalls
            });
            
            // Record tool calls
            if (agentResult.toolCalls) {
                for (const toolCall of agentResult.toolCalls) {
                    // Handle different tool call structures
                    let toolName: string;
                    let toolArgs: any;
                    
                    if (toolCall.function) {
                        // Standard OpenAI-style structure
                        toolName = toolCall.function.name;
                        toolArgs = JSON.parse(toolCall.function.arguments || '{}');
                    } else if (toolCall.name) {
                        // Simplified structure from our mock
                        toolName = toolCall.name;
                        toolArgs = toolCall.params || {};
                    } else {
                        console.warn('Unknown tool call structure:', toolCall);
                        continue;
                    }
                    
                    trace.toolCalls.push({
                        agent: targetAgent,
                        tool: toolName,
                        arguments: toolArgs,
                        timestamp: new Date()
                    });
                    
                    // Check for continue tool - means we need to go back to orchestrator
                    if (toolName === 'continue') {
                        // Update mock LLM context for next iteration
                        if ((context.mockLLM as any).updateContext) {
                            (context.mockLLM as any).updateContext({
                                lastContinueCaller: targetAgent,
                                iteration: iteration,
                            });
                        }
                        
                        // End conversation in specific scenarios:
                        // 1. If certain phases are completed
                        // 2. If workflow is complete
                        // Check if PM agent (first agent in project) completed certain phases
                        const pmAgent = context.projectContext.getProjectManager();
                        const isPMAgent = targetAgent === pmAgent.slug;
                        
                        if (targetAgent === 'orchestrator' || 
                            (isPMAgent && 
                             (routingDecision.phase === 'verification' || routingDecision.phase === 'plan'))) {
                            return trace;
                        }
                    }
                }
            }
            
            // Check for phase transitions
            const newState = await getConversationState(context, conversationId);
            if (newState.phase !== currentPhase) {
                // Phase change detected - record in execution trace
                trace.executions.push({
                    agent: targetAgent,
                    phase: newState.phase,
                    timestamp: new Date(),
                    message: `Phase changed from ${currentPhase} to ${newState.phase}: ${routingDecision.reason}`
                });
                
                if (options?.onPhaseTransition) {
                    options.onPhaseTransition(currentPhase, newState.phase);
                }
            }
        }
    }
    
    return trace;
}

/**
 * Create a new conversation
 */
export async function createConversation(
    context: E2ETestContext,
    userMessage: string = "Test conversation"
): Promise<string> {
    const conversationId = `conv-${Date.now()}`;
    
    // Create conversation in coordinator
    context.conversationCoordinator.createConversation(
        conversationId,
        userMessage,
        null,
        "discovery"
    );
    
    // Initialize conversation with user message
    await context.messageRepo.saveMessage({
        conversationId,
        role: "user",
        content: userMessage,
        timestamp: new Date()
    });
    
    return conversationId;
}

/**
 * Get conversation state
 */
export async function getConversationState(
    context: E2ETestContext,
    conversationId: string
): Promise<{ phase: string; messages: any[] }> {
    const conversation = context.conversationCoordinator.getConversation(conversationId);
    if (!conversation) {
        throw new Error(`Conversation not found: ${conversationId}`);
    }
    
    const messages = await context.messageRepo.getMessages(conversationId);
    
    return {
        phase: conversation.phase,
        messages
    };
}

/**
 * Wait for a specific phase
 */
export async function waitForPhase(
    context: E2ETestContext,
    conversationId: string,
    targetPhase: string,
    timeoutMs: number = 5000
): Promise<boolean> {
    const startTime = Date.now();
    
    while (Date.now() - startTime < timeoutMs) {
        const state = await getConversationState(context, conversationId);
        if (state.phase === targetPhase) {
            return true;
        }
        await new Promise(resolve => setTimeout(resolve, 100));
    }
    
    return false;
}

/**
 * Get tool calls from mock LLM history
 */
export function getToolCallsFromHistory(mockLLM: any): string[] {
    const toolCalls: string[] = [];
    
    // Access the conversational logger from the mock LLM
    if ((mockLLM as any).conversationalLogger) {
        const history = (mockLLM as any).conversationalLogger.getHistory();
        for (const entry of history) {
            if (entry.toolCalls) {
                for (const tc of entry.toolCalls) {
                    toolCalls.push(tc.name);
                }
            }
        }
    }
    
    return toolCalls;
}
</file>

<file path="src/test-utils/e2e-harness.ts">
/**
 * E2E Test Harness - Main export file
 * 
 * This file re-exports all the E2E testing utilities from their respective modules
 * to maintain backward compatibility while keeping the code organized.
 */

// Export types
export type {
    E2ETestContext,
    ExecutionTrace,
    AgentExecutionRecord,
    ToolCallRecord,
    ToolCall,
    AgentExecutionResult,
    RoutingDecision
} from "./e2e-types";

// Export setup and teardown functions
export { 
    setupE2ETest, 
    cleanupE2ETest 
} from "./e2e-setup";

// Export execution functions
export {
    executeConversationFlow,
    createConversation,
    getConversationState,
    waitForPhase,
    getToolCallsFromHistory
} from "./e2e-execution";

// Export assertion helpers
export {
    assertAgentSequence,
    assertPhaseTransitions,
    assertToolCalls,
    assertFeedbackPropagated
} from "./e2e-assertions";

// Export mock utilities
export { 
    createE2EMockEvent,
    createTestAgents 
} from "./e2e-mocks";

// Re-export createMockNDKEvent for backward compatibility
export { createMockNDKEvent } from "@/test-utils/mock-factories";
</file>

<file path="src/tools/implementations/agents_hire.ts">
import { tool } from 'ai';
import { getNDK } from "@/nostr";
import { getProjectContext } from "@/services/ProjectContext";
import { installAgentFromEvent } from "@/utils/agentInstaller";
import { logger } from "@/utils/logger";
import { normalizeNostrIdentifier } from "@/utils/nostr-entity-parser";
import { filterAndRelaySetFromBech32 } from "@nostr-dev-kit/ndk";
import { z } from "zod";
const agentsHireSchema = z.object({
  eventId: z.string().describe("The event ID of the Agent Definition Event to hire"),
  slug: z
    .string()
    .nullable()
    .describe("Optional custom slug for the agent (defaults to normalized name)"),
});

type AgentsHireInput = z.infer<typeof agentsHireSchema>;
type AgentsHireOutput = {
  success: boolean;
  message?: string;
  error?: string;
  agent?: {
    slug: string;
    name: string;
    role?: string;
    pubkey: string;
    eventId?: string;
  };
};

/**
 * Core implementation of the agents_hire functionality
 * Shared between AI SDK and legacy Tool interfaces
 */
async function executeAgentsHire(
  input: AgentsHireInput
): Promise<AgentsHireOutput> {
  const { eventId: rawEventId, slug } = input;

  if (!rawEventId) {
    return {
      success: false,
      error: "Event ID is required to hire an agent",
    };
  }

  // Normalize the event ID using our utility
  const eventId = normalizeNostrIdentifier(rawEventId);
  if (!eventId) {
    return {
      success: false,
      error: `Invalid event ID format: "${rawEventId}". Please provide a valid Nostr event ID in bech32 format (e.g., nevent1...) or hex format.`,
    };
  }

  // Get NDK instance for validation and fetching
  const ndk = getNDK();

  // Additional validation for bech32 format
  if (eventId.startsWith("nevent1") || eventId.startsWith("note1")) {
    try {
      filterAndRelaySetFromBech32(eventId, ndk);
    } catch {
      return {
        success: false,
        error: `Invalid event ID format: "${eventId}". Please provide a valid Nostr event ID.`,
      };
    }
  }

  // Get project context
  const projectContext = getProjectContext();
  const projectPath = process.cwd();

  // Use the shared function to install the agent
  const result = await installAgentFromEvent(
    eventId,
    projectPath,
    projectContext.project,
    slug,
    ndk
  );

  if (!result.success) {
    return {
      success: false,
      error: result.error || "Failed to install agent",
    };
  }

  if (result.alreadyExists) {
    return {
      success: true,
      message: result.message,
      agent: result.agent && result.slug ? {
        slug: result.slug,
        name: result.agent.name,
        pubkey: result.agent.pubkey,
      } : undefined,
    };
  }

  const agent = result.agent;
  const agentSlug = result.slug;

  if (!agent || !agentSlug) {
    return {
      success: false,
      error: "Agent installation succeeded but agent or slug is missing",
    };
  }

  // Note: We don't update the project event here because:
  // 1. The project event is signed by the user, not the agents
  // 2. The backend doesn't have the user's private key
  // 3. The agent is already installed locally in agents.json and .tenex/agents/
  // 4. The user can update their project event from the client if needed

  // Update the ProjectContext with the new agent to trigger 24010 event
  const updatedAgents = new Map(projectContext.agents);
  updatedAgents.set(agentSlug, agent);
  await projectContext.updateProjectData(projectContext.project, updatedAgents);

  logger.info(`Successfully hired agent "${agent.name}" (${agent.eventId})`);
  logger.info(`  Slug: ${agentSlug}`);
  logger.info(`  Pubkey: ${agent.pubkey}`);

  return {
    success: true,
    message: result.message,
    agent: {
      slug: agentSlug,
      name: agent.name,
      role: agent.role,
      pubkey: agent.pubkey,
      eventId: agent.eventId,
    },
  };
}

/**
 * Create an AI SDK tool for hiring agents
 * This is the primary implementation
 */
export function createAgentsHireTool(): ReturnType<typeof tool> {
  return tool({
    description: "Hire (add) a new agent from the Nostr network to the current project using its event ID",
    inputSchema: agentsHireSchema,
    execute: async (input: AgentsHireInput) => {
      try {
        return await executeAgentsHire(input);
      } catch (error) {
        logger.error("Failed to hire agent", { error });
        throw new Error(`Failed to hire agent: ${error instanceof Error ? error.message : String(error)}`);
      }
    },
  });
}
</file>

<file path="src/tools/implementations/nostr_projects.ts">
import { tool } from 'ai';
import { NDKProjectStatus } from "@/events/NDKProjectStatus";
import { getNDK } from "@/nostr";
import { getProjectContext } from "@/services/ProjectContext";
import { logger } from "@/utils/logger";
import { parseNostrUser } from "@/utils/nostr-entity-parser";
import { NDKArticle, NDKUser } from "@nostr-dev-kit/ndk";
import { z } from "zod";
import type { ExecutionContext } from "@/agents/execution/types";

// Define schema that gracefully handles no arguments, empty strings, or optional pubkey
// This handles cases where LLMs send "", {}, or {pubkey: "..."}
const nostrProjectsSchema = z
  .object({
    pubkey: z
      .string()
      .nullable()
      .describe(
        "Public key to fetch projects for. Defaults to project owner's pubkey if available"
      ),
  })
  .partial(); // Make all properties optional, effectively allowing empty object

type NostrProjectsInput = z.infer<typeof nostrProjectsSchema>;
type NostrProjectsOutput = {
  projects: Array<{
    id: string;
    title?: string;
    description?: string;
    repository?: string;
    image?: string;
    online: boolean;
    agents?: Record<string, string>;
    date?: number;
    specs: Array<{
      title?: string;
      summary?: string;
      id: string;
      date?: number;
    }>;
  }>;
  summary: {
    totalProjects: number;
    onlineProjects: number;
    offlineProjects: number;
    totalSpecDocuments: number;
  };
};

// Core implementation - extracted from existing execute function
async function executeNostrProjects(input: NostrProjectsInput, context: ExecutionContext): Promise<NostrProjectsOutput> {
  const ndk = getNDK();
  if (!ndk) {
    throw new Error("NDK instance not available");
  }

  // Determine which pubkey to use
  let targetPubkey: string | null = null;
  
  if (input.pubkey) {
    // Parse the provided pubkey (handles npub, nprofile, hex, with/without nostr: prefix)
    targetPubkey = parseNostrUser(input.pubkey, ndk);
    if (!targetPubkey) {
      throw new Error(`Invalid pubkey format: ${input.pubkey}`);
    }
  } else {
    // Try to get project owner's pubkey from context
    const projectCtx = getProjectContext();
    if (projectCtx?.project?.pubkey) {
      targetPubkey = projectCtx.project.pubkey;
      logger.info("üîç Using project owner's pubkey from context", {
        pubkey: targetPubkey,
        agent: context.agent.name,
      });
    } else {
      throw new Error("No pubkey provided and no project context available");
    }
  }

  logger.info("üîç Fetching projects for pubkey", {
    pubkey: targetPubkey,
    agent: context.agent.name,
    phase: context.phase,
  });

  // Publish status message about what we're doing
  try {
    const conversation = context.conversationCoordinator.getConversation(context.conversationId);
    
    if (conversation?.history?.[0]) {
      // Format the pubkey as npub for the status message
      const user = new NDKUser({ pubkey: targetPubkey });
      await context.agentPublisher.conversation(
        { content: `üîç Getting nostr:${user.npub}'s projects` },
        {
          triggeringEvent: context.triggeringEvent,
          rootEvent: conversation.history[0],
          conversationId: context.conversationId,
        }
      );
    }
  } catch (error) {
    // Don't fail the tool if we can't publish the status
    logger.warn("Failed to publish nostr_projects status:", error);
  }

  // Calculate 1 minute ago timestamp for online status check
  const oneMinuteAgo = Math.floor(Date.now() / 1000) - 60;

  // Fetch both kinds of events in parallel
  const [projectEvents, statusEvents] = await Promise.all([
    // Fetch 31933 events (NDKProject)
    ndk.fetchEvents({
      kinds: [31933],
      authors: [targetPubkey],
    }),
    // Fetch 24010 events (project status - online agents)
    // Only get status events from the last minute to determine if online
    ndk.fetchEvents({
      kinds: [NDKProjectStatus.kind],
      "#p": [targetPubkey],
      since: oneMinuteAgo,
    }),
  ]);

  // Build a map of online agents by project (keyed by project tagId)
  const onlineAgentsByProject = new Map<string, Record<string, string>>();

  // Process status events to find online agents
  Array.from(statusEvents).forEach((event) => {
    // Convert to NDKProjectStatus for type safety
    const statusEvent = NDKProjectStatus.from(event);

    // Get the project reference
    const projectTagId = statusEvent.projectReference;
    if (projectTagId) {
      // Get agents from the status event
      const agents = statusEvent.agents;
      const agentsMap: Record<string, string> = {};

      agents.forEach(({ pubkey, slug }) => {
        // Convert pubkey to npub format
        const agentUser = new NDKUser({ pubkey });
        agentsMap[slug] = agentUser.npub;
      });

      // Store agents for this specific project using its tagId as the key
      if (Object.keys(agentsMap).length > 0) {
        onlineAgentsByProject.set(projectTagId, agentsMap);
      }
    }
  });

  // Once we have the list of projects, fetch spec documents that tag them
  interface SpecArticle {
    title: string | undefined;
    summary: string | undefined;
    id: string;
    date: number | undefined;
    _projectRefs: string[];
  }
  let specArticles: SpecArticle[] = [];
  if (projectEvents.size > 0) {
    // Create array of project tag IDs for fetching articles
    const projectTagIds = Array.from(projectEvents).map((projectEvent) => {
      return projectEvent.tagId();
    });

    logger.info("üìÑ Fetching spec documents for projects", {
      projectCount: projectTagIds.length,
      agent: context.agent.name,
    });

    // Fetch NDKArticles (kind 30023) that tag these projects
    const articleEvents = await ndk.fetchEvents(
      {
        kinds: [30023],
        "#a": projectTagIds,
      },
      { subId: "spec-articles" }
    );

    // Process articles
    specArticles = Array.from(articleEvents).map((event) => {
      const article = NDKArticle.from(event);

      // Get project references from the article's tags (for internal filtering only)
      const projectRefs = event.tags
        .filter((tag) => tag[0] === "a" && projectTagIds.includes(tag[1]))
        .map((tag) => tag[1]);

      // Get summary or first 300 bytes of content
      let summary = article.summary;
      if (!summary && article.content) {
        summary = article.content.substring(0, 300);
        if (article.content.length > 300) {
          summary += "...";
        }
      }

      return {
        title: article.title,
        summary: summary,
        id: `nostr:${article.encode()}`,
        date: article.created_at,
        _projectRefs: projectRefs, // Keep for internal filtering but prefix with underscore
      };
    });

    logger.info("‚úÖ Spec documents fetched", {
      articleCount: specArticles.length,
      agent: context.agent.name,
    });
  }

  // Process project events (31933)
  const projects = Array.from(projectEvents).map((projectEvent) => {
    const title = projectEvent.tagValue("title") || projectEvent.tagValue("name");
    const description = projectEvent.tagValue("description");
    const repository = projectEvent.tagValue("repository");
    const image = projectEvent.tagValue("image");

    // Get the project's tagId for matching with status events and articles
    const projectTagId = projectEvent.tagId();

    // Check if this project has online agents using its tagId
    const isOnline = onlineAgentsByProject.has(projectTagId);
    const onlineAgents = isOnline ? onlineAgentsByProject.get(projectTagId) : undefined;

    // Get the encoded project ID with nostr: prefix
    const projectId = `nostr:${projectEvent.encode()}`;

    // Find spec articles for this project
    const projectSpecs = specArticles
      .filter((article) => article._projectRefs.includes(projectTagId))
      .map(({ _projectRefs, ...article }) => article); // Remove internal _projectRefs field

    return {
      id: projectId,
      title,
      description,
      repository,
      image,
      online: isOnline,
      agents: onlineAgents,
      date: projectEvent.created_at,
      specs: projectSpecs,
    };
  });

  // Sort projects by creation time (newest first)
  projects.sort((a, b) => (b.date || 0) - (a.date || 0));

  const result: NostrProjectsOutput = {
    projects,
    summary: {
      totalProjects: projects.length,
      onlineProjects: projects.filter((p) => p.online).length,
      offlineProjects: projects.filter((p) => !p.online).length,
      totalSpecDocuments: specArticles.length,
    },
  };

  logger.info("‚úÖ Projects fetched successfully", {
    pubkey: targetPubkey,
    projectCount: projects.length,
    onlineCount: result.summary.onlineProjects,
    specDocumentCount: specArticles.length,
    agent: context.agent.name,
  });

  return result;
}

// AI SDK tool factory
export function createNostrProjectsTool(context: ExecutionContext): ReturnType<typeof tool> {
  return tool({
    description: "Fetch Nostr projects for a pubkey, including online status and spec documents",
    inputSchema: nostrProjectsSchema,
    execute: async (input: NostrProjectsInput) => {
      return await executeNostrProjects(input, context);
    },
  });
}
</file>

<file path="src/tools/implementations/write_context_file.ts">
import { tool } from 'ai';
import { access, mkdir, writeFile } from "node:fs/promises";
import * as path from "node:path";
import { getNDK } from "@/nostr";
import { getProjectContext } from "@/services";
import { formatAnyError } from "@/utils/error-formatter";
import { logger } from "@/utils/logger";
import { NDKArticle } from "@nostr-dev-kit/ndk";
import { z } from "zod";
import type { ExecutionContext } from "@/agents/execution/types";

const WriteContextFileArgsSchema = z.object({
  filename: z.string().min(1, "filename must be a non-empty string"),
  content: z.string().min(1, "content must be a non-empty string"),
  title: z.string().min(1, "title must be a non-empty string"),
  changelog: z.string().nullable(),
});

type WriteContextFileInput = z.infer<typeof WriteContextFileArgsSchema>;

interface WriteContextFileOutput {
  message: string;
}

/**
 * Core implementation of write_context_file functionality
 * Shared between AI SDK and legacy Tool interfaces
 */
async function executeWriteContextFile(
  input: WriteContextFileInput,
  context: ExecutionContext
): Promise<WriteContextFileOutput> {
  logger.debug("write_context_file called", { input });

  const { filename: rawFilename, content, title, changelog } = input;

  // Extract just the filename from any path
  const filename = path.basename(rawFilename);

  // Only allow markdown files
  if (!filename.endsWith(".md")) {
    throw new Error("Only markdown files (.md) can be written to the context directory");
  }

  // Construct the full path
  const contextDir = path.join(context.projectPath, "context");
  const fullPath = path.join(contextDir, filename);

  // Check if this file was recently read from persisted conversation metadata
  const conversation = context.conversationCoordinator.getConversation(context.conversationId);
  const readFiles = conversation?.metadata?.readFiles || [];
  const contextPath = `context/${filename}`;
  const wasRecentlyRead = readFiles.includes(contextPath);

  // Check if file exists
  let fileExists = false;
  try {
    await access(fullPath);
    fileExists = true;
  } catch {
    // File doesn't exist, allow creation
    fileExists = false;
  }

  // If file exists and wasn't recently read, deny access
  if (fileExists && !wasRecentlyRead) {
    throw new Error(`You must read the file 'context/${filename}' before writing to it. Use the read_path tool first.`);
  }

  // Ensure context directory exists
  await mkdir(contextDir, { recursive: true });

  // Write the file
  await writeFile(fullPath, content, "utf-8");

  // Publish NDKArticle for this context file update
  try {
    const article = new NDKArticle(getNDK());

    // Use the filename without .md extension as the dTag
    const dTag = filename.replace(/\.md$/, "");
    article.dTag = dTag;

    // Set article properties
    article.title = title;
    article.content = content;
    article.published_at = Math.floor(Date.now() / 1000);

    // Tag the article with the project
    const projectCtx = getProjectContext();
    article.tag(projectCtx.project);

    // Sign with the agent's signer
    await article.sign(context.agent.signer);
    await article.publish();

    logger.debug("Published NDKArticle for context file", { filename, dTag });

    // Publish status message with the Nostr reference to the article
    try {
      const conversation = context.conversationCoordinator.getConversation(context.conversationId);
      
      if (conversation?.history?.[0]) {
        const nostrReference = `nostr:${article.encode()}`;
        await context.agentPublisher.conversation(
          { content: `üìù Writing context file: ${nostrReference}` },
          {
            triggeringEvent: context.triggeringEvent,
            rootEvent: conversation.history[0],
            conversationId: context.conversationId,
          }
        );
      }
    } catch (statusError) {
      console.warn("Failed to publish write_context_file status:", statusError);
    }

    // If changelog is provided, create a NIP-22 reply
    if (changelog) {
      try {
        const reply = await article.reply();
        reply.content = changelog;
        reply.created_at = Math.floor(Date.now() / 1000);

        await reply.sign(context.agent.signer);
        await reply.publish();

        logger.debug("Published changelog reply", { changelog, dTag });
      } catch (replyError) {
        logger.error("Failed to publish changelog reply", {
          error: formatAnyError(replyError),
        });
      }
    }
  } catch (error) {
    logger.error("Failed to publish NDKArticle", {
      error: formatAnyError(error),
    });
  }

  return {
    message: `Successfully wrote to context/${filename}`,
  };
}

/**
 * Create an AI SDK tool for writing context files
 */
export function createWriteContextFileTool(context: ExecutionContext): ReturnType<typeof tool> {
  return tool({
    description:
      "Write or update a specification file in the context/ directory. You must have read this file recently before writing to it.",
    
    inputSchema: WriteContextFileArgsSchema,
    
    execute: async (input: WriteContextFileInput) => {
      return await executeWriteContextFile(input, context);
    },
  });
}
</file>

<file path="README.md">
# TENEX

> **Collaborative AI development** - A revolutionary context-first development environment where AI agents collaborate autonomously to build software.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Built on Nostr](https://img.shields.io/badge/Built%20on-Nostr-purple)](https://nostr.com)

## What is TENEX?

TENEX represents a paradigm shift in software development. If LLMs have fundamentally changed how we write code, shouldn't our development environments evolve too? TENEX answers this by replacing the traditional text editor with a **context-first environment** where *context*, not code, becomes the primary building block.

At its core, TENEX is a sophisticated **multi-agent coordination system** built on the Nostr protocol. It enables autonomous AI agents to collaborate on complex software development tasks through intelligent routing, phase-based workflows, and continuous learning.

### Key Innovation: Intelligent Agent Coordination

Unlike traditional AI assistants where you interact with a single entity, TENEX employs an **intelligent routing** pattern. The system automatically routes your requests to specialized agents best suited for each task, creating a seamless experience where the right expertise appears exactly when needed.

## ‚ú® Key Features

### ü§ñ **Multi-Agent Architecture**
- **Specialized Agents**: Agents for planning, execution, and project management fetched from Nostr
- **Dynamic Routing**: Intelligent task delegation based on agent capabilities and context
- **Parallel Execution**: Multiple agents can work simultaneously on different aspects of your project
- **Custom Agents**: Extensible system allowing you to define domain-specific experts

### üîÑ **Phase-Based Workflow**
Every interaction follows a structured lifecycle ensuring quality and completeness:
1. **Chat** ‚Üí Initial conversation and understanding
2. **Brainstorm** ‚Üí Creative exploration and ideation
3. **Plan** ‚Üí Structured approach definition
4. **Execute** ‚Üí Implementation and tool usage
5. **Verification** ‚Üí Quality assurance and testing
6. **Chores** ‚Üí Documentation and maintenance
7. **Reflection** ‚Üí Learning capture and improvement

### üß† **Continuous Learning System**
- Agents capture and apply lessons from every interaction
- Cross-conversation knowledge sharing
- Self-improving behavior based on accumulated experience
- Persistent knowledge base stored on Nostr

### üîß **Powerful Tool System**
- **Comprehensive Tools**: File operations, code analysis, shell execution, Git integration
- **MCP Integration**: Model Context Protocol support for dynamic tool loading
- **Type-Safe**: Comprehensive validation and error handling
- **Composable**: Tools can be combined for complex operations

### üåê **Nostr-Native Architecture**
- **Decentralized by Design**: No central server, peer-to-peer agent communication
- **Cryptographic Identity**: Each project maintains its own nsec for secure context
- **Event Sourcing**: Complete audit trail of all agent actions
- **Resilient**: Continues operating even with network disruptions

### üéØ **LLM Provider Agnostic**
- Support for OpenAI, Anthropic, Google, OpenRouter, and more
- Intelligent model selection based on task requirements
- Automatic failover and rate limiting
- Cost optimization through smart routing

## üöÄ Getting Started

### Prerequisites

- **Node.js** 18+ or **Bun** runtime
- **Git** for version control integration
- An API key for at least one LLM provider (OpenAI, Anthropic, etc.)

### Installation

```bash
# Clone the repository
git clone https://github.com/tenex-chat/tenex
cd tenex

# Install dependencies
bun install

# Start TENEX
bun run start
```

### Quick Start

1. **Create a new project** using the [TENEX Web Client](https://github.com/tenex-chat/web-client) or iOS client

2. **Example interaction**:
```
You: Create a REST API for a todo application with authentication

TENEX: [System routes to Planner]
[Planner creates structured approach]
[Executor implements the API]
[Verification runs tests]
[Documentation is updated]
[Lessons are captured for future use]
```

## üìö Documentation

### Architecture Guides
- [Workflow Management](./documentation/workflow-management-architecture.md) - High-level system overview
- [Agent Execution](./documentation/agent-execution-architecture.md) - How agents operate
- [Phase Management](./documentation/phase-management-architecture.md) - Workflow control system
- [Tool System](./documentation/tool-system-architecture.md) - Capability implementation
- [Learning System](./documentation/learning-system-internals.md) - Continuous improvement mechanics

### Developer Documentation
For detailed technical documentation, see the [documentation](./documentation/) directory.

## üèóÔ∏è Project Structure

```
src/
‚îú‚îÄ‚îÄ agents/         # Agent system and execution
‚îú‚îÄ‚îÄ commands/       # CLI commands
‚îú‚îÄ‚îÄ conversations/  # Conversation management
‚îú‚îÄ‚îÄ daemon/         # Background processes
‚îú‚îÄ‚îÄ events/         # Nostr event definitions
‚îú‚îÄ‚îÄ llm/           # LLM provider integration
‚îú‚îÄ‚îÄ nostr/         # Nostr protocol layer
‚îú‚îÄ‚îÄ prompts/       # Prompt composition system
‚îú‚îÄ‚îÄ tools/         # Tool implementations
‚îî‚îÄ‚îÄ utils/         # Utility functions
```

## ü§ù Contributing

We welcome contributions! Please open issues and pull requests on GitHub.

### Development Setup

```bash
# Run tests
bun test

# Run tests with coverage
bun test --coverage

# Type checking
bun run typecheck

# Linting
bun run lint

# Build for production
bun run build

# Watch mode for development
bun test --watch
```

## üîÆ What Makes TENEX Different?

### **Context Over Code**
Traditional IDEs optimize for code editing. TENEX optimizes for context management, recognizing that in the LLM era, maintaining and utilizing context effectively is more valuable than syntax highlighting.

### **Invisible Complexity**
The coordination system operates behind the scenes, presenting a simple conversational interface while managing sophisticated multi-agent collaboration underneath.

### **Quality by Design**
Mandatory verification and reflection phases ensure every task meets quality standards and contributes to the system's collective knowledge.

### **Truly Decentralized**
Built on Nostr from the ground up, not as an afterthought. This enables censorship-resistant, peer-to-peer agent networks with no single point of failure.

## üéØ Use Cases

- **Rapid Prototyping**: Go from idea to working prototype through natural conversation
- **Code Migration**: Modernize legacy codebases with intelligent refactoring
- **Documentation**: Automatic generation and maintenance of technical documentation
- **Testing**: Comprehensive test generation and verification
- **Learning**: Agents that get better at your specific codebase over time

## üìà Roadmap

- [ ] Web-based interface improvements
- [ ] Multi-model ensemble execution
- [ ] Real-time collaborative editing
- [ ] Advanced debugging and profiling tools

## üìÑ License

MIT - see [LICENSE](LICENSE) file for details

## üìû Contact & Support

- **GitHub Issues**: [Report bugs or request features](https://github.com/tenex-chat/tenex/issues)
- **Nostr**: Follow the project at `npub1tenex...` 
- **Documentation**: [Full documentation](./documentation/)

---

**Ready to experience the future of software development?** Create your first project using the [TENEX Web Client](https://github.com/tenex-chat/web-client) and let your AI agents handle the rest.

> "The best code is the code you don't have to write. The second best is code written by agents who learn from every line they produce." - TENEX Philosophy
</file>

<file path="context/agents.md">
# Agents Module

## Overview

The `src/agents` module is the core of the TENEX application, responsible for defining and managing the agents that perform tasks. It includes the logic for agent execution, lifecycle management, and the registration of agents from Nostr events.

## Key Components

- **`AgentRegistry.ts`**: A singleton class that manages the registration and lifecycle of all agents. It allows for publishing, unpublishing, and republishing agents.

- **Agent Definitions**: All agents are defined via NDKAgentDefinition events (kind 4199) fetched from Nostr. All agents are treated uniformly and fetched the same way.

- **`execution/`**: This directory contains the core logic for the agent execution loop, including:
    - **`AgentExecutor.ts`**: The main class responsible for executing an agent's reasoning loop. It takes an agent, a conversation, and a set of tools, and then orchestrates the interaction between the LLM and the tools to accomplish a task.
    - **`ReasonActLoop.ts`**: Implements the ReAct (Reason and Act) pattern for agent execution.
    - **`ToolStreamHandler.ts`**: Handles the streaming of tool outputs.
    - **`StreamStateManager.ts`**: Manages the state of streaming operations during tool execution.
    - **`TerminationHandler.ts`**: Handles graceful termination of agent execution.


- **`constants.ts`**: Defines constants and default tool assignments used throughout the agents module.

- **`utils.ts`**: Utility functions for agent operations.

- **`types.ts`**: Defines the data structures and types used throughout the agents module, such as `AgentInstance`, `AgentConfig`, and `ToolCall`.

## Agent Management

### Project Manager Selection

The Project Manager (PM) agent is dynamically determined as the **first agent** listed in the NDKProject event's `agent` tags. This means the order of agent tags in the project definition is significant - the first agent reference becomes the PM for that project.

Example NDKProject event structure:
```
tags: [
  ["agent", "pm-event-id"],      // This agent becomes the PM
  ["agent", "executor-event-id"], 
  ["agent", "planner-event-id"]
]
```

The PM has special privileges such as access to the `shell` tool and the ability to coordinate other agents through phase delegation.

### Agent Loading

Agents are loaded from:
1. **Nostr Events**: NDKAgentDefinition events (kind 4199) containing agent specifications
2. **Local Registry**: JSON files in `.tenex/agents/` directory for offline development

All agents receive the same default tool set, which can be augmented by tool requirements specified in their definition events via `["tool", "tool-name"]` tags.
</file>

<file path="src/commands/inventory/index.ts">
import { handleCliError } from "@/utils/cli-error";
import { generateInventory, updateInventory } from "@/utils/inventory";
import { logger } from "@/utils/logger";
import { ensureProjectInitialized } from "@/utils/projectInitialization";
import chalk from "chalk";
import { Command } from "commander";

export const inventoryCommand = new Command("inventory")
  .description("Manage project inventory")
  .action(() => {
    inventoryCommand.help();
  });

inventoryCommand
  .command("generate")
  .description("Generate or update the project inventory using repomix + LLM analysis")
  .option("--path <path>", "Project path (defaults to current directory)")
  .action(async (options) => {
    try {
      const projectPath = options.path || process.cwd();

      // Initialize project context
      await ensureProjectInitialized(projectPath);

      logger.info("Generating project inventory", { projectPath });

      await generateInventory(projectPath);

      logger.info(chalk.green("\n‚úÖ Inventory generation completed successfully!"));
      logger.info(chalk.blue("üìã Main inventory saved to context/INVENTORY.md"));
      logger.info(chalk.blue("üìö Complex module guides (if any) saved to context/ directory"));
    } catch (error) {
      handleCliError(error, "Failed to generate inventory");
    }
  });

inventoryCommand
  .command("update")
  .description("Update inventory for specific files using repomix + LLM analysis")
  .argument("<files...>", "Files to update in the inventory")
  .option("--path <path>", "Project path (defaults to current directory)")
  .action(async (files, options) => {
    try {
      const projectPath = options.path || process.cwd();

      // Initialize project context
      await ensureProjectInitialized(projectPath);

      logger.info("Updating inventory for files", { files });

      await updateInventory(projectPath, files);

      logger.info(chalk.green("\n‚úÖ Inventory update completed successfully!"));
      logger.info(chalk.blue(`üìù Updated inventory for ${files.length} file(s)`));
      logger.info(chalk.blue("üìã Updated inventory saved to context/INVENTORY.md"));
    } catch (error) {
      handleCliError(error, "Failed to update inventory");
    }
  });
</file>

<file path="src/commands/mcp/list.ts">
import { configService } from "@/services/ConfigService";
import type { MCPServerConfig } from "@/services/config/types";
import { logger } from "@/utils/logger";
import chalk from "chalk";
import { Command } from "commander";

interface ListOptions {
  project?: boolean;
  global?: boolean;
  all?: boolean;
}

export const listCommand = new Command("list")
  .description("List configured MCP servers")
  .option("--project", "Show only project servers")
  .option("--global", "Show only global servers")
  .option("--all", "Show all servers (default)")
  .action(async (options: ListOptions) => {
    try {
      const projectPath = process.cwd();
      const isProject = await configService.projectConfigExists(projectPath, "config.json");

      // Default to showing all servers
      const showAll = options.all || (!options.project && !options.global);
      const showProject = options.project || showAll;
      const showGlobal = options.global || showAll;

      // Validate options
      if (options.project && !isProject) {
        logger.error(
          "Not in a TENEX project directory. Remove --project flag or run from a project."
        );
        process.exit(1);
      }

      // Load configurations
      const globalPath = configService.getGlobalPath();
      const globalMCP = await configService.loadTenexMCP(globalPath);
      const projectMCP = isProject
        ? await configService.loadTenexMCP(configService.getProjectPath(projectPath))
        : { servers: {}, enabled: true };

      // Check if any servers exist
      const hasGlobalServers = Object.keys(globalMCP.servers).length > 0;
      const hasProjectServers = Object.keys(projectMCP.servers).length > 0;

      if (!hasGlobalServers && !hasProjectServers) {
        logger.info("No MCP servers configured");
        process.exit(0);
      }

      logger.info(chalk.bold("Configured MCP Servers:"));
      logger.info(chalk.gray("‚îÄ".repeat(60)));

      // Display global servers
      if (showGlobal && hasGlobalServers) {
        logger.info(chalk.yellow("\nGlobal servers:"));
        for (const [name, server] of Object.entries(globalMCP.servers)) {
          const isOverridden = hasProjectServers && projectMCP.servers[name];
          displayServer(name, server, !!isOverridden);
        }
      }

      // Display project servers
      if (showProject && isProject && hasProjectServers) {
        logger.info(chalk.blue("\nProject servers:"));

        // Categorize servers
        const projectOnlyServers: [string, MCPServerConfig][] = [];
        const overriddenServers: [string, MCPServerConfig][] = [];

        for (const [name, server] of Object.entries(projectMCP.servers)) {
          if (globalMCP.servers[name]) {
            overriddenServers.push([name, server]);
          } else {
            projectOnlyServers.push([name, server]);
          }
        }

        // Show project-specific servers first
        for (const [name, server] of projectOnlyServers) {
          displayServer(name, server);
        }

        // Show overridden servers
        if (overriddenServers.length > 0) {
          logger.info(chalk.blue("\n  Overriding global servers:"));
          for (const [name, server] of overriddenServers) {
            displayServer(name, server, false, true);
          }
        }
      }

      // Display status summary
      logger.info(chalk.gray("\n‚îÄ".repeat(60)));

      // Load merged config to show final status
      const mergedConfig = await configService.loadConfig(isProject ? projectPath : undefined);
      logger.info(
        `MCP enabled: ${mergedConfig.mcp.enabled ? chalk.green("yes") : chalk.red("no")}`
      );
      logger.info(`Total active servers: ${Object.keys(mergedConfig.mcp.servers).length}`);

      process.exit(0);
    } catch (error) {
      logger.error("Failed to list MCP servers:", error);
      process.exit(1);
    }
  });

function displayServer(
  name: string,
  server: MCPServerConfig,
  isOverridden = false,
  isOverriding = false
): void {
  let serverName = name;
  if (isOverridden) {
    serverName = `${name} ${chalk.gray("(overridden by project)")}`;
  } else if (isOverriding) {
    serverName = `${name} ${chalk.gray("(overrides global)")}`;
  }

  logger.info(`\n  ${chalk.bold(serverName)}`);
  logger.info(`    Command: ${chalk.cyan(`${server.command} ${server.args.join(" ")}`)}`);

  if (server.description) {
    logger.info(`    Description: ${server.description}`);
  }

  if (server.allowedPaths && server.allowedPaths.length > 0) {
    logger.info(`    Allowed paths: ${server.allowedPaths.join(", ")}`);
  }

  if (server.env && Object.keys(server.env).length > 0) {
    logger.info(`    Environment: ${Object.keys(server.env).join(", ")}`);
  }
}
</file>

<file path="src/commands/mcp/remove.ts">
import { configService } from "@/services/ConfigService";
import { handleCliError } from "@/utils/cli-error";
import { logger } from "@/utils/logger";
import { confirm } from "@inquirer/prompts";
import { Command } from "commander";

interface RemoveOptions {
  project?: boolean;
  global?: boolean;
  force?: boolean;
}

export const removeCommand = new Command("remove")
  .description("Remove an MCP server")
  .argument("<name>", "MCP server name to remove")
  .option("--project", "Remove from project configuration")
  .option("--global", "Remove from global configuration")
  .option("-f, --force", "Skip confirmation prompt")
  .action(async (name: string, options: RemoveOptions) => {
    try {
      const projectPath = process.cwd();
      const isProject = await configService.projectConfigExists(projectPath, "config.json");

      // Determine where to remove from
      let useProject = false;
      if (options.global && options.project) {
        handleCliError("Cannot use both --global and --project flags");
      } else if (options.global) {
        useProject = false;
      } else if (options.project) {
        if (!isProject) {
          handleCliError(
            "Not in a TENEX project directory. Use --global flag or run from a project."
          );
        }
        useProject = true;
      } else {
        // Default: try project first if in one, otherwise global
        useProject = isProject;
      }

      // Load existing MCP config
      const basePath = useProject
        ? configService.getProjectPath(projectPath)
        : configService.getGlobalPath();
      const existingMCP = await configService.loadTenexMCP(basePath);

      // Check if server exists
      if (!existingMCP.servers[name]) {
        const location = useProject ? "project" : "global";
        // If we defaulted to project, suggest checking global
        if (useProject && !options.project) {
          logger.info("Try using --global flag to remove from global configuration");
        }
        handleCliError(`MCP server "${name}" not found in ${location} configuration`);
      }

      // Confirm deletion unless --force is used
      if (!options.force) {
        const serverConfig = existingMCP.servers[name];
        const confirmed = await confirm({
          message: `Are you sure you want to remove MCP server "${name}" (${serverConfig.command} ${serverConfig.args.join(" ")})?`,
          default: false,
        });

        if (!confirmed) {
          logger.info("Removal cancelled");
          process.exit(0);
        }
      }

      // Remove the server
      delete existingMCP.servers[name];

      // Save updated config
      if (useProject) {
        await configService.saveProjectMCP(projectPath, existingMCP);
        logger.info(`‚úÖ MCP server "${name}" removed from project configuration`);
      } else {
        await configService.saveGlobalMCP(existingMCP);
        logger.info(`‚úÖ MCP server "${name}" removed from global configuration`);
      }

      process.exit(0);
    } catch (error) {
      handleCliError(error, "Failed to remove MCP server");
    }
  });
</file>

<file path="src/commands/project/index.ts">
import { projectInitCommand } from "@/commands/project/init";
import { projectRunCommand } from "@/commands/project/run";
import { Command } from "commander";

export const projectCommand = new Command("project")
  .description("Project management commands")
  .addCommand(projectInitCommand)
  .addCommand(projectRunCommand);
</file>

<file path="src/commands/project/init.ts">
import * as path from "node:path";
import { logger } from "@/utils/logger";
import { Command } from "commander";
import { ProjectManager } from "../../daemon/ProjectManager";
import { getNDK, initNDK, shutdownNDK } from "../../nostr/ndkClient";
import { handleCliError } from "../../utils/cli-error";

export const projectInitCommand = new Command("init")
  .description("Initialize a new TENEX project")
  .argument("<path>", "Path where the project will be created")
  .argument("<naddr>", "Project naddr from Nostr")
  .action(async (projectPath: string, naddr: string) => {
    try {
      const resolvedPath = path.resolve(projectPath);

      logger.info("Initializing project", { path: resolvedPath, naddr });

      // Initialize NDK and get singleton
      await initNDK();
      const ndk = getNDK();

      const projectManager = new ProjectManager();
      const projectData = await projectManager.initializeProject(resolvedPath, naddr, ndk);

      // Shutdown NDK
      await shutdownNDK();

      logger.success(`\nProject created successfully at ${resolvedPath}`);
      logger.info(
        JSON.stringify({
          success: true,
          projectPath: resolvedPath,
          name: projectData.identifier,
          configured: true,
        })
      );

      process.exit(0);
    } catch (err) {
      handleCliError(err, "Failed to create project");
    }
  });
</file>

<file path="src/commands/setup/index.ts">
import { llmCommand } from "@/commands/setup/llm";
import { Command } from "commander";

export const setupCommand = new Command("setup")
  .description("Setup and configuration commands")
  .addCommand(llmCommand);
</file>

<file path="src/commands/daemon.ts">
import * as path from "node:path";
import { EventMonitor } from "@/daemon/EventMonitor";
import { ProcessManager } from "@/daemon/ProcessManager";
import { ProjectManager } from "@/daemon/ProjectManager";
import { initNDK, shutdownNDK } from "@/nostr/ndkClient";
import { configService } from "@/services";
import { logger } from "@/utils/logger";
import { setupGracefulShutdown } from "@/utils/process";
import { runInteractiveSetup } from "@/utils/setup";
import { Command } from "commander";

export const daemonCommand = new Command("daemon")
  .description("Start the TENEX daemon to monitor Nostr events")
  .option("-w, --whitelist <pubkeys>", "Comma-separated list of whitelisted pubkeys")
  .option("-c, --config <path>", "Path to config file")
  .option("-p, --projects-path <path>", "Path to projects directory")
  .action(async (options) => {
    // Load configuration
    const { config: globalConfig, llms: globalLLMs } = await configService.loadConfig(
      options.config ? path.dirname(options.config) : undefined
    );

    // Get whitelisted pubkeys
    let whitelistedPubkeys = configService.getWhitelistedPubkeys(options.whitelist, globalConfig);

    // Check for required configurations
    const needsSetup =
      whitelistedPubkeys.length === 0 ||
      !globalLLMs.configurations ||
      Object.keys(globalLLMs.configurations).length === 0;

    if (needsSetup) {
      if (whitelistedPubkeys.length === 0) {
        logger.info("No whitelisted pubkeys found. Starting interactive setup...");
      }
      if (!globalLLMs.configurations || Object.keys(globalLLMs.configurations).length === 0) {
        logger.info("No LLM configurations found. Starting interactive setup...");
      }

      // Run interactive setup
      const setupConfig = await runInteractiveSetup();

      // Save the setup configuration and reload
      await configService.saveGlobalConfig(setupConfig);
      whitelistedPubkeys = setupConfig.whitelistedPubkeys || [];
    }

    // Initialize NDK and get singleton
    await initNDK();

    // Initialize core components
    const projectManager = new ProjectManager(options.projectsPath);
    const processManager = new ProcessManager();
    const eventMonitor = new EventMonitor(projectManager, processManager);

    // Set up graceful shutdown
    setupGracefulShutdown(async () => {
      // Stop monitoring new events
      await eventMonitor.stop();

      // Stop all running projects
      await processManager.stopAll();

      // Shutdown NDK singleton
      await shutdownNDK();

      logger.info("Daemon shutdown complete");
    });

    try {
      // Start monitoring without passing LLM configs - let projects load from global config with proper default detection
      await eventMonitor.start(whitelistedPubkeys);

      logger.info("TENEX daemon is running. Press Ctrl+C to stop.");

      // Keep the process alive
      await new Promise(() => {
        // This promise never resolves, keeping the daemon running
      });
    } catch (error) {
      logger.error("Failed to start daemon", { error });
      process.exit(1);
    }
  });
</file>

<file path="src/conversations/services/ConversationPersistenceService.ts">
import { logger } from "@/utils/logger";
import { FileSystemAdapter } from "../persistence";
import type {
  ConversationMetadata,
  ConversationPersistenceAdapter,
  ConversationSearchCriteria,
} from "../persistence/types";
import type { Conversation } from "../types";

/**
 * Service for persisting conversations to storage.
 * Single Responsibility: Handle all persistence operations.
 */
export interface IConversationPersistenceService {
  initialize(): Promise<void>;
  save(conversation: Conversation): Promise<void>;
  load(id: string): Promise<Conversation | null>;
  loadAll(): Promise<Conversation[]>;
  archive(id: string): Promise<void>;
  search(criteria: ConversationSearchCriteria): Promise<Conversation[]>;
}

export class ConversationPersistenceService implements IConversationPersistenceService {
  constructor(private adapter: ConversationPersistenceAdapter) {}

  async initialize(): Promise<void> {
    await this.adapter.initialize();
    logger.info("[ConversationPersistenceService] Initialized");
  }

  async save(conversation: Conversation): Promise<void> {
    await this.adapter.save(conversation);
    logger.debug(`[ConversationPersistenceService] Saved conversation ${conversation.id}`);
  }

  async load(id: string): Promise<Conversation | null> {
    const conversation = await this.adapter.load(id);
    if (conversation) {
      logger.debug(`[ConversationPersistenceService] Loaded conversation ${id}`);
    }
    return conversation;
  }

  async loadAll(): Promise<Conversation[]> {
    const metadata = await this.adapter.list();
    const conversations: Conversation[] = [];

    for (const meta of metadata) {
      if (!meta.archived) {
        const conversation = await this.adapter.load(meta.id);
        if (conversation) {
          // Debug logging for session tracking
          if (conversation.agentStates) {
            for (const [agentSlug, state] of conversation.agentStates.entries()) {
              if (state.claudeSessionsByPhase) {
                logger.debug(`[ConversationPersistenceService] Loaded conversation ${meta.id.substring(0, 8)} with sessions for agent ${agentSlug}:`, {
                  conversationId: meta.id,
                  agentSlug,
                  sessions: state.claudeSessionsByPhase,
                });
              }
            }
          }
          conversations.push(conversation);
        }
      }
    }

    logger.info(`[ConversationPersistenceService] Loaded ${conversations.length} conversations`);
    return conversations;
  }

  async archive(id: string): Promise<void> {
    await this.adapter.archive(id);
    logger.info(`[ConversationPersistenceService] Archived conversation ${id}`);
  }

  async search(criteria: ConversationSearchCriteria): Promise<Conversation[]> {
    const metadata = await this.adapter.search(criteria);
    const conversations: Conversation[] = [];

    for (const meta of metadata) {
      const conversation = await this.adapter.load(meta.id);
      if (conversation) {
        conversations.push(conversation);
      }
    }

    return conversations;
  }
}

/**
 * Factory function to create a file-based persistence service
 */
export function createFileSystemPersistenceService(
  projectPath: string
): ConversationPersistenceService {
  return new ConversationPersistenceService(new FileSystemAdapter(projectPath));
}

/**
 * In-memory persistence adapter for testing and standalone usage
 */
export class InMemoryPersistenceAdapter implements ConversationPersistenceAdapter {
  private conversations: Map<string, Conversation> = new Map();
  private metadata: Map<string, ConversationMetadata> = new Map();

  async initialize(): Promise<void> {
    // No initialization needed for in-memory storage
  }

  async save(conversation: Conversation): Promise<void> {
    this.conversations.set(conversation.id, conversation);
    this.metadata.set(conversation.id, {
      id: conversation.id,
      title: conversation.title || "",
      createdAt: conversation.history[0]?.created_at || Date.now(),
      updatedAt: Date.now(),
      phase: conversation.phase,
      eventCount: conversation.history.length,
      agentCount: conversation.agentStates.size,
      archived: false,
    });
  }

  async load(conversationId: string): Promise<Conversation | null> {
    return this.conversations.get(conversationId) || null;
  }

  async delete(conversationId: string): Promise<void> {
    this.conversations.delete(conversationId);
    this.metadata.delete(conversationId);
  }

  async list(): Promise<ConversationMetadata[]> {
    return Array.from(this.metadata.values());
  }

  async search(criteria: ConversationSearchCriteria): Promise<ConversationMetadata[]> {
    let results = Array.from(this.metadata.values());

    if (criteria.title) {
      const searchTitle = criteria.title.toLowerCase();
      results = results.filter((m) => m.title.toLowerCase().includes(searchTitle));
    }

    if (criteria.phase) {
      results = results.filter((m) => m.phase === criteria.phase);
    }

    if (criteria.archived !== undefined) {
      results = results.filter((m) => m.archived === criteria.archived);
    }

    return results;
  }

  async archive(conversationId: string): Promise<void> {
    const meta = this.metadata.get(conversationId);
    if (meta) {
      meta.archived = true;
    }
  }

  async restore(conversationId: string): Promise<void> {
    const meta = this.metadata.get(conversationId);
    if (meta) {
      meta.archived = false;
    }
  }
}
</file>

<file path="src/logging/LLMLogger.ts">
import * as fs from "node:fs/promises";
import { join } from "node:path";
import type { NDKEvent } from "@nostr-dev-kit/ndk";
import { ModelMessage } from "@ai-sdk/provider-utils";

interface LLMLogEntry {
  timestamp: string;
  agent: string;
  rootEventId?: string;
  triggeringEventId?: string;
  conversationId?: string;
  phase?: string;
  configKey: string;
  provider: string;
  model: string;
  request: {
    messages: Array<{
      role: string;
      content: string;
    }>;
    tools?: string[];
  };
  response?: {
    content?: string;
    toolCalls?: Array<{
      name: string;
      params: Record<string, unknown>;
    }>;
    usage?: {
      promptTokens: number;
      completionTokens: number;
      totalTokens: number;
    };
    model?: string;
  };
  error?: {
    message: string;
    type: string;
    stack?: string;
  };
  durationMs?: number;
}

/**
 * Specialized logger for LLM interactions
 * Creates clear, human-readable logs with exact messages and responses
 */
export class LLMLogger {
  private logDir: string | null = null;
  private agent: string | null = null;

  constructor() {
    // Public constructor for dependency injection
  }

  /**
   * Initialize the logger with a project path
   * Must be called before using the logger
   */
  initialize(projectPath: string): void {
    this.logDir = join(projectPath, ".tenex", "logs", "llms");
    console.log(`[LLMLogger] Initialized with project path: ${projectPath}, logDir: ${this.logDir}`);
  }

  /**
   * Set the agent name for this logger instance
   */
  setAgent(agent: string): void {
    this.agent = agent;
  }

  /**
   * Get the current agent name
   */
  getAgent(): string | null {
    return this.agent;
  }

  /**
   * Create a new LLMLogger instance with the agent set
   */
  withAgent(agent: string): LLMLogger {
    const logger = new LLMLogger();
    logger.logDir = this.logDir;
    logger.agent = agent;
    return logger;
  }

  /**
   * Check if the logger has been initialized
   */
  isInitialized(): boolean {
    return this.logDir !== null;
  }

  private async ensureLogDirectory(): Promise<void> {
    if (!this.logDir) {
      throw new Error("[LLMLogger] Not initialized. Call initialize() with project path first.");
    }
    try {
      await fs.mkdir(this.logDir, { recursive: true });
    } catch (error) {
      if (error instanceof Error && "code" in error && error.code !== "EEXIST") {
        throw error;
      }
    }
  }

  private getLogFileName(): string {
    const now = new Date();
    const date = now.toISOString().split("T")[0];
    const hours = now.getHours();
    const minutes = now.getMinutes();
    // Round down to nearest 5-minute increment
    const roundedMinutes = Math.floor(minutes / 5) * 5;
    const timeStr = `${hours.toString().padStart(2, '0')}:${roundedMinutes.toString().padStart(2, '0')}`;
    return `${date}_${timeStr}.jsonl`;
  }

  private getLogFilePath(filename: string): string {
    if (!this.logDir) {
      throw new Error("[LLMLogger] Not initialized. Call initialize() with project path first.");
    }
    return join(this.logDir, filename);
  }

  /**
   * Log an LLM request
   */
  async logLLMRequest(params: {
    agent?: string;
    rootEvent?: NDKEvent;
    triggeringEvent?: NDKEvent;
    conversationId?: string;
    phase?: string;
    configKey: string;
    provider: string;
    model: string;
    messages: ModelMessage[];
    tools?: Array<{ name: string; description?: string }>;
    startTime: number;
  }): Promise<void> {
    console.log(`[LLMLogger] logLLMRequest called, initialized: ${this.isInitialized()}, logDir: ${this.logDir}`);
    if (!this.isInitialized()) {
      console.warn("[LLMLogger] Not initialized. Skipping request logging. logDir:", this.logDir);
      return;
    }
    await this.ensureLogDirectory();

    const agent = params.agent || this.agent;
    if (!agent) {
      throw new Error('[LLMLogger] Agent name is required for logging');
    }
    const logEntry: LLMLogEntry = {
      timestamp: new Date().toISOString(),
      agent,
      rootEventId: params.rootEvent?.id,
      triggeringEventId: params.triggeringEvent?.id,
      conversationId: params.conversationId,
      phase: params.phase,
      configKey: params.configKey,
      provider: params.provider,
      model: params.model,
      request: {
        messages: params.messages.map(msg => ({
          role: msg.role,
          content: msg.content
        })),
        tools: params.tools?.map(t => t.name)
      }
    };

    const filename = this.getLogFileName();
    const filepath = this.getLogFilePath(filename);
    
    try {
      // Append to JSONL file (one JSON object per line)
      await fs.appendFile(filepath, JSON.stringify({ ...logEntry, type: 'request' }) + "\n", "utf-8");
      console.log(`[LLMLogger] Logged LLM request to ${filename}`);
    } catch (error) {
      console.error("[LLMLogger] Failed to write log:", error);
    }

  }

  /**
   * Log an LLM response
   */
  async logLLMResponse(params: {
    agent?: string;
    response?: CompletionResponse;
    error?: Error;
    endTime: number;
    startTime: number;
  }): Promise<void> {
    if (!this.isInitialized()) {
      console.warn("[LLMLogger] Not initialized. Skipping response logging.");
      return;
    }
    const filename = this.getLogFileName();
    const filepath = this.getLogFilePath(filename);

    const agent = params.agent || this.agent;
    if (!agent) {
      throw new Error('[LLMLogger] Agent name is required for logging');
    }
    const responseEntry: Partial<LLMLogEntry> = {
      timestamp: new Date().toISOString(),
      agent,
      durationMs: params.endTime - params.startTime
    };

    if (params.response) {
      responseEntry.response = {
        content: params.response.content,
        toolCalls: params.response.toolCalls?.map(tc => ({
          name: tc.name,
          params: tc.params
        })),
        usage: params.response.usage ? {
          promptTokens: params.response.usage.prompt_tokens || 0,
          completionTokens: params.response.usage.completion_tokens || 0,
          totalTokens: (params.response.usage.prompt_tokens || 0) + (params.response.usage.completion_tokens || 0)
        } : undefined,
        model: params.response.model
      };
    }

    if (params.error) {
      responseEntry.error = {
        message: params.error.message,
        type: params.error.constructor.name,
        stack: params.error.stack
      };
    }

    try {
      // Append response entry
      await fs.appendFile(filepath, JSON.stringify({ ...responseEntry, type: 'response' }) + "\n", "utf-8");
      console.log(`[LLMLogger] Logged LLM response to ${filename}`);
    } catch (error) {
      console.error("[LLMLogger] Failed to write response log:", error);
    }
  }

  /**
   * Log an LLM request and response (backward compatibility)
   */
  async logLLMInteraction(params: {
    agent?: string;
    rootEvent?: NDKEvent;
    triggeringEvent?: NDKEvent;
    conversationId?: string;
    phase?: string;
    configKey: string;
    provider: string;
    model: string;
    messages: Message[];
    tools?: Array<{ name: string; description?: string }>;
    response?: CompletionResponse;
    error?: Error;
    startTime: number;
    endTime: number;
  }): Promise<void> {
    // First log the request
    await this.logLLMRequest({
      agent: params.agent || this.agent,
      rootEvent: params.rootEvent,
      triggeringEvent: params.triggeringEvent,
      conversationId: params.conversationId,
      phase: params.phase,
      configKey: params.configKey,
      provider: params.provider,
      model: params.model,
      messages: params.messages,
      tools: params.tools,
      startTime: params.startTime
    });

    // Then log the response if we have one
    if (params.response || params.error) {
      await this.logLLMResponse({
        agent: params.agent || this.agent,
        response: params.response,
        error: params.error,
        endTime: params.endTime,
        startTime: params.startTime
      });
    }
  }

  /**
   * Get recent log files
   */
  async getRecentLogs(limit: number = 10): Promise<string[]> {
    if (!this.logDir) {
      console.warn("[LLMLogger] Not initialized. Cannot get recent logs.");
      return [];
    }
    try {
      await this.ensureLogDirectory();
      const files = await fs.readdir(this.logDir);
      const jsonlFiles = files
        .filter(f => f.endsWith('.jsonl'))
        .sort()
        .reverse()
        .slice(0, limit);
      return jsonlFiles.map(f => this.getLogFilePath(f));
    } catch (error) {
      console.error("[LLMLogger] Failed to list logs:", error);
      return [];
    }
  }

  /**
   * Read a specific log file (JSONL format)
   */
  async readLog(filename: string): Promise<LLMLogEntry[] | null> {
    try {
      const filepath = this.getLogFilePath(filename);
      const content = await fs.readFile(filepath, "utf-8");
      const lines = content.split('\n').filter(line => line.trim());
      return lines.map(line => JSON.parse(line));
    } catch (error) {
      console.error(`[LLMLogger] Failed to read log ${filename}:`, error);
      return null;
    }
  }
}
</file>

<file path="src/nostr/ndkClient.ts">
import { getRelayUrls } from "@/utils/relays";
/**
 * TENEX CLI: NDK Singleton
 * Manages a single NDK instance for the CLI
 */
import NDK from "@nostr-dev-kit/ndk";

let ndk: NDK | undefined;

export async function initNDK(): Promise<void> {
  if (ndk) {
    // Disconnect existing instance
    if (ndk.pool?.relays) {
      for (const relay of ndk.pool.relays.values()) {
        relay.disconnect();
      }
    }
  }

  const relays = getRelayUrls();

  ndk = new NDK({
    explicitRelayUrls: [...relays],
    enableOutboxModel: false,
    autoConnectUserRelays: true,
    autoFetchUserMutelist: true,
  });

  await ndk.connect();
}

export function getNDK(): NDK {
  if (!ndk) {
    throw new Error(
      "NDK not initialized. Please call initNDK() first or check your network configuration."
    );
  }
  return ndk;
}

export async function shutdownNDK(): Promise<void> {
  if (ndk) {
    // Disconnect all relays
    if (ndk.pool?.relays) {
      for (const relay of ndk.pool.relays.values()) {
        relay.disconnect();
      }
    }
    ndk = undefined;
  }
}
</file>

<file path="src/tools/implementations/lesson_get.ts">
import { tool } from 'ai';
import { getProjectContext } from "@/services/ProjectContext";
import { logger } from "@/utils/logger";
import { z } from "zod";
import type { ExecutionContext } from "@/agents/execution/types";

const lessonGetSchema = z.object({
  title: z.string().describe("Title of the lesson to retrieve"),
});

type LessonGetInput = z.infer<typeof lessonGetSchema>;
type LessonGetOutput = {
  title: string;
  lesson: string;
  detailed?: string;
  category?: string;
  hashtags?: string[];
  hasDetailed: boolean;
};

// Core implementation - extracted from existing execute function
async function executeLessonGet(input: LessonGetInput, context: ExecutionContext): Promise<LessonGetOutput> {
  const { title } = input;

  logger.info("üìñ Agent retrieving lesson by title", {
    agent: context.agent.name,
    agentPubkey: context.agent.pubkey,
    title,
    phase: context.phase,
    conversationId: context.conversationId,
  });

  // Get the project context to access in-memory lessons
  const projectContext = getProjectContext();
  
  // Get lessons for this agent from memory
  const agentLessons = projectContext.getLessonsForAgent(context.agent.pubkey);
  
  // Search for a lesson matching the title (case-insensitive)
  const normalizedSearchTitle = title.toLowerCase().trim();
  const matchingLesson = agentLessons.find(lesson => {
    const lessonTitle = (lesson.title || "").toLowerCase().trim();
    return lessonTitle === normalizedSearchTitle;
  });

  // Determine which lesson to use (exact match or partial)
  const lesson = matchingLesson || agentLessons.find(lesson => {
    const lessonTitle = (lesson.title || "").toLowerCase().trim();
    return lessonTitle.includes(normalizedSearchTitle) || normalizedSearchTitle.includes(lessonTitle);
  });

  if (!lesson) {
    throw new Error(`No lesson found with title: "${title}"`);
  }

  // Publish status update about reading the lesson
  try {
    const conversation = context.conversationCoordinator.getConversation(context.conversationId);
    
    if (conversation?.history?.[0]) {
      const lessonTitle = lesson.title || title;
      const lessonNaddr = lesson.encode();
      await context.agentPublisher.conversation(
        { content: `Reading [${lessonTitle}](nostr:${lessonNaddr})` },
        {
          triggeringEvent: context.triggeringEvent,
          rootEvent: conversation.history[0],
          conversationId: context.conversationId,
        }
      );
    }
  } catch (error) {
    // Don't fail the tool if we can't publish the status
    logger.warn("Failed to publish lesson_get status:", error);
  }

  logger.info("‚úÖ Successfully retrieved lesson from memory", {
    agent: context.agent.name,
    agentPubkey: context.agent.pubkey,
    title: lesson.title || title,
    hasDetailed: !!lesson.detailed,
    phase: context.phase,
    conversationId: context.conversationId,
  });

  return {
    title: lesson.title || title,
    lesson: lesson.lesson || lesson.content,
    detailed: lesson.detailed,
    category: lesson.category,
    hashtags: lesson.hashtags,
    hasDetailed: !!lesson.detailed,
  };
}

// AI SDK tool factory
export function createLessonGetTool(context: ExecutionContext): ReturnType<typeof tool> {
  return tool({
    description: "Retrieve lessons learned from previous work by title. Lessons are knowledge persisted from past agent experiences. Search is case-insensitive and supports partial matches. Returns full lesson content including detailed explanations if available. Use when you need to recall specific knowledge or patterns that have been previously documented. Lessons are agent-specific and stored in memory.",
    inputSchema: lessonGetSchema,
    execute: async (input: LessonGetInput) => {
      return await executeLessonGet(input, context);
    },
  });
}
</file>

<file path="src/tools/implementations/report_write.ts">
import { tool } from 'ai';
import { ReportManager } from "@/services/ReportManager";
import { logger } from "@/utils/logger";
import { z } from "zod";
import type { ExecutionContext } from "@/agents/execution/types";

const reportWriteSchema = z.object({
  slug: z.string().describe("The slug identifier for the article, used as the d-tag"),
  title: z.string().describe("The title of the report"),
  summary: z.string().describe("A one-line summary of the report"),
  content: z.string().describe("The full content of the report in markdown format"),
  hashtags: z
    .array(z.string())
    .nullable()
    .describe("Array of hashtags to add to the article (without the # prefix)"),
});

type ReportWriteInput = z.infer<typeof reportWriteSchema>;
type ReportWriteOutput = {
  success: boolean;
  articleId: string;
  slug: string;
  message: string;
};

// Core implementation - extracted from existing execute function
async function executeReportWrite(input: ReportWriteInput, context: ExecutionContext): Promise<ReportWriteOutput> {
  const { slug, title, summary, content, hashtags } = input;

  logger.info("üìù Writing report", {
    slug,
    title,
    agent: context.agent.name,
    phase: context.phase,
  });

  const reportManager = new ReportManager();
  
  const articleId = await reportManager.writeReport(
    {
      slug,
      title,
      summary,
      content,
      hashtags,
    },
    context.agent
  );
  
  logger.info("‚úÖ Report written successfully", {
    slug,
    articleId,
    agent: context.agent.name,
  });

  // Publish status message with the Nostr reference to the article
  try {
    // Use shared AgentPublisher instance from context (guaranteed to be present)
    const conversation = context.conversationCoordinator.getConversation(context.conversationId);
    
    if (conversation?.history?.[0]) {
      const nostrReference = `nostr:${articleId}`;
      await context.agentPublisher.conversation(
        { content: `üìÑ Writing report: ${nostrReference}` },
        {
          triggeringEvent: context.triggeringEvent,
          rootEvent: conversation.history[0],
          conversationId: context.conversationId,
        }
      );
    }
  } catch (statusError) {
    // Don't fail the tool if we can't publish the status
    console.warn("Failed to publish report_write status:", statusError);
  }

  return {
    success: true,
    articleId: `nostr:${articleId}`,
    slug,
    message: `Report "${title}" published successfully`,
  };
}

// AI SDK tool factory
export function createReportWriteTool(context: ExecutionContext): ReturnType<typeof tool> {
  return tool({
    description: "Write reports and documentation as NDKArticle events. Use for creating persistent documentation like architecture docs, implementation plans, or project summaries. Reports are stored on Nostr network and accessible via slug. Updates existing reports with same slug. Supports markdown format and hashtags for categorization. Reports can be read back with report_read or listed with reports_list.",
    inputSchema: reportWriteSchema,
    execute: async (input: ReportWriteInput) => {
      return await executeReportWrite(input, context);
    },
  });
}
</file>

<file path="src/utils/conversation-utils.ts">
import type { ExecutionContext } from "@/agents/execution/types";
import { DelegationRegistry } from "@/services/DelegationRegistry";
import { logger } from "@/utils/logger";

/**
 * Gets the root conversation ID for a given context.
 * For delegated tasks, this returns the parent conversation ID.
 * For direct conversations, this returns the current conversation ID.
 */
export function getRootConversationId(context: ExecutionContext): string {
  // Check if this is a delegated task (kind 1934)
  if (context.triggeringEvent.kind === 1934) {
    const registry = DelegationRegistry.getInstance();
    const delegationContext = registry.findDelegationByEventAndResponder(
      context.triggeringEvent.id, 
      context.agent.pubkey
    );

    if (delegationContext) {
      logger.debug("[getRootConversationId] Found delegation context, using parent conversation", {
        currentConversationId: context.conversationId.substring(0, 8),
        rootConversationId: delegationContext.delegatingAgent.rootConversationId.substring(0, 8),
        delegatingAgent: delegationContext.delegatingAgent.slug,
      });
      return delegationContext.delegatingAgent.rootConversationId;
    }
  }

  // Not a delegation or no delegation context found - use current conversation
  logger.debug("[getRootConversationId] Using current conversation as root", {
    conversationId: context.conversationId.substring(0, 8),
  });
  return context.conversationId;
}
</file>

<file path="src/utils/repomix.ts">
import { randomUUID } from "node:crypto";
import { existsSync, readFileSync, unlinkSync } from "node:fs";
import { tmpdir } from "node:os";
import { join, relative, resolve } from "node:path";
import { logger } from "@/utils/logger";
import { type CliOptions, runDefaultAction } from "repomix";

export interface RepomixResult {
  content: string;
  size: number;
  lines: number;
  cleanup: () => void;
}

/**
 * Generate repository content using repomix
 * @param projectPath - The root path of the project
 * @param targetDirectory - Optional directory to analyze relative to projectPath
 */
export async function generateRepomixOutput(
  projectPath: string,
  targetDirectory?: string
): Promise<RepomixResult> {
  const outputPath = join(tmpdir(), `repomix-${randomUUID()}.xml`);

  try {
    // Resolve the target path
    let analyzePath = projectPath;
    if (targetDirectory) {
      const resolvedTarget = resolve(projectPath, targetDirectory);

      // Validate that the target directory exists
      if (!existsSync(resolvedTarget)) {
        throw new Error(`Target directory does not exist: ${targetDirectory}`);
      }

      // Ensure the target is within the project path
      const relativePath = relative(projectPath, resolvedTarget);
      if (relativePath.startsWith("..")) {
        throw new Error(`Target directory must be within the project: ${targetDirectory}`);
      }

      analyzePath = resolvedTarget;
    }

    logger.debug("Running repomix", { outputPath, projectPath, targetDirectory, analyzePath });

    // Configure repomix options for XML output
    const cliOptions: CliOptions = {
      output: outputPath,
      style: "xml",
      copyToClipboard: false,
      verbose: true,
    };

    // Use the programmatic API to generate repomix output
    const result = await runDefaultAction([analyzePath], analyzePath, cliOptions);

    // Read the generated file
    const content = readFileSync(outputPath, "utf-8");
    const lines = content.split("\n").length;

    logger.debug("Repomix output generated", {
      size: content.length,
      lines,
      totalFiles: result.packResult.totalFiles,
      totalTokens: result.packResult.totalTokens,
    });

    return {
      content,
      size: content.length,
      lines,
      cleanup: () => {
        try {
          unlinkSync(outputPath);
        } catch (e) {
          logger.warn("Failed to clean up temporary file", { outputPath, error: e });
        }
      },
    };
  } catch (error) {
    // Clean up on error
    try {
      unlinkSync(outputPath);
    } catch {
      // Ignore cleanup errors
    }
    throw error;
  }
}
</file>

<file path="src/utils/setup.ts">
import { LLMConfigEditor } from "@/llm/LLMConfigEditor";
import { configService } from "@/services";
import type { TenexConfig } from "@/services/config/types";
import { logger } from "@/utils/logger";
import chalk from "chalk";
import inquirer from "inquirer";

export async function runInteractiveSetup(): Promise<TenexConfig> {
  logger.info(chalk.cyan("\nüöÄ Welcome to TENEX Daemon Setup\n"));
  logger.info("Let's configure your daemon to get started.\n");

  // Load current configuration to check what's missing
  const { config: currentConfig, llms: currentLLMs } = await configService.loadConfig();
  const needsPubkeys =
    !currentConfig.whitelistedPubkeys || currentConfig.whitelistedPubkeys.length === 0;
  const needsLLMs =
    !currentLLMs.configurations || Object.keys(currentLLMs.configurations).length === 0;

  let pubkeys = currentConfig.whitelistedPubkeys || [];

  // Step 1: Get whitelisted pubkeys if needed
  if (needsPubkeys) {
    pubkeys = await promptForPubkeys();
  }

  const config: TenexConfig = {
    whitelistedPubkeys: pubkeys,
  };

  // Step 2: Save basic configuration
  await configService.saveGlobalConfig(config);

  // Step 3: Set up LLM configurations if needed
  if (needsLLMs) {
    logger.info(chalk.yellow("\nStep 2: LLM Configuration"));
    logger.info("You need at least one LLM configuration to run projects.\n");

    const llmEditor = new LLMConfigEditor("", true); // Global config
    await llmEditor.runOnboardingFlow();
  }

  logger.info(chalk.green("\n‚úÖ Setup complete!"));
  logger.info(chalk.green(`Configuration saved to: ${configService.getGlobalPath()}/`));
  logger.info(
    chalk.gray("\nYou can now run 'tenex daemon' to start the daemon with your configuration.")
  );

  return config;
}

async function promptForPubkeys(): Promise<string[]> {
  logger.info(chalk.yellow("Step 1: Whitelist Configuration"));
  logger.info("Enter the Nostr pubkeys (hex format) that are allowed to control this daemon.");
  logger.info("You can add multiple pubkeys, one at a time.\n");

  const pubkeys: string[] = [];
  let addMore = true;

  while (addMore) {
    const { pubkey } = await inquirer.prompt([
      {
        type: "input",
        name: "pubkey",
        message: "Enter a pubkey (hex format):",
        validate: (input) => {
          if (!input.trim()) {
            return "Pubkey cannot be empty";
          }
          if (!/^[a-f0-9]{64}$/i.test(input.trim())) {
            return "Invalid pubkey format. Must be 64 hex characters";
          }
          return true;
        },
      },
    ]);

    pubkeys.push(pubkey.trim().toLowerCase());

    if (pubkeys.length > 0) {
      const { continueAdding } = await inquirer.prompt([
        {
          type: "confirm",
          name: "continueAdding",
          message: "Add another pubkey?",
          default: false,
        },
      ]);
      addMore = continueAdding;
    }
  }

  logger.info(chalk.green(`\n‚úì Added ${pubkeys.length} whitelisted pubkey(s)\n`));
  return pubkeys;
}
</file>

<file path="biome.json">
{
  "$schema": "https://biomejs.dev/schemas/2.2.0/schema.json",
  "files": {
    "include": ["src/**/*.ts", "src/**/*.tsx", "scripts/**/*.js"]
  },
  "formatter": {
    "enabled": true,
    "formatWithErrors": false,
    "indentStyle": "space",
    "indentWidth": 4,
    "lineWidth": 100
  },
  "linter": {
    "enabled": true,
    "rules": {
      "recommended": true
    }
  },
  "javascript": {
    "formatter": {
      "quoteStyle": "double",
      "trailingCommas": "es5",
      "semicolons": "always"
    }
  }
}
</file>

<file path="src/commands/agent/add.ts">
import { AgentRegistry } from "@/agents/AgentRegistry";
import { DEFAULT_AGENT_LLM_CONFIG } from "@/llm/constants";
import { configService } from "@/services/ConfigService";
import { formatConfigScope, resolveConfigScope } from "@/utils/cli-config-scope";
import { logger } from "@/utils/logger";
import { isValidSlug } from "@/utils/validation";
import { confirm, input } from "@inquirer/prompts";
import { Command } from "commander";

interface AddOptions {
  project?: boolean;
  global?: boolean;
}

export const agentAddCommand = new Command("add")
  .description("Add a local agent")
  .option("--project", "Add to project configuration (default if in project)")
  .option("--global", "Add to global configuration")
  .action(async (options: AddOptions) => {
    try {
      // Determine where to save
      const projectPath = process.cwd();
      const scope = await resolveConfigScope(options, projectPath);

      if (scope.error) {
        throw new Error(scope.error);
      }

      const useProject = scope.isProject;

      // Interactive wizard
      const name = await input({
        message: "Agent name:",
        validate: (value) => {
          if (!value.trim()) return "Name is required";
          if (!isValidSlug(value)) {
            return "Name must contain only alphanumeric characters, hyphens, and underscores";
          }
          return true;
        },
      });

      const role = await input({
        message: "Agent role:",
        validate: (value) => (value.trim() ? true : "Role is required"),
      });

      const prompt = await input({
        message: "Agent prompt/instructions:",
        validate: (value) => (value.trim() ? true : "Prompt is required"),
      });

      const description = await input({
        message: "Agent description (optional):",
        default: "",
      });

      // Determine the base path for the registry
      const basePath = useProject
        ? configService.getProjectPath(projectPath)
        : configService.getGlobalPath();

      // Load existing registry
      const registryPath = useProject
        ? projectPath
        : configService.getGlobalPath().replace("/.tenex", "");
      const registry = new AgentRegistry(registryPath, !useProject);
      await registry.loadFromProject();

      // Check if agent already exists
      const existingAgent = registry.getAgentByName(name);
      if (existingAgent) {
        throw new Error(`Agent with name "${name}" already exists`);
      }

      // If creating a project agent, check if it would shadow a global one
      if (useProject) {
        try {
          const globalPath = configService.getGlobalPath().replace("/.tenex", "");
          const globalRegistry = new AgentRegistry(globalPath, true);
          await globalRegistry.loadFromProject();
          const globalAgent = globalRegistry.getAgent(name) || globalRegistry.getAgentByName(name);

          if (globalAgent) {
            const confirmed = await confirm({
              message: `A global agent named "${name}" already exists. Do you want to create a project-specific version that will override it?`,
              default: false,
            });

            if (!confirmed) {
              logger.info("Agent creation cancelled");
              process.exit(0);
            }
          }
        } catch (error) {
          // If we can't load global agents, continue anyway
          logger.debug("Could not check for global agents", { error });
        }
      }

      // Create agent config
      const agentConfig = {
        name,
        role,
        instructions: prompt,
        llmConfig: DEFAULT_AGENT_LLM_CONFIG,
        ...(description && { description }),
      };

      // Use AgentRegistry to ensure agent (this handles all file operations and Nostr publishing)
      const agent = await registry.ensureAgent(name, agentConfig);

      const location = formatConfigScope(scope);
      logger.info(`‚úÖ Local agent "${name}" created successfully in ${location}`);
      logger.info(`   Name: ${name}`);
      logger.info(`   Pubkey: ${agent.pubkey}`);
      logger.info(`   Stored in: ${basePath}/agents/`);
    } catch (error) {
      if (error instanceof Error) {
        logger.error("Failed to create agent:", error.message);
      } else {
        logger.error("Failed to create agent:", error);
      }
      process.exit(1);
    }
  });
</file>

<file path="src/commands/agent/list.ts">
import { AgentRegistry } from "@/agents/AgentRegistry";
import type { AgentInstance } from "@/agents/types";
import { configService } from "@/services/ConfigService";
import { logger } from "@/utils/logger";
import { Command } from "commander";

interface ListOptions {
  project?: boolean;
  global?: boolean;
  all?: boolean;
}

export const agentListCommand = new Command("list")
  .description("List available agents")
  .option("--project", "Show only project agents")
  .option("--global", "Show only global agents")
  .option("--all", "Show all agents (default)")
  .action(async (options: ListOptions) => {
    try {
      const projectPath = process.cwd();
      const isProject = await configService.projectConfigExists(projectPath, "config.json");

      // Default to showing all agents
      const showAll = options.all || (!options.project && !options.global);
      const showProject = options.project || showAll;
      const showGlobal = options.global || showAll;

      // Validate options
      if (options.project && !isProject) {
        logger.error(
          "Not in a TENEX project directory. Remove --project flag or run from a project."
        );
        process.exit(1);
      }

      logger.info("Available agents:");
      logger.info("");

      // Load and display global agents
      if (showGlobal) {
        try {
          const globalPath = configService.getGlobalPath().replace("/.tenex", "");
          const globalRegistry = new AgentRegistry(globalPath, true);
          await globalRegistry.loadFromProject();

          const globalAgents = globalRegistry.getAllAgents();
          if (globalAgents.length > 0) {
            logger.info("Global agents:");
            for (const agent of globalAgents) {
              logger.info(`  - ${agent.slug}: ${agent.name}`);
              logger.info(`    Role: ${agent.role}`);
              if (agent.description) {
                logger.info(`    Description: ${agent.description}`);
              }
              if (agent.eventId) {
                logger.info(`    Event ID: ${agent.eventId}`);
              }
            }
            logger.info("");
          } else {
            logger.info("No global agents found.");
            logger.info("");
          }
        } catch (error) {
          logger.error("Failed to load global agents", { error });
          if (showGlobal && !showProject) {
            process.exit(1);
          }
        }
      }

      // Load and display project agents
      if (showProject && isProject) {
        try {
          // Load global agents to check for overrides
          const globalPath = configService.getGlobalPath().replace("/.tenex", "");
          const globalRegistry = new AgentRegistry(globalPath, true);
          await globalRegistry.loadFromProject();
          const globalAgentSlugs = new Set(globalRegistry.getAllAgents().map((a) => a.slug));

          // Load project registry
          const projectRegistry = new AgentRegistry(projectPath, false);
          await projectRegistry.loadFromProject();

          const projectAgents = projectRegistry.getAllAgents();
          const projectOnlyAgents: AgentInstance[] = [];
          const overriddenAgents: AgentInstance[] = [];

          // Categorize agents
          for (const agent of projectAgents) {
            if (globalAgentSlugs.has(agent.slug)) {
              overriddenAgents.push(agent);
            } else {
              projectOnlyAgents.push(agent);
            }
          }

          if (projectOnlyAgents.length > 0 || overriddenAgents.length > 0) {
            logger.info("Project agents:");

            // Show project-specific agents first
            for (const agent of projectOnlyAgents) {
              logger.info(`  - ${agent.slug}: ${agent.name}`);
              logger.info(`    Role: ${agent.role}`);
              if (agent.description) {
                logger.info(`    Description: ${agent.description}`);
              }
              if (agent.eventId) {
                logger.info(`    Event ID: ${agent.eventId}`);
              }
            }

            // Show overridden agents
            if (overriddenAgents.length > 0) {
              logger.info("");
              logger.info("  Overriding global agents:");
              for (const agent of overriddenAgents) {
                logger.info(`  - ${agent.slug}: ${agent.name} (overrides global)`);
                logger.info(`    Role: ${agent.role}`);
                if (agent.description) {
                  logger.info(`    Description: ${agent.description}`);
                }
                if (agent.eventId) {
                  logger.info(`    Event ID: ${agent.eventId}`);
                }
              }
            }
          } else {
            logger.info("No project-specific agents found.");
          }
        } catch (error) {
          logger.error("Failed to load project agents", { error });
          if (showProject && !showGlobal) {
            process.exit(1);
          }
        }
      }

      process.exit(0);
    } catch (error) {
      logger.error("Failed to list agents:", error);
      process.exit(1);
    }
  });
</file>

<file path="src/commands/agent/remove.ts">
import { AgentRegistry } from "@/agents/AgentRegistry";
import { configService } from "@/services/ConfigService";
import { logger } from "@/utils/logger";
import { confirm } from "@inquirer/prompts";
import { Command } from "commander";

interface RemoveOptions {
  project?: boolean;
  global?: boolean;
  force?: boolean;
}

export const agentRemoveCommand = new Command("remove")
  .description("Remove an agent")
  .argument("<name>", "Agent name or slug to remove")
  .option("--project", "Remove from project configuration")
  .option("--global", "Remove from global configuration")
  .option("-f, --force", "Skip confirmation prompt")
  .action(async (name: string, options: RemoveOptions) => {
    try {
      const projectPath = process.cwd();
      const isProject = await configService.projectConfigExists(projectPath, "config.json");

      // Determine where to remove from
      let useProject = false;
      if (options.global && options.project) {
        logger.error("Cannot use both --global and --project flags");
        process.exit(1);
      } else if (options.global) {
        useProject = false;
      } else if (options.project) {
        if (!isProject) {
          logger.error(
            "Not in a TENEX project directory. Use --global flag or run from a project."
          );
          process.exit(1);
        }
        useProject = true;
      } else {
        // Default: try project first if in one, otherwise global
        useProject = isProject;
      }

      // Load the appropriate registry
      const registryPath = useProject
        ? projectPath
        : configService.getGlobalPath().replace("/.tenex", "");
      const registry = new AgentRegistry(registryPath, !useProject);
      await registry.loadFromProject();

      // Find the agent
      const agent = registry.getAgent(name) || registry.getAgentByName(name);
      if (!agent) {
        const location = useProject ? "project" : "global";
        logger.error(`Agent "${name}" not found in ${location} configuration`);

        // If we defaulted to project, suggest checking global
        if (useProject && !options.project) {
          logger.info("Try using --global flag to remove from global configuration");
        }
        process.exit(1);
      }


      // Confirm deletion unless --force is used
      if (!options.force) {
        const confirmed = await confirm({
          message: `Are you sure you want to remove agent "${agent.name}" (${agent.slug})?`,
          default: false,
        });

        if (!confirmed) {
          logger.info("Removal cancelled");
          process.exit(0);
        }
      }

      // Remove the agent
      const removed = agent.eventId
        ? await registry.removeAgentByEventId(agent.eventId)
        : await registry.removeAgentBySlug(agent.slug);

      if (removed) {
        const location = useProject ? "project" : "global";
        logger.info(`‚úÖ Agent "${agent.name}" removed from ${location} configuration`);
      } else {
        logger.error("Failed to remove agent");
        process.exit(1);
      }

      process.exit(0);
    } catch (error) {
      logger.error("Failed to remove agent:", error);
      process.exit(1);
    }
  });
</file>

<file path="src/commands/mcp/add.ts">
import { which } from "@/lib/shell";
import { configService } from "@/services/ConfigService";
import type { MCPServerConfig } from "@/services/config/types";
import { resolveConfigScope } from "@/utils/cli-config-scope";
import { handleCliError } from "@/utils/cli-error";
import { logger } from "@/utils/logger";
import { isValidSlug } from "@/utils/validation";
import { Command } from "commander";

interface AddOptions {
  project?: boolean;
  global?: boolean;
}

interface AddOptionsWithPaths extends AddOptions {
  paths?: string;
  env?: string[];
}

export const addCommand = new Command("add")
  .description("Add a new MCP server")
  .argument("<name>", "Name for the MCP server")
  .argument("<command...>", "Command and arguments to run the MCP server")
  .option("--project", "Add to project configuration (default if in project)")
  .option("--global", "Add to global configuration")
  .option("-p, --paths <paths>", "Allowed paths (comma-separated)")
  .option("-e, --env <vars...>", "Environment variables (KEY=VALUE format)")
  .allowUnknownOption()
  .action(async (name: string, commandArgs: string[], options: AddOptionsWithPaths) => {
    try {
      // Parse command and args from the array
      if (commandArgs.length === 0) {
        logger.info("Usage: tenex mcp add <name> <command> [args...]");
        logger.info("Example: tenex mcp add nostrbook npx -y xjsr @nostrbook/mcp");
        handleCliError("No command provided");
      }

      const command = commandArgs[0] as string; // Safe because we checked length above
      const args = commandArgs.slice(1);

      // Validate name
      if (!isValidSlug(name)) {
        handleCliError("Name can only contain letters, numbers, hyphens, and underscores");
      }

      // Validate command exists (skip for npx, npm, etc.)
      const skipValidation = ["npx", "npm", "node", "python", "python3", "ruby", "sh", "bash"];
      if (!skipValidation.includes(command)) {
        try {
          const commandPath = await which(command);
          if (!commandPath) {
            logger.info("Make sure the command is installed and in your PATH");
            handleCliError(`Command not found: ${command}`);
          }
        } catch {
          logger.info("Make sure the command is installed and in your PATH");
          handleCliError(`Command not found: ${command}`);
        }
      }

      // Parse allowed paths if provided
      const allowedPaths = options.paths
        ? options.paths
            .split(",")
            .map((p) => p.trim())
            .filter((p) => p.length > 0)
        : [];

      // Parse environment variables if provided
      const envVars: Record<string, string> = {};
      if (options.env && options.env.length > 0) {
        for (const envVar of options.env) {
          const [key, ...valueParts] = envVar.split("=");
          if (!key || valueParts.length === 0) {
            logger.info("Environment variables must be in KEY=VALUE format");
            handleCliError(`Invalid environment variable format: ${envVar}`);
          }
          envVars[key] = valueParts.join("=");
        }
      }

      // Create server config
      const serverConfig: MCPServerConfig = {
        command,
        args,
        ...(allowedPaths.length > 0 && { allowedPaths }),
        ...(Object.keys(envVars).length > 0 && { env: envVars }),
      };

      // Determine where to save
      const projectPath = process.cwd();
      const scopeInfo = await resolveConfigScope(options, projectPath);

      if (scopeInfo.error) {
        handleCliError(scopeInfo.error);
      }

      const useProject = scopeInfo.isProject;
      const basePath = scopeInfo.basePath;

      // Load existing MCP config
      const existingMCP = await configService.loadTenexMCP(basePath);

      // Check if server name already exists
      if (existingMCP.servers[name]) {
        handleCliError(`MCP server '${name}' already exists`);
      }

      // Add new server
      existingMCP.servers[name] = serverConfig;

      // Save config
      if (useProject) {
        await configService.saveProjectMCP(projectPath, existingMCP);
        logger.info(`Added MCP server '${name}' to project configuration`);
      } else {
        await configService.saveGlobalMCP(existingMCP);
        logger.info(`Added MCP server '${name}' to global configuration`);
      }

      logger.info(`Command: ${command} ${args.join(" ")}`);
      if (allowedPaths.length > 0) {
        logger.info(`Allowed paths: ${allowedPaths.join(", ")}`);
      }
      if (Object.keys(envVars).length > 0) {
        logger.info(`Environment variables: ${Object.keys(envVars).join(", ")}`);
      }

      // Exit successfully
      process.exit(0);
    } catch (error) {
      handleCliError(error, "Failed to add MCP server");
    }
  });
</file>

<file path="src/daemon/EventMonitor.ts">
import { getNDK } from "@/nostr/ndkClient";
import { logger } from "@/utils/logger";
import type { NDKEvent, NDKFilter, NDKSubscription } from "@nostr-dev-kit/ndk";
import { nip19 } from "nostr-tools";
import type { IProcessManager } from "./ProcessManager";
import type { IProjectManager } from "./ProjectManager";

export interface IEventMonitor {
  start(whitelistedPubkeys: string[]): Promise<void>;
  stop(): Promise<void>;
}

export class EventMonitor implements IEventMonitor {
  private subscription: NDKSubscription | null = null;

  constructor(
    private projectManager: IProjectManager,
    private processManager: IProcessManager
  ) {}

  async start(whitelistedPubkeys: string[]): Promise<void> {
    const filter: NDKFilter = {
      authors: whitelistedPubkeys,
      limit: 0,
    };

    this.subscription = getNDK().subscribe(filter, {
      closeOnEose: false,
      groupable: false,
    });

    this.subscription.on("event", (event: NDKEvent) => {
      this.handleEvent(event).catch((error) => {
        logger.error("Error handling event", { error, event: event.id });
      });
    });
  }

  async stop(): Promise<void> {
    if (this.subscription) {
      this.subscription.stop();
      this.subscription = null;
    }
  }

  private async handleEvent(event: NDKEvent): Promise<void> {
    // Check if event has project "a" tag
    const projectTag = this.getProjectTag(event);
    if (!projectTag) {
      return;
    }

    const projectIdentifier = this.extractProjectIdentifier(projectTag);
    if (!projectIdentifier) {
      return;
    }

    logger.info(`Received event kind ${event.kind}`);

    // Check if project is already running
    if (await this.processManager.isProjectRunning(projectIdentifier)) {
      return;
    }

    // Ensure project exists and get path
    try {
      const naddr = this.reconstructNaddr(projectTag, event.pubkey);
      const projectPath = await this.projectManager.ensureProjectExists(
        projectIdentifier,
        naddr,
        getNDK()
      );

      // Spawn project run process
      await this.processManager.spawnProjectRun(projectPath, projectIdentifier);

      logger.info("Started project process", {
        projectIdentifier,
        projectPath,
      });
    } catch (error) {
      logger.error("Failed to start project", {
        error,
        projectIdentifier,
      });
    }
  }

  private getProjectTag(event: NDKEvent): string | undefined {
    const aTag = event.tags.find((tag) => tag[0] === "a");
    return aTag ? aTag[1] : undefined;
  }

  private extractProjectIdentifier(aTag: string): string | undefined {
    // Format: kind:pubkey:identifier
    const parts = aTag.split(":");
    if (parts.length >= 3) {
      return parts[2];
    }
    return undefined;
  }

  private reconstructNaddr(aTag: string, eventPubkey: string): string {
    // Parse the a tag to get project details
    const parts = aTag.split(":");
    if (parts.length < 3) {
      throw new Error("Invalid project a tag format");
    }

    const [kind, pubkey, identifier] = parts;

    // Validate that kind is present
    if (!kind) {
      throw new Error("Missing kind in project a tag");
    }

    // Use the pubkey from the a tag if available, otherwise use event pubkey
    const projectPubkey = pubkey || eventPubkey;

    // Encode as naddr
    // Note: identifier can be empty for parameterized replaceable events without a d tag
    return nip19.naddrEncode({
      identifier: identifier || "",
      pubkey: projectPubkey,
      kind: Number.parseInt(kind, 10),
    });
  }
}
</file>

<file path="src/event-handler/newConversation.ts">
import type { NDKEvent } from "@nostr-dev-kit/ndk";
import chalk from "chalk";
import type { AgentExecutor } from "../agents/execution/AgentExecutor";
import type { ConversationCoordinator } from "../conversations";
import { getProjectContext } from "../services";
import { formatAnyError } from "../utils/error-formatter";
import { logger } from "../utils/logger";


interface EventHandlerContext {
  conversationCoordinator: ConversationCoordinator;
  agentExecutor: AgentExecutor;
}

export const handleNewConversation = async (
  event: NDKEvent,
  context: EventHandlerContext
): Promise<void> => {
  try {
    // Create conversation
    const conversation = await context.conversationCoordinator.createConversation(event);

    // Get project context
    const projectCtx = getProjectContext();

    // Check for p-tags to determine if user @mentioned a specific agent
    const pTags = event.tags.filter((tag) => tag[0] === "p");
    const mentionedPubkeys = pTags
      .map((tag) => tag[1])
      .filter((pubkey): pubkey is string => !!pubkey);

    let targetAgent = null;

    // If there are p-tags, check if any match system agents
    if (mentionedPubkeys.length > 0) {
      for (const pubkey of mentionedPubkeys) {
        const agent = Array.from(projectCtx.agents.values()).find((a) => a.pubkey === pubkey);
        if (agent) {
          targetAgent = agent;
          break;
        }
      }
    }

    // If no p-tags or no matching agent, just log and return
    if (!targetAgent) {
      logger.info(chalk.gray(`New conversation without p-tags or matching agents - not routing to any agent`));
      return;
    }

    // Execute with the appropriate agent
    await context.agentExecutor.execute({
      agent: targetAgent,
      conversationId: conversation.id,
      phase: conversation.phase,
      projectPath: process.cwd(),
      triggeringEvent: event,
      conversationCoordinator: context.conversationCoordinator,
    });

    logger.info(chalk.green("‚úÖ Conversation routed successfully"));
  } catch (error) {
    logger.info(chalk.red(`‚ùå Failed to route conversation: ${formatAnyError(error)}`));
  }
};
</file>

<file path="src/prompts/fragments/20-phase-context.ts">
import type { Phase, Conversation } from "@/conversations/types";
import { fragmentRegistry } from "../core/FragmentRegistry";
import type { PromptFragment } from "../core/types";

/**
 * Phase context fragment.
 * Provides context about the current phase and any transition information.  
 */
interface PhaseContextArgs {
  phase: Phase;
  phaseMetadata?: Record<string, unknown>;
  conversation?: Conversation;
}

export const phaseContextFragment: PromptFragment<PhaseContextArgs> = {
  id: "phase-context",
  priority: 10,
  template: ({ phase, phaseMetadata, conversation }) => {
    const parts: string[] = [];

    parts.push(`## Current Phase: ${phase.toUpperCase()}`);

    // Add custom phase instructions if available
    if (conversation?.phaseInstructions) {
      parts.push(`### Phase Instructions\n${conversation.phaseInstructions}`);
    }


    // Add any phase metadata
    if (phaseMetadata?.goal) {
      parts.push(`### Phase Goal\n${phaseMetadata.goal}`);
    }

    return parts.join("\n\n");
  },
};

// Register the fragment
fragmentRegistry.register(phaseContextFragment);
</file>

<file path="src/services/config/types.ts">
import { z } from "zod";

/**
 * Unified configuration types for TENEX
 * All configuration files use the same schemas for both global and project contexts
 */

// =====================================================================================
// MAIN CONFIG SCHEMA (config.json)
// =====================================================================================

export interface TenexConfig {
  // Global fields
  whitelistedPubkeys?: string[];

  // Project fields (optional for global config)
  description?: string;
  repoUrl?: string;
  projectNaddr?: string;
  paths?: {
    inventory?: string;
  };
}

export const TenexConfigSchema = z.object({
  whitelistedPubkeys: z.array(z.string()).optional(),
  description: z.string().optional(),
  repoUrl: z.string().optional(),
  projectNaddr: z.string().optional(),
  paths: z
    .object({
      inventory: z.string().optional(),
    })
    .optional(),
});

// =====================================================================================
// AGENTS SCHEMA (agents.json)
// =====================================================================================

export interface TenexAgents {
  [agentSlug: string]: {
    nsec: string;
    file: string;
    eventId?: string;
    isPM?: boolean;  // True if this agent is the project manager
  };
}

export const TenexAgentsSchema = z.record(
  z.object({
    nsec: z.string(),
    file: z.string(),
    eventId: z.string().optional(),
    isPM: z.boolean().optional(),
  })
);

// =====================================================================================
// LLM SCHEMA (llms.json)
// =====================================================================================

/**
 * Individual LLM configuration
 */
export interface LLMConfiguration {
  provider: string;
  model: string;
  temperature?: number;
  maxTokens?: number;
  topP?: number;
  [key: string]: any; // Allow additional provider-specific settings
}

/**
 * Main LLM configuration structure
 */
export interface TenexLLMs {
  providers: {
    openrouter?: {
      apiKey: string;
    };
    anthropic?: {
      apiKey: string;
    };
    openai?: {
      apiKey: string;
    };
    claudeCode?: {
      apiKey: string;
    };
  };
  configurations: {
    [name: string]: LLMConfiguration;
  };
  default?: string;
}

export const LLMConfigurationSchema = z.object({
  provider: z.string(),
  model: z.string(),
  temperature: z.number().optional(),
  maxTokens: z.number().optional(),
  topP: z.number().optional(),
}).passthrough(); // Allow additional properties

export const TenexLLMsSchema = z.object({
  providers: z.record(z.object({
    apiKey: z.string(),
  })).default({}),
  configurations: z.record(LLMConfigurationSchema).default({}),
  default: z.string().optional(),
});

// =====================================================================================
// MCP SCHEMA (mcp.json)
// =====================================================================================

export interface MCPServerConfig {
  command: string;
  args: string[];
  env?: Record<string, string>;
  description?: string;
  allowedPaths?: string[];
  eventId?: string; // Nostr event ID this server was installed from
}

export interface TenexMCP {
  servers: Record<string, MCPServerConfig>;
  enabled: boolean;
}

export const MCPServerConfigSchema = z.object({
  command: z.string(),
  args: z.array(z.string()),
  env: z.record(z.string()).optional(),
  description: z.string().optional(),
  allowedPaths: z.array(z.string()).optional(),
  eventId: z.string().optional(),
});

export const TenexMCPSchema = z.object({
  servers: z.record(MCPServerConfigSchema).default({}),
  enabled: z.boolean().default(true),
});

// =====================================================================================
// LOADED CONFIGURATION STATE
// =====================================================================================

export interface LoadedConfig {
  config: TenexConfig;
  agents: TenexAgents;
  llms: TenexLLMs;
  mcp: TenexMCP;
}

// =====================================================================================
// HELPER TYPES
// =====================================================================================

export type ConfigFile = "config.json" | "agents.json" | "llms.json" | "mcp.json";

export interface ConfigPaths {
  global: string;
  project?: string;
}
</file>

<file path="src/services/index.ts">
/**
 * Centralized services for TENEX
 */

export { ConfigService, configService } from "./ConfigService";
export { DelegationRegistry } from "./DelegationRegistry";
export {
  getProjectContext,
  isProjectContextInitialized,
  ProjectContext,
  setProjectContext,
} from "./ProjectContext";
export { PubkeyNameRepository, getPubkeyNameRepository } from "./PubkeyNameRepository";
export { StatusPublisher } from "./status";
export { OperationsStatusPublisher } from "./OperationsStatusPublisher";
</file>

<file path="src/tools/implementations/agents_write.ts">
import { tool } from 'ai';
import { ensureDirectory, fileExists, readFile, writeJsonFile } from "@/lib/fs";
import { getProjectContext } from "@/services/ProjectContext";
import { logger } from "@/utils/logger";
import { NDKPrivateKeySigner } from "@nostr-dev-kit/ndk";
import * as path from "node:path";
import { z } from "zod";
// Define the input schema
const agentsWriteSchema = z.object({
  slug: z.string().describe("The slug identifier for the agent"),
  name: z.string().describe("Display name of the agent"),
  role: z.string().describe("Primary role/function of the agent"),
  description: z.string().nullable().describe("Agent description"),
  instructions: z.string().nullable().describe("System instructions that guide agent behavior"),
  useCriteria: z.string().nullable().describe("Criteria for when this agent should be selected"),
  llmConfig: z.string().nullable().describe("LLM configuration identifier"),
  tools: z.array(z.string()).nullable().describe("List of tool names available to this agent. All agents automatically get core tools: lesson_get, lesson_learn, read_path, reports_list, report_read. Delegation tools (delegate, delegate_phase, delegate_external, delegate_followup) are automatically assigned based on PM status - do not include them. Additional tools can include: agents_write, agents_read, agents_list, agents_discover, agents_hire, analyze, generate_inventory, shell, claude_code, nostr_projects, discover_capabilities, write_context_file, report_write, report_delete. MCP tools use format: mcp__servername__toolname"),
  mcp: z.boolean().nullable().describe("Whether this agent has access to MCP tools (defaults to true)"),
});

type AgentsWriteInput = z.infer<typeof agentsWriteSchema>;

// Define the output type
interface AgentsWriteOutput {
  success: boolean;
  message?: string;
  error?: string;
  filePath?: string;
  agent?: {
    slug: string;
    name: string;
    pubkey: string;
  };
}

/**
 * Core implementation of the agents_write functionality
 * Shared between AI SDK and legacy Tool interfaces
 */
async function executeAgentsWrite(
  input: AgentsWriteInput
): Promise<AgentsWriteOutput> {
  const { slug, name, role, description, instructions, useCriteria, llmConfig, tools, mcp } = input;

  if (!slug) {
    return {
      success: false,
      error: "Agent slug is required",
    };
  }

  if (!name || !role) {
    return {
      success: false,
      error: `Agent ${name ? "role" : "name"} is required`,
    };
  }

  // Get project path
  const projectPath = process.cwd();
  
  // Determine agents directory
  const agentsDir = path.join(projectPath, ".tenex", "agents");
  await ensureDirectory(agentsDir);

  // Create the agent definition file path
  const fileName = `${slug}.json`;
  const filePath = path.join(agentsDir, fileName);

  // Check if file exists and load existing data if updating
  let existingData = {};
  if (await fileExists(filePath)) {
    try {
      const content = await readFile(filePath);
      existingData = JSON.parse(content);
      logger.info(`Updating existing agent definition: ${slug}`);
    } catch (error) {
      logger.warn(`Failed to read existing agent file, will create new`, { error });
    }
  } else {
    logger.info(`Creating new agent definition: ${slug}`);
  }

  // Create agent definition object
  const agentDefinition = {
    ...existingData,
    name,
    role,
    ...(description !== undefined && { description }),
    ...(instructions !== undefined && { instructions }),
    ...(useCriteria !== undefined && { useCriteria }),
    ...(llmConfig !== undefined && { llmConfig }),
    ...(tools !== undefined && { tools }),
    ...(mcp !== undefined && { mcp }),
  };

  // Write the agent definition to file
  await writeJsonFile(filePath, agentDefinition);

  // Update the agents registry
  const registryPath = path.join(projectPath, ".tenex", "agents.json");
  let registry: Record<string, { file: string; nsec?: string; eventId?: string }> = {};
  
  if (await fileExists(registryPath)) {
    try {
      const content = await readFile(registryPath);
      registry = JSON.parse(content);
    } catch (error) {
      logger.warn("Failed to read agents registry, will create new", { error });
    }
  }

  // Generate nsec if needed (check for both missing and empty string)
  let nsec = registry[slug]?.nsec;
  if (!nsec || nsec === "") {
    const signer = NDKPrivateKeySigner.generate();
    nsec = signer.privateKey;
    logger.info(`Generated new nsec for agent "${slug}"`);
  }

  // Add or update the agent in the registry
  registry[slug] = {
    file: fileName,
    nsec: nsec,
  };

  await writeJsonFile(registryPath, registry);

  // Use the existing agent registry from project context
  const projectContext = getProjectContext();
  
  // Ensure the agent is registered with all proper initialization
  const agentConfig = {
    name,
    role,
    description,
    instructions,
    useCriteria,
    llmConfig,
    tools,
    mcp,
  };
  
  // Use the existing agent registry to ensure the agent
  const agent = await projectContext.agentRegistry.ensureAgent(slug, agentConfig, projectContext.project);
  
  // The agentRegistry.ensureAgent already updates the registry internally,
  // but we need to update the ProjectContext's agents map as well
  const updatedAgents = new Map(projectContext.agents);
  updatedAgents.set(slug, agent);
  await projectContext.updateProjectData(projectContext.project, updatedAgents);

  logger.info(`Successfully wrote and activated agent "${name}" (${slug})`);
  logger.info(`  File: ${filePath}`);
  logger.info(`  Pubkey: ${agent.pubkey}`);

  return {
    success: true,
    message: `Successfully wrote and activated agent "${name}"`,
    filePath,
    agent: {
      slug,
      name,
      pubkey: agent.pubkey,
    },
  };
}

/**
 * Create an AI SDK tool for writing agents
 * This is the primary implementation
 */
export function createAgentsWriteTool(): ReturnType<typeof tool> {
  return tool({
    description: "Write or update agent configuration and tools. Creates/updates agent definition files in .tenex/agents/. All agents automatically get core tools: lesson_get, lesson_learn, read_path, reports_list, report_read. Delegation tools (delegate, delegate_phase, delegate_external, delegate_followup) are automatically assigned based on PM status - do not include them. Assign additional tools based on responsibilities. Agent activates immediately and becomes available for delegation. Use to create specialized agents for specific tasks or update existing agent configurations. Changes persist across sessions.",
    inputSchema: agentsWriteSchema,
    execute: async (input: AgentsWriteInput) => {
      try {
        return await executeAgentsWrite(input);
      } catch (error) {
        logger.error("Failed to write agent definition", { error });
        throw new Error(`Failed to write agent definition: ${error instanceof Error ? error.message : String(error)}`);
      }
    },
  });
}
</file>

<file path="src/tools/implementations/read_path.ts">
import { tool } from 'ai';
import { readFile, readdir, stat } from "node:fs/promises";
import { formatAnyError } from "@/utils/error-formatter";
import { z } from "zod";
import { resolveAndValidatePath } from "../utils";
import type { ExecutionContext } from "@/agents/execution/types";
import type { TenexTool } from "@/tools/registry";

const readPathSchema = z.object({
  path: z
    .string()
    .describe("The file or directory path to read (absolute or relative to project root)"),
});


/**
 * Core implementation of the read_path functionality
 * Shared between AI SDK and legacy Tool interfaces
 */
async function executeReadPath(
  path: string,
  context: ExecutionContext
): Promise<string> {
  // Resolve path and ensure it's within project
  const fullPath = resolveAndValidatePath(path, context.projectPath);

  // Check if path is a directory first
  const stats = await stat(fullPath);
  let content: string;
  
  if (stats.isDirectory()) {
    // Get directory contents
    const files = await readdir(fullPath);
    const fileList = files.map((file) => `  - ${file}`).join("\n");

    content = `Directory listing for ${path}:\n${fileList}\n\nTo read a specific file, please specify the full path to the file.`;
  } else {
    content = await readFile(fullPath, "utf-8");

    // Track file read in conversation metadata if path starts with context/
    if (path.startsWith("context/") && context.conversationCoordinator) {
      const conversation = context.conversationCoordinator.getConversation(context.conversationId);
      const currentMetadata = conversation?.metadata || {};
      const readFiles = currentMetadata.readFiles || [];

      // Only add if not already tracked
      if (!readFiles.includes(path)) {
        await context.conversationCoordinator.updateMetadata(context.conversationId, {
          readFiles: [...readFiles, path],
        });
      }
    }
  }

  return content;
}

/**
 * Create an AI SDK tool for reading paths
 * This is the primary implementation
 */
export function createReadPathTool(context: ExecutionContext): TenexTool {
  const toolInstance = tool({
    description:
      "Read a file or directory from the filesystem. Returns file contents for files, or directory listing for directories. Paths are relative to project root unless absolute. Use this instead of shell commands like cat, ls, find. Automatically tracks context file reads for conversation metadata. Safe and sandboxed to project directory.",
    
    inputSchema: readPathSchema,
    
    execute: async ({ path }: z.infer<typeof readPathSchema>) => {
      try {
        return await executeReadPath(path, context);
      } catch (error: unknown) {
        // If it's an EISDIR error that we somehow missed, provide helpful guidance
        if (error instanceof Error && "code" in error && error.code === "EISDIR") {
          try {
            const fullPath = resolveAndValidatePath(path, context.projectPath);
            const files = await readdir(fullPath);
            const fileList = files.map((file) => `  - ${file}`).join("\n");

            return `Directory listing for ${path}:\n${fileList}\n\nTo read a specific file, please specify the full path to the file.`;
          } catch {
            // If we can't read the directory, throw the original error
            throw new Error(`Failed to read ${path}: ${error.message}`);
          }
        }

        throw new Error(`Failed to read ${path}: ${formatAnyError(error)}`);
      }
    },
  });

  // Add human-readable content generation
  return Object.assign(toolInstance, {
    getHumanReadableContent: ({ path }: z.infer<typeof readPathSchema>) => {
      return `üìñ Reading ${path}`;
    }
  }) as TenexTool;
}
</file>

<file path="package.json">
{
    "name": "tenex-tools",
    "version": "0.4.4",
    "description": "TENEX Command Line Interface",
    "main": "./dist/index.js",
    "types": "./dist/index.d.ts",
    "exports": {
        ".": {
            "import": "./dist/index.js",
            "types": "./dist/index.d.ts"
        }
    },
    "bin": {
        "tenex": "./dist/tenex-wrapper.cjs"
    },
    "files": [
        "dist/**/*.js",
        "dist/**/*.cjs",
        "!dist/**/*.map",
        "!dist/**/__tests__",
        "!dist/**/*.test.js",
        "!dist/**/*.spec.js",
        "!dist/test-utils",
        "src/**/*.ts",
        "!src/**/__tests__",
        "!src/**/*.test.ts",
        "!src/**/*.spec.ts",
        "!src/test-utils",
        "tsconfig.json"
    ],
    "scripts": {
        "start": "bun run ./src/tenex.ts",
        "build": "bun scripts/build-bundled.js",
        "prepublishOnly": "bun run build",
        "test": "bun test",
        "test:watch": "bun test --watch",
        "test:coverage": "bun test --coverage",
        "test:unit": "bun test src/**/__tests__/*.test.ts",
        "test:integration": "bun test src/**/__tests__/*.integration.test.ts",
        "test:e2e": "bun test tests/e2e/*.test.ts",
        "test:ios-compat": "./scripts/test-ios-compat.sh",
        "test:mock": "MOCK_MODE=true bun test tests/e2e/ios-compatibility.test.ts",
        "validate:events": "bun run src/scripts/validate-events.ts",
        "report:compatibility": "bun run scripts/test-ios-compat.sh && cat ios-compat-report.md",
        "typecheck": "./scripts/typecheck.sh",
        "typecheck:verbose": "tsc --noEmit",
        "lint": "eslint src --ext .ts,.tsx",
        "lint:fix": "eslint src --ext .ts,.tsx --fix",
        "clean": "rm -rf dist node_modules bun.lockb coverage"
    },
    "engines": {
        "node": ">=18.0.0"
    },
    "publishConfig": {
        "access": "public",
        "registry": "https://registry.npmjs.org/"
    },
    "dependencies": {
        "@ai-sdk/anthropic": "^2.0.9",
        "@ai-sdk/openai": "^2.0.23",
        "@inquirer/search": "^3.0.15",
        "@modelcontextprotocol/sdk": "^1.13.2",
        "@nostr-dev-kit/ndk": "^2.14.33",
        "@openrouter/ai-sdk-provider": "^1.1.2",
        "ai": "^5.0.28",
        "ai-sdk-provider-claude-code": "^1.1.3",
        "chalk": "^5.4.1",
        "cli-table3": "^0.6.5",
        "commander": "^13.1.0",
        "date-fns": "^4.1.0",
        "inquirer": "^12.9.1",
        "nostr-tools": "^2.15.0",
        "ollama-ai-provider-v2": "^1.2.2",
        "repomix": "^1.1.0",
        "tseep": "^1.3.1",
        "uuid": "^11.1.0",
        "zod": "^3.25.67",
        "zod-to-json-schema": "^3.24.6"
    },
    "devDependencies": {
        "@eslint/js": "^9.30.1",
        "@types/inquirer": "^9.0.9",
        "esbuild": "^0.25.5",
        "esbuild-plugin-alias": "^0.2.1",
        "eslint": "^9.30.1",
        "jest-mock-extended": "^4.0.0",
        "typescript": "^5.8.3",
        "typescript-eslint": "^8.35.1"
    },
    "type": "module",
    "keywords": [],
    "author": "",
    "license": "ISC"
}
</file>

<file path="src/commands/mcp/server.ts">
import { ProjectManager } from "@/daemon/ProjectManager";
import { NDKAgentLesson } from "@/events/NDKAgentLesson";
import { NDKMCPTool } from "@/events/NDKMCPTool";
import { getNDK, initNDK } from "@/nostr/ndkClient";
import { getProjectContext } from "@/services/ProjectContext";
import { logger } from "@/utils/logger";
import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { type NDKKind, NDKPrivateKeySigner } from "@nostr-dev-kit/ndk";
import { Command } from "commander";
import { z } from "zod";

// Type definitions
interface MCPToolInfo {
  id: string;
  name: string;
  description?: string;
  command?: string;
  image?: string;
  slug: string;
  authorPubkey: string;
  createdAt?: number;
}

interface LessonData {
  title: string;
  lesson: string;
  detailed?: string;
  category?: string;
  hashtags?: string[];
}

interface LessonResult {
  title: string;
  lesson: string;
  eventId: string | undefined;
  hasDetailed: boolean;
}

interface LessonSummary {
  title: string;
  lesson: string;
  detailed?: string;
  category?: string;
  hashtags: string[];
  createdAt?: number;
  eventId: string;
}

/**
 * Format discovered MCP tools as markdown
 */
function formatMCPToolsAsMarkdown(tools: MCPToolInfo[]): string {
  if (tools.length === 0) {
    return "## No MCP tools found\n\nNo tools match your search criteria. Try broadening your search or check back later.";
  }

  const lines: string[] = [];
  lines.push("# MCP Tool Discovery Results");
  lines.push(`\nFound **${tools.length}** available tool${tools.length === 1 ? "" : "s"}:\n`);

  tools.forEach((tool, index) => {
    lines.push(`## ${index + 1}. ${tool.name}`);
    lines.push("");

    if (tool.description) {
      lines.push(`**Description:** ${tool.description}`);
      lines.push("");
    }

    if (tool.command) {
      lines.push(`**Command:** \`${tool.command}\``);
      lines.push("");
    }

    if (tool.image) {
      lines.push(`**Image:** \`${tool.image}\``);
      lines.push("");
    }

    lines.push(`**Nostr ID:** \`${tool.id}\``);
    lines.push("");

    if (tool.createdAt) {
      const date = new Date(tool.createdAt * 1000).toLocaleString();
      lines.push(`**Created:** ${date}`);
      lines.push("");
    }

    lines.push("---");
    lines.push("");
  });

  // Add installation instructions at the end
  lines.push("## Installation Instructions");
  lines.push("");
  lines.push("To request installation of any of these tools:");
  lines.push("1. Note the **Nostr ID** of the tool you want to install");
  lines.push("2. Send a message tagging the human user");
  lines.push("3. Include the tool reference using `nostr:<id>` format");
  lines.push("");
  lines.push(`Example: "I'd like to install the Git Helper tool: nostr:note1xyz..."`);

  return lines.join("\n");
}

import type { AgentInstance } from "@/agents/types";
import type NDK from "@nostr-dev-kit/ndk";
import type { NDKEvent, NDKSigner } from "@nostr-dev-kit/ndk";

// Schema definitions for MCP handlers
const ToolsListRequestSchema = z.object({
  method: z.literal("tools/list"),
});

const ToolsCallRequestSchema = z.object({
  method: z.literal("tools/call"),
  params: z.object({
    name: z.string(),
    arguments: z.any(),
  }),
});

/**
 * Service for managing lessons
 */
class LessonService {
  constructor(
    private ndk: NDK,
    private project: NDKEvent | null
  ) {}

  async createLesson(
    data: LessonData,
    agentEventId: string,
    signer: NDKSigner
  ): Promise<LessonResult> {
    const lessonEvent = new NDKAgentLesson(this.ndk);
    lessonEvent.title = data.title;
    lessonEvent.lesson = data.lesson;

    // Add optional fields if provided
    if (data.detailed) {
      lessonEvent.detailed = data.detailed;
    }
    if (data.category) {
      lessonEvent.category = data.category;
    }
    if (data.hashtags && data.hashtags.length > 0) {
      lessonEvent.hashtags = data.hashtags;
    }

    // Add reference to the agent event if available
    if (agentEventId) {
      const agentEvent = await this.ndk.fetchEvent(agentEventId);
      if (agentEvent) {
        // Agent reference would go here but NDKAgentLesson doesn't have agent property
        lessonEvent.tag(["e", agentEventId, "", "agent"]);
      } else {
        logger.warn("Could not fetch agent event for lesson", { agentEventId });
      }
    }

    // Add project tag for scoping if available
    if (this.project) {
      lessonEvent.tag(this.project);
    }

    await lessonEvent.sign(signer);
    await lessonEvent.publish();

    logger.info("‚úÖ Lesson published to Nostr", {
      title: data.title,
      eventId: lessonEvent.id,
      agentEventId,
      hasDetailed: !!data.detailed,
      category: data.category,
      hashtagCount: data.hashtags?.length || 0,
    });

    return {
      title: data.title,
      lesson: data.lesson,
      eventId: lessonEvent.id,
      hasDetailed: !!data.detailed,
    };
  }

  async getLessons(filter: { agentPubkey: string }): Promise<LessonSummary[]> {
    const lessons = await this.ndk.fetchEvents({
      kinds: [NDKAgentLesson.kind as NDKKind],
      authors: [filter.agentPubkey],
    });

    const lessonList = Array.from(lessons).map((event) => {
      const lesson = NDKAgentLesson.from(event);
      return {
        title: lesson.title || "",
        lesson: lesson.lesson,
        detailed: lesson.detailed,
        category: lesson.category,
        hashtags: lesson.hashtags || [],
        createdAt: lesson.created_at,
        eventId: lesson.id || "",
      };
    });

    return lessonList.sort((a, b) => (b.createdAt || 0) - (a.createdAt || 0));
  }
}

export const serverCommand = new Command("server")
  .description("Run MCP server for agent tools")
  .action(async () => {
    try {
      const projectPath = process.cwd();

      // Initialize NDK
      logger.info("Initializing NDK for MCP server...");
      await initNDK();
      const ndk = getNDK();

      if (!ndk) {
        throw new Error("NDK is undefined after initialization");
      }

      logger.debug("NDK initialized successfully", {
        hasNdk: !!ndk,
        hasFetchEvent: !!ndk?.fetchEvent,
      });

      // Try to load project context if available, but don't fail if not
      let projectContext: Awaited<ReturnType<typeof getProjectContext>> | null = null;
      let agents: Map<string, AgentInstance> = new Map();
      let project: NDKEvent | null = null;

      try {
        const projectManager = new ProjectManager();
        await projectManager.loadAndInitializeProjectContext(projectPath, ndk);
        projectContext = getProjectContext();
        agents = projectContext.agents;
        project = projectContext.project;
        logger.info("Running MCP server with project context");
      } catch (error) {
        const errorMessage = error instanceof Error ? error.message : String(error);
        if (errorMessage.includes("Project configuration missing projectNaddr")) {
          logger.info("Running MCP server without project context (standalone mode)");
        } else {
          // Re-throw if it's a different error
          throw error;
        }
      }

      // NDK is already available from above, no need to redeclare

      // Wait a moment for relays to connect
      logger.info("Waiting for relay connections...");
      await new Promise((resolve) => setTimeout(resolve, 2000));

      // Log relay status
      const connectedRelays = Array.from(ndk.pool?.relays?.values() || [])
        .filter((relay) => relay.status === 1)
        .map((relay) => relay.url);

      logger.info(`Connected to ${connectedRelays.length} relays:`, connectedRelays);

      // Create MCP server
      const server = new Server(
        {
          name: "tenex-mcp",
          version: "1.0.0",
        },
        {
          capabilities: {
            tools: {},
          },
        }
      );

      // Add tools handler
      server.setRequestHandler(ToolsListRequestSchema, async () => {
        return {
          tools: [
            {
              name: "lesson_learn",
              description:
                "Record an important lesson learned during execution that should be carried forward, with optional detailed version",
              inputSchema: {
                type: "object",
                properties: {
                  title: {
                    type: "string",
                    description: "Brief title/description of what this lesson is about",
                  },
                  lesson: {
                    type: "string",
                    description: "The key insight or lesson learned - be concise and actionable",
                  },
                  agentSlug: {
                    type: "string",
                    description:
                      "The slug identifier of the agent recording this lesson (required when in project context, mutually exclusive with nsec)",
                  },
                  nsec: {
                    type: "string",
                    description:
                      "The Nostr private key (nsec format) for signing the lesson (required when NOT in project context, mutually exclusive with agentSlug)",
                  },
                  detailed: {
                    type: "string",
                    description:
                      "Detailed version with richer explanation when deeper context is needed",
                  },
                  category: {
                    type: "string",
                    description:
                      "Single category for filing this lesson (e.g., 'architecture', 'debugging', 'user-preferences')",
                  },
                  hashtags: {
                    type: "array",
                    items: {
                      type: "string",
                    },
                    description:
                      "Hashtags for easier sorting and discovery (e.g., ['async', 'error-handling'])",
                  },
                },
                required: ["title", "lesson"],
              },
            },
            {
              name: "get_lessons",
              description: "Retrieve all lessons learned by this agent",
              inputSchema: {
                type: "object",
                properties: {
                  agentSlug: {
                    type: "string",
                    description:
                      "The slug identifier of the agent whose lessons to retrieve (required when in project context, mutually exclusive with pubkey)",
                  },
                  pubkey: {
                    type: "string",
                    description:
                      "The public key (hex format) to retrieve lessons for (required when NOT in project context, mutually exclusive with agentSlug)",
                  },
                },
                required: [],
              },
            },
            {
              name: "mcp_discover",
              description:
                "Discover MCP tool definitions from the Nostr network that can be installed and used",
              inputSchema: {
                type: "object",
                properties: {
                  searchText: {
                    type: "string",
                    description: "Text to search for in tool name/description",
                  },
                  limit: {
                    type: "number",
                    description: "Maximum number of tools to return (default: 50)",
                  },
                },
              },
            },
            {
              name: "nostr_projects",
              description:
                "Retrieve NDKProject (31933) events, online project status (24010) events, and spec documents (30023 NDKArticles) that tag the projects for a given pubkey",
              inputSchema: {
                type: "object",
                properties: {
                  pubkey: {
                    type: "string",
                    description: "The public key (hex format) to retrieve projects for",
                  },
                },
                required: ["pubkey"],
              },
            },
          ],
        };
      });

      // Handle tool calls
      server.setRequestHandler(ToolsCallRequestSchema, async (request) => {
        const toolName = request.params.name;

        if (toolName === "lesson_learn") {
          const { title, lesson, detailed, category, hashtags, agentSlug, nsec } =
            request.params.arguments;

          let agent: AgentInstance | null = null;
          let signer: NDKSigner;
          let agentEventId = "";

          // Ensure XOR logic - either agentSlug OR nsec, not both
          if (agentSlug && nsec) {
            throw new Error(
              "Cannot provide both agentSlug and nsec - use agentSlug when in project context, nsec when standalone"
            );
          }

          // Determine how to get the signer based on what's provided
          if (agentSlug) {
            // Project context mode - use agent slug
            if (agents.size === 0) {
              throw new Error(
                "agentSlug provided but no project context available - use nsec instead"
              );
            }
            agent = agents.get(agentSlug) || null;
            if (!agent) {
              throw new Error(`Agent '${agentSlug}' not found in project`);
            }
            if (!agent.signer) {
              throw new Error(`Agent '${agentSlug}' does not have a signer`);
            }
            signer = agent.signer;
            agentEventId = agent.eventId || "";
          } else if (nsec) {
            // Standalone mode - use nsec
            if (agents.size > 0) {
              throw new Error(
                "nsec provided but project context is available - use agentSlug instead"
              );
            }
            signer = new NDKPrivateKeySigner(nsec);
          } else {
            // Provide context-aware error message
            if (agents.size > 0) {
              throw new Error("agentSlug is required when running with project context");
            }
            throw new Error("nsec is required when running without project context");
          }

          logger.info("üéì MCP Server: Recording new lesson", {
            agent: agent?.name || "standalone",
            agentPubkey: agent?.pubkey || signer.pubkey,
            title,
            lessonLength: lesson.length,
            hasDetailed: !!detailed,
            category,
            hashtagCount: hashtags?.length || 0,
          });

          try {
            // Create LessonService instance
            const lessonService = new LessonService(ndk, project);

            // Use LessonService to create the lesson
            const result = await lessonService.createLesson(
              { title, lesson, detailed, category, hashtags },
              agentEventId,
              signer
            );

            const message = `‚úÖ Lesson recorded: "${result.title}"${result.hasDetailed ? " (with detailed version)" : ""}\n\nThis lesson will be available in future conversations to help avoid similar issues.`;

            return {
              content: [
                {
                  type: "text",
                  text: message,
                },
              ],
            };
          } catch (error) {
            logger.error("‚ùå MCP Server: Learn tool failed", {
              error,
              agent: agent?.name || "standalone",
              agentPubkey: agent?.pubkey || signer.pubkey,
              title,
            });
            throw error;
          }
        } else if (toolName === "get_lessons") {
          const { agentSlug, pubkey } = request.params.arguments;

          let agentPubkey: string;
          let agent: AgentInstance | null = null;

          // Ensure XOR logic - either agentSlug OR pubkey, not both
          if (agentSlug && pubkey) {
            throw new Error(
              "Cannot provide both agentSlug and pubkey - use agentSlug when in project context, pubkey when standalone"
            );
          }

          // Determine how to get the pubkey
          if (agentSlug) {
            // Project context mode - use agent slug
            if (agents.size === 0) {
              throw new Error(
                "agentSlug provided but no project context available - use pubkey instead"
              );
            }
            agent = agents.get(agentSlug) || null;
            if (!agent) {
              throw new Error(`Agent '${agentSlug}' not found in project`);
            }
            agentPubkey = agent.pubkey;
          } else if (pubkey) {
            // Standalone mode - use provided pubkey
            if (agents.size > 0) {
              throw new Error(
                "pubkey provided but project context is available - use agentSlug instead"
              );
            }
            agentPubkey = pubkey;
          } else {
            // Provide context-aware error message
            if (agents.size > 0) {
              throw new Error("agentSlug is required when running with project context");
            }
            throw new Error("pubkey is required when running without project context");
          }

          try {
            logger.info("üìö MCP Server: Fetching lessons", {
              agent: agent?.name || "standalone",
              agentPubkey,
            });

            // Create LessonService instance
            const lessonService = new LessonService(ndk, project);

            // Use LessonService to fetch lessons
            const lessons = await lessonService.getLessons({
              agentPubkey,
            });

            return {
              content: [
                {
                  type: "text",
                  text: JSON.stringify(lessons, null, 2),
                },
              ],
            };
          } catch (error) {
            logger.error("‚ùå MCP Server: Get lessons failed", {
              error,
              agent: agent?.name || "standalone",
              agentPubkey,
            });
            throw error;
          }
        } else if (toolName === "mcp_discover") {
          const { searchText, limit = 50 } = request.params.arguments;

          logger.info("üîç MCP Server: Discovering MCP tools", {
            searchText,
            limit,
          });

          try {
            // Fetch MCP tool events (kind 4200)
            const mcpToolEvents = await ndk.fetchEvents({
              kinds: [NDKMCPTool.kinds[0]],
              limit,
            });

            // Convert to NDKMCPTool instances and extract metadata
            let tools = Array.from(mcpToolEvents).map((event) => {
              const mcpTool = NDKMCPTool.from(event);

              return {
                id: mcpTool.encode(),
                name: mcpTool.name || "Unnamed Tool",
                description: mcpTool.description,
                command: mcpTool.command,
                image: mcpTool.image,
                slug: mcpTool.slug,
                authorPubkey: mcpTool.pubkey,
                createdAt: mcpTool.created_at,
              };
            });

            // Apply local filtering if specified
            if (searchText) {
              const searchLower = searchText.toLowerCase();
              tools = tools.filter((tool) => {
                const searchableText = [tool.name, tool.description || "", tool.command || ""]
                  .join(" ")
                  .toLowerCase();

                return searchableText.includes(searchLower);
              });
            }

            // Sort by creation time (newest first)
            tools.sort((a, b) => (b.createdAt || 0) - (a.createdAt || 0));

            // Format as markdown
            const markdown = formatMCPToolsAsMarkdown(tools);

            logger.info("‚úÖ MCP Server: MCP tools discovered successfully", {
              toolsFound: tools.length,
            });

            return {
              content: [
                {
                  type: "text",
                  text: markdown,
                },
              ],
            };
          } catch (error) {
            logger.error("‚ùå MCP Server: MCP discover failed", {
              error,
              searchText,
              limit,
            });
            throw error;
          }
        } else if (toolName === "nostr_projects") {
          const { pubkey } = request.params.arguments;

          logger.info("üîç MCP Server: Fetching projects for pubkey", {
            pubkey,
          });

          try {
            // Import NDK types needed for this handler
            const { NDKArticle, NDKUser } = await import("@nostr-dev-kit/ndk");

            // Calculate 1 minute ago timestamp for online status check
            const oneMinuteAgo = Math.floor(Date.now() / 1000) - 60;

            // Fetch both kinds of events in parallel
            const [projectEvents, statusEvents] = await Promise.all([
              // Fetch 31933 events (NDKProject)
              ndk.fetchEvents({
                kinds: [31933],
                authors: [pubkey],
              }),
              // Fetch 24010 events (project status - online agents)
              // Only get status events from the last minute to determine if online
              ndk.fetchEvents({
                kinds: [24010 as NDKKind],
                "#p": [pubkey],
                since: oneMinuteAgo,
              }),
            ]);

            // Build a map of online agents by project (keyed by project tagId)
            const onlineAgentsByProject = new Map<string, Record<string, string>>();

            // Process status events to find online agents
            Array.from(statusEvents).forEach((event) => {
              // Get the project reference from the "a" tag (this identifies which project the status is for)
              const projectTagId = event.tagValue("a");
              if (projectTagId) {
                // Get agent tags from the 24010 event
                const agentTags = event.tags.filter((tag) => tag[0] === "agent");
                const agents: Record<string, string> = {};

                agentTags.forEach((tag) => {
                  // agent tag format: ["agent", "<pubkey>", "<slug>"]
                  if (tag.length >= 3) {
                    const [, agentPubkey, agentSlug] = tag;
                    // Convert pubkey to npub format
                    const agentUser = new NDKUser({ pubkey: agentPubkey });
                    agents[agentSlug] = agentUser.npub;
                  }
                });

                // Store agents for this specific project using its tagId as the key
                if (Object.keys(agents).length > 0) {
                  onlineAgentsByProject.set(projectTagId, agents);
                }
              }
            });

            // Once we have the list of projects, fetch spec documents that tag them
            interface SpecArticle {
              title: string | undefined;
              summary: string | undefined;
              id: string;
              date: number | undefined;
              _projectRefs: string[];
            }
            let specArticles: SpecArticle[] = [];
            if (projectEvents.size > 0) {
              // Create array of project tag IDs for fetching articles
              const projectTagIds = Array.from(projectEvents).map((projectEvent) => {
                return projectEvent.tagId();
              });

              logger.info("üìÑ MCP Server: Fetching spec documents for projects", {
                projectCount: projectTagIds.length,
              });

              // Fetch NDKArticles (kind 30023) that tag these projects
              const articleEvents = await ndk.fetchEvents(
                {
                  kinds: [30023],
                  "#a": projectTagIds,
                },
                { subId: "spec-articles" }
              );

              // Process articles
              specArticles = Array.from(articleEvents).map((event) => {
                const article = NDKArticle.from(event);

                // Get project references from the article's tags (for internal filtering only)
                const projectRefs = event.tags
                  .filter((tag) => tag[0] === "a" && projectTagIds.includes(tag[1]))
                  .map((tag) => tag[1]);

                // Get summary or first 300 bytes of content
                let summary = article.summary;
                if (!summary && article.content) {
                  summary = article.content.substring(0, 300);
                  if (article.content.length > 300) {
                    summary += "...";
                  }
                }

                return {
                  title: article.title,
                  summary: summary,
                  id: `nostr:${article.encode()}`,
                  date: article.created_at,
                  _projectRefs: projectRefs, // Keep for internal filtering but prefix with underscore
                };
              });

              logger.info("‚úÖ MCP Server: Spec documents fetched", {
                articleCount: specArticles.length,
              });
            }

            // Process project events (31933)
            const projects = Array.from(projectEvents).map((projectEvent) => {
              const title = projectEvent.tagValue("title") || projectEvent.tagValue("name");
              const description = projectEvent.tagValue("description");
              const website = projectEvent.tagValue("website");
              const repository = projectEvent.tagValue("repository");
              const image = projectEvent.tagValue("image");

              // Get the project's tagId for matching with status events and articles
              const projectTagId = projectEvent.tagId();

              // Check if this project has online agents using its tagId
              const isOnline = onlineAgentsByProject.has(projectTagId);
              const onlineAgents = isOnline ? onlineAgentsByProject.get(projectTagId) : undefined;

              // Get the encoded project ID with nostr: prefix
              const projectId = `nostr:${projectEvent.encode()}`;

              // Find spec articles for this project
              const projectSpecs = specArticles
                .filter((article) => article._projectRefs.includes(projectTagId))
                .map(({ _projectRefs, ...article }) => article); // Remove internal _projectRefs field

              return {
                id: projectId,
                title,
                description,
                website,
                repository,
                image,
                online: isOnline,
                agents: onlineAgents,
                pubkey: projectEvent.pubkey,
                date: projectEvent.created_at,
                specs: projectSpecs,
              };
            });

            // Sort projects by creation time (newest first)
            projects.sort((a, b) => (b.date || 0) - (a.date || 0));

            const result = {
              projects,
              summary: {
                totalProjects: projects.length,
                onlineProjects: projects.filter((p) => p.online).length,
                offlineProjects: projects.filter((p) => !p.online).length,
                totalSpecDocuments: specArticles.length,
              },
            };

            logger.info("‚úÖ MCP Server: Projects fetched successfully", {
              pubkey,
              projectCount: projects.length,
              onlineCount: result.summary.onlineProjects,
              specDocumentCount: specArticles.length,
            });

            return {
              content: [
                {
                  type: "text",
                  text: JSON.stringify(result, null, 2),
                },
              ],
            };
          } catch (error) {
            logger.error("‚ùå MCP Server: Fetch projects failed", {
              error,
              pubkey,
            });
            throw error;
          }
        } else {
          throw new Error(`Unknown tool: ${toolName}`);
        }
      });

      // Start the server
      const transport = new StdioServerTransport();
      await server.connect(transport);

      logger.info("MCP server started");

      // Keep the process alive
      process.on("SIGINT", async () => {
        await server.close();
        process.exit(0);
      });
    } catch (error) {
      logger.error("Failed to start MCP server:", error);
      process.exit(1);
    }
  });
</file>

<file path="src/commands/setup/llm.ts">
import * as os from "node:os";
import * as path from "node:path";
import * as fileSystem from "@/lib/fs";
import { LLMConfigEditor } from "@/llm/LLMConfigEditor";
import { logger } from "@/utils/logger";
import { Command } from "commander";

export const llmCommand = new Command("llm")
  .description("Manage LLM configurations (global by default, --project for current project)")
  .option("--project", "Use project-specific configuration instead of global")
  .action(async (options) => {
    try {
      let configPath: string;
      let isGlobal: boolean;

      if (options.project) {
        // Project-specific configuration
        const projectPath = process.cwd();

        // Check if we're in a TENEX project
        if (!(await fileSystem.directoryExists(path.join(projectPath, ".tenex")))) {
          logger.error("No .tenex directory found. Make sure you're in a TENEX project directory.");
          process.exit(1);
        }

        configPath = projectPath;
        isGlobal = false;
      } else {
        // Global configuration
        const globalConfigDir = path.join(os.homedir(), ".tenex");

        // Ensure global config directory exists
        try {
          await fileSystem.ensureDirectory(globalConfigDir);
        } catch (error) {
          logger.error(`Failed to create global config directory: ${error}`);
          process.exit(1);
        }

        configPath = "";
        isGlobal = true;
      }

      const llmManager = new LLMConfigEditor(configPath, isGlobal);
      await llmManager.showMainMenu();
    } catch (error: unknown) {
      // Handle SIGINT (Ctrl+C) gracefully - just exit without error
      const errorMessage = error instanceof Error ? error.message : String(error);
      if (errorMessage?.includes('SIGINT') || errorMessage?.includes('force closed')) {
        process.exit(0);
      }
      // Only show error for actual problems
      logger.error(`Failed to start LLM configuration: ${error}`);
      process.exit(1);
    }
  });
</file>

<file path="src/llm/selection/ModelSelector.ts">
import type { LLMProvider } from "@/llm/types";
import search from "@inquirer/search";
// Removed ModelsList import - using simple string arrays now
import { getModelsForProvider } from "../models";

export interface ModelSelectionResult {
  model: string;
  supportsCaching: boolean;
}

/**
 * Model selection utilities for different LLM providers
 */
export class ModelSelector {
  async selectModelWithSearch(provider: string, models: string[]): Promise<string> {
    const formattedModels = models.map((model) => ({
      name: model,
      value: model,
    }));

    return search({
      message: `Select ${provider} model:`,
      source: async (input) => {
        if (!input) {
          return formattedModels;
        }
        const filtered = formattedModels.filter((model) =>
          model.name.toLowerCase().includes(input.toLowerCase())
        );
        return filtered.length > 0 ? filtered : formattedModels;
      },
    });
  }

  async selectOpenRouterModelWithPricing(models: string[]): Promise<ModelSelectionResult> {
    const formattedModels = models.map((model) => ({
      name: model,
      value: model,
      short: model,
    }));

    const model = await search({
      message: "Select OpenRouter model (üì¶ = supports caching):",
      source: async (input) => {
        if (!input) {
          return formattedModels;
        }
        const filtered = formattedModels.filter((model) =>
          model.value.toLowerCase().includes(input.toLowerCase())
        );
        return filtered.length > 0 ? filtered : formattedModels;
      },
    });

    return {
      model,
      supportsCaching: false, // We don't have this info available
    };
  }

  async fetchAndSelectModel(
    provider: LLMProvider,
    existingApiKey?: string,
    ollamaUrl?: string
  ): Promise<ModelSelectionResult | null> {
    try {
      const models = await getModelsForProvider(provider, existingApiKey, ollamaUrl);
      if (!models || models.length === 0) {
        return null;
      }

      const availableModels = models;

      if (provider === "openrouter") {
        return await this.selectOpenRouterModelWithPricing(availableModels);
      }
      const model = await this.selectModelWithSearch(provider, availableModels);
      return { model, supportsCaching: false };
    } catch (error) {
      throw new Error(`Failed to fetch ${provider} models: ${error}`);
    }
  }

  getAvailableModelCount(models: string[] | null): number {
    if (!models) return 0;
    return models.length;
  }

  shouldSupportCaching(provider: LLMProvider, model: string, supportsCaching: boolean): boolean {
    return (
      (provider === "anthropic" && model.includes("claude")) ||
      (provider === "openrouter" && supportsCaching)
    );
  }

  generateDefaultConfigName(provider: string, model: string): string {
    return `${provider}-${model}`.toLowerCase().replace(/[^a-z0-9-]/g, "-");
  }
}
</file>

<file path="src/llm/LLMConfigEditor.ts">
import type { TenexLLMs } from "@/services/config/types";
import { configService } from "@/services";
import { llmServiceFactory } from "./LLMServiceFactory";
import inquirer from "inquirer";
import chalk from "chalk";
import { AI_SDK_PROVIDERS } from "./types";
import { ProviderConfigUI } from "./utils/ProviderConfigUI";
import { ConfigurationManager } from "./utils/ConfigurationManager";
import { ConfigurationTester } from "./utils/ConfigurationTester";

/**
 * LLM Configuration Editor - Simple menu orchestrator
 */
export class LLMConfigEditor {
  constructor(
    private configPath: string,
    private isGlobal = true
  ) {}

  async showMainMenu(): Promise<void> {
    const llmsConfig = await this.loadConfig();
    
    console.log(chalk.cyan("\n=== LLM Configuration ===\n"));
    ProviderConfigUI.displayCurrentConfig(llmsConfig);
    
    const { action } = await inquirer.prompt([{
      type: "list",
      name: "action",
      message: "What would you like to do?",
      choices: [
        { name: "Configure provider API keys", value: "providers" },
        { name: "Add new configuration", value: "add" },
        { name: "Delete configuration", value: "delete" },
        { name: `Set default (current: ${llmsConfig.default || 'none'})`, value: "default" },
        { name: "Test configuration", value: "test" },
        { name: "Exit", value: "exit" }
      ]
    }]);
    
    if (action === "exit") process.exit(0);
    
    if (action === "providers") {
      await this.configureProviders(llmsConfig);
      await this.saveConfig(llmsConfig);
    } else if (action === "test") {
      await ConfigurationTester.test(llmsConfig);
    } else {
      // All other actions use ConfigurationManager
      if (action === "add") await ConfigurationManager.add(llmsConfig);
      if (action === "delete") await ConfigurationManager.delete(llmsConfig);
      if (action === "default") await ConfigurationManager.setDefault(llmsConfig);
      await this.saveConfig(llmsConfig);
    }
    
    await this.showMainMenu();
  }

  async runOnboardingFlow(): Promise<void> {
    console.log(chalk.green("\nüöÄ Welcome to TENEX LLM Setup!\n"));
    
    const llmsConfig = await this.loadConfig();
    
    // Step 1: Configure providers
    console.log(chalk.cyan("Step 1: Configure Provider API Keys"));
    await this.configureProviders(llmsConfig);
    await this.saveConfig(llmsConfig);
    
    // Step 2: Create first configuration
    console.log(chalk.cyan("\nStep 2: Create Your First Configuration"));
    await ConfigurationManager.add(llmsConfig, true);
    await this.saveConfig(llmsConfig);
    
    // Step 3: Offer to test
    const { shouldTest } = await inquirer.prompt([{
      type: "confirm",
      name: "shouldTest",
      message: "Would you like to test your configuration?",
      default: true
    }]);
    
    if (shouldTest) {
      await ConfigurationTester.test(llmsConfig);
    }
    
    console.log(chalk.green("\n‚úÖ LLM configuration complete!"));
  }

  private async configureProviders(llmsConfig: TenexLLMs): Promise<void> {
    const configured = AI_SDK_PROVIDERS.filter(p => !!llmsConfig.providers[p]?.apiKey);
    const unconfigured = AI_SDK_PROVIDERS.filter(p => !llmsConfig.providers[p]?.apiKey);
    
    let providers: string[];
    
    if (unconfigured.length === 0) {
      // All configured, ask if they want to reconfigure
      const { reconfigure } = await inquirer.prompt([{
        type: "confirm",
        name: "reconfigure",
        message: "All providers configured. Reconfigure existing?",
        default: false
      }]);
      
      if (!reconfigure) return;
      
      const { selected } = await inquirer.prompt([{
        type: "checkbox",
        name: "selected",
        message: "Select providers to reconfigure:",
        choices: configured.map(p => ({
          name: ProviderConfigUI.getProviderDisplayName(p),
          value: p
        }))
      }]);
      providers = selected;
    } else {
      // Select unconfigured providers
      const { selected } = await inquirer.prompt([{
        type: "checkbox",
        name: "selected",
        message: "Select providers to configure:",
        choices: unconfigured.map(p => ({
          name: ProviderConfigUI.getProviderDisplayName(p),
          value: p
        }))
      }]);
      providers = selected;
    }
    
    for (const provider of providers) {
      const config = await ProviderConfigUI.configureProvider(provider, llmsConfig);
      if (!llmsConfig.providers[provider]) {
        llmsConfig.providers[provider] = { apiKey: "" };
      }
      llmsConfig.providers[provider]!.apiKey = config.apiKey;
    }
  }

  private async loadConfig(): Promise<TenexLLMs> {
    return await configService.loadTenexLLMs(
      this.isGlobal ? configService.getGlobalPath() : this.configPath
    );
  }

  private async saveConfig(config: TenexLLMs): Promise<void> {
    if (this.isGlobal) {
      await configService.saveGlobalLLMs(config);
    } else {
      await configService.saveProjectLLMs(this.configPath, config);
    }
    llmServiceFactory.initializeProviders(config.providers);
  }
}
</file>

<file path="src/tools/implementations/create_project.ts">
import { tool } from 'ai';
import { getNDK } from "@/nostr";
import { formatAnyError } from "@/utils/error-formatter";
import { logger } from "@/utils/logger";
import { normalizeNostrIdentifier } from "@/utils/nostr-entity-parser";
import { NDKProject } from "@nostr-dev-kit/ndk";
import type { ExecutionContext } from "@/agents/execution/types";
import { z } from "zod";
const createProjectSchema = z.object({
  title: z.string().describe("The title/name of the project"),
  description: z.string().nullable().describe("Description of the project"),
  repository: z.string().nullable().describe("Repository URL for the project"),
  image: z.string().nullable().describe("Image URL for the project"),
  tags: z.array(z.string()).nullable().describe("Additional tags for the project"),
  agents: z.array(z.string()).nullable().describe("Array of agent definition event IDs to include in the project"),
  mcpServers: z.array(z.string()).nullable().describe("Array of MCP announcement event IDs to include in the project"),
});

type CreateProjectInput = z.infer<typeof createProjectSchema>;
type CreateProjectOutput = {
  id: string;
};

/**
 * Core implementation of the create_project functionality
 * Shared between AI SDK and legacy Tool interfaces
 */
async function executeCreateProject(
  input: CreateProjectInput,
  context: ExecutionContext
): Promise<CreateProjectOutput> {
  const { title, description, repository, image, tags, agents, mcpServers } = input;

    const ndk = getNDK();
    if (!ndk) {
      const error = "NDK instance not available";
      logger.error("‚ùå Create project failed", {
        error,
        agent: context.agent.name,
      });
      throw new Error(error);
    }

    logger.info("üìù Creating new NDKProject", {
      title,
      agent: context.agent.name,
      conversationId: context.conversationId,
    });

    try {
      // Create a new NDKProject event
      const project = new NDKProject(ndk);
      
      // Set project metadata
      project.title = title;
      
      if (description) {
        project.description = description;
      }
      
      if (repository) {
        project.repo = repository;
      }
      
      if (image) {
        project.picture = image;
      }
      
      // Add any additional tags
      if (tags && tags.length > 0) {
        tags.forEach(tag => {
          // Add as generic "t" tags for categorization
          project.tags.push(["t", tag]);
        });
      }

      // Add agent event IDs
      if (agents && agents.length > 0) {
        agents.forEach(agentEventId => {
          // Normalize the event ID (handles nostr: prefix and validates format)
          const cleanEventId = normalizeNostrIdentifier(agentEventId);
          if (cleanEventId) {
            project.tags.push(["agent", cleanEventId]);
          } else {
            logger.warn(`Invalid agent event ID format: ${agentEventId}`);
          }
        });
      }

      // Add MCP server event IDs
      if (mcpServers && mcpServers.length > 0) {
        mcpServers.forEach(mcpEventId => {
          // Normalize the event ID (handles nostr: prefix and validates format)
          const cleanEventId = normalizeNostrIdentifier(mcpEventId);
          if (cleanEventId) {
            project.tags.push(["mcp", cleanEventId]);
          } else {
            logger.warn(`Invalid MCP event ID format: ${mcpEventId}`);
          }
        });
      }

      // The project will be published with the agent's pubkey as the author
      // This is typically the project-manager agent creating projects
      
      // Sign and publish the event
      await project.sign(context.agent.signer);
      await project.publish();

      logger.info("‚úÖ NDKProject created successfully", {
        title,
        projectId: project.encode(),
        agent: context.agent.name,
      });

      const result: CreateProjectOutput = {
        id: `nostr:${project.encode()}`,
      };

      return result;
    } catch (error) {
      const errorMessage = formatAnyError(error);
      logger.error("‚ùå Failed to create NDKProject", {
        error: errorMessage,
        title,
        agent: context.agent.name,
      });

      throw new Error(`Failed to create project: ${errorMessage}`);
    }
}

/**
 * Create an AI SDK tool for creating projects
 * This is the primary implementation
 */
export function createCreateProjectTool(context: ExecutionContext): ReturnType<typeof tool> {
  return tool({
    description: "Create and publish a new NDKProject event to Nostr",
    inputSchema: createProjectSchema,
    execute: async (input: CreateProjectInput) => {
      try {
        return await executeCreateProject(input, context);
      } catch (error) {
        logger.error("Failed to create project", { error });
        throw new Error(`Failed to create project: ${error instanceof Error ? error.message : String(error)}`);
      }
    },
  });
}
</file>

<file path="src/commands/run/SubscriptionManager.ts">
import {
  addProcessedEvent,
  clearProcessedEvents,
  flushProcessedEvents,
  hasProcessedEvent,
  loadProcessedEvents,
} from "@/commands/run/processedEventTracking";
import type { EventHandler } from "@/event-handler";
import { NDKAgentLesson } from "@/events/NDKAgentLesson";
import { getNDK } from "@/nostr/ndkClient";
import { getProjectContext } from "@/services";
import { logger } from "@/utils/logger";
import {
  type NDKEvent,
  type NDKFilter,
  NDKKind,
  type NDKSubscription,
  filterAndRelaySetFromBech32,
} from "@nostr-dev-kit/ndk";
import chalk from "chalk";

export class SubscriptionManager {
  private subscriptions: NDKSubscription[] = [];
  private eventHandler: EventHandler;
  private projectPath: string;

  constructor(eventHandler: EventHandler, projectPath: string) {
    this.eventHandler = eventHandler;
    this.projectPath = projectPath;
  }

  async start(): Promise<void> {
    // Load previously processed event IDs from disk
    await loadProcessedEvents(this.projectPath);

    // 1. Subscribe to project updates (NDKProject events)
    await this.subscribeToProjectUpdates();

    // 2. Subscribe to agent lessons
    await this.subscribeToAgentLessons();

    // 3. Subscribe to all project-related events
    await this.subscribeToProjectEvents();

    // 4. Subscribe to spec replies (kind 1111 with #K:30023)
    await this.subscribeToSpecReplies();

    // 5. Subscribe to conversation metadata (kind 513)
    await this.subscribeToConversationMetadata();
  }

  private async subscribeToProjectUpdates(): Promise<void> {
    const ndk = getNDK();
    const projectCtx = getProjectContext();
    const project = projectCtx.project;
    const { filter: projectFilter } = filterAndRelaySetFromBech32(project.encode(), ndk);

    // Get all agent pubkeys
    const agentPubkeys = Array.from(projectCtx.agents.values()).map((agent) => agent.pubkey);

    logger.debug("Project update filter:", projectFilter);

    // Create filters array
    const filters: NDKFilter[] = [projectFilter];

    // Add filter for agent pubkeys if any exist
    if (agentPubkeys.length > 0) {
      filters.push({ "#p": agentPubkeys, limit: 1 });
      logger.debug(`Added #p filter for ${agentPubkeys.length} agent pubkeys`);
    }

    const projectSubscription = ndk.subscribe(filters, {
      closeOnEose: false,
      groupable: false,
    });

    projectSubscription.on("event", (event: NDKEvent) => {
      this.handleIncomingEvent(event, "project update");
    });

    this.subscriptions.push(projectSubscription);
  }

  private async subscribeToAgentLessons(): Promise<void> {
    const ndk = getNDK();
    const projectCtx = getProjectContext();

    // Get all agent pubkeys
    const agentPubkeys = Array.from(projectCtx.agents.values()).map((agent) => agent.pubkey);

    if (agentPubkeys.length === 0) {
      logger.warn("‚ö†Ô∏è No agent pubkeys found for lesson subscription");
      return;
    }

    // Create filter for agent lessons
    const lessonFilter: NDKFilter = {
      kinds: NDKAgentLesson.kinds,
      authors: agentPubkeys,
    };

    const lessonSubscription = ndk.subscribe(
      lessonFilter,
      {
        closeOnEose: false,
        groupable: false,
      },
      {
        onEvent: (event: NDKEvent) => {
          try {
            const lesson = NDKAgentLesson.from(event);
            projectCtx.addLesson(lesson.pubkey, lesson);
          } catch (error) {
            logger.error("‚ùå Error processing agent lesson:", error);
          }
        },
      }
    );

    // Log initial load completion
    lessonSubscription.on("eose", () => {
      const totalLessons = projectCtx.getAllLessons().length;
      logger.info(
        chalk.green(
          `    ‚úì Agent lessons subscription active - loaded ${totalLessons} historical lessons`
        )
      );

      // Log lesson distribution
      const distribution = new Map<string, number>();
      for (const [pubkey, lessons] of projectCtx.agentLessons) {
        const agent = Array.from(projectCtx.agents.values()).find((a) => a.pubkey === pubkey);
        const name = agent?.name || "Unknown";
        distribution.set(name, lessons.length);
      }
    });

    this.subscriptions.push(lessonSubscription);
  }

  private async subscribeToProjectEvents(): Promise<void> {
    // Filter for all events that tag this project
    const projectCtx = getProjectContext();
    const project = projectCtx.project;
    const projectTagFilter: NDKFilter = {
      ...project.filter(),
      limit: 1,
    };

    logger.debug("Project event filter:", projectTagFilter);

    const ndk = getNDK();
    const projectEventSubscription = ndk.subscribe(
      projectTagFilter,
      {
        closeOnEose: false,
        groupable: false,
      },
      {
        onEvent: (event: NDKEvent) => {
          this.handleIncomingEvent(event, "project event");
        },
      }
    );

    this.subscriptions.push(projectEventSubscription);
  }

  private async subscribeToSpecReplies(): Promise<void> {
    const ndk = getNDK();

    // Subscribe to spec replies (kind 1111 with #K:30023)
    const specReplyFilter: NDKFilter = {
      kinds: [1111],
      "#K": ["30023"],
    };

    logger.info(chalk.blue("  ‚Ä¢ Setting up spec reply subscription..."));
    logger.debug("Spec reply filter:", specReplyFilter);

    const specReplySubscription = ndk.subscribe(
      specReplyFilter,
      {
        closeOnEose: false,
        groupable: false,
      },
      {
        onEvent: (event: NDKEvent) => {
          // Use the A tag value as conversationId for routing
          const conversationId = event.tagValue("A");
          if (conversationId) {
            // Route as a normal conversation event
            this.handleIncomingEvent(event, "spec reply");
          } else {
            logger.warn("Spec reply event missing A tag:", event.id);
          }
        },
      }
    );

    this.subscriptions.push(specReplySubscription);
  }

  private async subscribeToConversationMetadata(): Promise<void> {
    const ndk = getNDK();
    const projectCtx = getProjectContext();

    // Get all agent pubkeys + project owner
    const agentPubkeys = Array.from(projectCtx.agents.values()).map((agent) => agent.pubkey);
    const projectOwnerPubkey = projectCtx.project.pubkey;
    const allPubkeys = [...agentPubkeys, projectOwnerPubkey];

    // Subscribe to metadata events from agents and project owner
    const metadataFilter: NDKFilter = {
      kinds: [513 as NDKKind],
      authors: allPubkeys,
      limit: 0, // Only new events, no historical fetch
    };

    logger.info(chalk.blue("  ‚Ä¢ Setting up conversation metadata subscription..."));
    logger.debug("Metadata filter:", metadataFilter);

    const metadataSubscription = ndk.subscribe(
      metadataFilter,
      {
        closeOnEose: false,
        groupable: false,
      },
      {
        onEvent: (event: NDKEvent) => {
          this.handleIncomingEvent(event, "conversation metadata");
        },
      }
    );

    this.subscriptions.push(metadataSubscription);
  }

  private async handleIncomingEvent(event: NDKEvent, source: string): Promise<void> {
    // Debug: Check event type at receipt
    if (typeof event.getMatchingTags !== 'function') {
      logger.error(`[SubscriptionManager] Received non-NDKEvent from ${source}!`, {
        eventId: event.id,
        eventConstructor: event.constructor?.name,
        isNDKEvent: event instanceof NDKEvent,
        hasGetMatchingTags: typeof event.getMatchingTags,
      });
    }

    // Check for duplicate events
    if (hasProcessedEvent(event.id)) {
      return;
    }

    // Mark as processed
    addProcessedEvent(this.projectPath, event.id);

    // Log receipt
    try {
      await this.eventHandler.handleEvent(event);
    } catch (error) {
      logger.error(`Error handling event from ${source}:`, error);
    }
  }

  async stop(): Promise<void> {
    for (const subscription of this.subscriptions) {
      subscription.stop();
    }

    this.subscriptions = [];

    // Flush any pending saves to disk before stopping
    await flushProcessedEvents(this.projectPath);
    clearProcessedEvents();
  }
}
</file>

<file path="src/conversations/persistence/FileSystemAdapter.ts">
import * as fs from "node:fs/promises";
import * as path from "node:path";
import { ensureDirectory, fileExists, readJsonFile, writeJsonFile } from "@/lib/fs";
import { getNDK } from "@/nostr/ndkClient";
import { logger } from "@/utils/logger";
import { NDKEvent } from "@nostr-dev-kit/ndk";
import type { z } from "zod";
import type { Phase } from "../phases";
import type { AgentState, Conversation } from "../types";
import { type AgentStateSchema, MetadataFileSchema, SerializedConversationSchema } from "./schemas";
import type {
  ConversationMetadata,
  ConversationPersistenceAdapter,
  ConversationSearchCriteria,
} from "./types";

export class FileSystemAdapter implements ConversationPersistenceAdapter {
  private conversationsDir: string;
  private metadataPath: string;
  private archiveDir: string;
  private metadataLock: Promise<void> = Promise.resolve();

  constructor(projectPath: string) {
    this.conversationsDir = path.join(projectPath, ".tenex", "conversations");
    this.metadataPath = path.join(this.conversationsDir, "metadata.json");
    this.archiveDir = path.join(this.conversationsDir, "archive");
  }

  async initialize(): Promise<void> {
    await ensureDirectory(this.conversationsDir);
    await ensureDirectory(this.archiveDir);

    // Initialize metadata file if it doesn't exist
    if (!(await fileExists(this.metadataPath))) {
      await writeJsonFile(this.metadataPath, { conversations: [] });
    }
  }

  async save(conversation: Conversation): Promise<void> {
    try {
      const filePath = this.getConversationPath(conversation.id);

      // Convert agentStates Map to a plain object for serialization
      const agentStatesObj: Record<string, z.infer<typeof AgentStateSchema>> = {};
      if (conversation.agentStates) {
        for (const [key, state] of conversation.agentStates.entries()) {
          agentStatesObj[key] = {
            lastProcessedMessageIndex: state.lastProcessedMessageIndex,
            claudeSessionsByPhase: state.claudeSessionsByPhase,
            lastSeenPhase: state.lastSeenPhase,
          };
        }
      }

      // Serialize NDKEvents to a storable format
      const serialized = {
        ...conversation,
        history: conversation.history.map((event) => event.serialize(true, true)),
        agentStates: agentStatesObj,
      };

      await writeJsonFile(filePath, serialized);

      // Update metadata
      await this.updateMetadata(conversation);
    } catch (error) {
      logger.error("Failed to save conversation", { error, id: conversation.id });
      throw error;
    }
  }

  async load(conversationId: string): Promise<Conversation | null> {
    try {
      const filePath = this.getConversationPath(conversationId);

      if (!(await fileExists(filePath))) {
        // Check archive
        const archivePath = this.getArchivePath(conversationId);
        if (!(await fileExists(archivePath))) {
          return null;
        }
      }

      const rawData = await readJsonFile(filePath);

      // Validate the loaded data with Zod
      const parseResult = SerializedConversationSchema.safeParse(rawData);
      if (!parseResult.success) {
        logger.error("Invalid conversation data", {
          id: conversationId,
          errors: parseResult.error.errors,
        });
        return null;
      }

      const data = parseResult.data;

      // Reconstruct conversation with validated data
      const ndk = getNDK();

      // Reconstruct agentStates Map
      const agentStatesMap = new Map<string, AgentState>();
      if (data.agentStates) {
        for (const [agentSlug, stateData] of Object.entries(data.agentStates)) {
          const state: AgentState = {
            lastProcessedMessageIndex: stateData.lastProcessedMessageIndex,
            claudeSessionsByPhase: stateData.claudeSessionsByPhase,
            lastSeenPhase: stateData.lastSeenPhase as Phase | undefined,
          };
          agentStatesMap.set(agentSlug, state);
        }
      }

      // Deserialize events first
      const deserializedEvents = data.history
        .map((serializedEvent: string) => {
          try {
            return NDKEvent.deserialize(ndk, serializedEvent);
          } catch (error) {
            logger.error("Failed to deserialize event", { error, serializedEvent });
            return null;
          }
        })
        .filter((event): event is NDKEvent => event !== null);

      // Deduplicate events based on event.id
      const seenIds = new Set<string>();
      const deduplicatedHistory: NDKEvent[] = [];
      for (const event of deserializedEvents) {
        if (event.id && !seenIds.has(event.id)) {
          deduplicatedHistory.push(event);
          seenIds.add(event.id);
        }
      }

      // Log if deduplication occurred
      if (deduplicatedHistory.length !== deserializedEvents.length) {
        logger.info("[FileSystemAdapter] Deduplicated conversation history during load", {
          conversationId,
          original: deserializedEvents.length,
          deduplicated: deduplicatedHistory.length,
          removed: deserializedEvents.length - deduplicatedHistory.length,
        });
      }

      const conversation: Conversation = {
        id: data.id,
        title: data.title || undefined,
        phase: data.phase as Phase, // Phase validation happens in schema parsing
        history: deduplicatedHistory,
        agentStates: agentStatesMap,
        phaseStartedAt: data.phaseStartedAt,
        metadata: data.metadata,
        executionTime: data.executionTime || {
          totalSeconds: 0,
          isActive: false,
          lastUpdated: Date.now(),
        },
      };

      return conversation;
    } catch (error) {
      logger.error("Failed to load conversation", { error, id: conversationId });
      return null;
    }
  }

  async delete(conversationId: string): Promise<void> {
    try {
      const filePath = this.getConversationPath(conversationId);

      if (await fileExists(filePath)) {
        await fs.unlink(filePath);
      }

      // Remove from metadata
      await this.removeFromMetadata(conversationId);

      logger.info("Conversation deleted", { id: conversationId });
    } catch (error) {
      logger.error("Failed to delete conversation", { error, id: conversationId });
      throw error;
    }
  }

  async list(): Promise<ConversationMetadata[]> {
    try {
      const metadata = await this.loadMetadata();
      return metadata.conversations;
    } catch (error) {
      logger.error("Failed to list conversations", { error });
      return [];
    }
  }

  async search(criteria: ConversationSearchCriteria): Promise<ConversationMetadata[]> {
    const allMetadata = await this.list();

    return allMetadata.filter((meta) => {
      if (criteria.title && !meta.title.toLowerCase().includes(criteria.title.toLowerCase())) {
        return false;
      }

      if (criteria.phase && meta.phase !== criteria.phase) {
        return false;
      }

      if (criteria.dateFrom && meta.createdAt < criteria.dateFrom) {
        return false;
      }

      if (criteria.dateTo && meta.createdAt > criteria.dateTo) {
        return false;
      }

      if (criteria.archived !== undefined && meta.archived !== criteria.archived) {
        return false;
      }

      return true;
    });
  }

  async archive(conversationId: string): Promise<void> {
    try {
      const sourcePath = this.getConversationPath(conversationId);
      const destPath = this.getArchivePath(conversationId);

      if (await fileExists(sourcePath)) {
        await fs.rename(sourcePath, destPath);
      }

      // Update metadata with lock
      this.metadataLock = this.metadataLock.then(async () => {
        try {
          const metadata = await this.loadMetadata();
          const conv = metadata.conversations.find((c) => c.id === conversationId);
          if (conv) {
            conv.archived = true;
            await this.saveMetadata(metadata);
          }
        } catch (error) {
          logger.error("Failed to update metadata for archive", {
            error,
            conversationId,
          });
          throw error;
        }
      });

      await this.metadataLock;

      logger.info("Conversation archived", { id: conversationId });
    } catch (error) {
      logger.error("Failed to archive conversation", { error, id: conversationId });
      throw error;
    }
  }

  async restore(conversationId: string): Promise<void> {
    try {
      const sourcePath = this.getArchivePath(conversationId);
      const destPath = this.getConversationPath(conversationId);

      if (await fileExists(sourcePath)) {
        await fs.rename(sourcePath, destPath);
      }

      // Update metadata with lock
      this.metadataLock = this.metadataLock.then(async () => {
        try {
          const metadata = await this.loadMetadata();
          const conv = metadata.conversations.find((c) => c.id === conversationId);
          if (conv) {
            conv.archived = false;
            await this.saveMetadata(metadata);
          }
        } catch (error) {
          logger.error("Failed to update metadata for restore", {
            error,
            conversationId,
          });
          throw error;
        }
      });

      await this.metadataLock;

      logger.info("Conversation restored", { id: conversationId });
    } catch (error) {
      logger.error("Failed to restore conversation", { error, id: conversationId });
      throw error;
    }
  }

  private getConversationPath(conversationId: string): string {
    return path.join(this.conversationsDir, `${conversationId}.json`);
  }

  private getArchivePath(conversationId: string): string {
    return path.join(this.archiveDir, `${conversationId}.json`);
  }

  private async loadMetadata(): Promise<{ conversations: ConversationMetadata[] }> {
    try {
      const rawData = await readJsonFile(this.metadataPath);

      // Validate with Zod
      const parseResult = MetadataFileSchema.safeParse(rawData);
      if (!parseResult.success) {
        logger.error("Invalid metadata file structure", {
          errors: parseResult.error.errors,
        });
        return { conversations: [] };
      }

      return parseResult.data;
    } catch {
      return { conversations: [] };
    }
  }

  private async saveMetadata(metadata: { conversations: ConversationMetadata[] }): Promise<void> {
    await writeJsonFile(this.metadataPath, metadata);
  }

  private async updateMetadata(conversation: Conversation): Promise<void> {
    // Serialize metadata updates to prevent race conditions
    this.metadataLock = this.metadataLock.then(async () => {
      try {
        const metadata = await this.loadMetadata();

        const existing = metadata.conversations.findIndex((c) => c.id === conversation.id);
        const meta: ConversationMetadata = {
          id: conversation.id,
          title: conversation.title || "",
          createdAt: conversation.history[0]?.created_at || Date.now() / 1000,
          updatedAt: Date.now() / 1000,
          phase: conversation.phase,
          eventCount: conversation.history.length,
          agentCount: new Set(conversation.history.map((e) => e.pubkey)).size,
          archived: false,
        };

        if (existing >= 0) {
          metadata.conversations[existing] = meta;
        } else {
          metadata.conversations.push(meta);
        }

        await this.saveMetadata(metadata);
      } catch (error) {
        logger.error("Failed to update metadata", {
          error,
          conversationId: conversation.id,
        });
        throw error;
      }
    });

    await this.metadataLock;
  }

  private async removeFromMetadata(conversationId: string): Promise<void> {
    // Serialize metadata updates to prevent race conditions
    this.metadataLock = this.metadataLock.then(async () => {
      try {
        const metadata = await this.loadMetadata();
        metadata.conversations = metadata.conversations.filter((c) => c.id !== conversationId);
        await this.saveMetadata(metadata);
      } catch (error) {
        logger.error("Failed to remove from metadata", { error, conversationId });
        throw error;
      }
    });

    await this.metadataLock;
  }
}
</file>

<file path="src/event-handler/project.ts">
import type { NDKEvent, NDKProject } from "@nostr-dev-kit/ndk";
import { AgentRegistry } from "../agents/AgentRegistry";
import type { AgentInstance } from "../agents/types";
import { NDKMCPTool } from "../events/NDKMCPTool";
import { getNDK } from "../nostr";
import { getProjectContext, isProjectContextInitialized } from "../services/ProjectContext";
import { mcpService } from "../services/mcp/MCPManager";
import {
  getInstalledMCPEventIds,
  installMCPServerFromEvent,
  removeMCPServerByEventId,
} from "../services/mcp/mcpInstaller";
import { installAgentsFromEvents } from "../utils/agentInstaller";
import { logger } from "../utils/logger";

/**
 * Handles project update events by syncing agent and MCP tool definitions.
 * When a project event is received, this function:
 * 1. Checks if the event is for the currently loaded project
 * 2. Identifies new agents and MCP tools that have been added to the project
 * 3. Fetches definitions from Nostr for new agents and MCP tools
 * 4. Saves definitions to disk and registers them
 * 5. Updates the ProjectContext with the new configuration
 */
export async function handleProjectEvent(event: NDKEvent, projectPath: string): Promise<void> {
  const title = event.tags.find((tag) => tag[0] === "title")?.[1] || "Untitled";
  logger.info(`üìã Project event update received: ${title}`);

  // Extract agent event IDs from the project
  const agentEventIds = event.tags
    .filter((tag) => tag[0] === "agent" && tag[1])
    .map((tag) => tag[1])
    .filter((id): id is string => typeof id === "string");

  // Extract MCP tool event IDs from the project
  const mcpEventIds = event.tags
    .filter((tag) => tag[0] === "mcp" && tag[1])
    .map((tag) => tag[1])
    .filter((id): id is string => typeof id === "string");

  if (agentEventIds.length > 0) {
    logger.info(`Project references ${agentEventIds.length} agent(s)`);
  }
  if (mcpEventIds.length > 0) {
    logger.info(`Project references ${mcpEventIds.length} MCP tool(s)`);
  }

  // Only process if project context is initialized (daemon is running)
  if (!isProjectContextInitialized()) {
    logger.debug("Project context not initialized, skipping agent update");
    return;
  }

  try {
    const currentContext = getProjectContext();

    // Check if this is the same project that's currently loaded
    const currentProjectDTag = currentContext.project.dTag;
    const eventDTag = event.tags.find((tag) => tag[0] === "d")?.[1];

    if (currentProjectDTag !== eventDTag) {
      logger.debug("Project event is for a different project, skipping", {
        currentProjectDTag,
        eventDTag,
      });
      return;
    }

    // Load agent registry
    const agentRegistry = new AgentRegistry(projectPath, false);
    await agentRegistry.loadFromProject();

    // Track which agents need to be added or updated
    const currentAgentEventIds = new Set<string>();
    for (const agent of currentContext.agents.values()) {
      if (agent.eventId) {
        currentAgentEventIds.add(agent.eventId);
      }
    }

    // Find new agents that need to be fetched
    const newAgentEventIds = agentEventIds.filter((id) => !!id && !currentAgentEventIds.has(id));

    // Find agents that need to be removed (exist locally but not in the project)
    const newAgentEventIdsSet = new Set(agentEventIds);
    const agentsToRemove = Array.from(currentAgentEventIds).filter(
      (id) => !newAgentEventIdsSet.has(id)
    );

    // We'll process if there are any changes to agents OR MCP tools

    if (newAgentEventIds.length > 0) {
      logger.info(`Found ${newAgentEventIds.length} new agent(s) to add`);
    }

    if (agentsToRemove.length > 0) {
      logger.info(`Found ${agentsToRemove.length} agent(s) to remove`);
    }

    // Handle agent removals first
    for (const eventId of agentsToRemove) {
      try {
        await agentRegistry.removeAgentByEventId(eventId);
      } catch (error) {
        logger.error("Failed to remove agent", { error, eventId });
      }
    }

    // Fetch and install new agent definitions using shared function
    if (newAgentEventIds.length > 0) {
      const ndkProject = event as NDKProject;
      await installAgentsFromEvents(newAgentEventIds, projectPath, ndkProject, getNDK());
    }

    // Process MCP tool changes
    const ndk = getNDK();

    // Get currently installed MCP event IDs (only those with event IDs)
    const installedMCPEventIds = await getInstalledMCPEventIds(projectPath);

    // Find new MCP tools that need to be fetched
    const newMCPEventIds = mcpEventIds.filter((id) => !!id && !installedMCPEventIds.has(id));

    // Find MCP tools that need to be removed (exist locally but not in the project)
    const newMCPEventIdsSet = new Set(mcpEventIds);
    const mcpToolsToRemove = Array.from(installedMCPEventIds).filter(
      (id) => !newMCPEventIdsSet.has(id)
    );

    if (newMCPEventIds.length > 0) {
      logger.info(`Found ${newMCPEventIds.length} new MCP tool(s) to add`);
    }

    if (mcpToolsToRemove.length > 0) {
      logger.info(`Found ${mcpToolsToRemove.length} MCP tool(s) to remove`);
    }

    // Handle MCP tool removals first
    for (const eventId of mcpToolsToRemove) {
      try {
        await removeMCPServerByEventId(projectPath, eventId);
      } catch (error) {
        logger.error("Failed to remove MCP tool", { error, eventId });
      }
    }

    // Fetch and install new MCP tools
    for (const eventId of newMCPEventIds) {
      try {
        const mcpEvent = await ndk.fetchEvent(eventId);
        if (mcpEvent) {
          const mcpTool = NDKMCPTool.from(mcpEvent);
          await installMCPServerFromEvent(projectPath, mcpTool);
          logger.info("Installed MCP tool from project update", {
            eventId,
            name: mcpTool.name,
          });
        }
      } catch (error) {
        logger.error("Failed to fetch or install MCP tool", { error, eventId });
      }
    }

    // Reload MCP service if there were any MCP tool changes
    const hasMCPChanges = newMCPEventIds.length > 0 || mcpToolsToRemove.length > 0;
    if (hasMCPChanges) {
      logger.info("Reloading MCP service after tool changes");
      await mcpService.reload(projectPath);
    }

    // Reload the agent registry to get all agents including new ones
    await agentRegistry.loadFromProject();

    // Update the project context with new agents
    const updatedAgents = new Map<string, AgentInstance>();
    for (const agent of agentRegistry.getAllAgents()) {
      updatedAgents.set(agent.slug, agent);
    }

    // Create NDKProject from the event
    const ndkProject = event as NDKProject;

    // Update the existing project context atomically
    await currentContext.updateProjectData(ndkProject, updatedAgents);

    logger.info("Project context updated", {
      totalAgents: updatedAgents.size,
      newAgentsAdded: newAgentEventIds.length,
      agentsRemoved: agentsToRemove.length,
      newMCPToolsAdded: newMCPEventIds.length,
      mcpToolsRemoved: mcpToolsToRemove.length,
      mcpReloaded: hasMCPChanges,
    });
  } catch (error) {
    logger.error("Failed to update project from event", { error });
  }
}
</file>

<file path="src/nostr/index.ts">
// Agent event system

export { AgentEventDecoder } from "./AgentEventDecoder";
export type {
  CompletionIntent,
  ConversationIntent,
  DelegationIntent,
  EventContext,
} from "./AgentEventEncoder";
export { AgentEventEncoder } from "./AgentEventEncoder";
export { AgentPublisher } from "./AgentPublisher";
export { getNDK } from "./ndkClient";
export {
  getAgentSlugFromEvent,
  isEventFromAgent,
  isEventFromUser,
} from "./utils";
</file>

<file path="src/nostr/utils.ts">
import { getProjectContext, isProjectContextInitialized } from "@/services";
import type { NDKEvent } from "@nostr-dev-kit/ndk";

/**
 * Check if an event is from an agent (either project agent or individual agent)
 * @param event - The NDK event to check
 * @returns true if the event is from an agent, false if from a user
 */
export function isEventFromAgent(event: NDKEvent): boolean {
  const projectCtx = getProjectContext();

  // Check if it's from the project itself
  if (projectCtx.pubkey && projectCtx.pubkey === event.pubkey) {
    return true;
  }

  // Check if it's from any of the registered agents
  for (const agent of projectCtx.agents.values()) {
    if (agent.pubkey === event.pubkey) {
      return true;
    }
  }

  return false;
}

/**
 * Check if an event is from a user (not from an agent)
 * @param event - The NDK event to check
 * @returns true if the event is from a user, false if from an agent
 */
export function isEventFromUser(event: NDKEvent): boolean {
  return !isEventFromAgent(event);
}

/**
 * Get the agent slug if the event is from an agent
 * @param event - The NDK event to check
 * @returns The agent slug if found, undefined otherwise
 */
export function getAgentSlugFromEvent(event: NDKEvent): string | undefined {
  if (!event.pubkey) return undefined;

  if (!isProjectContextInitialized()) {
    // Project context not initialized
    return undefined;
  }

  const projectCtx = getProjectContext();
  for (const [slug, agent] of projectCtx.agents) {
    if (agent.pubkey === event.pubkey) {
      return slug;
    }
  }

  return undefined;
}

/**
 * Get the agent slugs that are targeted by this event based on p-tags
 * @param event - The NDK event to check
 * @returns Array of agent slugs that are targeted by this event
 */
export function getTargetedAgentSlugsFromEvent(event: NDKEvent): string[] {
  if (!isProjectContextInitialized()) {
    return [];
  }

  const projectCtx = getProjectContext();
  const targetedSlugs: string[] = [];
  
  // Get all p-tags from the event
  const pTags = event.getMatchingTags("p");
  if (pTags.length === 0) {
    return [];
  }
  
  // Check each p-tag to see if it matches an agent
  for (const pTag of pTags) {
    const pubkey = pTag[1];
    if (!pubkey) continue;
    
    // Check if this pubkey belongs to an agent
    for (const [slug, agent] of projectCtx.agents) {
      if (agent.pubkey === pubkey) {
        targetedSlugs.push(slug);
        break;
      }
    }
  }
  
  return targetedSlugs;
}

/**
 * Check if an event targets a specific agent
 * @param event - The NDK event to check
 * @param agentSlug - The slug of the agent to check
 * @returns true if the event targets this specific agent
 */
export function isEventTargetedToAgent(event: NDKEvent, agentSlug: string): boolean {
  const targetedSlugs = getTargetedAgentSlugsFromEvent(event);
  return targetedSlugs.includes(agentSlug);
}
</file>

<file path="src/services/NDKAgentDiscovery.ts">
import { NDKAgentDefinition } from "@/events/NDKAgentDefinition";
import { logger } from "@/utils/logger";
import type NDK from "@nostr-dev-kit/ndk";
import type { NDKFilter } from "@nostr-dev-kit/ndk";

/**
 * Options for discovering NDKAgentDefinition events
 */
export interface AgentDiscoveryOptions {
  /** Text to search for in name/description/role */
  searchText?: string;
  /** Minimum creation timestamp */
  since?: number;
  /** Maximum creation timestamp */
  until?: number;
  /** Filter by specific phase */
  phase?: string;
}

/**
 * Service for discovering NDKAgentDefinition events from the Nostr network
 */
export class NDKAgentDiscovery {
  constructor(private ndk: NDK) {}

  /**
   * Discover NDKAgentDefinition events from the network
   */
  async discoverAgents(options: AgentDiscoveryOptions = {}): Promise<NDKAgentDefinition[]> {
    try {
      // Build filter for kind:4199 (NDKAgentDefinition)
      const filter: NDKFilter = {
        kinds: NDKAgentDefinition.kinds,
      };

      if (options.since) {
        filter.since = options.since;
      }
      if (options.until) {
        filter.until = options.until;
      }

      logger.debug("Discovering NDKAgentDefinition events", { filter });

      // Fetch events from network
      const events = await this.ndk.fetchEvents(filter, {
        closeOnEose: true,
        groupable: false,
      });

      logger.info(`Found ${events.size} NDKAgentDefinition events`);

      // Convert to NDKAgentDefinition instances
      const discoveredAgents: NDKAgentDefinition[] = [];

      for (const event of Array.from(events)) {
        const ndkAgent = NDKAgentDefinition.from(event);
        discoveredAgents.push(ndkAgent);
      }

      // Apply local filtering if specified
      let filtered = discoveredAgents;

      if (options.searchText) {
        filtered = this.filterByText(filtered, options.searchText);
      }

      if (options.phase !== undefined) {
        filtered = this.filterByPhase(filtered, options.phase);
      }

      // Sort by creation time (newest first)
      filtered.sort((a, b) => (b.created_at || 0) - (a.created_at || 0));

      return filtered;
    } catch (error) {
      logger.error("Failed to discover NDKAgentDefinition events", { error });
      throw error;
    }
  }

  /**
   * Filter agents by text search
   */
  private filterByText(agents: NDKAgentDefinition[], searchText: string): NDKAgentDefinition[] {
    const searchLower = searchText.toLowerCase();

    return agents.filter((agent) => {
      const searchableText = [
        agent.title || "",
        agent.role || "",
        agent.description || "",
        agent.useCriteria || "",
      ]
        .join(" ")
        .toLowerCase();

      return searchableText.includes(searchLower);
    });
  }

  /**
   * Filter agents by phase
   * @param agents - Array of agents to filter
   * @param phase - Phase to filter by (empty string means no phase, specific value means that phase)
   * @returns Filtered agents
   */
  private filterByPhase(agents: NDKAgentDefinition[], phase: string): NDKAgentDefinition[] {
    const { shouldUseDefinitionForPhase } = require("@/conversations/utils/phaseUtils");
    
    return agents.filter(agent => {
      // Get phase from agent definition
      const agentPhase = agent.phase;
      
      // Use phase validation utility to determine if this definition should be used
      return shouldUseDefinitionForPhase(agentPhase, phase);
    });
  }
}
</file>

<file path="src/utils/agent-resolution.ts">
import { getProjectContext } from "@/services/ProjectContext";
import { logger } from "@/utils/logger";
import { parseNostrUser } from "@/utils/nostr-entity-parser";

/**
 * Resolve a recipient string to a pubkey
 * @param recipient - Agent slug, name, npub, or hex pubkey
 * @returns Pubkey hex string or null if not found
 */
export function resolveRecipientToPubkey(recipient: string): string | null {
  // Trim whitespace
  recipient = recipient.trim();

  // Try to parse as a Nostr user identifier (npub, nprofile, hex, with/without nostr: prefix)
  const parsedPubkey = parseNostrUser(recipient);
  if (parsedPubkey) {
    return parsedPubkey;
  }

  // Try to resolve as agent slug or name (case-insensitive)
  try {
    const projectContext = getProjectContext();

    // Check project agents with case-insensitive matching for both slug and name
    const recipientLower = recipient.toLowerCase();
    const agents = projectContext.agentRegistry.getAllAgentsMap();
    for (const [slug, agent] of agents.entries()) {
      if (slug.toLowerCase() === recipientLower || agent.name.toLowerCase() === recipientLower) {
        return agent.pubkey;
      }
    }

    logger.debug("Agent slug or name not found", { recipient });
    return null;
  } catch (error) {
    logger.debug("Failed to resolve agent slug or name", { recipient, error });
    return null;
  }
}
</file>

<file path="src/agents/types.ts">
// Tool type removed - using AI SDK tools only
import type { NDKPrivateKeySigner } from "@nostr-dev-kit/ndk";

/**
 * Simplified agent representation for UI display and selection
 */
export interface AgentSummary {
  /** Display name of the agent */
  name: string;
  /** Primary role/function of the agent */
  role: string;
  /** Nostr public key for agent identity */
  pubkey: string;
}

/**
 * Complete agent configuration and identity
 */
export interface AgentInstance {
  /** Display name of the agent */
  name: string;
  /** Nostr public key for agent identity */
  pubkey: string;
  /** Cryptographic signer for Nostr events */
  signer: NDKPrivateKeySigner;
  /** Primary role/function of the agent */
  role: string;
  /** Agent description from NDKAgentDefinition event */
  description?: string;
  /** System instructions that guide agent behavior */
  instructions?: string;
  /** Criteria for when this agent should be selected by orchestrator */
  useCriteria?: string;
  /** LLM configuration identifier */
  llmConfig: string;
  /** Tool names available to this agent (stored as strings, converted to tools at runtime) */
  tools: string[];
  /** Whether this agent has access to MCP tools (defaults to true except for orchestrator) */
  mcp?: boolean;
  /** NDKAgentDefinition event ID for persisted configuration */
  eventId?: string;
  /** Agent slug/key from agents.json configuration */
  slug: string;
  /** Whether this agent is from the global configuration */
  isGlobal?: boolean;
  /** Project phase this agent instance is for */
  phase?: string;
}

/**
 * Arguments passed to tool functions during execution
 */
export interface ToolCallArguments {
  /** Shell command to execute (for shell tools) */
  command?: string;
  /** File system path (for file tools) */
  path?: string;
  /** Operation mode (for claude_code tool) */
  mode?: string;
  /** User prompt or query (for claude_code tool) */
  prompt?: string;

  /** Allow additional tool-specific arguments */
  [key: string]: string | number | boolean | undefined;
}

/**
 * Represents a tool invocation request
 */
export interface ToolCall {
  /** Name/identifier of the tool to call */
  tool: string;
  /** Arguments to pass to the tool */
  args: ToolCallArguments;
  /** Optional unique identifier for tracking */
  id?: string;
}

/**
 * Configuration load options
 */
export interface ConfigurationLoadOptions {
  skipGlobal?: boolean;
}

/**
 * Agent data stored in JSON files (.tenex/agents/*.json)
 */
export interface StoredAgentData {
  name: string;
  role: string;
  description?: string;
  instructions?: string;
  useCriteria?: string;
  llmConfig?: string;
  tools?: string[]; // Tool names in storage - converted to Tool instances at runtime
  mcp?: boolean; // Whether this agent has access to MCP tools
  phase?: string; // Project phase this agent definition is for
}

/**
 * Agent configuration including sensitive data from registry
 */
export interface AgentConfig extends StoredAgentData {
  nsec: string; // Private key from agents.json registry
  eventId?: string; // NDKAgentDefinition event ID if created from Nostr event
  pubkey?: string; // Public key derived from nsec
}

/**
 * Agent config for creation with optional nsec
 */
export interface AgentConfigOptionalNsec extends StoredAgentData {
  nsec?: string; // Optional during creation
  eventId?: string;
  pubkey?: string;
}

/**
 * Agent configuration for orchestration system
 */
export interface AgentConfiguration {
  name: string;
  nsec: string;
  eventId?: string;
  role?: string;
}

/**
 * Project agents configuration
 */
export interface ProjectAgentsConfig {
  agents: Record<string, AgentConfiguration>;
}
</file>

<file path="src/conversations/persistence/schemas.ts">
import { z } from "zod";

const PhaseSchema = z.string(); // Any string is a valid phase now

export const ConversationMetadataSchema = z.record(z.string(), z.unknown());

const ExecutionTimeSchema = z.object({
  totalSeconds: z.number(),
  currentSessionStart: z.number().optional(),
  isActive: z.boolean(),
  lastUpdated: z.number(),
});

// Simplified agent state schema
export const AgentStateSchema = z.object({
  lastProcessedMessageIndex: z.number().int().min(0),
  claudeSessionsByPhase: z.record(z.string(), z.string()).optional(), // Phase -> sessionId mapping
  lastSeenPhase: z.string().optional(), // Phase as string
});

export const SerializedConversationSchema = z.object({
  id: z.string(),
  title: z.string(),
  phase: PhaseSchema,
  history: z.array(z.string()),
  agentStates: z.record(z.string(), AgentStateSchema).optional(), // Map serialized as object
  phaseStartedAt: z.number().optional(),
  metadata: ConversationMetadataSchema,
  executionTime: ExecutionTimeSchema.optional(),
});

export const ConversationMetadataFileSchema = z.object({
  id: z.string(),
  title: z.string(),
  createdAt: z.number(),
  updatedAt: z.number(),
  phase: z.string(),
  eventCount: z.number(),
  agentCount: z.number(),
  archived: z.boolean().optional(),
});

export const MetadataFileSchema = z.object({
  conversations: z.array(ConversationMetadataFileSchema),
});

export type SerializedConversation = z.infer<typeof SerializedConversationSchema>;
export type MetadataFile = z.infer<typeof MetadataFileSchema>;
</file>

<file path="src/event-handler/DelegationCompletionHandler.ts">
import type { AgentInstance } from "@/agents/types";
import type { Conversation, ConversationCoordinator } from "@/conversations";
import type { DelegationRecord } from "@/services/DelegationRegistry";
import { getProjectContext } from "@/services";
import { DelegationRegistry } from "@/services/DelegationRegistry";
import { logger } from "@/utils/logger";
import type { NDKEvent } from "@nostr-dev-kit/ndk";
import chalk from "chalk";


export interface DelegationCompletionResult {
  shouldReactivate: boolean;
  targetAgent?: AgentInstance;
  replyTarget?: NDKEvent;
}

/**
 * DelegationCompletionHandler encapsulates all logic for processing delegation completion events.
 * This includes updating the DelegationRegistry, determining if all delegations in a batch
 * are complete, and preparing the context for agent reactivation.
 */

// biome-ignore lint/complexity/noStaticOnlyClass: <explanation>
export class DelegationCompletionHandler {
  /**
   * Process a delegation completion event using the DelegationRegistry
   * Updated to use conversation key lookups instead of synthetic IDs
   */
  static async handleDelegationCompletion(
    event: NDKEvent,
    conversation: Conversation,
    conversationCoordinator: ConversationCoordinator
  ): Promise<DelegationCompletionResult> {
    const registry = DelegationRegistry.getInstance();
    let delegationContext: DelegationRecord | undefined;
    
    logger.info("üîç [DelegationCompletionHandler] Processing potential delegation completion", {
      eventId: event.id?.substring(0, 8),
      from: event.pubkey.substring(0, 16),
      conversationId: conversation.id.substring(0, 8),
      hasStatusTag: !!event.tagValue("status"),
      status: event.tagValue("status"),
    });
    
    // We need to find the delegation by conversation key.
    // We know:
    // - The root conversation ID (from the conversation object)
    // - The responder pubkey (from event.pubkey)
    // - We need to find who delegated TO this responder
    
    // First, let's check if this is a response to a delegation by looking at e-tags
    const eTags = event.getMatchingTags("e");
    
    logger.debug("üîç Checking e-tags for delegation references", {
      eTagCount: eTags.length,
      eTags: eTags.map(tag => tag[1]?.substring(0, 8)),
    });
    
    // For each e-tag, check if it's a delegation event we're tracking
    for (const eTagArray of eTags) {
      const eTag = eTagArray[1]; // e-tag value is at index 1
      if (!eTag) continue;
      
      // Use the registry's method to find delegation by event ID and responder
      const potentialContext = registry.findDelegationByEventAndResponder(eTag, event.pubkey);
      
      if (potentialContext && potentialContext.status === "pending") {
        delegationContext = potentialContext;
        
        logger.info("‚úÖ [DelegationCompletionHandler] Found matching delegation via e-tag", {
          delegationEventId: eTag.substring(0, 8),
          from: event.pubkey.substring(0, 16),
          to: potentialContext.delegatingAgent.pubkey.substring(0, 16),
          status: potentialContext.status,
          isExplicitCompletion: event.tagValue("status") === "completed",
        });
        break;
      }
    }
    
    // Alternative: Try using conversation key if we can determine the delegator
    if (!delegationContext) {
      // Look for p-tags that might indicate who we're responding to
      const pTags = event.getMatchingTags("p");
      for (const pTagArray of pTags) {
        const delegatorPubkey = pTagArray[1];
        if (!delegatorPubkey) continue;
        
        // Try to find delegation using conversation key
        const potentialContext = registry.getDelegationByConversationKey(
          conversation.id, // root conversation ID
          delegatorPubkey,  // potential delegator
          event.pubkey      // responder (current event author)
        );
        
        if (potentialContext && potentialContext.status === "pending") {
          delegationContext = potentialContext;
          
          logger.info("‚úÖ [DelegationCompletionHandler] Found matching delegation via conversation key", {
            rootConversationId: conversation.id.substring(0, 8),
            delegator: delegatorPubkey.substring(0, 16),
            responder: event.pubkey.substring(0, 16),
            status: potentialContext.status,
          });
          break;
        }
      }
    }
    
    if (!delegationContext) {
      logger.debug("[DelegationCompletionHandler] No delegation context found");
      return { shouldReactivate: false };
    }

    logger.debug("[DelegationCompletionHandler] Found delegation context", {
      delegatingAgent: delegationContext.delegatingAgent.slug,
      status: delegationContext.status,
      batchId: delegationContext.delegationBatchId,
    });

    // Record the completion in the registry
    try {
      const result = await registry.recordDelegationCompletion({
        conversationId: delegationContext.delegatingAgent.rootConversationId,
        fromPubkey: delegationContext.delegatingAgent.pubkey,
        toPubkey: event.pubkey,
        completionEventId: event.id,
        response: event.content,
        summary: event.tagValue("summary"),
      });

      // Check if this batch was already handled synchronously
      const wasSyncHandled = registry.isBatchSyncHandled(result.batchId);
      if (wasSyncHandled) {
        logger.info("[DelegationCompletionHandler] ‚úÖ Batch was already handled synchronously, skipping reactivation", {
          batchId: result.batchId,
        });
        return { shouldReactivate: false };
      }

      const isAsyncFallback = !DelegationRegistry.getInstance().listenerCount(`${result.batchId}:completion`);
      
      logger.info(isAsyncFallback 
        ? "[DelegationCompletionHandler] üîÑ ASYNC FALLBACK: Processing completion (no sync listener)"
        : "[DelegationCompletionHandler] üîÅ Processing completion (sync listener active)", {
        batchComplete: result.batchComplete,
        remainingTasks: result.remainingDelegations,
        batchId: result.batchId,
        mode: isAsyncFallback ? "async-fallback" : "synchronous",
      });

      if (result.batchComplete) {
        logger.info(isAsyncFallback
          ? "[DelegationCompletionHandler] üîÑ ASYNC FALLBACK: Reactivating agent after delegation"
          : "[DelegationCompletionHandler] ‚ÑπÔ∏è Delegation complete (sync handler likely processed)", {
          agent: result.delegatingAgentSlug,
          batchId: result.batchId,
          mode: isAsyncFallback ? "async-reactivation" : "sync-already-handled",
        });

        // Find the target agent
        const targetAgent = getProjectContext().getAgent(result.delegatingAgentSlug);
        if (!targetAgent) {
          logger.error("[DelegationCompletionHandler] Could not find delegating agent", {
            agentSlug: result.delegatingAgentSlug,
          });
          return { shouldReactivate: false };
        }

        // Find the original user request to use as reply target
        const delegatingConversation = conversationCoordinator.getConversation(result.conversationId);
        if (!delegatingConversation) {
          logger.warn("[DelegationCompletionHandler] Could not find delegating conversation", {
            conversationId: result.conversationId.substring(0, 8),
          });
          return { shouldReactivate: true, targetAgent };
        }

        // Find first non-agent event (the original user request)
        const projectCtx = getProjectContext();
        const agentPubkeys = new Set([
          ...(projectCtx.pubkey ? [projectCtx.pubkey] : []),
          ...Array.from(projectCtx.agents.values()).map((a) => a.pubkey),
        ]);

        const originalUserEvent = delegatingConversation.history?.find(
          (e) => !agentPubkeys.has(e.pubkey)
        );

        if (originalUserEvent) {
          logger.debug("[DelegationCompletionHandler] Found original user event to reply to", {
            eventId: originalUserEvent.id?.substring(0, 8),
            userPubkey: originalUserEvent.pubkey?.substring(0, 8),
          });
        }

        return {
          shouldReactivate: true,
          targetAgent,
          replyTarget: originalUserEvent,
        };
      }
      logger.info(
        chalk.gray(
          `Delegation completed. Waiting for ${result.remainingDelegations} more delegations.`
        )
      );
      return { shouldReactivate: false };
    } catch (error) {
      logger.error("[DelegationCompletionHandler] Failed to record delegation completion", {
        error,
      });
      return { shouldReactivate: false };
    }
  }
}
</file>

<file path="src/services/ConfigService.ts">
import * as os from "node:os";
import * as path from "node:path";
import { AGENTS_FILE, CONFIG_FILE, LLMS_FILE, MCP_CONFIG_FILE, TENEX_DIR } from "@/constants";
import { ensureDirectory, fileExists, readJsonFile, writeJsonFile } from "@/lib/fs";
import { llmServiceFactory } from "@/llm/LLMServiceFactory";
import type { LLMService } from "@/llm/service";
import type { LLMLogger } from "@/logging/LLMLogger";
import type {
  ConfigFile,
  LLMConfiguration,
  LoadedConfig,
  TenexAgents,
  TenexConfig,
  TenexLLMs,
  TenexMCP,
} from "@/services/config/types";
import {
  TenexAgentsSchema,
  TenexConfigSchema,
  TenexLLMsSchema,
  TenexMCPSchema,
} from "@/services/config/types";
import { formatAnyError } from "@/utils/error-formatter";
import { logger } from "@/utils/logger";
import type { z } from "zod";

/**
 * Centralized configuration service for TENEX
 * Handles loading and saving of all configuration files
 * Pure file operations with validation - no business logic
 */
export class ConfigService {
  private static instance: ConfigService;
  private cache = new Map<string, { data: unknown; timestamp: number }>();
  private loadedConfig?: LoadedConfig;

  private constructor() {}

  static getInstance(): ConfigService {
    if (!ConfigService.instance) {
      ConfigService.instance = new ConfigService();
    }
    return ConfigService.instance;
  }

  // =====================================================================================
  // PATH UTILITIES
  // =====================================================================================

  getGlobalPath(): string {
    return path.join(os.homedir(), TENEX_DIR);
  }

  getProjectPath(projectPath: string): string {
    return path.join(projectPath, TENEX_DIR);
  }

  private getConfigFilePath(basePath: string, configFile: ConfigFile): string {
    return path.join(basePath, configFile);
  }

  // =====================================================================================
  // COMPLETE CONFIGURATION LOADING
  // =====================================================================================

  async loadConfig(projectPath?: string): Promise<LoadedConfig> {
    const globalPath = this.getGlobalPath();
    const projPath = projectPath ? this.getProjectPath(projectPath) : undefined;

    // Load global config
    const globalConfig = await this.loadTenexConfig(globalPath);

    // Load project config if provided
    let projectConfig: TenexConfig = {};
    if (projPath) {
      projectConfig = await this.loadTenexConfig(projPath);
    }

    // Merge configs (project overrides global)
    const config: TenexConfig = {
      ...globalConfig,
      ...projectConfig,
      // Merge arrays properly
      whitelistedPubkeys: [
        ...(globalConfig.whitelistedPubkeys || []),
        ...(projectConfig.whitelistedPubkeys || []),
      ],
    };

    // Load agents (merge global and project)
    const globalAgents = await this.loadTenexAgents(globalPath);
    const projectAgents = projPath ? await this.loadTenexAgents(projPath) : {};
    const agents: TenexAgents = { ...globalAgents, ...projectAgents };

    // Load LLMs (merge global and project)
    const globalLLMs = await this.loadTenexLLMs(globalPath);
    const projectLLMs = projPath
      ? await this.loadTenexLLMs(projPath)
      : { providers: {}, configurations: {}, default: undefined };
    const llms: TenexLLMs = {
      providers: { ...globalLLMs.providers, ...projectLLMs.providers },
      configurations: { ...globalLLMs.configurations, ...projectLLMs.configurations },
      default: projectLLMs.default ?? globalLLMs.default,
    };

    // Load MCP (merge global and project)
    const globalMCP = await this.loadTenexMCP(globalPath);
    const projectMCP = projPath
      ? await this.loadTenexMCP(projPath)
      : { servers: {}, enabled: true };
    const mcp: TenexMCP = {
      servers: { ...globalMCP.servers, ...projectMCP.servers },
      enabled: projectMCP.enabled !== undefined ? projectMCP.enabled : globalMCP.enabled,
    };

    const loadedConfig = { config, agents, llms, mcp };
    this.loadedConfig = loadedConfig;
    
    // Initialize the LLM factory with provider configs
    llmServiceFactory.initializeProviders(llms.providers);
    
    return loadedConfig;
  }

  // =====================================================================================
  // INDIVIDUAL FILE LOADING
  // =====================================================================================

  async loadTenexConfig(basePath: string): Promise<TenexConfig> {
    return this.loadConfigFile(
      this.getConfigFilePath(basePath, CONFIG_FILE),
      TenexConfigSchema,
      {}
    );
  }

  async loadTenexAgents(basePath: string): Promise<TenexAgents> {
    return this.loadConfigFile(
      this.getConfigFilePath(basePath, AGENTS_FILE),
      TenexAgentsSchema,
      {}
    );
  }

  async loadTenexLLMs(basePath: string): Promise<TenexLLMs> {
    return this.loadConfigFile(this.getConfigFilePath(basePath, LLMS_FILE), TenexLLMsSchema, {
      providers: {},
      configurations: {},
      default: undefined
    });
  }

  async loadTenexMCP(basePath: string): Promise<TenexMCP> {
    const result = await this.loadConfigFile(
      this.getConfigFilePath(basePath, MCP_CONFIG_FILE),
      TenexMCPSchema,
      {
        servers: {},
        enabled: true,
      }
    );
    // Ensure servers is always defined
    return {
      servers: result.servers || {},
      enabled: result.enabled ?? true,
    };
  }

  // =====================================================================================
  // INDIVIDUAL FILE SAVING
  // =====================================================================================

  async saveTenexConfig(basePath: string, config: TenexConfig): Promise<void> {
    await this.saveConfigFile(
      this.getConfigFilePath(basePath, CONFIG_FILE),
      config,
      TenexConfigSchema
    );
  }

  async saveTenexAgents(basePath: string, agents: TenexAgents): Promise<void> {
    await this.saveConfigFile(
      this.getConfigFilePath(basePath, AGENTS_FILE),
      agents,
      TenexAgentsSchema
    );
  }

  async saveTenexLLMs(basePath: string, llms: TenexLLMs): Promise<void> {
    await this.saveConfigFile(this.getConfigFilePath(basePath, LLMS_FILE), llms, TenexLLMsSchema);
  }

  async saveTenexMCP(basePath: string, mcp: TenexMCP): Promise<void> {
    await this.saveConfigFile(
      this.getConfigFilePath(basePath, MCP_CONFIG_FILE),
      mcp,
      TenexMCPSchema
    );
  }

  // =====================================================================================
  // LLM SERVICE CREATION
  // =====================================================================================

  /**
   * Get LLM configuration by name
   */
  getLLMConfig(configName?: string): LLMConfiguration {
    if (!this.loadedConfig) {
      throw new Error("Config not loaded. Call loadConfig() first.");
    }

    // If configName is "default" or not provided, use the actual default from config
    let name = configName;
    if (!name || name === "default") {
      name = this.loadedConfig.llms.default;
      if (!name) {
        // If no default is configured, try to use the first available configuration
        const available = Object.keys(this.loadedConfig.llms.configurations);
        if (available.length > 0) {
          name = available[0];
          logger.warn(`No default LLM configured, using first available: ${name}`);
        } else {
          throw new Error("No LLM configurations available");
        }
      }
    }
    
    // Try to get the configuration
    let config = this.loadedConfig.llms.configurations[name];
    
    // If configuration not found, fallback to default
    if (!config && name !== this.loadedConfig.llms.default) {
      const defaultName = this.loadedConfig.llms.default;
      if (defaultName) {
        logger.warn(`LLM configuration "${name}" not found, falling back to default: ${defaultName}`);
        config = this.loadedConfig.llms.configurations[defaultName];
        
        // If even the default isn't found, try first available
        if (!config) {
          const available = Object.keys(this.loadedConfig.llms.configurations);
          if (available.length > 0) {
            logger.warn(`Default configuration "${defaultName}" not found, using first available: ${available[0]}`);
            config = this.loadedConfig.llms.configurations[available[0]];
          }
        }
      }
    }
    
    // If still no config found, throw error
    if (!config) {
      const available = Object.keys(this.loadedConfig.llms.configurations);
      throw new Error(
        `No valid LLM configuration found. Requested: "${configName || 'default'}". ` +
        `Available: ${available.length > 0 ? available.join(", ") : "none"}`
      );
    }

    return config;
  }

  /**
   * Create an LLM service for a named configuration
   */
  createLLMService(
    llmLogger: LLMLogger,
    configName?: string
  ): LLMService {
    const config = this.getLLMConfig(configName);
    return llmServiceFactory.createService(llmLogger, config);
  }

  // =====================================================================================
  // BUSINESS LOGIC METHODS
  // =====================================================================================

  /**
   * Get whitelisted pubkeys with CLI override support
   * If CLI option is provided, it ONLY uses those pubkeys (doesn't merge with config)
   * Otherwise, returns pubkeys from the configuration
   */
  getWhitelistedPubkeys(cliOption?: string, config?: TenexConfig): string[] {
    const pubkeys: Set<string> = new Set();

    // If CLI option is provided, ONLY use those pubkeys (don't merge with config)
    if (cliOption) {
      for (const pk of cliOption.split(",")) {
        const trimmed = pk.trim();
        if (trimmed) pubkeys.add(trimmed);
      }
      return Array.from(pubkeys);
    }

    // Otherwise, use config pubkeys
    if (config?.whitelistedPubkeys) {
      if (Array.isArray(config.whitelistedPubkeys)) {
        for (const pk of config.whitelistedPubkeys) {
          if (pk) pubkeys.add(pk);
        }
      }
    }

    return Array.from(pubkeys);
  }

  // =====================================================================================
  // CONVENIENCE METHODS
  // =====================================================================================

  async saveGlobalConfig(config: TenexConfig): Promise<void> {
    const globalPath = this.getGlobalPath();
    await ensureDirectory(globalPath);
    await this.saveTenexConfig(globalPath, config);
  }

  async saveProjectConfig(projectPath: string, config: TenexConfig): Promise<void> {
    const projPath = this.getProjectPath(projectPath);
    await ensureDirectory(projPath);
    await this.saveTenexConfig(projPath, config);
  }

  async saveGlobalAgents(agents: TenexAgents): Promise<void> {
    const globalPath = this.getGlobalPath();
    await ensureDirectory(globalPath);
    await this.saveTenexAgents(globalPath, agents);
  }

  async loadProjectAgents(projectPath: string): Promise<TenexAgents> {
    const projPath = this.getProjectPath(projectPath);
    return this.loadTenexAgents(projPath);
  }

  async saveProjectAgents(projectPath: string, agents: TenexAgents): Promise<void> {
    const projPath = this.getProjectPath(projectPath);
    await ensureDirectory(projPath);
    await this.saveTenexAgents(projPath, agents);
  }

  async saveGlobalLLMs(llms: TenexLLMs): Promise<void> {
    const globalPath = this.getGlobalPath();
    await ensureDirectory(globalPath);
    await this.saveTenexLLMs(globalPath, llms);
  }

  async saveProjectLLMs(projectPath: string, llms: TenexLLMs): Promise<void> {
    const projPath = this.getProjectPath(projectPath);
    await ensureDirectory(projPath);
    await this.saveTenexLLMs(projPath, llms);
  }

  async saveGlobalMCP(mcp: TenexMCP): Promise<void> {
    const globalPath = this.getGlobalPath();
    await ensureDirectory(globalPath);
    await this.saveTenexMCP(globalPath, mcp);
  }

  async saveProjectMCP(projectPath: string, mcp: TenexMCP): Promise<void> {
    const projPath = this.getProjectPath(projectPath);
    await ensureDirectory(projPath);
    await this.saveTenexMCP(projPath, mcp);
  }

  // =====================================================================================
  // FILE EXISTENCE CHECKS
  // =====================================================================================

  async configExists(basePath: string, configFile: ConfigFile): Promise<boolean> {
    return fileExists(this.getConfigFilePath(basePath, configFile));
  }

  async globalConfigExists(configFile: ConfigFile): Promise<boolean> {
    return this.configExists(this.getGlobalPath(), configFile);
  }

  async projectConfigExists(projectPath: string, configFile: ConfigFile): Promise<boolean> {
    return this.configExists(this.getProjectPath(projectPath), configFile);
  }

  // =====================================================================================
  // PRIVATE IMPLEMENTATION
  // =====================================================================================

  private async loadConfigFile<T>(
    filePath: string,
    schema: z.ZodSchema<T>,
    defaultValue: T
  ): Promise<T> {
    // Check cache first
    const cached = this.getFromCache<T>(filePath);
    if (cached) {
      return cached;
    }

    try {
      if (!(await fileExists(filePath))) {
        logger.debug(`Config file not found, using default: ${filePath}`);
        return defaultValue;
      }

      const data = await readJsonFile(filePath);
      const validated = schema.parse(data);

      this.addToCache(filePath, validated);
      return validated;
    } catch (error) {
      logger.error(`Failed to load config file: ${filePath}`, { error: formatAnyError(error) });
      return defaultValue;
    }
  }

  private async saveConfigFile<T>(
    filePath: string,
    data: T,
    schema: z.ZodSchema<T>
  ): Promise<void> {
    try {
      // Ensure directory exists
      await ensureDirectory(path.dirname(filePath));

      // Validate before saving
      const validated = schema.parse(data);

      // Save to file
      await writeJsonFile(filePath, validated);

      // Update cache
      this.addToCache(filePath, validated);

      logger.debug(`Configuration saved: ${filePath}`);
    } catch (error) {
      logger.error(`Failed to save config file: ${filePath}`, { error: formatAnyError(error) });
      throw error;
    }
  }

  private getFromCache<T>(filePath: string): T | null {
    const entry = this.cache.get(filePath);
    if (!entry) {
      return null;
    }

    const now = Date.now();
    if (now - entry.timestamp > 5000) {
      // 5 seconds TTL
      this.cache.delete(filePath);
      return null;
    }

    return entry.data as T;
  }

  private addToCache<T>(filePath: string, data: T): void {
    this.cache.set(filePath, {
      data,
      timestamp: Date.now(),
    });
  }

  clearCache(filePath?: string): void {
    if (filePath) {
      this.cache.delete(filePath);
    } else {
      this.cache.clear();
    }
  }
}

// Export singleton instance
export const configService = ConfigService.getInstance();
</file>

<file path="src/utils/inventory.ts">
import * as fs from "node:fs/promises";
import * as path from "node:path";
// LLMLogger will be accessed from ProjectContext
import { PromptBuilder } from "@/prompts/core/PromptBuilder";
import { configService, getProjectContext, isProjectContextInitialized } from "@/services";
import { formatAnyError } from "@/utils/error-formatter";
import { logger } from "@/utils/logger";
import { generateRepomixOutput } from "./repomix.js";
import "@/prompts"; // This ensures all fragments are registered
import type { AgentInstance } from "@/agents/types";

const DEFAULT_INVENTORY_PATH = "context/INVENTORY.md";
const MAX_COMPLEX_MODULES = 10;
const JSON_BLOCK_REGEX = /```json\s*\n([\s\S]*?)\n```/;
const COMPLEX_MODULES_SECTION_REGEX =
  /At the end.*?```json\s*\n[\s\S]*?"complexModules"[\s\S]*?\n```/g;

interface ComplexModule {
  name: string;
  path: string;
  reason: string;
  suggestedFilename: string;
}

interface ComplexModulesResponse {
  complexModules: ComplexModule[];
}

interface InventoryResult {
  content: string;
  complexModules: ComplexModule[];
}

interface InventoryGenerationOptions {
  conversationRootEventId?: string;
  agent?: AgentInstance;
  focusFiles?: Array<{ path: string; status: string }>;
}

/**
 * Generate comprehensive inventory using repomix + LLM
 */
export async function generateInventory(
  projectPath: string,
  options?: InventoryGenerationOptions
): Promise<void> {
  logger.info("Generating project inventory with repomix + LLM", { projectPath });

  const inventoryPath = await getInventoryPath(projectPath);

  // Ensure context directory exists
  await fs.mkdir(path.dirname(inventoryPath), { recursive: true });

  // Step 1: Generate repomix content once for efficiency
  const repomixResult = await generateRepomixOutput(projectPath);

  try {
    // Step 2: Generate main inventory with complex module identification
    const inventoryResult = await generateMainInventory(
      projectPath,
      repomixResult.content,
      options?.focusFiles
    );

    // Step 3: Save main inventory
    await fs.writeFile(inventoryPath, inventoryResult.content, "utf-8");
    logger.info("Main inventory saved", { inventoryPath });

    // Step 4: Generate individual module guides for complex modules (max MAX_COMPLEX_MODULES)
    const modulesToProcess = inventoryResult.complexModules.slice(0, MAX_COMPLEX_MODULES);

    for (let i = 0; i < modulesToProcess.length; i++) {
      const module = modulesToProcess[i];
      if (!module) continue; // Skip if module is undefined

      // TypeScript now knows module is defined
      const definedModule: ComplexModule = module;

      try {
        logger.debug(`üî¨ Inspecting complex module: ${definedModule.name} at ${definedModule.path}`);

        await generateModuleGuide(projectPath, definedModule, repomixResult.content);
      } catch (error) {
        logger.warn("Failed to generate module guide", {
          module: definedModule.name,
          error: formatAnyError(error),
        });
      }
    }

    logger.info(
      `‚úÖ Project inventory generation completed!\n\nüìã Main inventory: ${inventoryPath}\nüìö Complex module guides: ${modulesToProcess.length} generated`
    );

    logger.info("Inventory generation completed", {
      inventoryPath,
      complexModules: modulesToProcess.length,
    });
  } finally {
    repomixResult.cleanup();
  }
}

/**
 * Generate main inventory and identify complex modules
 */
async function generateMainInventory(
  projectPath: string,
  repomixContent: string,
  focusFiles?: Array<{ path: string; status: string }>
): Promise<InventoryResult> {
  logger.debug("Generating main inventory", {
    hasFocusFiles: !!focusFiles,
    focusFileCount: focusFiles?.length,
  });

  // Use PromptBuilder to construct the prompt from fragments
  const prompt = new PromptBuilder()
    .add("main-inventory-generation", { repomixContent, focusFiles })
    .build();

  const projectCtx = getProjectContext();
  const llmLogger = projectCtx.llmLogger;
  const llmService = configService.createLLMService(llmLogger);

  // Debug: Log the LLM service loaded
  logger.debug("[inventory] LLM Service loaded");

  const userMessage = { role: "user" as const, content: prompt };

  logger.debug("[inventory] Calling LLM with configName", {
    configName: "defaults.analyze",
    expectedResolution: "Should resolve to gemini-2.5",
  });

  const response = await llmService.complete(
    "defaults.analyze",
    [userMessage],
    "inventory-generator",
    {
      temperature: 0.3,
      maxTokens: 4000,
    }
  );

  const content = response.text || "";

  // Extract complex modules from JSON at the end
  const complexModules = await extractComplexModules(content, projectPath);

  // Strip the complexModules JSON block from the content before saving
  const cleanContent = stripComplexModulesJson(content);

  return {
    content: cleanContent,
    complexModules,
  };
}

/**
 * Generate detailed guide for a specific complex module
 */
async function generateModuleGuide(
  projectPath: string,
  module: ComplexModule,
  repomixContent: string
): Promise<void> {
  logger.debug("Generating module guide", { module: module.name });

  // Use PromptBuilder to construct the prompt from fragments
  const prompt = new PromptBuilder()
    .add("module-guide-generation", {
      repomixContent,
      moduleName: module.name,
      modulePath: module.path,
      complexityReason: module.reason,
    })
    .build();

  const llmRouter = await loadLLMRouter(projectPath);
  const userMessage = new Message("user", prompt);

  logger.debug("[inventory] Calling LLM for module guide", {
    module: module.name,
    configName: "defaults.analyze",
  });

  const response = await llmRouter.complete({
    messages: [userMessage],
    options: {
      temperature: 0.3,
      maxTokens: 6000,
      configName: "defaults.analyze",
    },
  });

  // Save module guide
  const inventoryPath = await getInventoryPath(projectPath);
  const contextDir = path.dirname(inventoryPath);
  const guideFilePath = path.join(contextDir, module.suggestedFilename);

  await fs.writeFile(guideFilePath, response.text || "", "utf-8");
  logger.info("Module guide saved", {
    module: module.name,
    guideFilePath,
  });
}

/**
 * Strip the complexModules JSON block from the inventory content
 */
function stripComplexModulesJson(content: string): string {
  // Remove the entire complex modules JSON section
  let cleanedContent = content.replace(COMPLEX_MODULES_SECTION_REGEX, "").trim();

  // Also handle case where JSON block might appear without the instruction text
  const jsonMatches = cleanedContent.match(JSON_BLOCK_REGEX);
  if (jsonMatches) {
    for (const match of jsonMatches) {
      if (match.includes('"complexModules"')) {
        cleanedContent = cleanedContent.replace(match, "").trim();
      }
    }
  }

  return cleanedContent;
}

/**
 * Type guard to validate complex modules response structure
 */
function isComplexModulesResponse(data: unknown): data is ComplexModulesResponse {
  if (typeof data !== "object" || data === null) {
    return false;
  }

  const obj = data as Record<string, unknown>;

  if (!Array.isArray(obj.complexModules)) {
    return false;
  }

  return obj.complexModules.every((module: unknown) => {
    if (typeof module !== "object" || module === null) {
      return false;
    }

    const mod = module as Record<string, unknown>;
    return (
      typeof mod.name === "string" &&
      typeof mod.path === "string" &&
      typeof mod.reason === "string" &&
      typeof mod.suggestedFilename === "string"
    );
  });
}

/**
 * Parse JSON from content and validate it
 */
function parseComplexModulesJson(jsonString: string): ComplexModule[] | null {
  try {
    const jsonData = JSON.parse(jsonString) as unknown;
    if (isComplexModulesResponse(jsonData)) {
      return jsonData.complexModules;
    }
    return null;
  } catch {
    return null;
  }
}

/**
 * Extract complex modules from LLM response with fallback mechanism
 */
async function extractComplexModules(
  content: string,
  projectPath?: string
): Promise<ComplexModule[]> {
  try {
    // Look for JSON block at the end
    const jsonMatch = content.match(JSON_BLOCK_REGEX);
    if (!jsonMatch) {
      logger.debug("No JSON block found in response, trying fallback extraction");
      return projectPath ? await fallbackExtractComplexModules(content, projectPath) : [];
    }

    const jsonString = jsonMatch[1];
    if (!jsonString) {
      logger.warn("Empty JSON match found");
      return projectPath ? await fallbackExtractComplexModules(content, projectPath) : [];
    }

    const modules = parseComplexModulesJson(jsonString);
    if (modules) {
      return modules;
    }

    logger.warn("Invalid JSON structure for complex modules");
    return [];
  } catch (error) {
    logger.warn("Failed to extract complex modules from JSON, trying fallback", { error });
    return projectPath ? await fallbackExtractComplexModules(content, projectPath) : [];
  }
}

/**
 * Fallback mechanism for JSON extraction using a cleanup LLM call
 */
async function fallbackExtractComplexModules(
  content: string,
  projectPath?: string
): Promise<ComplexModule[]> {
  if (!projectPath) {
    logger.warn("No project path provided for fallback extraction");
    return [];
  }

  try {
    // Use PromptBuilder to construct the prompt from fragments
    const cleanupPrompt = new PromptBuilder()
      .add("complex-modules-extraction", { content })
      .build();

    const projectCtx = getProjectContext();
  const llmLogger = projectCtx.llmLogger;
  const llmService = configService.createLLMService(llmLogger);
    const userMessage = { role: "user" as const, content: cleanupPrompt };

    logger.debug("[inventory] Calling LLM for fallback extraction", {
      configName: "defaults.analyze",
    });

    const response = await llmService.complete(
      "defaults.analyze",
      [userMessage],
      "inventory-search",
      {
        temperature: 0.1,
        maxTokens: 1000,
      }
    );

    const fallbackContent = response.text || "";
    const jsonMatch = fallbackContent.match(JSON_BLOCK_REGEX);

    if (jsonMatch) {
      const jsonString = jsonMatch[1];
      if (!jsonString) {
        logger.warn("Empty JSON match found in fallback");
        return [];
      }

      const modules = parseComplexModulesJson(jsonString);
      if (modules) {
        return modules;
      }

      logger.warn("Invalid JSON structure in fallback extraction");
    }

    return [];
  } catch (error) {
    logger.warn("Fallback extraction failed", { error });
    return [];
  }
}

/**
 * Update inventory for specific files (placeholder for future implementation)
 */
export async function updateInventory(projectPath: string, files: string[]): Promise<void> {
  logger.info("Updating inventory", { projectPath, files });
  // For now, just regenerate the full inventory
  // Future optimization: implement partial updates
  await generateInventory(projectPath);
}

/**
 * Check if inventory exists
 */
export async function inventoryExists(projectPath: string): Promise<boolean> {
  try {
    const inventoryPath = await getInventoryPath(projectPath);
    await fs.access(inventoryPath);
    return true;
  } catch {
    return false;
  }
}

/**
 * Load inventory content for system prompts
 */
export async function loadInventoryContent(projectPath: string): Promise<string | null> {
  try {
    const inventoryPath = await getInventoryPath(projectPath);
    const content = await fs.readFile(inventoryPath, "utf-8");
    return content;
  } catch (error) {
    logger.debug("Failed to load inventory content", { error });
    return null;
  }
}

/**
 * Get the inventory file path
 */
async function getInventoryPath(projectPath: string): Promise<string> {
  const projectConfig = await loadProjectConfig(projectPath);
  const inventoryPath = projectConfig?.paths?.inventory || DEFAULT_INVENTORY_PATH;
  return path.join(projectPath, inventoryPath);
}

/**
 * Load project configuration
 */
async function loadProjectConfig(
  projectPath: string
): Promise<{ paths?: { inventory?: string }; title?: string }> {
  try {
    if (isProjectContextInitialized()) {
      // Get config from ProjectContext if available
      const projectCtx = getProjectContext();
      const project = projectCtx.project;
      const titleTag = project.tags.find((tag) => tag[0] === "title");
      return {
        paths: { inventory: DEFAULT_INVENTORY_PATH },
        title: titleTag?.[1] || "Untitled Project",
      };
    }
    // Fallback: try to load config directly
    const { config } = await configService.loadConfig(projectPath);
    return config;
  } catch (error) {
    logger.debug("Failed to load project config", { error });
    return { paths: { inventory: DEFAULT_INVENTORY_PATH } };
  }
}
</file>

<file path="src/tenex.ts">
#!/usr/bin/env bun

import { handleCliError } from "@/utils/cli-error";
// CLI entry point for TENEX
import { Command } from "commander";
import { agentCommand } from "./commands/agent/index";
import { daemonCommand } from "./commands/daemon";
import { runDebugSystemPrompt } from "./commands/debug/index";
import { inventoryCommand } from "./commands/inventory/index";
import { mcpCommand } from "./commands/mcp/index";
import { projectCommand } from "./commands/project/index";
import { setupCommand } from "./commands/setup/index";
import { initNDK } from "./nostr/ndkClient";

const program = new Command();

program.name("tenex").description("TENEX Command Line Interface").version("0.1.0");

// Add main commands
program.addCommand(agentCommand);
program.addCommand(daemonCommand);
program.addCommand(projectCommand);
program.addCommand(setupCommand);
program.addCommand(inventoryCommand);
program.addCommand(mcpCommand);

// Add debug command
const debug = program.command("debug").description("Debug commands");
debug
  .command("system-prompt")
  .description("Show the system prompt for an agent")
  .option("--agent <name>", "Agent name", "default")
  .action((options) => runDebugSystemPrompt(options));

// Initialize NDK before parsing commands
export async function main(): Promise<void> {
  await initNDK();
  program.parse(process.argv);
}

// Only run if called directly (not imported)
if (import.meta.url === `file://${process.argv[1]}`) {
  main().catch((error) => {
    handleCliError(error, "Fatal error in TENEX CLI");
  });
}
</file>

<file path="src/conversations/services/ConversationEventProcessor.ts">
import { getNDK } from "@/nostr";
import { getAgentSlugFromEvent, isEventFromUser } from "@/nostr/utils";
import { logger } from "@/utils/logger";
import type { NDKEvent } from "@nostr-dev-kit/ndk";
import { NDKArticle } from "@nostr-dev-kit/ndk";
import { ensureExecutionTimeInitialized } from "../executionTime";
import type { Conversation, ConversationMetadata } from "../types";

/**
 * Processes events and creates/updates conversations.
 * Single Responsibility: Handle event processing and metadata extraction.
 */
export class ConversationEventProcessor {
  /**
   * Create a new conversation from an initial event
   */
  async createConversationFromEvent(event: NDKEvent): Promise<Conversation> {
    const id = event.id;
    if (!id) {
      throw new Error("Event must have an ID to create a conversation");
    }

    const title = event.tags.find((tag) => tag[0] === "title")?.[1] || "Untitled Conversation";
    const referencedArticle = await this.extractReferencedArticle(event);

    const conversation: Conversation = {
      id,
      title,
      phase: "CHAT", // Default initial phase - can be changed dynamically
      history: [event],
      agentStates: new Map(),
      phaseStartedAt: Date.now(),
      metadata: {
        summary: event.content,
        referencedArticle,
      },
      executionTime: {
        totalSeconds: 0,
        isActive: false,
        lastUpdated: Date.now(),
      },
    };

    ensureExecutionTimeInitialized(conversation);

    return conversation;
  }

  /**
   * Process an incoming event and add it to a conversation
   */
  processIncomingEvent(conversation: Conversation, event: NDKEvent): void {
    // Check if event already exists in history to prevent duplicates
    if (conversation.history.some((e) => e.id === event.id)) {
      return;
    }

    // Add to history
    conversation.history.push(event);

    // Update metadata if it's a user message
    if (event.content && isEventFromUser(event)) {
      conversation.metadata.summary = event.content;
      conversation.metadata.last_user_message = event.content;
    }

    logger.debug(
      `[ConversationEventProcessor] Processed event for conversation ${conversation.id}`,
      {
        eventId: event.id,
        isUser: isEventFromUser(event),
      }
    );
  }

  /**
   * Update conversation metadata
   */
  updateMetadata(conversation: Conversation, metadata: Partial<ConversationMetadata>): void {
    conversation.metadata = {
      ...conversation.metadata,
      ...metadata,
    };

    logger.debug(
      `[ConversationEventProcessor] Updated metadata for conversation ${conversation.id}`,
      {
        updatedFields: Object.keys(metadata),
      }
    );
  }

  /**
   * Extract referenced NDKArticle from event tags
   */
  private async extractReferencedArticle(
    event: NDKEvent
  ): Promise<ConversationMetadata["referencedArticle"] | undefined> {
    const articleTag = event.tags.find((tag) => tag[0] === "a" && tag[1]?.startsWith("30023:"));

    if (!articleTag || !articleTag[1]) {
      return undefined;
    }

    try {
      // Parse the article reference (format: 30023:pubkey:dtag)
      const [_kind, pubkey, dTag] = articleTag[1].split(":");

      if (!pubkey || !dTag) {
        return undefined;
      }

      const ndk = getNDK();
      const filter = {
        kinds: [30023],
        authors: [pubkey],
        "#d": [dTag],
      };

      const articles = await ndk.fetchEvents(filter);

      if (articles.size > 0) {
        const articleEvent = Array.from(articles)[0];
        if (!articleEvent) {
          throw new Error("Article event not found");
        }
        const article = NDKArticle.from(articleEvent);

        return {
          title: article.title || `Context: ${dTag}`,
          content: article.content || "",
          dTag: dTag,
        };
      }
    } catch (error) {
      logger.error("[ConversationEventProcessor] Failed to fetch referenced NDKArticle", { error });
    }

    return undefined;
  }

  /**
   * Clean up conversation metadata that's no longer needed
   */
  cleanupMetadata(conversation: Conversation): void {
    // Clear readFiles tracking
    if (conversation.metadata.readFiles) {
      logger.info("[ConversationEventProcessor] Cleaning up readFiles metadata", {
        conversationId: conversation.id,
        fileCount: conversation.metadata.readFiles.length,
      });
      conversation.metadata.readFiles = undefined;
    }

  }

  /**
   * Extract completion from an event
   */
  extractCompletionFromEvent(event: NDKEvent): {
    agent: string;
    message: string;
    timestamp?: number;
  } | null {
    // Check if event has ["status", "completed"] tag
    const isCompletion = event.tags?.some((tag) => 
      tag[0] === "status" && tag[1] === "completed"
    );

    if (!isCompletion || !event.content) return null;

    // Get agent slug from the event's pubkey
    const agentSlug = getAgentSlugFromEvent(event);
    if (!agentSlug) return null;

    return {
      agent: agentSlug,
      message: event.content,
      timestamp: event.created_at,
    };
  }
}
</file>

<file path="src/conversations/types.ts">
import type { NDKEvent } from "@nostr-dev-kit/ndk";

// Phase is now just a string - fully dynamic
export type Phase = string;

// Simplified agent state to track what an agent has seen
export interface AgentState {
  lastProcessedMessageIndex: number; // Index into Conversation.history
  claudeSessionsByPhase?: Record<Phase, string>; // Claude Code session IDs per phase
  claudeAiSdkSessionsByPhase?: Record<Phase, string>; // AI SDK Claude Code session IDs per phase (parallel implementation)
  lastSeenPhase?: Phase; // Track the last phase this agent operated in
}

export interface Conversation {
  id: string;
  title?: string;
  phase: Phase;
  phaseInstructions?: string; // Custom instructions for the current phase
  history: NDKEvent[]; // The SINGLE source of truth for all events/messages
  agentStates: Map<string, AgentState>; // Track what each agent has seen in 'history'
  phaseStartedAt?: number;
  metadata: ConversationMetadata;

  // Execution time tracking
  executionTime: {
    totalSeconds: number;
    currentSessionStart?: number;
    isActive: boolean;
    lastUpdated: number;
  };
}

export interface ConversationMetadata {
  branch?: string; // Git branch for execution phase
  summary?: string; // Current understanding/summary
  requirements?: string; // Captured requirements
  plan?: string; // Approved plan
  readFiles?: string[]; // Files read during this conversation (for write_context_file security)
  projectPath?: string; // Project path for debug commands
  last_user_message?: string; // Last message from the user
  referencedArticle?: {
    title: string;
    content: string;
    dTag: string;
  }; // NDKArticle referenced by kind:11 event (30023)
}
</file>

<file path="src/llm/models.ts">
import type { LLMProvider } from "./types";

// Simple model lists - no need to fetch dynamically
// OpenRouter handles 300+ models, we just need to know the string format

export const KNOWN_MODELS = {
  openai: [
    "gpt-4-turbo",
    "gpt-4",
    "gpt-3.5-turbo",
    "gpt-4o",
    "gpt-4o-mini",
  ],
  anthropic: [
    "claude-3-opus",
    "claude-3-sonnet", 
    "claude-3-haiku",
    "claude-3.5-sonnet",
  ],
  google: [
    "gemini-2.0-flash",
    "gemini-1.5-pro",
    "gemini-1.5-flash",
  ],
  // OpenRouter handles all these through provider prefixes
  openrouter: [
    "openai/gpt-4",
    "anthropic/claude-3-sonnet",
    "google/gemini-2.0-flash",
    "meta-llama/llama-3.3-70b-instruct",
    // ... 300+ more models
  ],
  // ClaudeCode phases - LIMITED to phase-0
  claudeCode: [
    "phase-0",  // Only phase-0 is available in Track 1
  ]
};

/**
 * Get available models for a provider
 */
export async function getModelsForProvider(
  provider: LLMProvider
): Promise<string[] | null> {
  // For OpenRouter, models are specified as provider/model
  if (provider === "openrouter") {
    return KNOWN_MODELS.openrouter;
  }
  
  // Return known models for each provider
  return KNOWN_MODELS[provider as keyof typeof KNOWN_MODELS] || null;
}

/**
 * Get all available models grouped by provider
 */
export async function getAllModels(): Promise<typeof KNOWN_MODELS> {
  return KNOWN_MODELS;
}
</file>

<file path="src/llm/service.ts">
import type { LLMLogger } from "@/logging/LLMLogger";
import type { AISdkTool } from "@/tools/registry";
import { logger } from "@/utils/logger";
import {
    type LanguageModelUsage,
    type LanguageModel,
    type StepResult,
    type TextStreamPart,
    type ProviderRegistry,
    generateText,
    stepCountIs,
    streamText,
} from "ai";
import type { ModelMessage } from "ai";
import chalk from "chalk";
import { EventEmitter } from "tseep";
import { LanguageModelUsageWithCostUsd } from "./types";

// Define the event types for LLMService
interface LLMServiceEvents {
    content: (data: { delta: string }) => void;
    "chunk-type-change": (data: { from: string | undefined; to: string }) => void;
    "tool-will-execute": (data: { toolName: string; toolCallId: string; args: unknown }) => void;
    "tool-did-execute": (data: {
        toolName: string;
        toolCallId: string;
        result: unknown;
        error?: boolean;
    }) => void;
    complete: (data: {
        message: string;
        steps: StepResult<Record<string, AISdkTool>>[];
        usage: LanguageModelUsageWithCostUsd;
    }) => void;
    "stream-error": (data: { error: unknown }) => void;
    // Add index signatures for EventEmitter compatibility
    [key: string]: (...args: any[]) => void;
    [key: symbol]: (...args: any[]) => void;
}

/**
 * LLM Service for runtime execution with AI SDK providers
 * Pure runtime concerns - no configuration management
 */
export class LLMService extends EventEmitter<LLMServiceEvents> {
    public readonly provider: string;
    public readonly model: string;
    private readonly temperature?: number;
    private readonly maxTokens?: number;
    private previousChunkType?: string;

    constructor(
        private readonly llmLogger: LLMLogger,
        private readonly registry: ProviderRegistry,
        provider: string,
        model: string,
        temperature?: number,
        maxTokens?: number
    ) {
        super();
        this.provider = provider;
        this.model = model;
        this.temperature = temperature;
        this.maxTokens = maxTokens;

        logger.debug("[LLMService] Initialized", {
            provider: this.provider,
            model: this.model,
            temperature: this.temperature,
            maxTokens: this.maxTokens,
        });
    }

    /**
     * Get a language model from the registry.
     * This method encapsulates the AI SDK's requirement for concatenated strings.
     */
    private getLanguageModel(): LanguageModel {
        // AI SDK requires this format - we encapsulate it here
        return this.registry.languageModel(`${this.provider}:${this.model}`);
    }

    /**
     * Add provider-specific cache control to messages.
     * Only Anthropic requires explicit cache control; OpenAI and Gemini cache automatically.
     */
    private addCacheControl(messages: ModelMessage[]): ModelMessage[] {
        // Only add cache control for Anthropic
        if (this.provider !== 'anthropic') {
            return messages;
        }

        return messages.map((msg) => {
            // Only cache system messages and only if they're large enough (>1024 tokens estimate)
            if (msg.role === 'system' && msg.content.length > 4000) { // ~1000 tokens
                return {
                    ...msg,
                    providerOptions: {
                        anthropic: {
                            cacheControl: { type: 'ephemeral' }
                        }
                    }
                };
            }
            return msg;
        });
    }

    async complete(
        messages: ModelMessage[],
        tools: Record<string, AISdkTool>,
        options?: {
            temperature?: number;
            maxTokens?: number;
        }
    ): Promise<unknown> {
        const model = this.getLanguageModel();
        const startTime = Date.now();
        
        // Add provider-specific cache control
        const processedMessages = this.addCacheControl(messages);

        // Log the request
        this.llmLogger
            .logLLMRequest({
                provider: this.provider,
                model: this.model,
                messages,
                tools: Object.keys(tools).map((name) => ({ name })),
                startTime,
            })
            .catch((err) => {
                logger.error("[LLMService] Failed to log request", { error: err });
            });

        try {
            const result = await generateText({
                model,
                messages: processedMessages,
                tools,
                temperature: options?.temperature ?? this.temperature,
                maxOutputTokens: options?.maxTokens ?? this.maxTokens,
            });

            const duration = Date.now() - startTime;

            // Log the response
            this.llmLogger
                .logLLMResponse({
                    response: {
                        content: result.text,
                        usage: result.usage,
                    },
                    endTime: Date.now(),
                    startTime,
                })
                .catch((err) => {
                    logger.error("[LLMService] Failed to log response", { error: err });
                });

            logger.info("[LLMService] Complete response received", {
                model: `${this.provider}:${this.model}`,
                duration,
                usage: result.usage,
                toolCallCount: result.toolCalls?.length || 0,
                responseLength: result.text?.length || 0,
            });

            return result;
        } catch (error) {
            const duration = Date.now() - startTime;

            this.llmLogger
                .logLLMResponse({
                    error: error as Error,
                    endTime: Date.now(),
                    startTime,
                })
                .catch((err) => {
                    logger.error("[LLMService] Failed to log error", { error: err });
                });

            logger.error("[LLMService] Complete failed", {
                model: `${this.provider}:${this.model}`,
                duration,
                error: error instanceof Error ? error.message : String(error),
            });
            throw error;
        }
    }

    async stream(
        messages: ModelMessage[], 
        tools: Record<string, AISdkTool>,
        options?: {
            abortSignal?: AbortSignal;
        }
    ): Promise<void> {
        const model = this.getLanguageModel();
        
        // Add provider-specific cache control
        const processedMessages = this.addCacheControl(messages);

        // Log the request
        this.llmLogger
            .logLLMRequest({
                provider: this.provider,
                model: this.model,
                messages,
                tools: Object.keys(tools).map((name) => ({ name })),
                startTime: Date.now(),
            })
            .catch((err) => {
                logger.error("[LLMService] Failed to log request", { error: err });
            });

        const startTime = Date.now();

        // Create the stream outside the promise
        const { textStream, response } = streamText({
            model,
            messages: processedMessages,
            tools: tools,
            temperature: this.temperature,
            maxOutputTokens: this.maxTokens,
            stopWhen: stepCountIs(20),
            abortSignal: options?.abortSignal,
            providerOptions: {
                openrouter: {
                    usage: { include: true },
                },
            },

            // Check for delegation completion and inject follow-up hint
            prepareStep: async (options) => {
                // console.log(
                //     `running prepareStep (${options.stepNumber}) (${options.messages.length})`,
                //     options.steps.map((s) => ({
                //         content: s.content,
                //         usage: s.usage,
                //         finishReason: s.finishReason,
                //         providerMetadata: s.providerMetadata,
                //     }))
                // );
                // console.log(`<MESSAGES ${options.stepNumber}>`)
                // console.log(JSON.stringify(options.messages, null, 4));
                // console.log(`</MESSAGES ${options.stepNumber}>`);

                const lastStep = options.steps[options.steps.length - 1];
                const lastToolCall = lastStep?.toolCalls?.[0];

                // Check if last tool was a delegation
                const delegationTools = [
                    "delegate",
                    "delegate_phase",
                    "delegate_external",
                    "delegate_followup",
                ];
                if (lastToolCall && delegationTools.includes(lastToolCall.toolName)) {
                    const lastResult = lastStep?.toolResults?.[0];

                    // Check if we got responses
                    if (lastResult?.responses?.length > 0) {
                        // Add assistant message about follow-up capability
                        return {
                            messages: [
                                {
                                    role: "assistant",
                                    content: `I've received the delegation response. If I need any clarification or have follow-up questions, I can use delegate_followup to continue the conversation with the responding agent.`,
                                },
                            ],
                        };
                    }
                }
            },

            onChunk: this.handleChunk.bind(this),
            onFinish: this.createFinishHandler(startTime),
        });

        // Consume the stream (this is what triggers everything!)
        try {
            // CRITICAL: This loop is what actually triggers the stream execution
            for await (const _chunk of textStream) {
                // Consume the stream to trigger execution
            }

            await textStream;

            const responseAwaited = await response;
            console.log("llm service response messages", responseAwaited?.messages);
        } catch (error) {
            await this.handleStreamError(error, startTime);
            throw error;
        }
    }

    private handleChunk(event: { chunk: TextStreamPart<Record<string, AISdkTool>> }): void {
        const chunk = event.chunk;
        console.log("LLMService chunk", event, chunk.type, chalk.gray(chunk.text));

        // Emit chunk-type-change event if the type changed
        if (this.previousChunkType !== undefined && this.previousChunkType !== chunk.type) {
            this.emit("chunk-type-change", {
                from: this.previousChunkType,
                to: chunk.type
            });
        }

        switch (chunk.type) {
            case "text-delta":
                if (chunk.text) {
                    this.handleTextDelta(chunk.text);
                }
                break;
            case "reasoning-delta":
                // Handle reasoning-delta separately - emit reasoning event
                if (chunk.text) {
                    this.handleReasoningDelta(chunk.text);
                }
                break;
            case "tool-call":
                console.log(chunk)
                this.handleToolCall(chunk.toolCallId, chunk.toolName, chunk.input);
                break;
            case "tool-result":
                this.handleToolResult(chunk.toolCallId, chunk.toolName, chunk.output);
                break;
        }

        // Update previous chunk type
        this.previousChunkType = chunk.type;
    }

    private createFinishHandler(startTime: number) {
        return async (
            e: StepResult<Record<string, AISdkTool>> & {
                steps: StepResult<Record<string, AISdkTool>>[];
                totalUsage: LanguageModelUsage;
                providerMetadata: Record<string, any>;
            }
        ) => {
            const duration = Date.now() - startTime;

            try {
                await this.llmLogger.logLLMResponse({
                    response: {
                        content: e.text,
                        usage: e.totalUsage,
                    },
                    endTime: Date.now(),
                    startTime,
                });

                logger.info("[LLMService] Stream finished", {
                    duration,
                    model: this.model,
                    startTime,
                });

                this.emit("complete", {
                    message: e.text || "",
                    steps: e.steps,
                    usage: {
                        costUsd: e.providerMetadata?.openrouter?.usage?.cost,
                        ...(e.totalUsage || {}),
                    },
                });
            } catch (error) {
                logger.error("[LLMService] Error in onFinish handler", {
                    error: error instanceof Error ? error.message : String(error),
                });
                throw error;
            }
        };
    }

    private async handleStreamError(error: unknown, startTime: number): Promise<void> {
        console.log("error", error);
        const duration = Date.now() - startTime;

        await this.llmLogger
            .logLLMResponse({
                error: error as Error,
                endTime: Date.now(),
                startTime,
            })
            .catch((err) => {
                logger.error("[LLMService] Failed to log error response", { error: err });
            });

        logger.error("[LLMService] Stream failed", {
            model: `${this.provider}:${this.model}`,
            duration,
            error: error instanceof Error ? error.message : String(error),
        });
    }

    private handleTextDelta(text: string): void {
        this.emit("content", { delta: text });
    }

    private handleReasoningDelta(text: string): void {
        this.emit("reasoning", { delta: text });
    }

    private handleToolCall(toolCallId: string, toolName: string, args: unknown): void {
        console.log("LLM Service: tool will execute", toolName, args);
        this.emit("tool-will-execute", {
            toolName,
            toolCallId,
            args,
        });
    }

    private handleToolResult(toolCallId: string, toolName: string, result: unknown): void {
        console.log("LLM Service: tool did execute", toolName, result);
        this.emit("tool-did-execute", {
            toolName,
            toolCallId,
            result,
        });
    }
}
</file>

<file path="src/prompts/utils/llmMetadata.ts">
import type { CompletionResponse } from "@/llm/types";
import type { LLMMetadata } from "@/nostr/types";
import type { ModelMessage } from "ai";

interface ResponseWithUsage {
  usage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens?: number;
  };
  experimental_providerMetadata?: {
    openrouter?: { usage?: { total_cost?: number } };
  };
  model?: string;
}

export async function buildLLMMetadata(
  response: CompletionResponse,
  messages: ModelMessage[]
): Promise<LLMMetadata | undefined> {
  if (!response.usage) {
    return undefined;
  }

  // Convert CompletionResponse to ResponseWithUsage format
  const responseWithUsage: ResponseWithUsage = {
    usage: {
      promptTokens: response.usage.prompt_tokens,
      completionTokens: response.usage.completion_tokens,
      totalTokens: response.usage.prompt_tokens + response.usage.completion_tokens,
    },
    model: response.model,
    experimental_providerMetadata:
      "experimental_providerMetadata" in response
        ? (response.experimental_providerMetadata as ResponseWithUsage["experimental_providerMetadata"])
        : undefined,
  };

  const model = responseWithUsage.model || "unknown";
  const cost = await calculateCost(responseWithUsage, model);

  const systemPrompt = messages.find((m) => m.role === "system")?.content;
  const userPrompt = messages.find((m) => m.role === "user")?.content;

  return {
    model,
    cost,
    promptTokens: response.usage.prompt_tokens,
    completionTokens: response.usage.completion_tokens,
    totalTokens: response.usage.prompt_tokens + response.usage.completion_tokens,
    systemPrompt,
    userPrompt,
    rawResponse: response.content,
  };
}

export async function calculateCost(response: ResponseWithUsage): Promise<number> {
  // Check if OpenRouter already calculated the cost
  const openRouterCost = response.experimental_providerMetadata?.openrouter?.usage?.total_cost;
  if (openRouterCost !== undefined) {
    return openRouterCost;
  }

  // Fallback: rough estimate based on typical pricing
  // No hardcoded pricing - just use a generic estimate
  if (response.usage) {
    const { promptTokens, completionTokens } = response.usage;
    return ((promptTokens + completionTokens) / 1_000_000) * 1.0;
  }

  return 0;
}
</file>

<file path="src/nostr/AgentEventDecoder.ts">
import type { AgentInstance } from "@/agents/types";
import { EVENT_KINDS } from "@/llm/types";
import { getProjectContext } from "@/services";
import { type NDKEvent, NDKTask } from "@nostr-dev-kit/ndk";

/**
 * AgentEventDecoder - Utilities for decoding and analyzing Nostr events
 *
 * This class provides static methods for extracting information from Nostr events
 * and determining their types, targets, and relationships.
 */

// biome-ignore lint/complexity/noStaticOnlyClass: Static utility class for decoding event semantics
export class AgentEventDecoder {
  /**
   * Check if an event is directed to the system (project or agents)
   */
  static isDirectedToSystem(event: NDKEvent, systemAgents: Map<string, AgentInstance>): boolean {
    const pTags = event.tags.filter((tag) => tag[0] === "p");
    if (pTags.length === 0) return false;

    const mentionedPubkeys = pTags
      .map((tag) => tag[1])
      .filter((pubkey): pubkey is string => !!pubkey);

    const systemPubkeys = new Set([...Array.from(systemAgents.values()).map((a) => a.pubkey)]);

    // Add project pubkey if available
    const projectCtx = getProjectContext();
    if (projectCtx.pubkey) {
      systemPubkeys.add(projectCtx.pubkey);
    }

    return mentionedPubkeys.some((pubkey) => systemPubkeys.has(pubkey));
  }

  /**
   * Check if event is from an agent in the system
   */
  static isEventFromAgent(event: NDKEvent, systemAgents: Map<string, AgentInstance>): boolean {
    const agentPubkeys = new Set(Array.from(systemAgents.values()).map((a) => a.pubkey));
    return agentPubkeys.has(event.pubkey);
  }

  /**
   * Check if this is a task completion event (for NDKTask kind:1934)
   * Note: This is different from delegation completions (kind:1111)
   */
  static isTaskCompletionEvent(event: NDKEvent): boolean {
    // Only for actual NDKTask completions, not delegations
    if (
      event.tagValue("K") === NDKTask.kind.toString() &&
      event.tagValue("P") === event.tagValue("p")
    ) {
      return true;
    }

    return false;
  }

  /**
   * Extract task ID from an event
   */
  static getTaskId(event: NDKEvent): string | undefined {
    // For task completions, the task ID is in the E tag
    if (AgentEventDecoder.isTaskCompletionEvent(event)) {
      return event.tagValue("E");
    }

    // For task events themselves
    if (event.kind === NDKTask.kind) {
      return event.id;
    }

    return undefined;
  }

  /**
   * Get conversation root from event
   */
  static getConversationRoot(event: NDKEvent): string | undefined {
    return event.tagValue("E") || event.tagValue("A");
  }

  /**
   * Get Claude session ID from event
   */
  static getClaudeSessionId(event: NDKEvent): string | undefined {
    return event.tagValue("claude-session");
  }

  /**
   * Check if event is an orphaned reply (reply without findable root)
   */
  static isOrphanedReply(event: NDKEvent): boolean {
    // Must be a kind 11 (text note reply)
    if (event.tagValue("K") !== "11") {
      return false;
    }

    // Must have a conversation root reference
    const hasRoot = !!(event.tagValue("E") || event.tagValue("A"));

    // Must have p-tags (directed to someone)
    const hasPTags = event.tags.some((tag) => tag[0] === "p");

    return hasRoot && hasPTags;
  }

  /**
   * Get mentioned pubkeys from event
   */
  static getMentionedPubkeys(event: NDKEvent): string[] {
    return event.tags
      .filter((tag) => tag[0] === "p")
      .map((tag) => tag[1])
      .filter((pubkey): pubkey is string => !!pubkey);
  }

  /**
   * Check if this is an agent's internal message (completion, delegation, etc)
   */
  static isAgentInternalMessage(event: NDKEvent): boolean {
    // Events with tool tags are internal agent operations
    if (event.tagValue("tool")) {
      return true;
    }

    // Status events are internal
    if (event.tagValue("status")) {
      return true;
    }

    return false;
  }

  /**
   * Extract phase from event if present
   */
  static getPhase(event: NDKEvent): string | undefined {
    return event.tagValue("phase");
  }

  /**
   * Check if event is a delegation request (kind:1111 from agent to agent)
   */
  static isDelegationRequest(event: NDKEvent, systemAgents?: Map<string, AgentInstance>): boolean {
    // Must be kind:1111
    if (event.kind !== 1111) return false;
    
    // If we have system agents, verify it's from an agent
    if (systemAgents) {
      const isFromAgent = this.isEventFromAgent(event, systemAgents);
      if (!isFromAgent) return false;
      
      // Check if p-tag points to another agent
      const pTag = event.tagValue("p");
      if (pTag && Array.from(systemAgents.values()).some(a => a.pubkey === pTag)) {
        return true;
      }
    } else {
      // Fallback: just check if it has a p-tag (less accurate)
      return !!event.tagValue("p");
    }
    
    return false;
  }
  
  /**
   * Check if event is a delegation completion (kind:1111 with tool:complete)
   */
  static isDelegationCompletion(event: NDKEvent): boolean {
    return event.kind === 1111 && 
           event.tagValue("status") === "completed";
  }
  
  /**
   * Get the delegation request ID from a completion event
   * Checks all e-tags to find the first valid delegation request ID
   */
  static getDelegationRequestId(event: NDKEvent): string | undefined {
    if (this.isDelegationCompletion(event)) {
      // Check all e-tags to find a delegation request ID
      // For explicit completions, we return the first e-tag as the most likely candidate
      // The DelegationCompletionHandler will validate if it's actually a tracked delegation
      const eTags = event.getMatchingTags("e");
      if (eTags.length > 0 && eTags[0][1]) {
        return eTags[0][1]; // Return the first e-tag value
      }
    }
    return undefined;
  }
  

  /**
   * Check if event is a status event
   */
  static isStatusEvent(event: NDKEvent): boolean {
    return event.kind === EVENT_KINDS.PROJECT_STATUS;
  }

  /**
   * Extract error type from error event
   */
  static getErrorType(event: NDKEvent): string | undefined {
    return event.tagValue("error");
  }

  /**
   * Get the K tag value (referenced event kind)
   */
  static getReferencedKind(event: NDKEvent): string | undefined {
    return event.tagValue("K");
  }

  /**
   * Check if event has a specific tool tag
   */
  static hasTool(event: NDKEvent, toolName: string): boolean {
    return event.tagValue("tool") === toolName;
  }

  /**
   * Get all tool tags from event
   */
  static getToolTags(event: NDKEvent): Array<{ name: string; args?: unknown }> {
    return event.tags
      .filter((tag) => tag[0] === "tool")
      .map((tag) => ({
        name: tag[1],
        args: tag[2] ? JSON.parse(tag[2]) : undefined,
      }));
  }

  /**
   * Check if this is a streaming event
   */
  static isStreamingEvent(event: NDKEvent): boolean {
    return event.kind === EVENT_KINDS.STREAMING_RESPONSE;
  }

  /**
   * Check if this is a typing indicator event
   */
  static isTypingEvent(event: NDKEvent): boolean {
    return event.kind === EVENT_KINDS.TYPING_INDICATOR;
  }
}
</file>

<file path="src/commands/run/ProjectDisplay.ts">
import { logger } from "@/utils/logger";


import type { AgentInstance } from "@/agents/types";
import { getProjectContext, configService } from "@/services";
import chalk from "chalk";

export class ProjectDisplay {
  async displayProjectInfo(projectPath: string): Promise<void> {
    this.displayBasicInfo(projectPath);
    await this.displayAgentConfigurations();
    // Note: Documentation display moved to after subscription EOSE
    logger.info(chalk.blue("\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"));
  }

  private displayBasicInfo(projectPath: string): void {
    const projectCtx = getProjectContext();
    const project = projectCtx.project;
    const titleTag = project.tagValue("title") || "Untitled Project";
    const repoTag = project.tagValue("repo") || "No repository";

    logger.info(chalk.blue("\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"));
    logger.info(chalk.cyan("üì¶ Project Information"));
    logger.info(chalk.blue("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"));
    logger.info(chalk.gray("Title:      ") + chalk.white(titleTag));
    logger.info(chalk.gray("Repository: ") + chalk.white(repoTag));
    logger.info(chalk.gray("Path:       ") + chalk.white(projectPath));
    if (project.id) {
      logger.info(chalk.gray("Event ID:   ") + chalk.gray(project.id));
    }
  }

  private async displayAgentConfigurations(): Promise<void> {
    const projectCtx = getProjectContext();
    const agents = projectCtx.agents;

    // Debug logging
    logger.debug("Displaying agent configurations", {
      agentsSize: agents.size,
      agentKeys: Array.from(agents.keys()),
    });

    logger.info(chalk.blue("\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"));
    logger.info(chalk.cyan("ü§ñ Agent Configurations"));
    logger.info(chalk.blue("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"));

    if (agents.size === 0) {
      logger.info(chalk.yellow("No agent configurations found for this project."));
      return;
    }

    for (const [slug, agent] of agents) {
      logger.debug(`Checking agent for display: ${slug}`, {
        name: agent.name,
        hasEventId: !!agent.eventId,
        eventId: agent.eventId,
        pubkey: agent.pubkey,
      });
      await this.displayAgentBySlug(slug, agent);
    }
  }

  private async displayAgentBySlug(slug: string, agent: AgentInstance): Promise<void> {
    // Display agent information
    logger.info(chalk.gray("\nAgent:       ") + chalk.yellow(agent.name));
    logger.info(chalk.gray("Slug:        ") + chalk.white(slug));
    logger.info(chalk.gray("Role:        ") + chalk.white(agent.role));
    
    // Resolve and display the actual model that will be used
    const modelString = agent.llmConfig || "default";
    try {
      const config = await configService.loadConfig();
      
      // Check if configuration exists
      const llmConfig = config.llms.configurations?.[modelString] || 
                       (modelString === "default" && config.llms.default ? config.llms.configurations?.[config.llms.default] : null);
      
      if (llmConfig) {
        logger.info(chalk.gray("Model:       ") + chalk.magenta(`${llmConfig.provider}:${llmConfig.model}`));
      } else {
        logger.info(chalk.gray("Model:       ") + chalk.red(`Configuration not found: ${modelString}`));
      }
    } catch {
      logger.info(chalk.gray("Model:       ") + chalk.red(`Error resolving model: ${modelString}`));
    }

    // Separate regular tools from MCP tools
    const regularTools = agent.tools.filter(t => !t.startsWith("mcp__"));
    const mcpTools = agent.tools.filter(t => t.startsWith("mcp__"));
    
    // Display regular tools
    const regularToolNames = regularTools.join(", ");
    const regularToolCount = regularTools.length;
    logger.info(chalk.gray("Tools:       ") + chalk.cyan(`[${regularToolCount}] ${regularToolNames || "none"}`));
    
    // Display MCP tools grouped by server
    if (mcpTools.length > 0) {
      // Group MCP tools by server
      const mcpByServer = new Map<string, string[]>();
      
      for (const tool of mcpTools) {
        // Extract server name from mcp__<server>__<tool>
        const parts = tool.split("__");
        if (parts.length >= 3) {
          const serverName = parts[1];
          const toolName = parts.slice(2).join("__");
          
          if (!mcpByServer.has(serverName)) {
            mcpByServer.set(serverName, []);
          }
          mcpByServer.get(serverName)!.push(toolName);
        }
      }
      
      // Try to get all available MCP tools to check if server has all tools enabled
      const serverSummaries: string[] = [];
      
      try {
        // Import mcpService to check available tools per server
        const { mcpService } = await import("@/services/mcp/MCPManager");
        const allMcpTools = mcpService.getCachedTools();
        
        // Count tools per server in the full set
        const allToolsByServer = new Map<string, number>();
        for (const toolName of Object.keys(allMcpTools)) {
          const parts = toolName.split("__");
          if (parts.length >= 3) {
            const serverName = parts[1];
            allToolsByServer.set(serverName, (allToolsByServer.get(serverName) || 0) + 1);
          }
        }
        
        // Build server summaries
        for (const [serverName, tools] of mcpByServer) {
          const totalAvailable = allToolsByServer.get(serverName) || tools.length;
          
          if (tools.length === totalAvailable) {
            // All tools from this server are enabled - show just server name
            serverSummaries.push(`${serverName} (${tools.length})`);
          } else {
            // Partial tools - show count
            serverSummaries.push(`${serverName} (${tools.length}/${totalAvailable})`);
          }
        }
      } catch {
        // Fallback if we can't get MCP service info
        for (const [serverName, tools] of mcpByServer) {
          serverSummaries.push(`${serverName} (${tools.length})`);
        }
      }
      
      logger.info(chalk.gray("MCP Tools:   ") + chalk.cyan(`[${mcpTools.length}] ${serverSummaries.join(", ")}`));
    }

    logger.info(chalk.gray("Pubkey:      ") + chalk.white(agent.pubkey));
    if (agent.eventId) {
      logger.info(chalk.gray("Event ID:    ") + chalk.gray(agent.eventId));
    }
  }
}
</file>

<file path="src/event-handler/AgentRouter.ts">
import type { AgentInstance } from "@/agents/types";
import { AgentEventDecoder } from "@/nostr/AgentEventDecoder";
import type { ProjectContext } from "@/services/ProjectContext";
import { logger } from "@/utils/logger";
import type { NDKEvent } from "@nostr-dev-kit/ndk";
import chalk from "chalk";


/**
 * AgentRouter is a static utility class that determines which agent
 * should handle an incoming event. This centralizes the routing logic
 * that was previously embedded in reply.ts.
 */

// biome-ignore lint/complexity/noStaticOnlyClass: <explanation>
export  class AgentRouter {
  /**
   * Determine which agents should handle the event based on p-tags,
   * event author, and other context.
   *
   * @returns Array of target agents that should process this event
   */
  static resolveTargetAgents(
    event: NDKEvent,
    projectContext: ProjectContext,
  ): AgentInstance[] {
    const mentionedPubkeys = AgentEventDecoder.getMentionedPubkeys(event);

    // Check if the event author is an agent in the system
    const isAuthorAnAgent = AgentEventDecoder.isEventFromAgent(event, projectContext.agents);

    // Check for p-tagged agents regardless of sender
    if (mentionedPubkeys.length > 0) {
      // Find ALL p-tagged system agents
      const targetAgents: AgentInstance[] = [];
      for (const pubkey of mentionedPubkeys) {
        const agent = projectContext.getAgentByPubkey(pubkey);
        if (agent) {
          // Check if this is a global agent that needs project validation
          if (agent.isGlobal && !this.validateProjectContext(event, projectContext)) {
            logger.info(chalk.gray(`Skipping global agent ${agent.name} - event not for this project context`));
            continue;
          }
          targetAgents.push(agent);
        }
      }
      
      if (targetAgents.length > 0) {
        const agentNames = targetAgents.map(a => a.name).join(", ");
        logger.info(chalk.gray(`Routing to ${targetAgents.length} p-tagged agent(s): ${agentNames}`));
        return targetAgents;
      }
    }

    // If no p-tags, don't route to anyone - just log it
    if (mentionedPubkeys.length === 0) {
      const senderType = isAuthorAnAgent ? "agent" : "user";
      logger.info(
        chalk.gray(`Event from ${senderType} ${event.pubkey.substring(0, 8)} without p-tags - not routing to any agent`)
      );
      return [];
    }

    return [];
  }

  /**
   * Legacy method for backward compatibility - returns first agent
   * @deprecated Use resolveTargetAgents instead
   */
  static resolveTargetAgent(
    event: NDKEvent,
    projectContext: ProjectContext
  ): AgentInstance | null {
    const agents = this.resolveTargetAgents(event, projectContext);
    return agents.length > 0 ? agents[0] : null;
  }

  /**
   * Check if any of the resolved agents would be processing their own message (self-reply)
   * Returns the agents that would NOT be self-replying
   */
  static filterOutSelfReplies(event: NDKEvent, targetAgents: AgentInstance[]): AgentInstance[] {
    return targetAgents.filter(agent => agent.pubkey !== event.pubkey);
  }

  /**
   * Check if the resolved agent would be processing its own message (self-reply)
   */
  static wouldBeSelfReply(event: NDKEvent, targetAgent: AgentInstance | null): boolean {
    if (!targetAgent) return false;
    return targetAgent.pubkey === event.pubkey;
  }

  /**
   * Get a human-readable description of why an event was routed to particular agents
   */
  static getRoutingReasons(
    event: NDKEvent,
    targetAgents: AgentInstance[],
  ): string {
    if (targetAgents.length === 0) {
      return "No agents assigned (event will not be processed)";
    }

    const mentionedPubkeys = AgentEventDecoder.getMentionedPubkeys(event);

    const reasons: string[] = [];
    for (const agent of targetAgents) {
      // Check if target was p-tagged
      if (mentionedPubkeys.includes(agent.pubkey)) {
        reasons.push(`Agent "${agent.name}" was directly mentioned (p-tagged)`);
      }
    }

    return reasons.length > 0 ? reasons.join("; ") : "Unknown routing reason";
  }

  /**
   * Get a human-readable description of why an event was routed to a particular agent
   */
  static getRoutingReason(
    event: NDKEvent,
    targetAgent: AgentInstance | null,
  ): string {
    if (!targetAgent) {
      return "No agent assigned (event will not be processed)";
    }

    const mentionedPubkeys = AgentEventDecoder.getMentionedPubkeys(event);

    // Check if target was p-tagged
    if (mentionedPubkeys.includes(targetAgent.pubkey)) {
      return `Agent "${targetAgent.name}" was directly mentioned (p-tagged)`;
    }

    return "Unknown routing reason";
  }

  /**
   * Validate that an event's project context matches the current project
   * This is used to filter events for global agents to ensure they only
   * process events from their assigned project.
   *
   * @param event - The event to validate
   * @param projectContext - The current project context
   * @returns true if the event is for this project, false otherwise
   */
  private static validateProjectContext(
    event: NDKEvent,
    projectContext: ProjectContext,
  ): boolean {
    const aTag = event.tags.find((tag) => tag[0] === "a");
    if (!aTag || !aTag[1]) {
      return true; // No project reference - allow routing (backward compatibility)
    }

    const parts = aTag[1].split(":");
    if (parts.length !== 3 || parts[0] !== "31933") {
      return true; // Not a valid project reference - allow routing
    }

    const eventProjectIdentifier = parts[2];
    const currentProjectIdentifier = projectContext.project.tagValue("d");
    
    // Handle case where current project has no identifier
    if (!currentProjectIdentifier) {
      return true;
    }

    if (eventProjectIdentifier !== currentProjectIdentifier) {
      logger.debug(`Event project mismatch: event="${eventProjectIdentifier}", current="${currentProjectIdentifier}"`);
      return false;
    }

    return true;
  }
}
</file>

<file path="src/services/DelegationService.ts">
import type { AgentInstance } from "@/agents/types";
import type { ConversationCoordinator } from "@/conversations";
import type { DelegationIntent } from "@/nostr/AgentEventEncoder";
import { AgentPublisher } from "@/nostr/AgentPublisher";
import { DelegationRegistry } from "@/services/DelegationRegistry";
import { logger } from "@/utils/logger";
import type { NDKEvent } from "@nostr-dev-kit/ndk";

export interface DelegationResponses {
  type: "delegation_responses";
  responses: Array<{
    response: string;
    summary?: string;
    from: string;
    event?: NDKEvent; // The actual response event for threading
  }>;
}

/**
 * Service that handles delegation execution.
 * Orchestrates the complete delegation workflow: publishing events and waiting for responses.
 */
export class DelegationService {
  constructor(
    private agent: AgentInstance,
    private conversationId: string,
    private conversationCoordinator: ConversationCoordinator,
    private triggeringEvent: NDKEvent,
    private publisher: AgentPublisher,
    private phase?: string
  ) {}

  /**
   * Execute a delegation and wait for all responses.
   */
  async execute(intent: DelegationIntent): Promise<DelegationResponses> {
    // Check for self-delegation
    const selfDelegationAttempts = intent.recipients.filter(
      pubkey => pubkey === this.agent.pubkey
    );
    
    if (selfDelegationAttempts.length > 0) {
      logger.warn("[DelegationService] ‚ùå Agent attempted to delegate to itself", {
        fromAgent: this.agent.slug,
        agentPubkey: this.agent.pubkey,
        attemptedRecipients: intent.recipients,
      });
      
      throw new Error("Cannot delegate to yourself. Consider handling this task directly or choosing a different agent to delegate to.");
    }

    // Build event context
    const conversation = this.conversationCoordinator.getConversation(this.conversationId);
    const eventContext = {
      triggeringEvent: this.triggeringEvent,
      rootEvent: conversation?.history[0] ?? this.triggeringEvent, // Use triggering event as fallback
      conversationId: this.conversationId,
      phase: this.phase,
    };

    // Publish based on intent type
    const result = intent.type === "delegation_followup"
      ? await this.publisher.delegateFollowUp(intent, eventContext)
      : await this.publisher.delegate(intent, eventContext);

    // Wait for all responses
    const registry = DelegationRegistry.getInstance();
    
    // Wait for all responses - no timeout as delegations are long-running
    const completions = await registry.waitForBatchCompletion(result.batchId);
    
    // Return formatted responses with event details
    return {
      type: "delegation_responses",
      responses: completions.map(c => ({
        response: c.response,
        summary: c.summary,
        from: c.assignedTo,
        event: c.event,
      })),
    };
  }
}
</file>

<file path="src/agents/constants.ts">
import type { AgentInstance } from "./types";


/**
 * Core tools that ALL agents must have access to regardless of configuration.
 * These are fundamental capabilities that every agent needs.
 */
export const CORE_AGENT_TOOLS = [
  "lesson_get",    // All agents should access lessons
  "lesson_learn",  // All agents should be able to learn
  "read_path",     // All agents need file system access
  "reports_list",  // All agents should see available reports
  "report_read",   // All agents should read reports
  // NOTE: delegate tools are NOT core - they're added dynamically in AgentExecutor based on PM status
] as const;

/**
 * Get all available tools for an agent based on their role
 * Note: Since PM is now dynamic (first agent in project), we can't determine
 * PM-specific tools here. Tool assignment should be done via agent definition events.
 */
export function getDefaultToolsForAgent(_agent: AgentInstance): string[] {
  // Default tools for all agents
  // Specific tools should be configured via agent definition events
  // NOTE: delegate, delegate_phase, delegate_external, and delegate_followup are NOT included here
  // They are added via getDelegateToolsForAgent based on PM status
  const tools = [
    "read_path",
    "lesson_learn", 
    "claude_code",
    "write_context_file",
    "shell",
    "discover_capabilities",
    "agents_hire",
    "agents_discover",
    "nostr_projects",
  ];

  return tools;
}

/**
 * Delegate tools that should be excluded from configuration and kind 24010 events
 */
export const DELEGATE_TOOLS = ['delegate', 'delegate_phase', 'delegate_external', 'delegate_followup'] as const;

/**
 * Get the correct delegate tools for an agent based on PM status
 * This is the SINGLE source of truth for delegate tool assignment
 */
export function getDelegateToolsForAgent(isPM: boolean): string[] {
  const tools: string[] = [];
  
  if (isPM) {
    // PM gets delegate_phase (NOT delegate)
    tools.push('delegate_phase');
  } else {
    // Non-PM agents get delegate (NOT delegate_phase)
    tools.push('delegate');
  }
  
  // All agents get delegate_external and delegate_followup
  tools.push('delegate_external');
  tools.push('delegate_followup');
  
  return tools;
}
</file>

<file path="src/commands/debug/index.ts">
import { AgentRegistry } from "@/agents/AgentRegistry";
import type { Phase } from "@/conversations/types";
import type { NDKAgentLesson } from "@/events/NDKAgentLesson";
import { buildSystemPromptMessages } from "@/prompts/utils/systemPromptBuilder";
import { getProjectContext } from "@/services";
import { mcpService } from "@/services/mcp/MCPManager";
// Tool type removed - using AI SDK tools only
import { handleCliError } from "@/utils/cli-error";
import { colorizeJSON, formatMarkdown } from "@/utils/formatting";
import { logger } from "@/utils/logger";
import { ensureProjectInitialized } from "@/utils/projectInitialization";
import chalk from "chalk";

// Format content with enhancements
function formatContentWithEnhancements(content: string, isSystemPrompt = false): string {
  let formattedContent = content.replace(/\\n/g, "\n");

  if (isSystemPrompt) {
    formattedContent = formatMarkdown(formattedContent);
  }

  // Handle <tool_use> blocks
  formattedContent = formattedContent.replace(
    /<tool_use>([\s\S]*?)<\/tool_use>/g,
    (_match, jsonContent) => {
      try {
        const parsed = JSON.parse(jsonContent.trim());
        const formatted = JSON.stringify(parsed, null, 2);
        return chalk.gray("<tool_use>\n") + colorizeJSON(formatted) + chalk.gray("\n</tool_use>");
      } catch {
        return chalk.gray("<tool_use>") + jsonContent + chalk.gray("</tool_use>");
      }
    }
  );

  return formattedContent;
}

interface DebugSystemPromptOptions {
  agent: string;
  phase: string;
}

export async function runDebugSystemPrompt(options: DebugSystemPromptOptions): Promise<void> {
  try {
    const projectPath = process.cwd();

    // Initialize project context if needed
    await ensureProjectInitialized(projectPath);

    // Load agent from registry
    const agentRegistry = new AgentRegistry(projectPath, false);
    await agentRegistry.loadFromProject();
    const agent = agentRegistry.getAgent(options.agent);

    logger.info(chalk.cyan("\n=== Agent Information ==="));
    if (agent) {
      logger.info(`${chalk.white("Name:")} ${agent.name}`);
      logger.info(`${chalk.white("Role:")} ${agent.role}`);
      logger.info(`${chalk.white("Phase:")} ${options.phase}`);
      if (agent.tools && agent.tools.length > 0) {
        logger.info(`${chalk.white("Tools:")} ${agent.tools.join(", ")}`);
      }
    } else {
      logger.warn(`Note: Agent '${options.agent}' not found in registry`);
    }

    logger.info(chalk.cyan("\n=== System Prompt ==="));

    if (agent) {
      const projectCtx = getProjectContext();

      // Get all available agents for delegations
      const availableAgents = Array.from(projectCtx.agents.values());

      // Validate phase
      const phase = (options.phase || "CHAT") as Phase;

      // Initialize MCP service to get tools
      let mcpTools: Record<string, unknown> = {};
      try {
        await mcpService.initialize(projectPath);
        mcpTools = mcpService.getCachedTools();
        logger.info(`Loaded ${Object.keys(mcpTools).length} MCP tools`);
      } catch (error) {
        logger.error(`Failed to initialize MCP service: ${error}`);
        // Continue without MCP tools - don't fail the whole debug command
      }

      // Build system prompt using the shared function - exactly as production does
      // Only pass the current agent's lessons
      const agentLessonsMap = new Map<string, NDKAgentLesson[]>();
      const currentAgentLessons = projectCtx.getLessonsForAgent(agent.pubkey);
      if (currentAgentLessons.length > 0) {
        agentLessonsMap.set(agent.pubkey, currentAgentLessons);
      }

      // Check if this agent is the project manager
      const isProjectManager = agent.pubkey === projectCtx.getProjectManager().pubkey;

      const systemMessages = buildSystemPromptMessages({
        agent,
        phase,
        project: projectCtx.project,
        availableAgents,
        conversation: undefined, // No conversation in debug mode
        agentLessons: agentLessonsMap,
        mcpTools,
        isProjectManager,
      });

      // Display each system message separately with metadata
      logger.info(chalk.bold.cyan("\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"));
      logger.info(chalk.bold.cyan("                    SYSTEM PROMPT MESSAGES"));
      logger.info(chalk.bold.cyan("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"));

      for (let i = 0; i < systemMessages.length; i++) {
        const msg = systemMessages[i];

        // Display message metadata
        console.log(chalk.bold.yellow(`\n‚îÄ‚îÄ‚îÄ Message ${i + 1} ‚îÄ‚îÄ‚îÄ`));
        if (msg.metadata?.description) {
          console.log(chalk.dim(`Description: ${msg.metadata.description}`));
        }
        if (msg.metadata?.cacheable) {
          console.log(chalk.green(`‚úì Cacheable (key: ${msg.metadata.cacheKey})`));
        }
        console.log();

        // Format and display message content
        const formattedContent = formatContentWithEnhancements(msg.message.content, true);
        console.log(formattedContent);

        if (i < systemMessages.length - 1) {
          console.log(chalk.dim(`\n${"‚îÄ".repeat(60)}\n`));
        }
      }

      console.log(
        chalk.bold.cyan("\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n")
      );
    } else {
      console.log(chalk.yellow(`Agent '${options.agent}' not found in registry`));
    }

    console.log(chalk.cyan("===================\n"));

    logger.info("System prompt displayed successfully");
    process.exit(0);
  } catch (err) {
    handleCliError(err, "Failed to generate system prompt");
  }
}
</file>

<file path="src/test-utils/mock-factories.ts">
import type { ExecutionContext } from "@/agents/execution/types";
import type { AgentInstance } from "@/agents/types";
import type { Conversation } from "@/conversations/types";
import type { ToolCall } from "@/llm/types";
import { EVENT_KINDS } from "@/llm/types";
import type NDK from "@nostr-dev-kit/ndk";
import type { NDKEvent } from "@nostr-dev-kit/ndk";

/**
 * Factory functions for creating mock objects in tests
 */

/**
 * MockNostrEvent class that implements the serialize method required by FileSystemAdapter
 */
export class MockNostrEvent implements Partial<NDKEvent> {
  id: string;
  pubkey: string;
  created_at: number;
  kind: number;
  tags: string[][];
  content: string;
  sig?: string;

  constructor(overrides?: Partial<NDKEvent>) {
    this.id = overrides?.id || `mock-event-${Math.random().toString(36).substr(2, 9)}`;
    this.pubkey = overrides?.pubkey || "mock-pubkey";
    this.created_at = overrides?.created_at || Math.floor(Date.now() / 1000);
    this.kind = overrides?.kind || EVENT_KINDS.GENERIC_REPLY;
    this.tags = overrides?.tags || [];
    this.content = overrides?.content || "Mock event content";
    this.sig = overrides?.sig || "mock-signature";
  }

  serialize(includeSignature?: boolean, includeId?: boolean): string {
    const obj = {
      id: includeId ? this.id : undefined,
      pubkey: this.pubkey,
      created_at: this.created_at,
      kind: this.kind,
      tags: this.tags,
      content: this.content,
      sig: includeSignature ? this.sig : undefined,
    };
    return JSON.stringify(obj);
  }

  tagValue(tagName: string): string | undefined {
    const tag = this.tags.find((t) => t[0] === tagName);
    return tag?.[1];
  }

  static deserialize(_ndk: NDK, serialized: string): MockNostrEvent {
    const data = JSON.parse(serialized);
    return new MockNostrEvent(data);
  }
}

export function createMockNDKEvent(overrides?: Partial<NDKEvent>): NDKEvent {
  return new MockNostrEvent(overrides) as NDKEvent;
}

export function createMockAgent(overrides?: Partial<AgentInstance>): AgentInstance {
  const mockSigner = {
    privateKey: "mock-private-key",
    sign: async () => "mock-signature",
  } as unknown;

  return {
    name: "MockAgent",
    pubkey: "mock-pubkey",
    signer: mockSigner,
    role: "Mock Role",
    description: "A mock agent for testing",
    instructions: "You are a mock agent for testing",
    useCriteria: "Mock use criteria",
    llmConfig: "default",
    tools: [],
    mcp: false,
    eventId: "mock-event-id",
    slug: "mock-agent",
    backend: "reason-act-loop",
    ...overrides,
  } as AgentInstance;
}

export function createMockConversation(overrides?: Partial<Conversation>): Conversation {
  const id = overrides?.id || `mock-conv-${Math.random().toString(36).substr(2, 9)}`;
  return {
    id,
    title: "Mock Conversation",
    phase: "CHAT",
    history: [],
    agentStates: new Map(),
    phaseStartedAt: Date.now(),
    metadata: {
      summary: "Mock conversation summary",
      requirements: "Mock requirements",
    },
    executionTime: {
      totalSeconds: 0,
      isActive: false,
      lastUpdated: Date.now(),
    },
    ...overrides,
  };
}

export function createMockExecutionContext(
  overrides?: Partial<ExecutionContext>
): ExecutionContext {
  const agent = overrides?.agent || createMockAgent();
  const mockEvent = createMockNDKEvent();

  // Create mock publisher and conversation manager
  const mockPublisher = {
    publishReply: async () => mockEvent,
    publishToolCall: async () => mockEvent,
    publishAgentThinking: async () => mockEvent,
  } as unknown;

  const mockConversationCoordinator = {
    getConversation: async () => createMockConversation(),
    updateConversation: async () => {},
    transitionPhase: async () => {},
  } as unknown;

  return {
    agent,
    conversationId:
      overrides?.conversationId || `mock-conv-${Math.random().toString(36).substr(2, 9)}`,
    phase: "CHAT",
    projectPath: "/mock/project",
    triggeringEvent: mockEvent,
    publisher: mockPublisher,
    conversationCoordinator: mockConversationCoordinator,
    ...overrides,
  } as ExecutionContext;
}

export function createMockToolCall(overrides?: Partial<ToolCall>): ToolCall {
  return {
    id: `tool-${Math.random().toString(36).substr(2, 9)}`,
    message: null,
    function: "analyze",
    args: JSON.stringify({ query: "Mock query" }),
    ...overrides,
  };
}

/**
 * Create a builder for complex mock objects
 */
export class MockBuilder<T> {
  private obj: Partial<T> = {};

  with<K extends keyof T>(key: K, value: T[K]): this {
    this.obj[key] = value;
    return this;
  }

  build(defaults: T): T {
    return { ...defaults, ...this.obj };
  }
}
</file>

<file path="src/conversations/services/ConversationResolver.ts">
import type { Conversation, ConversationCoordinator } from "@/conversations";
import { AgentEventDecoder } from "@/nostr/AgentEventDecoder";
import { getProjectContext } from "@/services";
import { logger } from "@/utils/logger";
import type { NDKEvent } from "@nostr-dev-kit/ndk";
import chalk from "chalk";


export interface ConversationResolutionResult {
  conversation: Conversation | undefined;
  isNew?: boolean;
}

/**
 * ConversationResolver encapsulates all logic for finding or creating conversations
 * based on incoming Nostr events. This centralizes the complex resolution logic
 * that was previously scattered throughout reply.ts.
 */
export class ConversationResolver {
  constructor(
    private conversationCoordinator: ConversationCoordinator
  ) {}

  /**
   * Resolve the conversation for an incoming event.
   * This may find an existing conversation, create a new one for orphaned replies,
   * or use delegation context to find parent conversations.
   */
  async resolveConversationForEvent(event: NDKEvent): Promise<ConversationResolutionResult> {
    // Try standard conversation resolution
    const result = await this.findConversationForReply(event);

    // If no conversation found and this could be an orphaned reply, try to create one
    if (!result.conversation && AgentEventDecoder.isOrphanedReply(event)) {
      const mentionedPubkeys = AgentEventDecoder.getMentionedPubkeys(event);
      const newConversation = await this.handleOrphanedReply(event, mentionedPubkeys);
      if (newConversation) {
        return {
          conversation: newConversation,
          isNew: true,
        };
      }
    }

    return result;
  }

  /**
   * Find the conversation for a reply event using various strategies
   */
  private async findConversationForReply(event: NDKEvent): Promise<ConversationResolutionResult> {
    const convRoot = AgentEventDecoder.getConversationRoot(event);

    const conversation = convRoot
      ? this.conversationCoordinator.getConversationByEvent(convRoot)
      : undefined;

    return { conversation };
  }

  /**
   * Handle orphaned replies by creating a new conversation
   */
  private async handleOrphanedReply(
    event: NDKEvent,
    mentionedPubkeys: string[]
  ): Promise<Conversation | undefined> {
    if (AgentEventDecoder.getReferencedKind(event) !== "11" || mentionedPubkeys.length === 0) {
      return undefined;
    }

    const projectCtx = getProjectContext();
    const isDirectedToAgent = mentionedPubkeys.some((pubkey) =>
      Array.from(projectCtx.agents.values()).some((a) => a.pubkey === pubkey)
    );

    if (!isDirectedToAgent) {
      return undefined;
    }

    const convRoot = AgentEventDecoder.getConversationRoot(event);
    logger.info(
      chalk.yellow(
        `Creating new conversation for orphaned kTag 11 reply to conversation root: ${convRoot}`
      )
    );

    // Create a synthetic root event based on the reply
    const syntheticRootEvent: NDKEvent = {
      ...event,
      id: convRoot || event.id, // Use conversation root if available, otherwise use the reply's ID
      content: `[Orphaned conversation - original root not found]\n\n${event.content}`,
      tags: event.tags.filter((tag) => tag[0] !== "E" && tag[0] !== "e"), // Remove reply tags
    } as NDKEvent;

    const conversation = await this.conversationCoordinator.createConversation(syntheticRootEvent);

    // Add the actual reply event to the conversation history
    if (conversation && event.id !== conversation.id) {
      await this.conversationCoordinator.addEvent(conversation.id, event);
    }

    return conversation;
  }
}
</file>

<file path="src/llm/types.ts">
// Export AI SDK types directly
export type { 
  ModelMessage,
  Tool as CoreTool,
  ToolCall as CoreToolCall,
  ToolResult as CoreToolResult,
  GenerateTextResult,
  StreamTextResult
} from 'ai';

// Export execution context type
import type { ExecutionContext } from "@/agents/execution/types";
import type { LanguageModelUsage } from 'ai';
export type { ExecutionContext };

/**
 * AI SDK supported providers
 * Note: claudeCode is a limited provider (phase-0 only in Track 1)
 */
export const AI_SDK_PROVIDERS = ["openrouter", "anthropic", "openai", "ollama", "claudeCode"] as const;
export type AISdkProvider = (typeof AI_SDK_PROVIDERS)[number];

/**
 * LLM Provider type alias for compatibility
 */
export type LLMProvider = AISdkProvider;

/**
 * Model configuration
 */
export interface ModelConfig {
  provider: AISdkProvider;
  model: string;
  temperature?: number;
  maxTokens?: number;
}

export type LanguageModelUsageWithCostUsd = LanguageModelUsage & { costUsd?: number };

/**
 * Event kinds used in the TENEX system
 * 
 * Don't add kinds here if they are defined in NDKKind or if we have NDKEvent wrappers (i.e. don't add NDKKind.GenericReply or NDKProject.kind)
 */
export const EVENT_KINDS = {
  PROJECT_STATUS: 24010, // Ephemeral event kind (not stored by relays) - consider regular/addressable kinds for persistence
  AGENT_REQUEST: 4133,
  TYPING_INDICATOR: 24111,
  TYPING_INDICATOR_STOP: 24112,
  STREAMING_RESPONSE: 21111,
  FORCE_RELEASE: 24019,
  AGENT_CONFIG_UPDATE: 24020,
  OPERATIONS_STATUS: 24133, // LLM operations status (one per event being processed)
} as const;
</file>

<file path="src/prompts/utils/systemPromptBuilder.ts">
import type { AgentInstance } from "@/agents/types";
import type { Phase, Conversation } from "@/conversations/types";
import type { NDKAgentLesson } from "@/events/NDKAgentLesson";
import { PromptBuilder } from "@/prompts/core/PromptBuilder";
import type { NDKEvent, NDKProject } from "@nostr-dev-kit/ndk";
import type { ModelMessage } from "ai";
import { isVoiceMode } from "@/prompts/fragments/20-voice-mode";

// Import fragment registration manifest
import "@/prompts/fragments"; // This auto-registers all fragments

export interface BuildSystemPromptOptions {
  // Required data
  agent: AgentInstance;
  phase: Phase;
  project: NDKProject;

  // Optional runtime data
  availableAgents?: AgentInstance[];
  conversation?: Conversation;
  agentLessons?: Map<string, NDKAgentLesson[]>;
  triggeringEvent?: NDKEvent;
  isProjectManager?: boolean; // Indicates if this agent is the PM
}

export interface BuildStandalonePromptOptions {
  // Required data
  agent: AgentInstance;
  phase: Phase;

  // Optional runtime data
  availableAgents?: AgentInstance[];
  conversation?: Conversation;
  agentLessons?: Map<string, NDKAgentLesson[]>;
  triggeringEvent?: NDKEvent;
}

export interface SystemMessage {
  message: ModelMessage;
  metadata?: {
    description?: string;
  };
}

/**
 * Add core agent fragments that are common to both project and standalone modes
 */
function addCoreAgentFragments(
    builder: PromptBuilder,
    agent: AgentInstance,
    phase: Phase,
    conversation?: Conversation,
    agentLessons?: Map<string, NDKAgentLesson[]>,
    triggeringEvent?: NDKEvent
): void {
    // Add voice mode instructions if applicable
    builder.add("voice-mode", { isVoiceMode: isVoiceMode(triggeringEvent) });

    // Add referenced article context if present
    if (conversation?.metadata?.referencedArticle) {
        builder.add("referenced-article", conversation.metadata.referencedArticle);
    }

    // Add retrieved lessons
    builder.add("retrieved-lessons", {
        agent,
        phase,
        conversation,
        agentLessons: agentLessons || new Map(),
    });
}

/**
 * Add agent-specific fragments
 */
function addAgentFragments(
    builder: PromptBuilder,
    agent: AgentInstance,
    availableAgents: AgentInstance[]
): void {
    // Add available agents for delegations
    builder.add("available-agents", {
        agents: availableAgents,
        currentAgent: agent,
    });
}

/**
 * Add delegated task context if applicable
 */
function addDelegatedTaskContext(
    builder: PromptBuilder,
    triggeringEvent?: NDKEvent
): void {
    // Check if this is a delegated task (NDKTask kind 1934)
    const isDelegatedTask = triggeringEvent?.kind === 1934;
    if (isDelegatedTask) {
        builder.add("delegated-task-context", {
            taskDescription: triggeringEvent?.content || "Complete the assigned task",
        });
    }
}

/**
 * Export phase instruction building for use by other modules
 */
export function buildPhaseInstructions(phase: Phase, conversation?: Conversation): string {
  // If the conversation has custom phase instructions, use those
  if (conversation?.phaseInstructions) {
    return `=== CURRENT PHASE: ${phase.toUpperCase()} ===

${conversation.phaseInstructions}`;
  }
  
  // Otherwise, fall back to standard phase instructions
  const builder = new PromptBuilder()
      .add("phase-context", {
          phase,
          phaseMetadata: conversation?.metadata,
          conversation,
      });

  return builder.build();
}

/**
 * Export phase transition formatting for use by other modules
 */
export function formatPhaseTransitionMessage(
  lastSeenPhase: Phase,
  currentPhase: Phase,
  phaseInstructions: string
): string {
  return `=== PHASE TRANSITION ===

You were last active in the ${lastSeenPhase.toUpperCase()} phase.
The conversation has now moved to the ${currentPhase.toUpperCase()} phase.

${phaseInstructions}

Please adjust your behavior according to the new phase requirements.`;
}

/**
 * Builds the system prompt messages for an agent, returning an array of messages
 * with optional caching metadata.
 * This is the single source of truth for system prompt generation.
 */
export function buildSystemPromptMessages(options: BuildSystemPromptOptions): SystemMessage[] {
  const messages: SystemMessage[] = [];

  // Build the main system prompt
  const mainPrompt = buildMainSystemPrompt(options);
  messages.push({
    message: { role: "system", content: mainPrompt },
    metadata: {
      description: "Main system prompt",
    },
  });

  // Add PROJECT.md as separate cacheable message for project manager
  if (options.isProjectManager) {
    const projectMdContent = buildProjectMdContent(options);
    if (projectMdContent) {
      messages.push({
        message: { role: "system", content: projectMdContent },
        metadata: {
          description: "PROJECT.md content",
        },
      });
    }
  }

  // Add project inventory as separate cacheable message for all agents
  // XXX TEMPORARILY DISABLED! RESTORE ASAP!
  // const inventoryContent = buildProjectInventoryContent();
  // if (inventoryContent) {
  //   messages.push({
  //     message: { role: "system", content: inventoryContent },
  //     metadata: {
  //       description: "Project inventory",
  //     },
  //   });
  // }

  return messages;
}

/**
 * Builds the main system prompt content (without PROJECT.md and inventory)
 */
function buildMainSystemPrompt(options: BuildSystemPromptOptions): string {
  const {
    agent,
    phase,
    project,
    availableAgents = [],
    conversation,
    agentLessons,
    triggeringEvent,
  } = options;

  const systemPromptBuilder = new PromptBuilder();

  // Add agent identity
  systemPromptBuilder.add("agent-identity", {
    agent,
    projectTitle: project.tagValue("title") || "Unknown Project",
    projectOwnerPubkey: project.pubkey,
  });

  // Add delegated task context if applicable
  addDelegatedTaskContext(systemPromptBuilder, triggeringEvent);

  // Add core agent fragments using shared composition
  addCoreAgentFragments(
    systemPromptBuilder,
    agent,
    phase,
    conversation,
    agentLessons,
    triggeringEvent
  );

  // Add agent-specific fragments
  addAgentFragments(
    systemPromptBuilder,
    agent,
    availableAgents
  );

  return systemPromptBuilder.build();
}

/**
 * Builds PROJECT.md content as a separate message
 */
function buildProjectMdContent(options: BuildSystemPromptOptions): string | null {
  const builder = new PromptBuilder();
  builder.add("project-md", {
    projectPath: process.cwd(),
    currentAgent: options.agent,
  });
  const content = builder.build();
  return content.trim() ? content : null;
}

/**
 * Builds project inventory content as a separate message
 */
function buildProjectInventoryContent(): string | null {
  const builder = new PromptBuilder();
  builder.add("project-inventory-context", {});
  const content = builder.build();
  return content.trim() ? content : null;
}

/**
 * Builds system prompt messages for standalone agents (without project context).
 * Includes most fragments except project-specific ones.
 */
export function buildStandaloneSystemPromptMessages(
  options: BuildStandalonePromptOptions
): SystemMessage[] {
  const messages: SystemMessage[] = [];

  // Build the main system prompt
  const mainPrompt = buildStandaloneMainPrompt(options);
  messages.push({
    message: { role: "system", content: mainPrompt },
    metadata: {
      description: "Main standalone system prompt",
    },
  });

  return messages;
}

/**
 * Builds the main system prompt for standalone agents
 */
function buildStandaloneMainPrompt(options: BuildStandalonePromptOptions): string {
  const {
    agent,
    phase,
    availableAgents = [],
    conversation,
    agentLessons,
    triggeringEvent,
  } = options;

  const systemPromptBuilder = new PromptBuilder();

  // For standalone agents, use a simplified identity without project references
  systemPromptBuilder.add("agent-identity", {
    agent,
    projectTitle: "Standalone Mode",
    projectOwnerPubkey: agent.pubkey, // Use agent's own pubkey as owner
  });

  // Add delegated task context if applicable
  addDelegatedTaskContext(systemPromptBuilder, triggeringEvent);

  // Add core agent fragments using shared composition
  addCoreAgentFragments(
    systemPromptBuilder,
    agent,
    phase,
    conversation,
    agentLessons,
    triggeringEvent
  );

  // Add agent-specific fragments only if multiple agents available
  if (availableAgents.length > 1) {
    addAgentFragments(
      systemPromptBuilder,
      agent,
      availableAgents
    );
  }

  return systemPromptBuilder.build();
}
</file>

<file path="src/tools/implementations/delegate_external.ts">
import { tool } from 'ai';
import { getNDK } from "@/nostr/ndkClient";
import { DelegationRegistry } from "@/services/DelegationRegistry";
import type { DelegationResponses } from "@/services/DelegationService";
import { formatAnyError } from "@/utils/error-formatter";
import { logger } from "@/utils/logger";
import { parseNostrUser, normalizeNostrIdentifier } from "@/utils/nostr-entity-parser";
import { NDKEvent } from "@nostr-dev-kit/ndk";
import { z } from "zod";
import type { ExecutionContext } from "@/agents/execution/types";

const delegateExternalSchema = z.object({
  content: z.string().describe("The content of the chat message to send"),
  recipient: z.string().describe("The recipient's pubkey or npub (will be p-tagged)"),
  projectId: z
    .string()
    .optional()
    .describe("Optional project event ID (naddr1...) to reference in the message. This should be the project the agent you are delegating TO works on (if you know it)"),
});

type DelegateExternalInput = z.infer<typeof delegateExternalSchema>;
type DelegateExternalOutput = DelegationResponses;

// Core implementation - extracted from existing execute function
async function executeDelegateExternal(input: DelegateExternalInput, context: ExecutionContext): Promise<DelegateExternalOutput> {
  const { content, recipient, projectId } = input;

  const ndk = getNDK();
  
  // Parse recipient using the utility function
  const pubkey = parseNostrUser(recipient);
  if (!pubkey) {
    throw new Error(`Invalid recipient format: ${recipient}`);
  }

  logger.info("üöÄ Delegating to external agent", {
    agent: context.agent.name,
    hasProject: !!projectId,
    recipientPubkey: pubkey.substring(0, 8),
    contentLength: content.length,
  });

  // Normalize optional IDs
  const cleanProjectId = normalizeNostrIdentifier(projectId);

  logger.debug("Processing recipient", { pubkey });

  // Create a new kind:11 event for starting a thread
  const chatEvent = new NDKEvent(ndk);
  chatEvent.kind = 11;
  
  if (context.phase) chatEvent.tags.push(["phase", context.phase]);
  chatEvent.tags.push(["tool", "delegate_external"]);
  chatEvent.content = content;
  chatEvent.tags.push(["p", pubkey]);

  // Add project reference if provided
  if (cleanProjectId) {
    const projectEvent = await ndk.fetchEvent(cleanProjectId);
    if (projectEvent) {
        chatEvent.tag(projectEvent.tagReference());
    } else {
      logger.warn("Project event not found, skipping project tag", {
        projectId: cleanProjectId,
      });
    }
  }

  logger.debug("Chat event details", { eventId: chatEvent.id, kind: chatEvent.kind });
  
  // Sign and publish the event
  await chatEvent.sign(context.agent.signer);
  chatEvent.publish();

  const registry = DelegationRegistry.getInstance();
  const batchId = await registry.registerDelegation({
    delegationEventId: chatEvent.id,
    recipients: [{
      pubkey: pubkey,
      request: content,
      phase: context.phase,
    }],
    delegatingAgent: context.agent,
    rootConversationId: context.conversationId,
    originalRequest: content,
  });

  // Publish conversation status event
  try {
    // Use shared AgentPublisher instance from context (guaranteed to be present)
    const conversation = context.conversationCoordinator.getConversation(context.conversationId);

    if (conversation?.history?.[0]) {
      await context.agentPublisher.conversation(
        { content: `üöÄ External delegation sent: nostr:${chatEvent.encode()}` },
        {
          triggeringEvent: context.triggeringEvent,
          rootEvent: conversation.history[0],
          conversationId: context.conversationId,
        }
      );
    }
  } catch (statusError) {
    // Don't fail the tool if we can't publish the status
    console.warn("Failed to publish delegation status:", statusError);
  }

  try {
    // Wait for batch completion (will be triggered when response is received and processed)
    const completions = await registry.waitForBatchCompletion(batchId);

    logger.info("‚úÖ Synchronous wait complete - received response from external agent", {
      eventId: chatEvent.id,
      batchId,
      completionCount: completions.length,
    });

    // Convert to DelegationResponses format
    const response: DelegationResponses = {
      type: "delegation_responses",
      responses: completions.map(c => ({
        response: c.response,
        summary: c.summary,
        from: c.assignedTo,
      })),
    };

    return response;
  } catch (error) {
    // Synchronous wait failed - this should only happen if there's a network issue
    logger.error("‚ùå Synchronous wait failed for external response", {
      eventId: chatEvent.id,
      batchId,
      error,
    });

    throw new Error(`Failed to wait for response: ${formatAnyError(error)}`);
  }
}

// AI SDK tool factory
export function createDelegateExternalTool(context: ExecutionContext): ReturnType<typeof tool> {
  return tool({
    description: "Delegate a task to an external agent or user and wait for their response. Use this tool only to engage with agents in OTHER projects.",
    inputSchema: delegateExternalSchema,
    execute: async (input: DelegateExternalInput) => {
      return await executeDelegateExternal(input, context);
    },
  });
}
</file>

<file path="src/tools/registry.ts">
/**
 * Tool Registry - AI SDK Tools
 * 
 * Central registry for all AI SDK tools in the TENEX system.
 */

import type { Tool as CoreTool } from "ai";
import type { ExecutionContext } from "@/agents/execution/types";
import { createReadPathTool } from "./implementations/read_path";
import { createWriteContextFileTool } from "./implementations/write_context_file";
import { createGenerateInventoryTool } from "./implementations/generate_inventory";
import { createLessonLearnTool } from "./implementations/learn";
import { createLessonGetTool } from "./implementations/lesson_get";
import { createShellTool } from "./implementations/shell";
import { createAgentsDiscoverTool } from "./implementations/agents_discover";
import { createAgentsHireTool } from "./implementations/agents_hire";
import { createAgentsListTool } from "./implementations/agents_list";
import { createAgentsReadTool } from "./implementations/agents_read";
import { createAgentsWriteTool } from "./implementations/agents_write";
import { createMcpDiscoverTool } from "./implementations/mcp_discover";
import { createDelegateTool } from "./implementations/delegate";
import { createDelegatePhaseTool } from "./implementations/delegate_phase";
import { createDelegateFollowupTool } from "./implementations/delegate_followup";
import { createNostrProjectsTool } from "./implementations/nostr_projects";
import { createClaudeCodeTool } from "./implementations/claude_code";
import { createCreateProjectTool } from "./implementations/create_project";
import { createDelegateExternalTool } from "./implementations/delegate_external";
import { createReportWriteTool } from "./implementations/report_write";
import { createReportReadTool } from "./implementations/report_read";
import { createReportsListTool } from "./implementations/reports_list";
import { createReportDeleteTool } from "./implementations/report_delete";

/**
 * Tool names available in the system
 */
export type ToolName =
  | "read_path"
  | "write_context_file"
  | "generate_inventory"
  | "lesson_learn"
  | "lesson_get"
  | "shell"
  | "agents_discover"
  | "agents_hire"
  | "agents_list"
  | "agents_read"
  | "agents_write"
  | "discover_capabilities"
  | "delegate"
  | "delegate_phase"
  | "delegate_followup"
  | "nostr_projects"
  | "claude_code"
  | "create_project"
  | "delegate_external"
  | "report_write"
  | "report_read"
  | "reports_list"
  | "report_delete";

/**
 * Extended AI SDK Tool type with human-readable content generation
 */
export interface TenexTool extends CoreTool<any, any> {
  /**
   * Generate human-readable content for tool execution
   * Used when publishing tool events to Nostr
   */
  getHumanReadableContent?: (args: any) => string;
}

/**
 * AI SDK Tool type - this is what the tool() function returns
 * CoreTool includes the description and parameters properties we need
 */
export type AISdkTool = TenexTool;

/**
 * Tool factory type - functions that create AI SDK tools with context
 */
export type ToolFactory = (context: ExecutionContext) => AISdkTool;

/**
 * Registry of tool factories
 */
const toolFactories: Record<ToolName, ToolFactory> = {
  read_path: createReadPathTool,
  write_context_file: createWriteContextFileTool,
  generate_inventory: createGenerateInventoryTool,
  lesson_learn: createLessonLearnTool,
  lesson_get: createLessonGetTool,
  shell: createShellTool,
  agents_discover: createAgentsDiscoverTool,
  agents_hire: createAgentsHireTool,
  agents_list: createAgentsListTool,
  agents_read: createAgentsReadTool,
  agents_write: createAgentsWriteTool,
  discover_capabilities: createMcpDiscoverTool,
  delegate: createDelegateTool,
  delegate_phase: createDelegatePhaseTool,
  delegate_followup: createDelegateFollowupTool,
  nostr_projects: createNostrProjectsTool,
  claude_code: createClaudeCodeTool,
  create_project: createCreateProjectTool,
  delegate_external: createDelegateExternalTool,
  report_write: createReportWriteTool,
  report_read: createReportReadTool,
  reports_list: createReportsListTool,
  report_delete: createReportDeleteTool,
};

/**
 * Get a single tool by name
 * @param name - The tool name
 * @param context - Execution context for the tool
 * @returns The instantiated AI SDK tool or undefined if not found
 */
export function getTool(name: ToolName, context: ExecutionContext): AISdkTool | undefined {
  const factory = toolFactories[name];
  return factory ? factory(context) : undefined;
}

/**
 * Get multiple tools by name
 * @param names - Array of tool names
 * @param context - Execution context for the tools
 * @returns Array of instantiated AI SDK tools
 */
export function getTools(names: ToolName[], context: ExecutionContext): AISdkTool[] {
  return names
    .map(name => getTool(name, context))
    .filter((tool): tool is AISdkTool => tool !== undefined);
}

/**
 * Get all available tools
 * @param context - Execution context for the tools
 * @returns Array of all instantiated AI SDK tools
 */
export function getAllTools(context: ExecutionContext): AISdkTool[] {
  return Object.keys(toolFactories).map(name => 
    getTool(name as ToolName, context)
  ).filter((tool): tool is AISdkTool => tool !== undefined);
}

/**
 * Get all available tool names
 * @returns Array of all tool names in the registry
 */
export function getAllToolNames(): ToolName[] {
  return Object.keys(toolFactories) as ToolName[];
}

/**
 * Get tools as a keyed object (for AI SDK usage)
 * @param names - Tool names to include (can include MCP tool names)
 * @param context - Execution context for the tools
 * @returns Object with tools keyed by name
 */
export function getToolsObject(names: string[], context: ExecutionContext): Record<string, AISdkTool> {
  const tools: Record<string, AISdkTool> = {};
  
  // Separate MCP tools from regular tools
  const regularTools: ToolName[] = [];
  const mcpToolNames: string[] = [];
  
  for (const name of names) {
    if (name.startsWith('mcp__')) {
      mcpToolNames.push(name);
    } else if (name in toolFactories) {
      regularTools.push(name as ToolName);
    }
  }
  
  // Add regular tools
  for (const name of regularTools) {
    const tool = getTool(name, context);
    if (tool) {
      tools[name] = tool;
    }
  }
  
  // Add MCP tools if any requested
  if (mcpToolNames.length > 0) {
    try {
      // Import and get MCP tools dynamically
      const { mcpService } = require("@/services/mcp/MCPManager");
      const allMcpTools = mcpService.getCachedTools();
      
      for (const mcpToolName of mcpToolNames) {
        // getCachedTools returns an object keyed by tool name
        const mcpTool = allMcpTools[mcpToolName];
        if (mcpTool) {
          // MCP tools from AI SDK already have the correct structure
          // They are CoreTool instances with description, parameters, and execute
          tools[mcpToolName] = mcpTool;
        } else {
          console.debug(`MCP tool '${mcpToolName}' not found in cached tools`);
        }
      }
    } catch (error) {
      // MCP not available, continue without MCP tools
      console.debug("Could not load MCP tools:", error);
    }
  }
  
  return tools;
}

/**
 * Get all tools as a keyed object
 * @param context - Execution context for the tools
 * @returns Object with all tools keyed by name
 */
export function getAllToolsObject(context: ExecutionContext): Record<string, AISdkTool> {
  const tools: Record<string, AISdkTool> = {};
  
  for (const name of Object.keys(toolFactories) as ToolName[]) {
    const tool = getTool(name, context);
    if (tool) {
      tools[name] = tool;
    }
  }
  
  return tools;
}

/**
 * Check if a tool name is valid
 * @param name - The tool name to check
 * @returns True if the tool name is valid
 */
export function isValidToolName(name: string): name is ToolName {
  return name in toolFactories;
}
</file>

<file path="src/agents/execution/types.ts">
import type { AgentInstance } from "@/agents/types";
import type { ConversationCoordinator } from "@/conversations";
import type { Phase } from "@/conversations/types";
import type { AgentPublisher } from "@/nostr/AgentPublisher";
import type { NDKEvent } from "@nostr-dev-kit/ndk";

export interface ExecutionContext {
  agent: AgentInstance;
  conversationId: string;
  phase: Phase;
  projectPath: string;
  triggeringEvent: NDKEvent;
  conversationCoordinator: ConversationCoordinator;
  agentPublisher: AgentPublisher; // Required: shared publisher instance for consistent event ordering
  isDelegationCompletion?: boolean; // True when agent is reactivated after a delegated task completes
}
</file>

<file path="src/commands/project/run.ts">
import * as path from "node:path";
import { ProjectDisplay } from "@/commands/run/ProjectDisplay";
import { SubscriptionManager } from "@/commands/run/SubscriptionManager";
import { EventHandler } from "@/event-handler";
// LLMLogger will be accessed from ProjectContext
import { shutdownNDK } from "@/nostr/ndkClient";
import { configService, getProjectContext } from "@/services";
import { mcpService } from "@/services/mcp/MCPManager";
import { StatusPublisher } from "@/services/status";
import { handleCliError } from "@/utils/cli-error";
import { formatAnyError } from "@/utils/error-formatter";
import { logger } from "@/utils/logger";
import { setupGracefulShutdown } from "@/utils/process";
import { ensureProjectInitialized } from "@/utils/projectInitialization";
import { Command } from "commander";

export const projectRunCommand = new Command("run")
  .description("Run the TENEX agent orchestration system for the current project")
  .option("-p, --path <path>", "Project path", process.cwd())
  .action(async (options) => {
    try {
      const projectPath = path.resolve(options.path);

      // Initialize project context (includes NDK setup)
      await ensureProjectInitialized(projectPath);

      // Initialize MCP service BEFORE displaying agents so MCP tools are available
      await mcpService.initialize(projectPath);

      // Refresh agent tools now that MCP is initialized
      // Update the agents directly in ProjectContext since AgentRegistry isn't exposed
      const projectCtx = getProjectContext();
      try {
        const allMcpTools = mcpService.getCachedTools();
        const mcpToolNames = Object.keys(allMcpTools);
        
        if (mcpToolNames.length > 0) {
          
          for (const [_, agent] of projectCtx.agents) {
            // Skip agents that have MCP disabled
            if (agent.mcp === false) continue;
            
            // Add MCP tools that aren't already in the agent's tool list
            const newMcpTools = mcpToolNames.filter(t => !agent.tools.includes(t));
            if (newMcpTools.length > 0) {
              agent.tools = [...agent.tools, ...newMcpTools];
              logger.debug(`Added ${newMcpTools.length} MCP tools to agent "${agent.name}"`);
            }
          }
          
          logger.info(`Updated agents with ${mcpToolNames.length} MCP tools`);
        }
      } catch (error) {
        logger.debug("Could not refresh agent tools with MCP", error);
      }

      // Display project information (now with MCP tools available)
      const projectDisplay = new ProjectDisplay();
      await projectDisplay.displayProjectInfo(projectPath);

      // Start the project listener
      await runProjectListener(projectPath);
    } catch (err) {
      // Don't double-log project configuration errors
      // as they're already handled in ensureProjectInitialized
      const error = err as Error;
      if (!error?.message?.includes("Project configuration missing projectNaddr")) {
        handleCliError(error, "Failed to start project");
      }
    }
  });

async function runProjectListener(projectPath: string): Promise<void> {
  try {
    const projectCtx = getProjectContext();
    const project = projectCtx.project;
    const titleTag = project.tagValue("title") || "Untitled Project";
    const dTag = project.tagValue("d") || "";
    logger.info(`Starting listener for project: ${titleTag} (${dTag})`);

    // Load LLM service from config
    const llmLogger = projectCtx.llmLogger;
    const llmService = configService.createLLMService(llmLogger);

    // MCP service already initialized before displaying agents

    // Initialize event handler
    const eventHandler = new EventHandler(projectPath, llmService);
    await eventHandler.initialize();

    // Initialize subscription manager
    const subscriptionManager = new SubscriptionManager(eventHandler, projectPath);
    await subscriptionManager.start();

    // Start status publisher
    const statusPublisher = new StatusPublisher();
    await statusPublisher.startPublishing(projectPath);

    // Start operations status publisher
    const { OperationsStatusPublisher } = await import("@/services");
    const { llmOpsRegistry } = await import("@/services/LLMOperationsRegistry");
    const operationsStatusPublisher = new OperationsStatusPublisher(llmOpsRegistry);
    operationsStatusPublisher.start();

    // Set up graceful shutdown
    setupGracefulShutdown(async () => {
      // Stop subscriptions first
      await subscriptionManager.stop();

      // Stop status publishers
      statusPublisher.stopPublishing();
      operationsStatusPublisher.stop();

      // Clean up event handler subscriptions
      await eventHandler.cleanup();

      // Shutdown MCP service
      await mcpService.shutdown();

      // Shutdown NDK singleton
      await shutdownNDK();

      logger.info("Project shutdown complete");
    });

    // Keep the process running
    await new Promise(() => {
      // This promise never resolves, keeping the listener active
    });
  } catch (err) {
    const errorMessage = formatAnyError(err);
    logger.error(`Failed to run project listener: ${errorMessage}`);
    throw err;
  }
}
</file>

<file path="src/services/ProjectContext.ts">
import type { AgentRegistry } from "@/agents/AgentRegistry";
import type { AgentInstance } from "@/agents/types";
import type { ConversationCoordinator } from "@/conversations";
import type { NDKAgentLesson } from "@/events/NDKAgentLesson";
import type { LLMLogger } from "@/logging/LLMLogger";
import { logger } from "@/utils/logger";
import type { Hexpubkey, NDKPrivateKeySigner } from "@nostr-dev-kit/ndk";
import { type NDKProject } from "@nostr-dev-kit/ndk";

/**
 * ProjectContext provides system-wide access to loaded project and agents
 * Initialized during "tenex project run" by ProjectManager
 */
export class ProjectContext {
  /**
   * Event that represents this project, note that this is SIGNED
   * by the USER, so this.project.pubkey is NOT the project's pubkey but the
   * USER OWNER'S pubkey.
   *
   * - projectCtx.pubkey = The project agent's pubkey (the bot/system)
   * - projectCtx.project.pubkey = The user's pubkey (who created the project)
   */
  public project: NDKProject;

  /**
   * Signer the project uses (hardwired to project manager's signer)
   */
  public readonly signer?: NDKPrivateKeySigner;

  /**
   * Pubkey of the project (PM's pubkey)
   */
  public readonly pubkey?: Hexpubkey;

  /**
   * The project manager agent for this project
   */
  public projectManager?: AgentInstance;

  /**
   * Agent registry - single source of truth for all agents
   */
  public readonly agentRegistry: AgentRegistry;

  /**
   * Getter for agents map to maintain compatibility
   */
  get agents(): Map<string, AgentInstance> {
    return this.agentRegistry.getAllAgentsMap();
  }

  /**
   * Lessons learned by agents in this project
   * Key: agent pubkey, Value: array of lessons (limited to most recent 50 per agent)
   */
  public readonly agentLessons: Map<string, NDKAgentLesson[]>;

  /**
   * Conversation manager for the project (optional, initialized when needed)
   */
  public conversationCoordinator?: ConversationCoordinator;

  /**
   * LLM Logger instance for this project
   */
  public readonly llmLogger: LLMLogger;

  constructor(project: NDKProject, agentRegistry: AgentRegistry, llmLogger: LLMLogger) {
    this.project = project;
    this.agentRegistry = agentRegistry;
    this.llmLogger = llmLogger;

    const agents = agentRegistry.getAllAgentsMap();
    
    // Debug logging
    logger.debug("Initializing ProjectContext", {
      projectId: project.id,
      projectTitle: project.tagValue("title"),
      agentsCount: agents.size,
      agentSlugs: Array.from(agents.keys()),
      agentDetails: Array.from(agents.entries()).map(([slug, agent]) => ({
        slug,
        name: agent.name,
        eventId: agent.eventId,
      })),
    });

    // Find the project manager agent - look for "pm" role suffix first
    const pmAgentTag = project.tags.find((tag: string[]) => 
      tag[0] === "agent" && tag[2] === "pm"
    );
    
    let projectManagerAgent: AgentInstance | undefined;
    
    if (pmAgentTag && pmAgentTag[1]) {
      const pmEventId = pmAgentTag[1];
      logger.info("Found explicit PM designation in project tags");
      
      // Find the agent with matching eventId
      for (const agent of agents.values()) {
        if (agent.eventId === pmEventId) {
          projectManagerAgent = agent;
          break;
        }
      }
      
      if (!projectManagerAgent) {
        throw new Error(
          `Project Manager agent not found. PM agent (eventId: ${pmEventId}) not loaded in registry.`
        );
      }
    } else {
      // Fallback: use first agent from tags or from registry
      const firstAgentTag = project.tags.find((tag: string[]) => tag[0] === "agent" && tag[1]);
      
      if (firstAgentTag) {
        const pmEventId = firstAgentTag[1];
        logger.info("No explicit PM found, using first agent from project tags as PM");
        
        // Find the agent with matching eventId
        for (const agent of agents.values()) {
          if (agent.eventId === pmEventId) {
            projectManagerAgent = agent;
            break;
          }
        }
        
        if (!projectManagerAgent) {
          throw new Error(
            `Project Manager agent not found. PM agent (eventId: ${pmEventId}) not loaded in registry.`
          );
        }
      } else if (agents.size > 0) {
        // No agent tags in project, but agents exist in registry (e.g., global agents)
        projectManagerAgent = agents.values().next().value;
        logger.info("No agent tags in project event, using first agent from registry as PM", {
          agentName: projectManagerAgent.name,
          agentSlug: projectManagerAgent.slug
        });
      } else {
        // No agents at all - this is allowed, project might work without agents
        logger.warn("No agents found in project or registry. Project will run without a project manager.");
      }
    }

    if (projectManagerAgent) {
      logger.info(`Using "${projectManagerAgent.name}" as Project Manager`);
    }

    // Hardwire to project manager's signer and pubkey (if available)
    if (projectManagerAgent) {
      this.signer = projectManagerAgent.signer;
      this.pubkey = projectManagerAgent.pubkey;
      this.projectManager = projectManagerAgent;
      
      // Tell AgentRegistry who the PM is so it can assign delegate tools correctly
      // Note: This is synchronous now, file saving happens later
      this.agentRegistry.setPMPubkey(projectManagerAgent.pubkey);
    }
    
    this.agentLessons = new Map();
  }

  // =====================================================================================
  // AGENT ACCESS HELPERS
  // =====================================================================================

  getAgent(slug: string): AgentInstance | undefined {
    return this.agentRegistry.getAgent(slug);
  }

  getAgentByPubkey(pubkey: Hexpubkey): AgentInstance | undefined {
    return this.agentRegistry.getAgentByPubkey(pubkey);
  }

  getProjectManager(): AgentInstance {
    return this.projectManager;
  }

  getProjectAgent(): AgentInstance {
    // Returns the project manager agent
    return this.projectManager;
  }

  getAgentSlugs(): string[] {
    return Array.from(this.agentRegistry.getAllAgentsMap().keys());
  }

  hasAgent(slug: string): boolean {
    return this.agentRegistry.getAgent(slug) !== undefined;
  }

  // =====================================================================================
  // LESSON MANAGEMENT
  // =====================================================================================

  /**
   * Add a lesson for an agent, maintaining the 50-lesson limit per agent
   */
  addLesson(agentPubkey: string, lesson: NDKAgentLesson): void {
    const existingLessons = this.agentLessons.get(agentPubkey) || [];

    // Add the new lesson at the beginning (most recent first)
    const updatedLessons = [lesson, ...existingLessons];

    // Keep only the most recent 50 lessons
    const limitedLessons = updatedLessons.slice(0, 50);

    this.agentLessons.set(agentPubkey, limitedLessons);
  }

  /**
   * Get lessons for a specific agent
   */
  getLessonsForAgent(agentPubkey: string): NDKAgentLesson[] {
    return this.agentLessons.get(agentPubkey) || [];
  }

  /**
   * Get all lessons across all agents
   */
  getAllLessons(): NDKAgentLesson[] {
    return Array.from(this.agentLessons.values()).flat();
  }

  /**
   * Safely update project data without creating a new instance.
   * This ensures all parts of the system work with consistent state.
   */
  async updateProjectData(newProject: NDKProject): Promise<void> {
    this.project = newProject;
    
    // Reload agents from project
    await this.agentRegistry.loadFromProject();
    
    const agents = this.agentRegistry.getAllAgentsMap();

    // Update project manager reference - look for "pm" role first
    const pmAgentTag = newProject.tags.find((tag: string[]) => 
      tag[0] === "agent" && tag[2] === "pm"
    );
    
    let pmEventId: string;
    if (pmAgentTag && pmAgentTag[1]) {
      pmEventId = pmAgentTag[1];
    } else {
      // Fallback to first agent
      const firstAgentTag = newProject.tags.find((tag: string[]) => tag[0] === "agent" && tag[1]);
      if (firstAgentTag) {
        pmEventId = firstAgentTag[1];
      } else {
        logger.error("No agents found in updated project");
        return;
      }
    }
    
    for (const agent of agents.values()) {
      if (agent.eventId === pmEventId) {
        this.projectManager = agent;
        break;
      }
    }
    
    // Tell AgentRegistry who the PM is after reload
    if (this.projectManager) {
      this.agentRegistry.setPMPubkey(this.projectManager.pubkey);
      await this.agentRegistry.persistPMStatus();
    }

    logger.info("ProjectContext updated with new data", {
      projectId: newProject.id,
      projectTitle: newProject.tagValue("title"),
      totalAgents: agents.size,
      agentSlugs: Array.from(agents.keys()),
    });
  }
}

// Module-level variable for global access
let projectContext: ProjectContext | undefined;

/**
 * Initialize the project context. Should be called once during project startup.
 */
export async function setProjectContext(project: NDKProject, agentRegistry: AgentRegistry, llmLogger: LLMLogger): Promise<void> {
  projectContext = new ProjectContext(project, agentRegistry, llmLogger);
  // Persist the PM status to disk
  await agentRegistry.persistPMStatus();
  // Note: publishProjectStatus() should be called explicitly after context is set
  // to avoid duplicate events during initialization
}

/**
 * Get the initialized project context
 * @throws Error if not initialized
 */
export function getProjectContext(): ProjectContext {
  if (!projectContext) {
    throw new Error(
      "ProjectContext not initialized. Please call setProjectContext() first or ensure the project has been properly initialized."
    );
  }
  return projectContext;
}

/**
 * Check if project context is initialized
 */
export function isProjectContextInitialized(): boolean {
  return projectContext !== undefined;
}
</file>

<file path="src/tools/implementations/shell.ts">
import { tool } from 'ai';
import { exec } from "node:child_process";
import { promisify } from "node:util";
import { ExecutionConfig } from "@/agents/execution/constants";
import { logger } from "@/utils/logger";
import { z } from "zod";
import type { ExecutionContext } from "@/agents/execution/types";

const execAsync = promisify(exec);

const shellSchema = z.object({
  command: z.string().describe("The shell command to execute"),
  cwd: z
    .string()
    .nullable()
    .describe("Working directory for the command (defaults to project root)"),
  timeout: z.coerce
    .number()
    .nullable()
    .describe(
      `Command timeout in milliseconds (default: ${ExecutionConfig.DEFAULT_COMMAND_TIMEOUT_MS})`
    ),
});

type ShellInput = z.infer<typeof shellSchema>;
type ShellOutput = string;

/**
 * Core implementation of shell command execution
 * Shared between AI SDK and legacy Tool interfaces
 */
async function executeShell(
  input: ShellInput,
  context: ExecutionContext
): Promise<ShellOutput> {
  const { command, cwd, timeout = ExecutionConfig.DEFAULT_COMMAND_TIMEOUT_MS } = input;

  const workingDir = cwd || context.projectPath;

  logger.info("Executing shell command", {
    command,
    cwd: workingDir,
    agent: context.agent.name,
    timeout,
  });

  // Publish status message about what command we're running
  try {
    const agentPublisher = context.agentPublisher;
    const conversation = context.conversationCoordinator.getConversation(context.conversationId);
    
    if (conversation?.history?.[0]) {
      await agentPublisher.conversation(
        { content: `‚ö° Executing: ${command}` },
        {
          triggeringEvent: context.triggeringEvent,
          rootEvent: conversation.history[0],
          conversationId: context.conversationId,
        }
      );
    }
  } catch (error) {
    console.warn("Failed to publish shell status:", error);
  }

  const { stdout, stderr } = await execAsync(command, {
    cwd: workingDir,
    timeout,
    env: {
      ...process.env,
      PATH: process.env.PATH,
      HOME: process.env.HOME,
    },
  });

  const output = stdout + (stderr ? `\nSTDERR:\n${stderr}` : "");

  logger.info("Shell command completed", {
    command,
    hasStdout: !!stdout,
    hasStderr: !!stderr,
  });

  return output;
}

/**
 * Create an AI SDK tool for executing shell commands
 */
export function createShellTool(context: ExecutionContext): ReturnType<typeof tool> {
  return tool({
    description:
      "Execute shell commands in the project directory. Use for system operations like git, npm, build tools, etc. NEVER use for file operations - use read_path/write_path instead. NEVER use for code modifications - edit files directly. Restricted to project-manager agent only. Commands run with timeout (default 2 minutes). Always prefer specialized tools over shell commands when available.",
    
    inputSchema: shellSchema,
    
    execute: async (input: ShellInput) => {
      try {
        return await executeShell(input, context);
      } catch (error) {
        throw new Error(`Command failed: ${error instanceof Error ? error.message : String(error)}`);
      }
    },
  });
}
</file>

<file path="src/conversations/AgentConversationContext.ts">
import { logger } from "@/utils/logger";
import type { NDKEvent } from "@nostr-dev-kit/ndk";
import type { ModelMessage } from "ai";
import { NostrEntityProcessor } from "./processors/NostrEntityProcessor";
import { MessageRoleAssigner } from "./processors/MessageRoleAssigner";
import { DelegationFormatter } from "./processors/DelegationFormatter";
import { stripThinkingBlocks, isOnlyThinkingBlocks, logThinkingBlockRemoval, hasReasoningTag } from "./utils/content-utils";
import type { AgentState, Conversation } from "./types";
import type { Phase } from "./phases";
import { toolMessageStorage } from "./persistence/ToolMessageStorage";

/**
 * Orchestrates message building for a specific agent in a conversation.
 * Single Responsibility: Coordinate the selection and ordering of messages for an agent.
 * This is now a STATELESS component that builds messages on-demand.
 * Note: Strip <thinking>...</thinking> blocks from conversation history; skip messages that are purely thinking blocks.
 */
export class AgentConversationContext {
  constructor(
    private conversationId: string,
    private agentSlug: string,
    private agentPubkey?: string
  ) {}

  /**
   * Get the thread path for an event by tracing e tags back to E tag
   * Returns array of event IDs from root to the target event
   */
  private getThreadPath(
    history: NDKEvent[],
    targetEvent: NDKEvent
  ): string[] {
    const path: string[] = [];
    const eventMap = new Map<string, NDKEvent>();
    
    // Build a map of event IDs to events for quick lookup
    for (const event of history) {
      eventMap.set(event.id, event);
    }

    // Get the root ID from E tag
    const rootId = targetEvent.tagValue("E");
    if (!rootId) {
      // No E tag means this is likely the root itself or an orphaned event
      return history.map(e => e.id);
    }

    // Trace back from target event to root via e tags
    let currentEvent: NDKEvent | undefined = targetEvent;
    const visitedIds = new Set<string>();
    
    while (currentEvent) {
      // Prevent infinite loops
      if (visitedIds.has(currentEvent.id)) {
        logger.warn("[THREAD_PATH] Circular reference detected", {
          eventId: currentEvent.id,
          conversationId: this.conversationId
        });
        break;
      }
      visitedIds.add(currentEvent.id);
      
      // Add to path (we'll reverse it later)
      path.unshift(currentEvent.id);
      
      // Check if we've reached the root
      if (currentEvent.id === rootId) {
        break;
      }
      
      // Get parent via e tag
      const parentId = currentEvent.tagValue("e");
      if (!parentId) {
        // No parent, we're at a thread root (or orphaned)
        break;
      }
      
      // If parent is the root, add it and stop
      if (parentId === rootId) {
        path.unshift(rootId);
        break;
      }
      
      // Move to parent
      currentEvent = eventMap.get(parentId);
      
      // If parent not in history, we have an incomplete thread
      if (!currentEvent) {
        logger.debug("[THREAD_PATH] Parent event not in history", {
          parentId,
          childId: path[0],
          conversationId: this.conversationId
        });
        // Try to at least include the root if we know about it
        if (eventMap.has(rootId)) {
          path.unshift(rootId);
        }
        break;
      }
    }
    
    return path;
  }

  /**
   * Filter conversation history to only include events in the thread path
   */
  private getThreadEvents(
    history: NDKEvent[],
    triggeringEvent?: NDKEvent
  ): NDKEvent[] {
    // If no triggering event, return all history (root context)
    if (!triggeringEvent) {
      return history;
    }

    // Get E and e tags to determine if this is a root or thread reply
    const rootTag = triggeringEvent.tagValue("E");
    const parentTag = triggeringEvent.tagValue("e");
    
    // If no root tag, treat as root conversation
    if (!rootTag) {
      return history;
    }
    
    // Check if this is a reply to the root (E == e or e points to root)
    const rootEvent = history.find(e => e.id === rootTag);
    const isRootReply = parentTag === rootTag || 
                       (rootEvent && parentTag === rootEvent.id);
    
    if (isRootReply) {
      // Root reply: include all chronological messages
      logger.debug("[THREAD_FILTER] Root reply detected, using full history", {
        conversationId: this.conversationId,
        rootTag,
        parentTag
      });
      return history;
    }
    
    // Thread reply: build thread-specific path
    logger.debug("[THREAD_FILTER] Thread reply detected, filtering to thread path", {
      conversationId: this.conversationId,
      rootTag,
      parentTag,
      historyLength: history.length
    });
    
    // Find the parent event we're replying to
    const parentEvent = history.find(e => e.id === parentTag);
    if (!parentEvent) {
      logger.warn("[THREAD_FILTER] Parent event not found in history", {
        parentTag,
        conversationId: this.conversationId
      });
      // Fall back to full history if we can't find the parent
      return history;
    }
    
    // Get the thread path
    const threadPath = this.getThreadPath(history, parentEvent);
    
    // Filter history to only include events in the thread path
    const threadEvents = history.filter(e => threadPath.includes(e.id));
    
    logger.debug("[THREAD_FILTER] Filtered to thread events", {
      conversationId: this.conversationId,
      originalCount: history.length,
      filteredCount: threadEvents.length,
      threadPath
    });
    
    return threadEvents;
  }

  /**
   * Filter a list of events to only include those in the same thread
   */
  private filterEventsToThread(
    events: NDKEvent[],
    triggeringEvent: NDKEvent
  ): NDKEvent[] {
    const rootTag = triggeringEvent.tagValue("E");
    const parentTag = triggeringEvent.tagValue("e");
    
    if (!rootTag) {
      return events;
    }
    
    // Check if this is a root reply
    const isRootReply = parentTag === rootTag;
    if (isRootReply) {
      return events;
    }
    
    // Get the thread path from the full conversation history
    // We need this because missed events might not have all intermediate events
    const allEvents = [...events];
    const threadPath = this.getThreadPath(allEvents, triggeringEvent);
    
    // Filter to only events in the thread path
    return events.filter(e => threadPath.includes(e.id));
  }


  /**
   * Build messages from conversation history for this agent
   * This is now a pure function that doesn't maintain state
   */
  async buildMessages(
    conversation: Conversation,
    agentState: AgentState,
    triggeringEvent?: NDKEvent,
    phaseInstructions?: string
  ): Promise<ModelMessage[]> {
    const messages: ModelMessage[] = [];

    // Get thread-filtered events based on the triggering event
    const threadEvents = this.getThreadEvents(conversation.history, triggeringEvent);

    // Process history up to (but not including) the triggering event
    for (const event of threadEvents) {
      if (!event.content) continue;
      if (triggeringEvent?.id && event.id === triggeringEvent.id) {
        break; // Don't include the triggering event in history
      }

      // Check if this is a tool event from this agent
      const isToolEvent = event.hasTag("tool");
      const isThisAgent = this.agentPubkey && event.pubkey === this.agentPubkey;

      if (isToolEvent && isThisAgent) {
        // Load the full tool messages from filesystem
        const toolMessages = await toolMessageStorage.load(event.id);
        if (toolMessages) {
          messages.push(...toolMessages);
          logger.debug("[AGENT_CONTEXT] Loaded tool messages", {
            eventId: event.id.substring(0, 8),
            messageCount: toolMessages.length,
          });
        } else {
          // Fallback: use the human-readable content
          const processed = await NostrEntityProcessor.processEntities(event.content);
          const message = await MessageRoleAssigner.assignRole(
            event,
            processed,
            this.agentSlug,
            this.conversationId
          );
          messages.push(message);
        }
      } else if (!isToolEvent) {
        // Regular non-tool message processing
        
        // Skip events with reasoning tag
        if (hasReasoningTag(event)) {
          logger.debug("[AGENT_CONTEXT] Skipping event with reasoning tag", {
            eventId: event.id.substring(0, 8),
            kind: event.kind,
          });
          continue;
        }

        // Skip events that are purely thinking blocks
        if (isOnlyThinkingBlocks(event.content)) {
          logger.debug("[AGENT_CONTEXT] Skipping event with only thinking blocks", {
            eventId: event.id.substring(0, 8),
            originalLength: event.content.length,
          });
          continue;
        }

        // Strip thinking blocks from content
        const strippedContent = stripThinkingBlocks(event.content);
        logThinkingBlockRemoval(event.id, event.content.length, strippedContent.length);
        
        // Process the stripped content
        const processed = await NostrEntityProcessor.processEntities(strippedContent);
        const message = await MessageRoleAssigner.assignRole(
          event, 
          processed, 
          this.agentSlug, 
          this.conversationId
        );
        messages.push(message);
      }
      // Skip tool events from other agents
    }

    // Add phase transition message if needed
    if (phaseInstructions) {
      const phaseMessage = this.buildSimplePhaseTransitionMessage(
        agentState.lastSeenPhase,
        conversation.phase
      );
      messages.push({ role: "system", content: phaseMessage + "\n\n" + phaseInstructions });
    }

    // Add the triggering event last
    if (triggeringEvent && triggeringEvent.content) {
      // Skip if triggering event has reasoning tag
      if (hasReasoningTag(triggeringEvent)) {
        logger.debug("[AGENT_CONTEXT] Triggering event has reasoning tag, skipping", {
          eventId: triggeringEvent.id.substring(0, 8),
        });
      } else if (isOnlyThinkingBlocks(triggeringEvent.content)) {
        // Skip if triggering event is only thinking blocks
        logger.debug("[AGENT_CONTEXT] Triggering event contains only thinking blocks, skipping", {
          eventId: triggeringEvent.id.substring(0, 8),
        });
      } else {
        // Strip thinking blocks from triggering event
        const strippedContent = stripThinkingBlocks(triggeringEvent.content);
        logThinkingBlockRemoval(triggeringEvent.id, triggeringEvent.content.length, strippedContent.length);
        
        const processed = await NostrEntityProcessor.processEntities(strippedContent);
        const message = await MessageRoleAssigner.assignRole(
          triggeringEvent,
          processed,
          this.agentSlug,
          this.conversationId
        );
        messages.push(message);
      }
    }

    logger.debug(`[AGENT_CONTEXT] Built ${messages.length} messages for ${this.agentSlug}`, {
      conversationId: this.conversationId,
      hasPhaseInstructions: !!phaseInstructions,
      hasTriggeringEvent: !!triggeringEvent,
    });

    return messages;
  }

  /**
   * Build messages with missed conversation history
   * Used when an agent needs to catch up on messages they missed
   */
  async buildMessagesWithMissedHistory(
    conversation: Conversation,
    agentState: AgentState,
    missedEvents: NDKEvent[],
    delegationSummary?: string,
    triggeringEvent?: NDKEvent,
    phaseInstructions?: string
  ): Promise<ModelMessage[]> {
    const messages: ModelMessage[] = [];

    // Filter missed events to only include those in the thread path
    let threadFilteredMissedEvents = triggeringEvent 
      ? this.filterEventsToThread(missedEvents, triggeringEvent)
      : missedEvents;

    // Filter out reasoning events
    threadFilteredMissedEvents = threadFilteredMissedEvents.filter(event => {
      if (hasReasoningTag(event)) {
        logger.debug("[AGENT_CONTEXT] Filtering reasoning event from missed history", {
          eventId: event.id.substring(0, 8),
        });
        return false;
      }
      return true;
    });

    // Add missed messages block if there are any
    if (threadFilteredMissedEvents.length > 0) {
      const missedBlock = await DelegationFormatter.buildMissedMessagesBlock(
        threadFilteredMissedEvents,
        this.agentSlug,
        delegationSummary
      );
      messages.push(missedBlock);
    }

    // Add phase transition if needed
    if (phaseInstructions) {
      const phaseMessage = this.buildSimplePhaseTransitionMessage(
        agentState.lastSeenPhase,
        conversation.phase
      );
      messages.push({ role: "system", content: phaseMessage + "\n\n" + phaseInstructions });
    }

    // Add triggering event
    if (triggeringEvent && triggeringEvent.content) {
      // Skip if triggering event has reasoning tag
      if (hasReasoningTag(triggeringEvent)) {
        logger.debug("[AGENT_CONTEXT] Triggering event has reasoning tag, skipping", {
          eventId: triggeringEvent.id.substring(0, 8),
        });
      } else if (isOnlyThinkingBlocks(triggeringEvent.content)) {
        // Skip if triggering event is only thinking blocks
        logger.debug("[AGENT_CONTEXT] Triggering event contains only thinking blocks, skipping", {
          eventId: triggeringEvent.id.substring(0, 8),
        });
      } else {
        // Strip thinking blocks from triggering event
        const strippedContent = stripThinkingBlocks(triggeringEvent.content);
        logThinkingBlockRemoval(triggeringEvent.id, triggeringEvent.content.length, strippedContent.length);
        
        const processed = await NostrEntityProcessor.processEntities(strippedContent);
        const message = await MessageRoleAssigner.assignRole(
          triggeringEvent,
          processed,
          this.agentSlug,
          this.conversationId
        );
        messages.push(message);
      }
    }

    return messages;
  }

  /**
   * Build messages with delegation responses
   */
  buildMessagesWithDelegationResponses(
    responses: Map<string, NDKEvent>,
    originalRequest: string,
    conversation: Conversation,
    agentState: AgentState,
    triggeringEvent?: NDKEvent,
    phaseInstructions?: string
  ): ModelMessage[] {
    const messages: ModelMessage[] = [];

    // Add the delegation responses block
    const delegationBlock = DelegationFormatter.buildDelegationResponsesBlock(
      responses,
      originalRequest
    );
    messages.push(delegationBlock);

    // Add phase transition if needed  
    if (phaseInstructions) {
      const phaseMessage = this.buildSimplePhaseTransitionMessage(
        agentState.lastSeenPhase,
        conversation.phase
      );
      messages.push({ role: "system", content: phaseMessage + "\n\n" + phaseInstructions });
    }

    // Note: Triggering event would typically already be in the delegation responses
    // but we can add it if needed for context
    if (triggeringEvent && triggeringEvent.content) {
      logger.debug("[AGENT_CONTEXT] Adding triggering event after delegation responses", {
        eventId: triggeringEvent.id,
      });
    }

    return messages;
  }

  /**
   * Extract session ID from an event (utility method)
   */
  extractSessionId(event: NDKEvent): string | undefined {
    return event.tagValue?.("claude-session");
  }

  /**
   * Build simple phase transition message (without instructions)
   * This is the simple format, different from the full transition with instructions
   */
  private buildSimplePhaseTransitionMessage(fromPhase: Phase | undefined, toPhase: Phase): string {
    if (fromPhase) {
      return `=== PHASE TRANSITION: ${fromPhase.toUpperCase()} ‚Üí ${toPhase.toUpperCase()} ===`;
    }
    return `=== CURRENT PHASE: ${toPhase.toUpperCase()} ===`;
  }
}
</file>

<file path="src/daemon/ProjectManager.ts">
import { exec } from "node:child_process";
import * as fs from "node:fs/promises";
import * as path from "node:path";
import { promisify } from "node:util";
import { NDKMCPTool } from "@/events/NDKMCPTool";
import { LLMConfigEditor } from "@/llm/LLMConfigEditor";
import { configService, setProjectContext } from "@/services";
import type { TenexConfig } from "@/services/config/types";
import { installMCPServerFromEvent } from "@/services/mcp/mcpInstaller";
import { LLMLogger } from "@/logging/LLMLogger";
import { ensureTenexInGitignore, initializeGitRepository } from "@/utils/git";
import { logger } from "@/utils/logger";
// createAgent functionality has been moved to AgentRegistry
import type NDK from "@nostr-dev-kit/ndk";
import type { NDKProject } from "@nostr-dev-kit/ndk";
import chalk from "chalk";

const execAsync = promisify(exec);

export interface ProjectData {
  identifier: string;
  pubkey: string;
  naddr: string;
  title: string;
  description?: string;
  repoUrl?: string;
  hashtags: string[];
  agentEventIds: string[];
  mcpEventIds: string[];
  createdAt?: number;
  updatedAt?: number;
}

export interface IProjectManager {
  initializeProject(projectPath: string, naddr: string, ndk: NDK): Promise<ProjectData>;
  loadProject(projectPath: string): Promise<ProjectData>;
  ensureProjectExists(identifier: string, naddr: string, ndk: NDK): Promise<string>;
  loadAndInitializeProjectContext(projectPath: string, ndk: NDK): Promise<void>;
}

export class ProjectManager implements IProjectManager {
  private projectsPath: string;

  constructor(projectsPath?: string) {
    this.projectsPath = projectsPath || path.join(process.cwd(), "projects");
  }
  async initializeProject(projectPath: string, naddr: string, ndk: NDK): Promise<ProjectData> {
    try {
      // Fetch project from Nostr
      const project = await this.fetchProject(naddr, ndk);
      const projectData = this.projectToProjectData(project);

      // Clone repository if provided, otherwise create directory and init git
      if (projectData.repoUrl) {
        await this.cloneRepository(projectData.repoUrl, projectPath);
      } else {
        // Create project directory and initialize git
        await fs.mkdir(projectPath, { recursive: true });
        await initializeGitRepository(projectPath);
        logger.info("Created new project directory and initialized git repository", {
          projectPath,
        });
      }

      // Ensure .tenex is in .gitignore
      await ensureTenexInGitignore(projectPath);

      // Create project structure (without nsec in config)
      await this.createProjectStructure(projectPath, projectData);

      // Initialize agent registry
      const AgentRegistry = (await import("@/agents/AgentRegistry")).AgentRegistry;
      const agentRegistry = new AgentRegistry(projectPath, false);

      // First, fetch and install agents from Nostr (source of truth)
      logger.info(`Installing ${projectData.agentEventIds.length} agents from Nostr events`);
      const { installAgentFromEvent } = await import("@/utils/agentInstaller");
      
      for (const eventId of projectData.agentEventIds) {
        try {
          logger.debug(`Installing agent from event: ${eventId}`);
          await installAgentFromEvent(eventId, projectPath, project, undefined, ndk);
        } catch (error) {
          logger.error(`Failed to install agent ${eventId} from Nostr`, { error });
        }
      }

      // Install MCP servers
      for (const eventId of projectData.mcpEventIds) {
        try {
          const event = await ndk.fetchEvent(eventId);
          if (event) {
            const mcpTool = NDKMCPTool.from(event);
            await installMCPServerFromEvent(projectPath, mcpTool);
            logger.info("Installed MCP server", { eventId, name: mcpTool.name });
          }
        } catch (error) {
          logger.error(`Failed to fetch or install MCP server ${eventId}`, { error });
        }
      }

      // Now load from local files (which were just created/updated)
      await agentRegistry.loadFromProject();

      // Create and initialize LLM logger
      const llmLogger = new LLMLogger();
      llmLogger.initialize(projectPath);

      // Now set the project context with the agent registry
      await setProjectContext(project, agentRegistry, llmLogger);

      // Republish kind:0 events for all agents
      await agentRegistry.republishAllAgentProfiles(project);

      // Check if LLM configuration is needed
      await this.checkAndRunLLMConfigWizard(projectPath);

      return projectData;
    } catch (error) {
      logger.error("Failed to initialize project", { error });
      throw error;
    }
  }

  async loadProject(projectPath: string): Promise<ProjectData> {
    try {
      const { config } = await configService.loadConfig(projectPath);

      if (!config.projectNaddr) {
        throw new Error("Project configuration missing projectNaddr");
      }

      // For now, return a simplified version without decoding naddr
      // The identifier and pubkey will be filled when the project is fetched from Nostr
      return {
        identifier: config.projectNaddr, // Use naddr as identifier temporarily
        pubkey: "", // Will be filled when fetched from Nostr
        naddr: config.projectNaddr,
        title: "Untitled Project", // This should come from NDKProject
        description: config.description,
        repoUrl: config.repoUrl || undefined,
        hashtags: [], // This should come from NDKProject
        agentEventIds: [],
        mcpEventIds: [],
        createdAt: undefined, // This should come from NDKProject
        updatedAt: undefined, // This should come from NDKProject
      };
    } catch (error) {
      logger.error("Failed to load project", { error, projectPath });
      throw new Error(`Failed to load project from ${projectPath}`);
    }
  }

  async ensureProjectExists(identifier: string, naddr: string, ndk: NDK): Promise<string> {
    const projectPath = path.join(this.projectsPath, identifier);

    // Check if project already exists
    if (await this.projectExists(projectPath)) {
      return projectPath;
    }

    // Initialize the project
    await this.initializeProject(projectPath, naddr, ndk);

    return projectPath;
  }

  async loadAndInitializeProjectContext(projectPath: string, ndk: NDK): Promise<void> {
    try {
      // Load project configuration
      const { config } = await configService.loadConfig(projectPath);

      if (!config.projectNaddr) {
        throw new Error("Project configuration missing projectNaddr");
      }

      // Fetch project from Nostr
      const project = await this.fetchProject(config.projectNaddr, ndk);
      logger.debug("Fetched project from Nostr", {
        projectId: project.id,
        projectTitle: project.tagValue("title"),
        projectNaddr: config.projectNaddr,
      });

      // Load agents using AgentRegistry
      const AgentRegistry = (await import("@/agents/AgentRegistry")).AgentRegistry;
      const agentRegistry = new AgentRegistry(projectPath, false);
      
      // First, fetch and install agents from Nostr (source of truth)
      const agentEventIds = project.tags
        .filter((t) => t[0] === "agent" && t[1])
        .map((t) => t[1])
        .filter(Boolean) as string[];
      
      logger.info(`Installing ${agentEventIds.length} agents from Nostr events`);
      const { installAgentFromEvent } = await import("@/utils/agentInstaller");
      
      for (const eventId of agentEventIds) {
        try {
          logger.debug(`Installing agent from event: ${eventId}`);
          await installAgentFromEvent(eventId, projectPath, project, undefined, ndk);
        } catch (error) {
          logger.error(`Failed to install agent ${eventId} from Nostr`, { error });
        }
      }
      
      // Now load from local files (which were just created/updated)
      await agentRegistry.loadFromProject();

      // Create and initialize LLM logger
      const llmLogger = new LLMLogger();
      llmLogger.initialize(projectPath);

      // Initialize ProjectContext with the agent registry
      await setProjectContext(project, agentRegistry, llmLogger);

      // Initialize ConversationCoordinator for CLI commands
      const projectCtx = (await import("@/services")).getProjectContext();
      const ConversationCoordinator = (await import("@/conversations"))
        .ConversationCoordinator;

      const conversationCoordinator = new ConversationCoordinator(projectPath);
      await conversationCoordinator.initialize();
      
      projectCtx.conversationCoordinator = conversationCoordinator;

      // Republish kind:0 events for all agents on project load
      await agentRegistry.republishAllAgentProfiles(project);

      // LLM logger is now initialized and passed to ProjectContext above
    } catch (error: unknown) {
      // Only log if it's not a missing project configuration error
      // The MCP server command will handle this specific error with a friendlier message
      const errorMessage = error instanceof Error ? error.message : String(error);
      if (!errorMessage.includes("Project configuration missing projectNaddr")) {
        logger.error("Failed to initialize ProjectContext", { error, projectPath });
      }
      throw error;
    }
  }

  private async fetchProject(naddr: string, ndk: NDK): Promise<NDKProject> {
    const event = await ndk.fetchEvent(naddr);
    if (!event) {
      throw new Error(`Project event not found: ${naddr}`);
    }
    return event as NDKProject;
  }

  private projectToProjectData(project: NDKProject): ProjectData {
    if (!project.dTag) {
      throw new Error("Project missing required d tag identifier");
    }
    
    const repoTag = project.tagValue("repo");
    const titleTag = project.tagValue("title");
    const hashtagTags = project.tags
      .filter((t) => t[0] === "t")
      .map((t) => t[1])
      .filter(Boolean) as string[];

    const agentTags = project.tags
      .filter((t) => t[0] === "agent")
      .map((t) => t[1])
      .filter(Boolean) as string[];

    const mcpTags = project.tags
      .filter((t) => t[0] === "mcp")
      .map((t) => t[1])
      .filter(Boolean) as string[];

    return {
      identifier: project.dTag,
      pubkey: project.pubkey,
      naddr: project.encode(),
      title: titleTag || "Untitled Project",
      description: project.description,
      repoUrl: repoTag,
      hashtags: hashtagTags,
      agentEventIds: agentTags,
      mcpEventIds: mcpTags,
      createdAt: project.created_at,
      updatedAt: project.created_at,
    };
  }

  private async cloneRepository(repoUrl: string, projectPath: string): Promise<void> {
    try {
      await fs.mkdir(path.dirname(projectPath), { recursive: true });
      const { stdout, stderr } = await execAsync(`git clone "${repoUrl}" "${projectPath}"`);
      if (stderr) {
        logger.warn("Git clone warning", { stderr });
      }
      logger.info("Cloned repository", { repoUrl, projectPath, stdout });
    } catch (error) {
      logger.error("Failed to clone repository", { error, repoUrl });
      throw error;
    }
  }

  private async createProjectStructure(
    projectPath: string,
    projectData: ProjectData
  ): Promise<void> {
    const tenexPath = path.join(projectPath, ".tenex");
    await fs.mkdir(tenexPath, { recursive: true });

    // Create project config (without nsec - it's now in agents.json)
    const projectConfig: TenexConfig = {
      description: projectData.description,
      repoUrl: projectData.repoUrl || undefined,
      projectNaddr: projectData.naddr,
    };

    await configService.saveProjectConfig(projectPath, projectConfig);

    logger.info("Created project structure with config", { projectPath });
  }


  private async projectExists(projectPath: string): Promise<boolean> {
    try {
      await fs.access(projectPath);
      const tenexPath = path.join(projectPath, ".tenex");
      await fs.access(tenexPath);

      // Also verify that config.json exists and has projectNaddr
      const { config } = await configService.loadConfig(projectPath);
      if (!config.projectNaddr) {
        logger.warn("Project directory exists but config is incomplete (missing projectNaddr)", {
          projectPath,
        });
        return false;
      }

      return true;
    } catch {
      return false;
    }
  }

  private async checkAndRunLLMConfigWizard(projectPath: string): Promise<void> {
    try {
      const { llms: llmsConfig } = await configService.loadConfig(projectPath);

      // Check if there are any LLM configurations
      const hasLLMConfig =
        llmsConfig?.configurations && Object.keys(llmsConfig.configurations).length > 0;

      if (!hasLLMConfig) {
        logger.info(
          chalk.yellow(
            "\n‚ö†Ô∏è  No LLM configurations found. Let's set up your LLMs for this project.\n"
          )
        );

        const llmEditor = new LLMConfigEditor(projectPath, false);
        await llmEditor.runOnboardingFlow();
      }
    } catch (error) {
      logger.warn("Failed to check LLM configuration", { error });
      // Don't throw - LLM configuration is not critical for project initialization
    }
  }
}
</file>

<file path="src/tools/implementations/delegate.ts">
import { tool } from 'ai';
import { DelegationService, type DelegationResponses } from "@/services/DelegationService";
import { resolveRecipientToPubkey } from "@/utils/agent-resolution";
import { logger } from "@/utils/logger";
import { z } from "zod";
import type { ExecutionContext } from "@/agents/execution/types";

const delegateSchema = z.object({
  recipients: z
    .array(z.string())
    .describe(
      "Array of agent slug(s) (e.g., ['architect']), name(s) (e.g., ['Architect']), npub(s), or hex pubkey(s) of the recipient agent(s)"
    ),
  fullRequest: z
    .string()
    .describe("The complete request or question to delegate to the recipient agent(s)"),
});

type DelegateInput = z.infer<typeof delegateSchema>;
type DelegateOutput = DelegationResponses;

// Core implementation - extracted from existing execute function
async function executeDelegate(input: DelegateInput, context: ExecutionContext): Promise<DelegateOutput> {
  const { recipients, fullRequest } = input;

  // Recipients is always an array due to schema validation
  if (!Array.isArray(recipients)) {
    throw new Error("Recipients must be an array of strings");
  }

  // Resolve recipients to pubkeys
  const resolvedPubkeys: string[] = [];
  const failedRecipients: string[] = [];

  for (const recipient of recipients) {
    const pubkey = resolveRecipientToPubkey(recipient);
    if (pubkey) {
      resolvedPubkeys.push(pubkey);
    } else {
      failedRecipients.push(recipient);
    }
  }

  if (failedRecipients.length > 0) {
    logger.warn("Some recipients could not be resolved", {
      failed: failedRecipients,
      resolved: resolvedPubkeys.length,
    });
  }

  if (resolvedPubkeys.length === 0) {
    throw new Error("No valid recipients provided.");
  }

  // Use DelegationService to execute the delegation
  const delegationService = new DelegationService(
    context.agent,
    context.conversationId,
    context.conversationCoordinator,
    context.triggeringEvent,
    context.agentPublisher, // Pass the required AgentPublisher
    context.phase
  );
  
  return await delegationService.execute({
    recipients: resolvedPubkeys,
    request: fullRequest,
  });
}

// AI SDK tool factory
export function createDelegateTool(context: ExecutionContext): ReturnType<typeof tool> {
  return tool({
    description: "Delegate a task or question to one or more agents and wait for their responses. Use for complex multi-step operations that require specialized expertise. Provide complete context in the request - agents have no visibility into your conversation. Can delegate to multiple agents in parallel by providing array of recipients. Recipients can be agent slugs (e.g., 'architect'), names (e.g., 'Architect'), npubs, or hex pubkeys. Responses are returned synchronously - the tool waits for all agents to complete.",
    inputSchema: delegateSchema,
    execute: async (input: DelegateInput) => {
      return await executeDelegate(input, context);
    },
  });
}

/**
 * Delegate tool - enables agents to communicate with each other via kind:1111 conversation events
 *
 * This tool allows an agent to delegate a request or question to one or more agents by:
 * 1. Resolving each recipient (agent slug or pubkey) to a pubkey
 * 2. Publishing a kind:1111 conversation event for each recipient with p-tag assignment
 * 3. Setting up delegation state so the agent waits for all responses
 *
 * Recipients can be:
 * - A single recipient or array of recipients
 * - Agent slugs (e.g., "architect", "planner") - resolved from project agents
 * - Agent names (e.g., "Architect", "Planner") - resolved from project agents
 * - Npubs (e.g., "npub1...") - decoded to hex pubkeys
 * - Hex pubkeys (64 characters) - used directly
 *
 * If any recipient cannot be resolved, the tool fails with an error.
 *
 * When delegating to multiple recipients, the agent will wait for all responses
 * before continuing. The agent should NOT complete after delegating.
 *
 * Each delegation creates a kind:1111 conversation event (following NIP-22) that:
 * - Is addressed to a specific agent via p-tag
 * - Maintains conversation threading via E/e tags
 * - Enables natural agent-to-agent communication
 * - Supports parallel execution when delegating to multiple agents
 */
</file>

<file path="src/services/status/StatusPublisher.ts">
// Status publishing interval
const STATUS_INTERVAL_MS = 30_000; // 30 seconds

import { EVENT_KINDS } from "@/llm/types";
import type { StatusIntent } from "@/nostr/AgentEventEncoder";
import { getNDK } from "@/nostr/ndkClient";
import { configService, getProjectContext, isProjectContextInitialized } from "@/services";
import { mcpService } from "@/services/mcp/MCPManager";
import { formatAnyError } from "@/utils/error-formatter";
import { logger } from "@/utils/logger";
import { NDKEvent } from "@nostr-dev-kit/ndk";

/**
 * StatusPublisher handles periodic publishing of status events to Nostr.
 *
 * This class manages the lifecycle of status event publishing, including:
 * - Starting and stopping the periodic publishing interval
 * - Creating and publishing status events with agent and model information
 * - Handling errors gracefully to ensure the main process continues
 *
 * Status events are published at regular intervals (STATUS_INTERVAL_MS) and include:
 * - Project reference tags
 * - Agent pubkeys and slugs
 * - Model configurations
 *
 * @example
 * ```typescript
 * const publisher = new StatusPublisher();
 * await publisher.startPublishing('/path/to/project');
 * // ... later
 * publisher.stopPublishing();
 * ```
 */
export class StatusPublisher {
  private statusInterval?: NodeJS.Timeout;

  constructor() {
    // No dependencies needed
  }

  async startPublishing(projectPath: string): Promise<void> {
    await this.publishStatusEvent(projectPath);

    this.statusInterval = setInterval(async () => {
      await this.publishStatusEvent(projectPath);
    }, STATUS_INTERVAL_MS);
  }

  stopPublishing(): void {
    if (this.statusInterval) {
      clearInterval(this.statusInterval);
      this.statusInterval = undefined;
    }
  }

  /**
   * Create a status event from the intent.
   * Directly creates the event without depending on AgentPublisher.
   */
  private createStatusEvent(intent: StatusIntent): NDKEvent {
    const event = new NDKEvent(getNDK());
    event.kind = EVENT_KINDS.PROJECT_STATUS;
    event.content = "";

    // Add project tag
    const projectCtx = getProjectContext();
    event.tag(projectCtx.project.tagReference());

    // Add p-tag for the project owner's pubkey
    event.tag(["p", projectCtx.project.pubkey]);

    // Track unique agent slugs for single-letter tags
    const uniqueAgentSlugs = new Set<string>();

    // Add agent pubkeys with PM flag for project manager
    const pmPubkey = projectCtx.projectManager?.pubkey;
    for (const agent of intent.agents) {
      const tags = ["agent", agent.pubkey, agent.slug];
      // Add "pm" flag if this is the project manager
      if (pmPubkey && agent.pubkey === pmPubkey) {
        tags.push("pm");
      }
      event.tag(tags);
      
      // Collect unique agent slugs
      uniqueAgentSlugs.add(agent.slug);
    }

    // Add model access tags
    for (const model of intent.models) {
      event.tag(["model", model.slug, ...model.agents]);
      
      // Collect agent slugs from models
      for (const agentSlug of model.agents) {
        uniqueAgentSlugs.add(agentSlug);
      }
    }

    // Add tool access tags
    for (const tool of intent.tools) {
      event.tag(["tool", tool.name, ...tool.agents]);
    }

    return event;
  }

  private async publishStatusEvent(projectPath: string): Promise<void> {
    try {
      const projectCtx = getProjectContext();

      // Build status intent
      const intent: StatusIntent = {
        type: "status",
        agents: [],
        models: [],
        tools: [],
        queue: [],
      };

      // Gather agent info - preserve order from NDKProject
      if (isProjectContextInitialized()) {
        // Get agent tags from project in their original order
        const projectAgentTags = projectCtx.project.tags
          .filter((tag) => tag[0] === "agent" && tag[1]);
        
        // Track which agents we've already added (by slug)
        const addedAgentSlugs = new Set<string>();
        
        // First, add agents that have eventIds in the order they appear in the project
        for (const agentTag of projectAgentTags) {
          const eventId = agentTag[1];
          
          // Find agent with matching eventId
          for (const [agentSlug, agent] of projectCtx.agentRegistry.getAllAgentsMap()) {
            if (agent.eventId === eventId) {
              intent.agents.push({
                pubkey: agent.pubkey,
                slug: agentSlug,
              });
              addedAgentSlugs.add(agentSlug);
              break;
            }
          }
        }
        
        // Then add any remaining agents (global or inline agents without eventIds)
        for (const [agentSlug, agent] of projectCtx.agentRegistry.getAllAgentsMap()) {
          if (!addedAgentSlugs.has(agentSlug)) {
            intent.agents.push({
              pubkey: agent.pubkey,
              slug: agentSlug,
            });
          }
        }
      }

      // Gather model info
      await this.gatherModelInfo(intent, projectPath);

      // Gather tool info
      await this.gatherToolInfo(intent);

      // Gather queue info
      // Queue functionality removed

      // Create and publish the status event directly
      const event = this.createStatusEvent(intent);

      // Sign and publish with project signer if available
      if (projectCtx.signer) {
        await event.sign(projectCtx.signer);
        await event.publish();
      } else {
        logger.warn("No project signer available, cannot publish status event");
      }
    } catch (err) {
      const errorMessage = formatAnyError(err);
      logger.warn(`Failed to publish status event: ${errorMessage}`);
    }
  }

  private async gatherModelInfo(intent: StatusIntent, projectPath: string): Promise<void> {
    try {
      const { llms } = await configService.loadConfig(projectPath);

      if (!llms || !llms.configurations) {
        logger.debug("No LLM configurations found");
        return;
      }

      // Build a map of configuration slugs to agents that use them
      const configToAgents = new Map<string, Set<string>>();

      // First, add ALL configured models (even if not used by any agent)
      for (const configSlug of Object.keys(llms.configurations)) {
        configToAgents.set(configSlug, new Set());
      }

      logger.debug(`Found ${Object.keys(llms.configurations).length} LLM configurations`);
      logger.debug(`Global default configuration: ${llms.default || 'none'}`);

      // Process agent-specific configurations
      if (isProjectContextInitialized()) {
        const projectCtx = getProjectContext();

        // Get the global default configuration name
        const globalDefault = llms.default;

        // Map each agent to its configuration
        const agentsList = Array.from(projectCtx.agentRegistry.getAllAgentsMap().keys());
        logger.debug(`Mapping ${agentsList.length} agents to configurations: ${agentsList.join(', ')}`);
        
        for (const [agentSlug, agent] of projectCtx.agentRegistry.getAllAgentsMap()) {
          // Check if agent has a specific llmConfig
          const agentConfig = agent.llmConfig;
          
          if (agentConfig && llms.configurations[agentConfig]) {
            // Agent has a specific configuration that exists
            configToAgents.get(agentConfig)?.add(agentSlug);
            logger.debug(`Agent '${agentSlug}' mapped to specific configuration '${agentConfig}'`);
          } else if (globalDefault && llms.configurations[globalDefault]) {
            // Fall back to global default configuration
            configToAgents.get(globalDefault)?.add(agentSlug);
            logger.debug(`Agent '${agentSlug}' mapped to default configuration '${globalDefault}'`);
          } else {
            logger.debug(`Agent '${agentSlug}' not mapped - no valid configuration found (agent config: ${agentConfig}, default: ${globalDefault})`);
          }
        }
      } else {
        if (!isProjectContextInitialized()) {
          logger.debug("Project context not initialized for agent mapping");
        }
      }

      // Add models to intent
      for (const [configSlug, agentSet] of configToAgents) {
        const agentSlugs = Array.from(agentSet).sort(); // Sort for consistency
        logger.debug(`Configuration '${configSlug}' has ${agentSlugs.length} agents: ${agentSlugs.join(', ')}`);
        intent.models.push({
          slug: configSlug,
          agents: agentSlugs,
        });
      }
    } catch (err) {
      logger.warn(
        `Could not load LLM information for status event model tags: ${formatAnyError(err)}`
      );
    }
  }

  private async gatherToolInfo(intent: StatusIntent): Promise<void> {
    try {
      if (!isProjectContextInitialized()) {
        logger.warn("ProjectContext not initialized for tool tags");
        return;
      }

      const projectCtx = getProjectContext();
      const toolAgentMap = new Map<string, Set<string>>();

      // Import the delegate tools and core tools lists from the single source of truth
      const { DELEGATE_TOOLS, CORE_AGENT_TOOLS } = await import("@/agents/constants");

      // First, add ALL tool names from the registry (except delegate tools and core tools)
      const { getAllToolNames } = await import("@/tools/registry");
      const allToolNames = getAllToolNames();
      for (const toolName of allToolNames) {
        // Skip delegate tools and core tools from kind 24010 events
        // These are handled automatically by the system
        if (!DELEGATE_TOOLS.includes(toolName) && !CORE_AGENT_TOOLS.includes(toolName)) {
          toolAgentMap.set(toolName, new Set());
        }
      }

      // Then build a map of tool name -> set of agent slugs that have access
      for (const [agentSlug, agent] of projectCtx.agentRegistry.getAllAgentsMap()) {
        // Get the agent's configured tools
        const agentTools = agent.tools || [];

        for (const toolName of agentTools) {
          // Skip invalid tool names
          if (!toolName) {
            logger.warn(`Agent ${agentSlug} has invalid tool name: ${toolName}`);
            continue;
          }
          // Skip delegate tools and core tools - they're not included in kind 24010 events
          // These are handled automatically by the system
          if (DELEGATE_TOOLS.includes(toolName) || CORE_AGENT_TOOLS.includes(toolName)) {
            continue;
          }
          const toolAgents = toolAgentMap.get(toolName);
          if (toolAgents) {
            toolAgents.add(agentSlug);
          }
        }

        // If agent has MCP access, add all MCP tools
        if (agent.mcp) {
          try {
            const mcpTools = mcpService.getCachedTools();
            for (const [toolNameKey] of Object.entries(mcpTools)) {
              // Tool name is the key
              
              // Skip if somehow there's no tool name (shouldn't happen with object keys)
              if (!toolNameKey) {
                continue;
              }
              
              const toolName = toolNameKey;
              
              if (!toolAgentMap.has(toolName)) {
                toolAgentMap.set(toolName, new Set());
              }
              const toolAgents = toolAgentMap.get(toolName);
              if (toolAgents) {
                toolAgents.add(agentSlug);
              }
            }
          } catch (err) {
            // MCP tools might not be available yet, that's okay
            logger.warn(`Could not get MCP tools for status event: ${formatAnyError(err)}`);
          }
        }
      }

      // Convert the map to tool entries
      // Include ALL tools with valid names, even if no agents are assigned
      for (const [toolName, agentSlugs] of toolAgentMap) {
        if (toolName) {
          const agentArray = Array.from(agentSlugs).sort(); // Sort for consistency
          intent.tools.push({
            name: toolName,
            agents: agentArray, // Can be empty array for unassigned tools
          });
        }
      }
    } catch (err) {
      logger.warn(`Could not add tool tags to status event: ${formatAnyError(err)}`);
    }
  }

}
</file>

<file path="src/tools/implementations/learn.ts">
import { tool } from 'ai';
import type { EventContext, LessonIntent } from "@/nostr/AgentEventEncoder";
import { logger } from "@/utils/logger";
import { z } from "zod";
import type { ExecutionContext } from "@/agents/execution/types";

const lessonLearnSchema = z.object({
  title: z.string().describe("Brief title/description of what this lesson is about"),
  lesson: z.string().describe("The key insight or lesson learned - be concise and actionable"),
  detailed: z
    .string()
    .nullable()
    .describe("Detailed version with richer explanation when deeper context is needed"),
  category: z
    .string()
    .nullable()
    .describe(
      "Single category for filing this lesson (e.g., 'architecture', 'debugging', 'user-preferences')"
    ),
  hashtags: z
    .array(z.string())
    .nullable()
    .describe("Hashtags for easier sorting and discovery (e.g., ['async', 'error-handling'])"),
});

type LessonLearnInput = z.infer<typeof lessonLearnSchema>;
type LessonLearnOutput = {
  message: string;
  eventId: string;
  title: string;
  hasDetailed: boolean;
};

// Core implementation - extracted from existing execute function
async function executeLessonLearn(input: LessonLearnInput, context: ExecutionContext): Promise<LessonLearnOutput> {
  const { title, lesson, detailed, category, hashtags } = input;

  logger.info("üéì Agent recording new lesson", {
    agent: context.agent.name,
    agentPubkey: context.agent.pubkey,
    title,
    lessonLength: lesson.length,
    phase: context.phase,
    conversationId: context.conversationId,
  });

  // Create lesson intent
  const intent: LessonIntent = {
    title,
    lesson,
    detailed,
    category,
    hashtags,
  };

  // Get conversation for the event context
  const conversation = context.conversationCoordinator.getConversation(context.conversationId);

  // Create event context
  const eventContext: EventContext = {
    triggeringEvent: context.triggeringEvent,
    rootEvent: conversation?.history[0] ?? context.triggeringEvent, // Use triggering event as fallback
    conversationId: context.conversationId,
    model: context.agent.llmConfig, // Include LLM configuration
  };

  // Use shared AgentPublisher instance from context to create and publish the lesson
  const lessonEvent = await context.agentPublisher.lesson(intent, eventContext);

  // Publish status message with the Nostr reference
  try {
    const conversation = context.conversationCoordinator.getConversation(context.conversationId);
    if (conversation?.history?.[0]) {
      const nostrReference = `nostr:${lessonEvent.encode()}`;
      await context.agentPublisher.conversation(
        { content: `üìö Learning lesson: ${nostrReference}` },
        {
          triggeringEvent: context.triggeringEvent,
          rootEvent: conversation.history[0],
          conversationId: context.conversationId,
          model: context.agent.llmConfig, // Include LLM configuration
        }
      );
    }
  } catch (error) {
    // Don't fail the tool if we can't publish the status
    console.warn("Failed to publish learn status:", error);
  }

  const message = `‚úÖ Lesson recorded: "${title}"${detailed ? " (with detailed version)" : ""}\n\nThis lesson will be available in future conversations to help avoid similar issues.`;

  return {
    message,
    eventId: lessonEvent.encode(),
    title,
    hasDetailed: !!detailed,
  };
}

// AI SDK tool factory
export function createLessonLearnTool(context: ExecutionContext): ReturnType<typeof tool> {
  return tool({
    description: "Record new lessons and insights for future reference. Use when discovering patterns, solutions, or important knowledge that should be preserved. Lessons persist across conversations and help build institutional memory. Include both concise lesson and detailed explanation when complexity warrants it. Categorize and tag appropriately for future discovery. Lessons become immediately available via lesson_get.",
    inputSchema: lessonLearnSchema,
    execute: async (input: LessonLearnInput) => {
      return await executeLessonLearn(input, context);
    },
  });
}
</file>

<file path="src/services/DelegationRegistry.ts">
import { EventEmitter } from "node:events";
import { promises as fs } from "node:fs";
import path from "node:path";
import type { AgentInstance } from "@/agents/types";
import { logger } from "@/utils/logger";
import { NDKEvent } from "@nostr-dev-kit/ndk";
import { z } from "zod";

export interface DelegationRecord {
  // Core identifiers
  delegationEventId: string; // Delegation event ID (kind:1111) - actual Nostr event ID
  delegationBatchId: string; // Groups tasks delegated together

  // Context from delegating agent
  delegatingAgent: {
    slug: string;
    pubkey: string;
    rootConversationId: string; // Root conversation where delegation originated
  };

  // Delegation assignment
  assignedTo: {
    pubkey: string;
    slug?: string; // May not be known at delegation time
  };

  // Delegation details
  content: {
    fullRequest: string;
    phase?: string;
  };

  // Status tracking
  status: "pending" | "in_progress" | "completed" | "failed";

  // Completion details (when status !== 'pending')
  completion?: {
    response: string;
    summary?: string;
    completedAt: number;
    completedBy: string; // Pubkey of completing agent
    event?: NDKEvent; // The actual completion event for threading
  };

  // Metadata
  createdAt: number;
  updatedAt: number;

  // Related delegations (siblings in same delegation batch)
  siblingDelegationIds: string[];
}

interface DelegationBatch {
  batchId: string;
  delegatingAgent: string;
  delegationKeys: string[]; // Conversation keys for each delegation
  allCompleted: boolean;
  createdAt: number;
  originalRequest: string;
  rootConversationId: string;
}

// Zod schemas for validation
const DelegationRecordSchema = z.object({
  delegationEventId: z.string(),
  delegationBatchId: z.string(),
  delegatingAgent: z.object({
    slug: z.string(),
    pubkey: z.string(),
    rootConversationId: z.string(),
  }),
  assignedTo: z.object({
    pubkey: z.string(),
    slug: z.string().optional(),
  }),
  content: z.object({
    fullRequest: z.string(),
    phase: z.string().optional(),
  }),
  status: z.enum(["pending", "in_progress", "completed", "failed"]),
  completion: z
    .object({
      response: z.string(),
      summary: z.string().optional(),
      completedAt: z.number(),
      completedBy: z.string(),
      event: z.string().optional(), // Serialized NDKEvent
    })
    .optional(),
  createdAt: z.number(),
  updatedAt: z.number(),
  siblingDelegationIds: z.array(z.string()),
});

const DelegationBatchSchema = z.object({
  batchId: z.string(),
  delegatingAgent: z.string(),
  delegationKeys: z.array(z.string()),
  allCompleted: z.boolean(),
  createdAt: z.number(),
  originalRequest: z.string(),
  rootConversationId: z.string(),
});

const PersistedDataSchema = z.object({
  delegations: z.array(z.tuple([z.string(), DelegationRecordSchema])),
  batches: z.array(z.tuple([z.string(), DelegationBatchSchema])),
  agentTasks: z.array(z.tuple([z.string(), z.array(z.string())])),
  conversationTasks: z.array(z.tuple([z.string(), z.array(z.string())])),
  version: z.literal(1),
});

export class DelegationRegistry extends EventEmitter {
  private static instance: DelegationRegistry;
  private static isInitialized = false;

  // Primary storage: conversation key -> full record
  // Key format: "${rootConversationId}:${fromPubkey}:${toPubkey}"
  private delegations: Map<string, DelegationRecord> = new Map();

  // Index: batch ID -> batch info
  private batches: Map<string, DelegationBatch> = new Map();
  
  // Track batches that were handled synchronously to prevent double processing
  private syncHandledBatches = new Set<string>();

  // Index: agent pubkey -> active delegation event IDs
  private agentDelegations: Map<string, Set<string>> = new Map();

  // Index: root conversation ID -> delegation event IDs
  private conversationDelegations: Map<string, Set<string>> = new Map();

  // Persistence
  private persistencePath: string;
  private persistenceTimer?: NodeJS.Timeout;
  private cleanupTimer?: NodeJS.Timeout;
  private isDirty = false;

  private constructor() {
    super();
    this.persistencePath = path.join(process.cwd(), ".tenex", "delegations.json");
  }

  /**
   * Initialize the singleton instance.
   * Must be called once at app startup before using getInstance().
   */
  static async initialize(): Promise<void> {
    if (DelegationRegistry.isInitialized) return;

    logger.debug("Initializing DelegationRegistry singleton");

    // Create instance if it doesn't exist
    if (!DelegationRegistry.instance) {
      DelegationRegistry.instance = new DelegationRegistry();
    }

    // Restore data
    await DelegationRegistry.instance.restore();

    // Set up periodic cleanup (every hour)
    DelegationRegistry.instance.cleanupTimer = setInterval(
      () => {
        DelegationRegistry.instance.cleanupOldDelegations();
        if (DelegationRegistry.instance.isDirty) {
          DelegationRegistry.instance.schedulePersistence();
        }
      },
      60 * 60 * 1000
    );

    // Set up graceful shutdown

    DelegationRegistry.isInitialized = true;
    logger.debug("DelegationRegistry singleton initialized successfully");
  }

  /**
   * Get the singleton instance.
   * Throws if initialize() hasn't been called.
   */
  static getInstance(): DelegationRegistry {
    if (!DelegationRegistry.isInitialized || !DelegationRegistry.instance) {
      throw new Error(
        "DelegationRegistry not initialized. Call DelegationRegistry.initialize() at app startup."
      );
    }
    return DelegationRegistry.instance;
  }

  /**
   * Register a delegation - Unified interface for single and multi-recipient
   * 
   * @param delegationEventId - The actual Nostr event ID (kind:11 or kind:1111)
   * @param recipients - Array of recipients (can be single or multiple)
   * @param delegatingAgent - The agent creating the delegation  
   * @param rootConversationId - The root conversation where delegation originated
   * @param originalRequest - The original request text
   */
  async registerDelegation(params: {
    delegationEventId: string;
    recipients: Array<{
      pubkey: string;
      request: string;
      phase?: string;
    }>;
    delegatingAgent: AgentInstance;
    rootConversationId: string;
    originalRequest: string;
  }): Promise<string> {
    const batchId = this.generateBatchId();

    // Create batch record
    const batch: DelegationBatch = {
      batchId,
      delegatingAgent: params.delegatingAgent.pubkey,
      delegationKeys: [],
      allCompleted: false,
      createdAt: Date.now(),
      originalRequest: params.originalRequest,
      rootConversationId: params.rootConversationId,
    };

    // Registration details logged at the end of this method

    // Create individual delegation records
    for (const recipient of params.recipients) {
      const convKey = `${params.rootConversationId}:${params.delegatingAgent.pubkey}:${recipient.pubkey}`;
      
      const record: DelegationRecord = {
        delegationEventId: params.delegationEventId,
        delegationBatchId: batchId,
        delegatingAgent: {
          slug: params.delegatingAgent.slug,
          pubkey: params.delegatingAgent.pubkey,
          rootConversationId: params.rootConversationId,
        },
        assignedTo: {
          pubkey: recipient.pubkey,
        },
        content: {
          fullRequest: recipient.request,
          phase: recipient.phase,
        },
        status: "pending",
        createdAt: Date.now(),
        updatedAt: Date.now(),
        siblingDelegationIds: [],
      };

      this.delegations.set(convKey, record);
      batch.delegationKeys.push(convKey);
      this.indexDelegation(record);
    }

    // Update sibling IDs
    for (const convKey of batch.delegationKeys) {
      const record = this.delegations.get(convKey);
      if (!record) {
        throw new Error(`No delegation record found for ${convKey}`);
      }
      record.siblingDelegationIds = batch.delegationKeys.filter(k => k !== convKey);
    }

    this.batches.set(batchId, batch);
    this.schedulePersistence();

    logger.debug("‚úÖ Delegation registered", {
      batchId,
      delegationEventId: params.delegationEventId.substring(0, 8),
      recipientCount: params.recipients.length,
      delegatingAgent: params.delegatingAgent.slug,
    });

    return batchId;
  }


  /**
   * Check if an event is a delegation response we're waiting for.
   * A valid delegation response must:
   * 1. Be kind 1111
   * 2. Have an e-tag pointing to the delegation event
   * 3. Have a p-tag pointing to the delegating agent
   */
  isDelegationResponse(event: NDKEvent): boolean {
    if (event.kind !== 1111) return false;
    
    const eTags = event.getMatchingTags("e");
    for (const eTagArray of eTags) {
      const delegationEventId = eTagArray[1];
      if (!delegationEventId) continue;
      
      const delegation = this.findDelegationByEventAndResponder(delegationEventId, event.pubkey);
      if (delegation) {
        // Check if the event p-tags the delegating agent
        const pTags = event.getMatchingTags("p");
        for (const pTagArray of pTags) {
          const taggedPubkey = pTagArray[1];
          if (taggedPubkey === delegation.delegatingAgent.pubkey) {
            logger.debug("Valid delegation response detected", {
              respondingAgent: event.pubkey.substring(0, 8),
              delegatingAgent: delegation.delegatingAgent.pubkey.substring(0, 8),
              delegationEventId: delegationEventId.substring(0, 8),
              eventId: event.id.substring(0, 8),
            });
            return true;
          }
        }
        
        logger.debug("Event references delegation but doesn't p-tag delegating agent", {
          respondingAgent: event.pubkey.substring(0, 8),
          delegatingAgent: delegation.delegatingAgent.pubkey.substring(0, 8),
          delegationEventId: delegationEventId.substring(0, 8),
          eventId: event.id.substring(0, 8),
          pTags: pTags.map(p => p[1].substring(0, 8)),
        });
      }
    }
    return false;
  }

  /**
   * Handle a delegation response - find the delegation and record completion
   */
  async handleDelegationResponse(event: NDKEvent): Promise<void> {
    if (!this.isDelegationResponse(event)) {
      throw new Error(`Event ${event.id} is not a delegation response`);
    }

    // Find the delegation this is responding to
    const eTags = event.getMatchingTags("e");
    for (const eTagArray of eTags) {
      const delegationEventId = eTagArray[1];
      if (!delegationEventId) continue;
      
      const delegation = this.findDelegationByEventAndResponder(delegationEventId, event.pubkey);
      if (delegation) {
        await this.recordDelegationCompletion({
          conversationId: delegation.delegatingAgent.rootConversationId,
          fromPubkey: delegation.delegatingAgent.pubkey,
          toPubkey: event.pubkey,
          completionEventId: event.id,
          response: event.content,
          summary: event.tagValue?.("summary"),
          completionEvent: event, // Pass the actual event
        });
        break;
      }
    }
  }

  /**
   * Record delegation completion
   * Called when a delegation completion event (kind:1111 reply) is received
   */
  async recordDelegationCompletion(params: {
    conversationId: string; // The root conversation ID
    fromPubkey: string;
    toPubkey: string;
    completionEventId: string;
    response: string;
    summary?: string;
    completionEvent?: NDKEvent; // The actual completion event
  }): Promise<{
    batchComplete: boolean;
    batchId: string;
    delegatingAgent: string;
    delegatingAgentSlug: string;
    remainingDelegations: number;
    conversationId: string;
  }> {
    const convKey = `${params.conversationId}:${params.fromPubkey}:${params.toPubkey}`;
    const record = this.delegations.get(convKey);
    if (!record) {
      throw new Error(`No delegation record for ${convKey}`);
    }
    
    // Prevent duplicate completions
    if (record.status === "completed") {
      throw new Error(`Delegation already completed for ${convKey}. Original completion: ${record.completion?.event?.id}`);
    }

    // Log which event is being used to mark delegation as complete
    logger.info("üìù Marking delegation as complete", {
      convKey,
      delegationEventId: record.delegationEventId,
      completionEventId: params.completionEventId,
      completingAgent: params.toPubkey,
      batchId: record.delegationBatchId,
    });

    // Update record
    record.status = "completed";
    record.completion = {
      response: params.response,
      summary: params.summary,
      completedAt: Date.now(),
      completedBy: params.toPubkey,
      event: params.completionEvent,
    };
    record.updatedAt = Date.now();

    // Update indexes
    this.updateIndexesForCompletion(record);

    // Check if batch is complete
    const batch = this.batches.get(record.delegationBatchId);
    if (!batch) {
      throw new Error(`No batch found for ${record.delegationBatchId}`);
    }

    const batchDelegations = batch.delegationKeys.map((convKey) => this.delegations.get(convKey));
    const allComplete = batchDelegations.every((d) => d?.status === "completed");
    const remainingDelegations = batchDelegations.filter((d) => d?.status === "pending").length;

    if (allComplete) {
      batch.allCompleted = true;
      
      // Check if there's a synchronous listener waiting
      const hasListener = this.listenerCount(`${batch.batchId}:completion`) > 0;
      
      logger.info("üéØ Delegation batch completed - emitting completion event", {
        batchId: batch.batchId,
        delegationCount: batch.delegationKeys.length,
        rootConversationId: record.delegatingAgent.rootConversationId.substring(0, 8),
        hasListeners: hasListener,
        mode: hasListener ? "synchronous" : "async-fallback",
      });
      
      // If there's a sync listener, mark this batch as sync-handled
      if (hasListener) {
        this.syncHandledBatches.add(batch.batchId);
        // Auto-cleanup after 10 seconds to prevent memory leak
        setTimeout(() => {
          this.syncHandledBatches.delete(batch.batchId);
          logger.debug("Cleaned up sync-handled batch", { batchId: batch.batchId });
        }, 10000);
      }
      
      // Emit completion event for synchronous waiting
      const completions = this.getBatchCompletions(batch.batchId);
      this.emit(`${batch.batchId}:completion`, {
        batchId: batch.batchId,
        completions: completions.map(c => ({
          taskId: c.delegationId,
          response: c.response,
          summary: c.summary,
          assignedTo: c.assignedTo
        })),
        rootConversationId: record.delegatingAgent.rootConversationId,
        delegatingAgent: record.delegatingAgent.pubkey,
      });
    } else {
      logger.debug("Delegation completed, batch still pending", {
        delegationEventId: record.delegationEventId.substring(0, 8),
        batchId: batch.batchId,
        remainingDelegations,
      });
    }

    this.schedulePersistence();

    return {
      batchComplete: allComplete,
      batchId: record.delegationBatchId,
      delegatingAgent: record.delegatingAgent.pubkey,
      delegatingAgentSlug: record.delegatingAgent.slug,
      remainingDelegations,
      conversationId: record.delegatingAgent.rootConversationId,
    };
  }

  /**
   * Get delegation context by conversation key lookup
   * This is the primary way to find a delegation record
   * 
   * @param rootConversationId - The root conversation where delegation originated
   * @param fromPubkey - The delegating agent's pubkey
   * @param toPubkey - The recipient agent's pubkey
   * @returns The delegation record if found
   */
  getDelegationByConversationKey(
    rootConversationId: string,
    fromPubkey: string,
    toPubkey: string
  ): DelegationRecord | undefined {
    const convKey = `${rootConversationId}:${fromPubkey}:${toPubkey}`;
    
    logger.debug("üîç Looking up delegation by conversation key", {
      convKey,
      rootConversationId: rootConversationId.substring(0, 8),
      fromPubkey: fromPubkey.substring(0, 16),
      toPubkey: toPubkey.substring(0, 16),
      exists: this.delegations.has(convKey),
    });

    const record = this.delegations.get(convKey);
    
    if (record) {
      logger.debug("‚úÖ Found delegation by conversation key", {
        delegationEventId: record.delegationEventId.substring(0, 8),
        status: record.status,
        batchId: record.delegationBatchId,
      });
    } else {
      logger.debug("‚ùå No delegation found for conversation key", {
        convKey,
        availableKeys: Array.from(this.delegations.keys()).slice(0, 5), // Log first 5 for debugging
      });
    }

    return record;
  }

  

  /**
   * Check if a batch was handled synchronously
   */
  isBatchSyncHandled(batchId: string): boolean {
    return this.syncHandledBatches.has(batchId);
  }

  /**
   * Get all completions for a batch
   * Used when synthesizing responses after all delegations complete
   */
  getBatchCompletions(batchId: string): Array<{
    delegationId: string;
    response: string;
    summary?: string;
    assignedTo: string;
    event?: NDKEvent;
  }> {
    const batch = this.batches.get(batchId);
    if (!batch) return [];

    return batch.delegationKeys
      .map((convKey) => this.delegations.get(convKey))
      .filter(
        (
          record
        ): record is DelegationRecord & {
          completion: NonNullable<DelegationRecord["completion"]>;
        } => record !== undefined && record.completion !== undefined
      )
      .map((record) => ({
        delegationId: record.delegationEventId,
        response: record.completion.response,
        summary: record.completion.summary,
        assignedTo: record.assignedTo.pubkey,
        event: record.completion.event,
      }));
  }

  /**
   * Wait for a delegation batch to complete.
   * Used by delegate() tool to synchronously wait for responses.
   * This will wait indefinitely as delegations are long-running jobs.
   * 
   * @param batchId - The batch ID to wait for
   * @returns The batch completions when all delegations are done
   */
  async waitForBatchCompletion(
    batchId: string
  ): Promise<Array<{
    delegationId: string;
    response: string;
    summary?: string;
    assignedTo: string;
    event?: NDKEvent;
  }>> {
    // Check if already complete
    const batch = this.batches.get(batchId);
    if (batch?.allCompleted) {
      logger.debug("Batch already completed, returning immediately", { batchId });
      return this.getBatchCompletions(batchId);
    }

    // Wait for completion event - no timeout as delegations are long-running
    return new Promise((resolve) => {
      const handler = (data: { completions: Array<{ taskId: string; response: string; summary?: string; assignedTo: string; event?: NDKEvent; }> }): void => {
        logger.debug("Batch completion event received", { 
          batchId, 
          completionCount: data.completions.length 
        });
        resolve(data.completions.map(c => ({
          delegationId: c.taskId,
          response: c.response,
          summary: c.summary,
          assignedTo: c.assignedTo,
          event: c.event
        })));
      };

      this.once(`${batchId}:completion`, handler);
    });
  }



  // Private helper methods

  private generateBatchId(): string {
    return `batch_${Date.now()}_${Math.random().toString(36).substring(2, 9)}`;
  }

  private indexDelegation(record: DelegationRecord): void {
    // Index by agent
    let agentDelegationSet = this.agentDelegations.get(record.delegatingAgent.pubkey);
    if (!agentDelegationSet) {
      agentDelegationSet = new Set();
      this.agentDelegations.set(record.delegatingAgent.pubkey, agentDelegationSet);
    }
    agentDelegationSet.add(record.delegationEventId);

    // Index by conversation
    let conversationDelegationSet = this.conversationDelegations.get(record.delegatingAgent.rootConversationId);
    if (!conversationDelegationSet) {
      conversationDelegationSet = new Set();
      this.conversationDelegations.set(record.delegatingAgent.rootConversationId, conversationDelegationSet);
    }
    conversationDelegationSet.add(record.delegationEventId);
  }

  private updateIndexesForCompletion(record: DelegationRecord): void {
    // Remove from active agent delegations if completed
    if (record.status === "completed" || record.status === "failed") {
      const agentDelegations = this.agentDelegations.get(record.delegatingAgent.pubkey);
      if (agentDelegations) {
        agentDelegations.delete(record.delegationEventId);
      }
    }
  }

  private schedulePersistence(): void {
    this.isDirty = true;

    if (this.persistenceTimer) {
      clearTimeout(this.persistenceTimer);
    }

    // Debounce persistence to avoid excessive writes
    this.persistenceTimer = setTimeout(() => {
      this.persist().catch((err) =>
        logger.error("Failed to persist delegation registry", { error: err })
      );
    }, 1000);
  }

  private async persist(): Promise<void> {
    if (!this.isDirty) return;

    // Serialize NDKEvent objects properly before JSON.stringify
    const serializableDelegations = Array.from(this.delegations.entries()).map(([key, record]) => {
      const serializedRecord = { ...record };
      if (record.completion?.event) {
        serializedRecord.completion = {
          ...record.completion,
          event: record.completion.event.serialize() as any, // Serialize NDKEvent to string
        };
      }
      return [key, serializedRecord];
    });

    const data = {
      delegations: serializableDelegations,
      batches: Array.from(this.batches.entries()),
      agentTasks: Array.from(this.agentDelegations.entries()).map(([k, v]) => [k, Array.from(v)]),
      conversationTasks: Array.from(this.conversationDelegations.entries()).map(([k, v]) => [
        k,
        Array.from(v),
      ]),
      version: 1,
    };

    try {
      // Ensure directory exists
      const dir = path.dirname(this.persistencePath);
      await fs.mkdir(dir, { recursive: true });

      // Write atomically with temp file
      const tempPath = `${this.persistencePath}.tmp`;
      await fs.writeFile(tempPath, JSON.stringify(data, null, 2));
      await fs.rename(tempPath, this.persistencePath);

      this.isDirty = false;
      logger.debug("Persisted delegation registry", {
        delegations: this.delegations.size,
        batches: this.batches.size,
      });
    } catch (error) {
      logger.error("Failed to persist delegation registry", {
        error,
        delegations: this.delegations.size,
        batches: this.batches.size,
      });
      throw error;
    }
  }

  private async restore(): Promise<void> {
    let dataLoaded = false;
    let data: unknown = null;

    // Try to load from main file first
    try {
      const rawData = await fs.readFile(this.persistencePath, "utf-8");
      data = JSON.parse(rawData);
      dataLoaded = true;
      logger.debug("Loaded delegation registry from main file");
    } catch (error) {
      if (error && typeof error === "object" && "code" in error && error.code !== "ENOENT") {
        logger.warn("Failed to load main delegation registry file", { error });
      }
    }


    // If no data loaded, start fresh
    if (!dataLoaded) {
      logger.info("No existing delegation registry found, starting fresh");
      return;
    }

    // Validate and load data
    try {
      const validatedData = PersistedDataSchema.parse(data);
      
      // Deserialize NDKEvent objects when loading delegations
      const deserializedDelegations = validatedData.delegations.map(([key, record]) => {
        if (record.completion?.event) {
          // Deserialize the NDKEvent from string
          const deserializedRecord = { ...record };
          deserializedRecord.completion = {
            ...record.completion,
            event: NDKEvent.deserialize(undefined, record.completion.event as string) as any,
          };
          return [key, deserializedRecord] as [string, DelegationRecord];
        }
        return [key, record] as [string, DelegationRecord];
      });
      
      this.delegations = new Map(deserializedDelegations);
      this.batches = new Map(validatedData.batches);
      this.agentDelegations = new Map(validatedData.agentTasks.map(([k, v]) => [k, new Set(v)]));
      this.conversationDelegations = new Map(
        validatedData.conversationTasks.map(([k, v]) => [k, new Set(v)])
      );

      // Clean up old completed delegations (older than 24 hours)
      this.cleanupOldDelegations();

      logger.info("Restored delegation registry", {
        delegations: this.delegations.size,
        batches: this.batches.size,
        activeTasks: Array.from(this.delegations.values()).filter((d) => d.status === "pending")
          .length,
      });
    } catch (error) {
      logger.error("Failed to validate restored delegation data", {
        error,
        dataKeys: data && typeof data === "object" && data !== null ? Object.keys(data) : [],
      });

      // If validation fails, start fresh but save the corrupted data for debugging
      const corruptPath = `${this.persistencePath}.corrupt.${Date.now()}`;
      try {
        await fs.writeFile(corruptPath, JSON.stringify(data, null, 2));
        logger.info("Saved corrupted delegation data for debugging", { path: corruptPath });
      } catch (saveError) {
        logger.error("Failed to save corrupted data", { error: saveError });
      }
    }
  }

  private cleanupOldDelegations(): void {
    const oneDayAgo = Date.now() - 24 * 60 * 60 * 1000;
    let cleaned = 0;

    for (const [delegationKey, record] of this.delegations.entries()) {
      if (record.status === "completed" && record.updatedAt < oneDayAgo) {
        this.delegations.delete(delegationKey);

        // Clean up from indexes
        const agentDelegations = this.agentDelegations.get(record.delegatingAgent.pubkey);
        if (agentDelegations) {
          agentDelegations.delete(record.delegationEventId);
        }

        const convDelegations = this.conversationDelegations.get(record.delegatingAgent.rootConversationId);
        if (convDelegations) {
          convDelegations.delete(record.delegationEventId);
        }

        cleaned++;
      }
    }

    // Clean up completed batches
    for (const [batchId, batch] of this.batches.entries()) {
      if (batch.allCompleted && batch.createdAt < oneDayAgo) {
        this.batches.delete(batchId);
      }
    }

    if (cleaned > 0) {
      logger.debug("Cleaned up old delegations", { count: cleaned });
      this.isDirty = true;
    }
  }


  /**
   * Find delegation records by event ID and responder pubkey
   * Used when processing completion events
   * 
   * @param eventId - The delegation event ID from the e-tag
   * @param responderPubkey - The pubkey of the responding agent
   * @returns The matching delegation record if found
   */
  findDelegationByEventAndResponder(
    eventId: string,
    responderPubkey: string
  ): DelegationRecord | undefined {
    logger.debug("üîç Finding delegation by event ID and responder", {
      eventId: eventId.substring(0, 8),
      responderPubkey: responderPubkey.substring(0, 16),
    });
    
    // Search through all delegations
    for (const [convKey, record] of this.delegations.entries()) {
      if (record.delegationEventId === eventId && 
          record.assignedTo.pubkey === responderPubkey) {
        
        logger.debug("‚úÖ Found delegation match", {
          conversationKey: convKey,
          status: record.status,
          delegatingAgent: record.delegatingAgent.slug,
        });
        
        return record;
      }
    }
    
    logger.debug("‚ùå No delegation found for event+responder combination");
    return undefined;
  }

}
</file>

<file path="src/tools/implementations/claude_code.ts">
import { tool } from 'ai';
import { claudeCode } from 'ai-sdk-provider-claude-code';
import { createProviderRegistry } from 'ai';
import chalk from "chalk";
import { LLMService } from '@/llm/service';
import { LLMLogger } from '@/logging/LLMLogger';
import type { Phase } from "@/conversations/types";
import { formatAnyError } from "@/utils/error-formatter";
import { logger } from "@/utils/logger";
import type { ExecutionContext } from "@/agents/execution/types";
import { z } from "zod";
import type { EventContext } from "@/nostr/AgentEventEncoder";
import { startExecutionTime, stopExecutionTime } from "@/conversations/executionTime";
import { llmOpsRegistry } from '@/services/LLMOperationsRegistry';

export enum ClaudeCodeMode {
  WRITE = "WRITE",
  PLAN = "PLAN",
  READ = "READ"
}

const claudeCodeSchema = z.object({
  prompt: z.string().min(1).describe("The prompt for Claude Code to execute"),
  title: z.string().describe("Title for the task"),
  mode: z.enum([ClaudeCodeMode.WRITE, ClaudeCodeMode.PLAN, ClaudeCodeMode.READ]).describe("Execution mode: WRITE for making changes, PLAN for planning tasks, READ for research/analysis only"),
});

type ClaudeCodeInput = z.infer<typeof claudeCodeSchema>;
type ClaudeCodeOutput = {
  sessionId?: string;
  totalCost: number;
  messageCount: number;
  duration: number;
  response: string;
};

/**
 * AI SDK-based implementation using LLMService
 * Leverages existing streaming infrastructure instead of reimplementing
 */
async function executeClaudeCode(
  input: ClaudeCodeInput,
  context: ExecutionContext
): Promise<ClaudeCodeOutput> {
  const { prompt, title, mode } = input;
  const startTime = Date.now();

  logger.debug("[claude_code] Starting execution with LLMService", {
    prompt: prompt.substring(0, 100),
    mode,
    agent: context.agent.name,
  });

  try {
    // Look up existing session
    const conversation = context.conversationCoordinator.getConversation(context.conversationId);
    const agentState = conversation?.agentStates.get(context.agent.slug);
    const existingSessionId = agentState?.claudeSessionsByPhase?.[context.phase];

    if (existingSessionId) {
      logger.info(`[claude_code] Found existing session`, {
        sessionId: existingSessionId,
        agent: context.agent.slug,
        conversationId: context.conversationId.substring(0, 8),
      });
    }

    // Create event context for Nostr publishing
    const rootEvent = conversation?.history[0] ?? context.triggeringEvent;
    const baseEventContext: EventContext = {
      triggeringEvent: context.triggeringEvent,
      rootEvent: rootEvent,
      conversationId: context.conversationId,
      model: context.agent.llmConfig, // Include LLM configuration
    };

    // Create task through AgentPublisher
    const task = await context.agentPublisher.createTask(
      title,
      prompt,
      baseEventContext,
      existingSessionId, // Only pass if we have a real session ID
    );

    logger.info("[claude_code] Created task", {
      taskId: task.id,
      sessionId: existingSessionId,
      title,
    });

    // Register operation with LLM Operations Registry
    const abortSignal = llmOpsRegistry.registerOperation(context);

    // Start execution timing
    if (conversation) {
      startExecutionTime(conversation);
    }

    // Track execution state
    let lastAssistantMessage = "";
    let planResult: string | null = null;
    let totalCost = 0;
    let messageCount = 0;
    let capturedSessionId: string | undefined;

    // Determine which tools to allow based on mode
    let allowedTools: string[] | undefined;
    let disallowedTools: string[] | undefined;
    
    switch (mode) {
      case ClaudeCodeMode.READ:
        // Read-only mode - no write operations allowed
        disallowedTools = ['Write', 'Edit', 'MultiEdit', 'NotebookEdit', 'Delete'];
        break;
      case ClaudeCodeMode.PLAN:
        // Planning mode - focus on reading and todo management
        allowedTools = ['Read', 'LS', 'Grep', 'Glob', 'TodoWrite', 'ExitPlanMode'];
        break;
      case ClaudeCodeMode.WRITE:
        // Write mode - full access to all tools (default behavior)
        // Don't restrict any tools
        break;
    }

    // Create provider registry with Claude Code
    const registry = createProviderRegistry({
      'claude-code': {
        languageModel: (modelId: string) => {
          const options: any = {
            cwd: context.projectPath,
            permissionMode: 'bypassPermissions',
            // Resume existing session if we have one
            resume: existingSessionId,
          };
          
          // Add tool restrictions based on mode
          if (allowedTools) {
            options.allowedTools = allowedTools;
          } else if (disallowedTools) {
            options.disallowedTools = disallowedTools;
          }
          
          return claudeCode(modelId, options);
        }
      }
    });

    // Create LLMLogger instance
    const llmLogger = new LLMLogger();

    // Create LLMService with Claude Code provider
    const llmService = new LLMService(
      llmLogger,
      registry,
      'claude-code',
      'opus',
      undefined, // temperature
      undefined  // maxTokens
    );

    // Set up event handlers for Nostr publishing
    llmService.on('content', async ({ delta }) => {
      logger.info("[claude_code] content", { delta });
      lastAssistantMessage += delta;
      messageCount++;
      
      // Publish text update to Nostr
      await context.agentPublisher.publishTaskUpdate(
        task,
        delta,
        baseEventContext
      );
    });

    llmService.on('tool-did-execute', async ({ toolName, result }: any) => {
      logger.info("[claude_code] Tool executed", { toolName, result });
      
      if (toolName === 'TodoWrite' && result?.todos) {
        const todos = result.todos as Array<{
          content: string;
          status: "pending" | "in_progress" | "completed";
          activeForm?: string;
        }>;
        
        const todoLines = todos.map(todo => {
          let checkbox = "- [ ]";
          if (todo.status === "in_progress") {
            checkbox = "- ‚û°Ô∏è";
          } else if (todo.status === "completed") {
            checkbox = "- ‚úÖ";
          }
          const text = todo.status === "in_progress" && todo.activeForm ? todo.activeForm : todo.content;
          return `${checkbox} ${text}`;
        });
        
        await context.agentPublisher.publishTaskUpdate(
          task,
          todoLines.join("\n"),
          baseEventContext
        );
      } else if (toolName === 'ExitPlanMode' && mode === ClaudeCodeMode.PLAN) {
        // Capture plan result and abort
        planResult = result?.plan || "Plan completed";
        logger.info("[claude_code] ExitPlanMode detected", {
          plan: planResult.substring(0, 100),
        });
        await context.agentPublisher.publishTaskUpdate(task, "Plan complete", baseEventContext, "complete");
        // Abort the stream since we have the plan
        // Note: We can't directly abort from here, but the stream will complete naturally
        logger.info("[claude_code] Plan completed, stream will finish", {
        });
      }
    });

    llmService.on('complete', ({ message, steps, text, usage }: any) => {
      console.log("ai sdk cc complete", chalk.blue(text), chalk.green(message));
      // Try to extract session ID from the last step's provider metadata
      const lastStep = steps[steps.length - 1];
      if (lastStep?.providerMetadata?.['claude-code']?.sessionId) {
        capturedSessionId = lastStep.providerMetadata['claude-code'].sessionId;
        logger.info("[claude_code] Captured session ID from provider metadata", {
          sessionId: capturedSessionId,
        });
      }
      
      logger.info("[claude_code] Stream completed", {
        messageLength: message.length,
        stepCount: steps.length,
        taskId: task.id,
        capturedSessionId,
        usage
      });

      context.agentPublisher.publishTaskUpdate(task, "Task complete", baseEventContext, "complete");
    });

    // Build messages
    const messages: any[] = [];
    messages.push({
      role: 'user',
      content: prompt
    });

    try {
      // Execute stream with LLMService, passing abort signal from registry
      // Claude Code provider handles its own tools internally based on mode
      await llmService.stream(messages, {}, {
        abortSignal
      });

      // Stop execution timing
      if (conversation) {
        stopExecutionTime(conversation);
      }
    } finally {
      // Complete the operation (handles both success and abort cases)
      llmOpsRegistry.completeOperation(context);
    }

    try {

      // Only use real session IDs from Claude Code provider
      const sessionId = capturedSessionId || existingSessionId;

      // Store session ID for future resumption
      if (sessionId && conversation) {
        const agentState = conversation.agentStates.get(context.agent.slug) || {
          lastProcessedMessageIndex: 0,
        };

        if (!agentState.claudeSessionsByPhase) {
          agentState.claudeSessionsByPhase = {} as Record<Phase, string>;
        }

        agentState.claudeSessionsByPhase[context.phase] = sessionId;

        await context.conversationCoordinator.updateAgentState(
          context.conversationId,
          context.agent.slug,
          agentState
        );

        logger.info(`[claude_code] Stored session ID for phase ${context.phase}`, {
          sessionId,
          agent: context.agent.slug,
          conversationId: context.conversationId.substring(0, 8),
        });
      }

      // Return appropriate response
      const finalResponse = planResult || lastAssistantMessage || "Task completed successfully";
      const duration = Date.now() - startTime;

      logger.info("[claude_code] Execution completed", {
        sessionId,
        totalCost,
        messageCount,
        finalResponse,
        duration,
        mode,
        hasPlanResult: !!planResult,
      });

      return {
        sessionId,
        totalCost,
        messageCount,
        duration,
        response: finalResponse,
      };

    } catch (streamError) {
      // Stop timing on error
      if (conversation) {
        stopExecutionTime(conversation);
      }

      const errorMessage = formatAnyError(streamError);
      const isAborted = errorMessage.includes("aborted") || errorMessage.includes("interrupted");

      // Publish error update
      await context.agentPublisher.publishTaskUpdate(
        task,
        `‚ùå Task ${isAborted ? 'interrupted' : 'failed'}\n\nError: ${errorMessage}`,
        baseEventContext
      );

      logger.error("[claude_code] Stream execution failed", { 
        error: errorMessage, 
        isAborted 
      });

      throw new Error(`Claude Code execution failed: ${errorMessage}`);
    }

  } catch (error) {
    logger.error("[claude_code] Tool failed", { error });
    throw new Error(`Claude Code execution failed: ${formatAnyError(error)}`);
  }
}

/**
 * Create an AI SDK tool for Claude Code execution using LLMService
 */
export function createClaudeCodeTool(context: ExecutionContext): ReturnType<typeof tool> {
  return tool({
    description: "Execute Claude Code to perform planning or to execute changes. Claude Code has full access to read, write, and execute code in the project. This tool maintains session continuity for iterative development. Usage warning: claude_code is a powerful, intelligent tool; don't micromanage its work, don't try to direct how it should implement things unless explicitly asked to do so. Rely on claude_code's intelligence and only provide corrections where necessary.",
    inputSchema: claudeCodeSchema,
    execute: async (input: ClaudeCodeInput) => {
      try {
        return await executeClaudeCode(input, context);
      } catch (error) {
        logger.error("[claude_code] Tool execution failed", { error });
        throw new Error(`Claude Code failed: ${error instanceof Error ? error.message : String(error)}`);
      }
    },
  });
}
</file>

<file path="src/event-handler/reply.ts">
import type { NDKEvent } from "@nostr-dev-kit/ndk";
import chalk from "chalk";
import type { AgentExecutor } from "../agents/execution/AgentExecutor";
import type { ExecutionContext } from "../agents/execution/types";
import type { AgentInstance } from "../agents/types";
import type { Conversation, ConversationCoordinator } from "../conversations";
import { ConversationResolver } from "../conversations/services/ConversationResolver";
// New refactored modules
import { AgentEventDecoder } from "../nostr/AgentEventDecoder";
import { getProjectContext } from "../services";
import { formatAnyError } from "../utils/error-formatter";
import { logger } from "../utils/logger";
import { AgentRouter } from "./AgentRouter";


interface EventHandlerContext {
  conversationCoordinator: ConversationCoordinator;
  agentExecutor: AgentExecutor;
}

/**
 * Main entry point for handling chat messages
 */
export const handleChatMessage = async (
  event: NDKEvent,
  context: EventHandlerContext
): Promise<void> => {
  logger.info(
    chalk.gray("Message: ") +
      chalk.white(event.content.substring(0, 100) + (event.content.length > 100 ? "..." : ""))
  );

  const projectCtx = getProjectContext();

  // Check if this message is directed to the system using centralized decoder
  const isDirectedToSystem = AgentEventDecoder.isDirectedToSystem(event, projectCtx.agents);
  const isFromAgent = AgentEventDecoder.isEventFromAgent(event, projectCtx.agents);
  
  if (!isDirectedToSystem && isFromAgent) {
    // Agent event not directed to system - only add to conversation history, don't process
    logger.debug(`Agent event not directed to system - adding to history only: ${event.id?.substring(0, 8)}`);
    
    // Try to find and update the conversation this event belongs to
    const resolver = new ConversationResolver(context.conversationCoordinator);
    const result = await resolver.resolveConversationForEvent(event);
    
    if (result.conversation) {
      // Add the event to conversation history without triggering any agent processing
      await context.conversationCoordinator.addEvent(result.conversation.id, event);
      logger.debug(`Added agent response to conversation history: ${result.conversation.id.substring(0, 8)}`);
    } else {
      logger.debug(`Could not find conversation for agent event: ${event.id?.substring(0, 8)}`);
    }
    return;
  }

  // Process the reply (triggers agent execution)
  try {
    await handleReplyLogic(event, context);
  } catch (error) {
    logger.info(chalk.red(`‚ùå Failed to route reply: ${formatAnyError(error)}`));
  }
};

/**
 * Execute the agent with proper error handling
 */
async function executeAgent(
  executionContext: ExecutionContext,
  agentExecutor: AgentExecutor,
  conversation: Conversation,
  projectManager: AgentInstance,
  event: NDKEvent
): Promise<void> {
  try {
    await agentExecutor.execute(executionContext);
  } catch (error) {
    const errorMessage = formatAnyError(error);

    // Check if it's an insufficient credits error
    const isCreditsError =
      errorMessage.includes("Insufficient credits") || errorMessage.includes("402");

    const displayMessage = isCreditsError
      ? "‚ö†Ô∏è Unable to process your request: Insufficient credits. Please add more credits at https://openrouter.ai/settings/credits to continue."
      : "‚ö†Ô∏è Unable to process your request due to an error. Please try again later.";

    // Use AgentPublisher to publish error
    const { AgentPublisher } = await import("@/nostr/AgentPublisher");
    const agentPublisher = new AgentPublisher(projectManager);

    await agentPublisher.error(
      {
        message: displayMessage,
        errorType: isCreditsError ? "insufficient_credits" : "execution_error",
      },
      {
        triggeringEvent: event,
        rootEvent: conversation.history[0], // Root event is first in history
        conversationId: conversation.id,
      }
    );

    logger.error(
      isCreditsError
        ? "Agent execution failed due to insufficient credits"
        : "Agent execution failed",
      {
        error: errorMessage,
        conversation: conversation.id,
      }
    );
  }
}

/**
 * Main reply handling logic - orchestrates all the helper functions
 */
async function handleReplyLogic(
  event: NDKEvent,
  { conversationCoordinator, agentExecutor }: EventHandlerContext
): Promise<void> {
  const projectCtx = getProjectContext();
  const projectManager = projectCtx.getProjectManager();
  if (!projectManager) {
    throw new Error("Project Manager agent not found - required for conversation coordination");
  }

  // 1. Resolve conversation context
  const conversationResolver = new ConversationResolver(conversationCoordinator);
  const {
    conversation,
    isNew,
  } = await conversationResolver.resolveConversationForEvent(event);

  if (!conversation) {
    logger.error("No conversation found or created for event", {
      eventId: event.id,
      convRoot: AgentEventDecoder.getConversationRoot(event),
      kTag: AgentEventDecoder.getReferencedKind(event),
    });
    return;
  }

  // 2. Add event to conversation history (if not new and not an internal message)
  if (!isNew && !AgentEventDecoder.isAgentInternalMessage(event)) {
    await conversationCoordinator.addEvent(conversation.id, event);
  }

  // 3. Determine target agents
  let targetAgents = AgentRouter.resolveTargetAgents(event, projectCtx);
  if (targetAgents.length === 0) {
    logger.debug(`No target agents resolved for event: ${event.id?.substring(0, 8)}`);
    return;
  }

  // 4. Filter out self-replies
  const nonSelfReplyAgents = AgentRouter.filterOutSelfReplies(event, targetAgents);
  if (nonSelfReplyAgents.length === 0) {
    const routingReasons = AgentRouter.getRoutingReasons(event, targetAgents);
    logger.info(
      chalk.gray(
        `Skipping self-reply: all target agents would process their own message (${routingReasons})`
      )
    );
    return;
  }
  
  // Log if some agents were filtered out due to self-reply
  if (nonSelfReplyAgents.length < targetAgents.length) {
    const filteredAgents = targetAgents.filter(a => !nonSelfReplyAgents.includes(a));
    logger.info(
      chalk.gray(
        `Filtered out self-reply for: ${filteredAgents.map(a => a.name).join(", ")}`
      )
    );
  }
  
  targetAgents = nonSelfReplyAgents;

  // 5. Execute each target agent in parallel
  const executionPromises = targetAgents.map(async (targetAgent) => {
    // Build execution context for this agent
    const executionContext: ExecutionContext = {
      agent: targetAgent,
      conversationId: conversation.id,
      phase: conversation.phase,
      projectPath: process.cwd(),
      triggeringEvent: event,
      conversationCoordinator,
    };

    // Execute agent
    await executeAgent(
      executionContext,
      agentExecutor,
      conversation,
      projectManager,
      event
    );
  });
  
  // Wait for all agents to complete
  await Promise.all(executionPromises);
}
</file>

<file path="src/nostr/AgentPublisher.ts">
import type { AgentConfig, AgentInstance } from "@/agents/types";
import { EVENT_KINDS } from "@/llm/types";
import { getNDK } from "@/nostr/ndkClient";
import { DelegationRegistry } from "@/services/DelegationRegistry";
import { logger } from "@/utils/logger";
import {
  NDKEvent,
  type NDKTask,
  type NDKPrivateKeySigner,
  type NDKProject,
} from "@nostr-dev-kit/ndk";
import {
  AgentEventEncoder,
  type CompletionIntent,
  type ConversationIntent,
  type DelegationIntent,
  type ErrorIntent,
  type EventContext,
  type LessonIntent,
  type StreamingIntent,
  type TypingIntent,
  type ToolUseIntent,
} from "./AgentEventEncoder";

/**
 * Comprehensive publisher for all agent-related Nostr events.
 * Handles agent creation, responses, completions, and delegations.
 * Also manages streaming buffer to ensure correct event ordering.
 */
export class AgentPublisher {
  private agent: AgentInstance;
  private encoder: AgentEventEncoder;
  private streamSequence = 0;

  constructor(agent: AgentInstance) {
    this.agent = agent;
    this.encoder = new AgentEventEncoder();
  }


  /**
   * Publish a completion event.
   * Creates and publishes a properly tagged completion event.
   */
  async complete(intent: CompletionIntent, context: EventContext): Promise<NDKEvent> {
    logger.debug("Dispatching completion", {
      agent: this.agent.name,
      contentLength: intent.content.length,
      summary: intent.summary,
    });

    const event = this.encoder.encodeCompletion(intent, context);

    // Sign and publish
    await event.sign(this.agent.signer);
    await event.publish();

    logger.debug("Completion event published", {
      eventId: event.id,
      agent: this.agent.name,
    });

    return event;
  }

  /**
   * Publish delegation request events.
   * Creates and publishes a single kind:1111 conversation event with multiple p-tags.
   */
  async delegate(
    intent: DelegationIntent,
    context: EventContext
  ): Promise<{
    events: NDKEvent[];
    batchId: string;
  }> {
    const events = this.encoder.encodeDelegation(intent, context);

    // Sign the event (should be single event now)
    for (const event of events) {
      await event.sign(this.agent.signer);
    }
    
    // Register delegation using the new clean interface
    const registry = DelegationRegistry.getInstance();
    const mainEvent = events[0]; // Should only be one event now
    
    // Removed redundant logging - registration is logged in DelegationRegistry
    
    const batchId = await registry.registerDelegation({
      delegationEventId: mainEvent.id,
      recipients: intent.recipients.map(recipientPubkey => ({
        pubkey: recipientPubkey,
        request: intent.request,
        phase: intent.phase,
      })),
      delegatingAgent: this.agent,
      rootConversationId: context.rootEvent.id,
      originalRequest: intent.request,
    });

    // Publish the single event
    for (const [index, event] of events.entries()) {
      await event.publish();
      logger.debug("Published delegation request", {
        index,
        eventId: event.id,
        eventIdTruncated: event.id?.substring(0, 8),
        kind: event.kind,
        assignedTo: event.tagValue("p")?.substring(0, 16),
      });
    }

    logger.debug("Delegation batch published", {
      batchId,
      eventCount: events.length,
    });

    return { events, batchId };
  }

  /**
   * Publish delegation follow-up request event.
   * Creates and publishes a follow-up event as a reply to a previous delegation response.
   */
  async delegateFollowUp(
    intent: DelegationIntent,
    context: EventContext
  ): Promise<{
    events: NDKEvent[];
    batchId: string;
  }> {
    // For follow-ups, triggeringEvent should be the response event we're replying to
    const responseEvent = context.triggeringEvent;
    const recipientPubkey = intent.recipients[0]; // Follow-ups are always to single recipient
    
    logger.debug("[AgentPublisher] Creating follow-up event", {
      agent: this.agent.name,
      recipientPubkey: recipientPubkey.substring(0, 8),
      responseEventId: responseEvent.id?.substring(0, 8),
    });
    
    // Use encoder to create the follow-up event
    const followUpEvent = this.encoder.encodeFollowUp(responseEvent, intent.request);
    
    // Sign the event
    await followUpEvent.sign(this.agent.signer);
    
    // Register with DelegationRegistry for tracking
    const registry = DelegationRegistry.getInstance();
    const batchId = await registry.registerDelegation({
      delegationEventId: followUpEvent.id,
      recipients: [{
        pubkey: recipientPubkey,
        request: intent.request,
        phase: intent.phase,
      }],
      delegatingAgent: this.agent,
      rootConversationId: context.rootEvent.id,
      originalRequest: intent.request,
    });
    
    // Publish the follow-up event
    await followUpEvent.publish();
    
    logger.debug("Follow-up event published", {
      eventId: followUpEvent.id?.substring(0, 8),
      replyingTo: responseEvent.id?.substring(0, 8),
      batchId,
    });
    
    return { events: [followUpEvent], batchId };
  }

  /**
   * Publish a conversation response.
   * Creates and publishes a standard response event.
   */
  async conversation(intent: ConversationIntent, context: EventContext): Promise<NDKEvent> {
    logger.debug("Dispatching conversation response", {
      agent: this.agent.name,
      contentLength: intent.content.length,
    });

    const event = this.encoder.encodeConversation(intent, context);

    // Sign and publish
    await event.sign(this.agent.signer);
    await event.publish();

    return event;
  }


  /**
   * Publish an error event.
   * Creates and publishes an error notification event.
   */
  async error(intent: ErrorIntent, context: EventContext): Promise<NDKEvent> {
    logger.debug("Dispatching error", {
      agent: this.agent.name,
      error: intent.message,
    });

    const event = this.encoder.encodeError(intent, context);

    // Sign and publish
    await event.sign(this.agent.signer);
    await event.publish();

    logger.debug("Error event published", {
      eventId: event.id,
      agent: this.agent.name,
      error: intent.message,
    });

    return event;
  }

  /**
   * Publish a typing indicator event.
   */
  async typing(intent: TypingIntent, context: EventContext): Promise<NDKEvent> {
    // Note: Don't flush stream for typing indicators as they're transient
    logger.debug("Dispatching typing indicator", {
      agent: this.agent.name,
      state: intent.state,
    });

    const event = this.encoder.encodeTypingIndicator(intent, context, this.agent);

    // Sign and publish
    await event.sign(this.agent.signer);
    await event.publish();

    return event;
  }

  /**
   * Publish a streaming progress event.
   */
  async streaming(intent: StreamingIntent, context: EventContext): Promise<NDKEvent> {
    // Note: Don't flush stream for streaming events as they ARE the stream
    const event = this.encoder.encodeStreamingContent(intent, context);

    // Sign and publish
    await event.sign(this.agent.signer);
    await event.publish();

    return event;
  }

  /**
   * Publish a lesson learned event.
   */
  async lesson(intent: LessonIntent, context: EventContext): Promise<NDKEvent> {
    logger.debug("Dispatching lesson", {
      agent: this.agent.name,
    });

    const lessonEvent = this.encoder.encodeLesson(intent, context, this.agent);

    // Sign and publish
    await lessonEvent.sign(this.agent.signer);
    await lessonEvent.publish();

    logger.debug("Lesson event published", {
      eventId: lessonEvent.id,
      agent: this.agent.name,
    });

    return lessonEvent;
  }

  /**
   * Publish a tool usage event.
   * Creates and publishes an event with tool name and output tags.
   */
  async toolUse(intent: ToolUseIntent, context: EventContext): Promise<NDKEvent> {
    logger.debug("Dispatching tool usage", {
      agent: this.agent.name,
      tool: intent.toolName,
      contentLength: intent.content.length,
    });

    const event = this.encoder.encodeToolUse(intent, context);

    // Sign and publish
    await event.sign(this.agent.signer);
    await event.publish();

    logger.debug("Tool usage event published", {
      eventId: event.id,
      agent: this.agent.name,
      tool: intent.toolName,
    });

    return event;
  }

  /**
   * Handle content streaming from LLMService.
   * Adds content to buffer and publishes streaming events.
   */
  async handleContent(
    event: { delta: string },
    context: EventContext,
    isReasoning = false
  ): Promise<void> {
    // Stream the delta directly
    const streamingIntent: StreamingIntent = {
      content: event.delta,
      sequence: ++this.streamSequence,
      isReasoning,
    };
    
    await this.streaming(streamingIntent, context);
  }


  /**
   * Create a task event that references the triggering event.
   * Used for Claude Code and other task-based executions.
   */
  async createTask(
    title: string,
    content: string,
    context: EventContext,
    claudeSessionId?: string,
  ): Promise<NDKTask> {
    // Use encoder to create task with proper tagging
    const task = this.encoder.encodeTask(
      title,
      content,
      context,
      claudeSessionId,
    );

    // Sign with agent's signer
    await task.sign(this.agent.signer);
    await task.publish();

    logger.debug("Created task", {
      taskId: task.id,
      title,
      agent: this.agent.name,
      sessionId: claudeSessionId,
    });

    return task;
  }

  /**
   * Publish a task update (progress or completion).
   * Strips "p" tags to avoid notifications.
   */
  async publishTaskUpdate(
    task: NDKTask,
    content: string,
    context: EventContext,
    status = "in-progress"
  ): Promise<NDKEvent> {
    const update = task.reply();
    update.content = content;

    // Strip all "p" tags (no notifications)
    update.tags = update.tags.filter(t => t[0] !== "p");

    // Add standard tags using existing encoder methods
    this.encoder.addStandardTags(update, context);

    update.tag(["status", status]);
    await update.sign(this.agent.signer);
    await update.publish();

    logger.debug("Published task update", {
      taskId: task.id,
      contentLength: content.length,
      agent: this.agent.name,
    });

    return update;
  }

  // ===== Agent Creation Events (from src/agents/AgentPublisher.ts) =====

  /**
   * Publishes a kind:0 profile event for an agent
   */
  static async publishAgentProfile(
    signer: NDKPrivateKeySigner,
    agentName: string,
    agentRole: string,
    projectTitle: string,
    projectEvent: NDKProject,
    agentDefinitionEventId?: string
  ): Promise<void> {
    try {
      // Generate random dicebear avatar
      const avatarStyle = "bottts"; // Using bottts style for agents
      const seed = signer.pubkey; // Use pubkey as seed for consistent avatar
      const avatarUrl = `https://api.dicebear.com/7.x/${avatarStyle}/svg?seed=${seed}`;

      const profile = {
        name: agentName,
        description: `${agentRole} agent for ${projectTitle}`,
        picture: avatarUrl,
        project: projectTitle,
      };

      const profileEvent = new NDKEvent(getNDK(), {
        kind: 0,
        pubkey: signer.pubkey,
        content: JSON.stringify(profile),
        tags: [],
      });

      // Properly tag the project event (creates an "a" tag for kind:31933)
      profileEvent.tag(projectEvent.tagReference());

      // Add e-tag for the agent definition event if it exists and is valid
      if (agentDefinitionEventId) {
        // Validate that it's a proper hex event ID (64 characters)
        profileEvent.tags.push(["e", agentDefinitionEventId]);
      }

      await profileEvent.sign(signer);
      profileEvent.publish();
    } catch (error) {
      logger.error("Failed to publish agent profile", {
        error,
        agentName,
      });
      throw error;
    }
  }

  /**
   * Publishes an agent request event
   */
  static async publishAgentRequest(
    signer: NDKPrivateKeySigner,
    agentConfig: Omit<AgentConfig, "nsec">,
    projectEvent: NDKProject,
    ndkAgentEventId?: string
  ): Promise<NDKEvent> {
    try {
      const requestEvent = new NDKEvent(getNDK(), {
        kind: EVENT_KINDS.AGENT_REQUEST,
        content: "",
        tags: [],
      });

      // Properly tag the project event
      requestEvent.tag(projectEvent);

      const tags: string[][] = [];

      // Only add e-tag if this agent was created from an NDKAgentDefinition event and is valid
      if (ndkAgentEventId && ndkAgentEventId.trim() !== "") {
        // Validate that it's a proper hex event ID (64 characters)
        const trimmedId = ndkAgentEventId.trim();
        if (/^[a-f0-9]{64}$/i.test(trimmedId)) {
          tags.push(["e", trimmedId, "", "agent-definition"]);
        } else {
          logger.warn("Invalid event ID format for agent definition in request, skipping e-tag", {
            eventId: ndkAgentEventId,
          });
        }
      }

      // Add agent metadata tags
      tags.push(["name", agentConfig.name]);

      // Add the other tags
      requestEvent.tags.push(...tags);

      await requestEvent.sign(signer);
      await requestEvent.publish();

      logger.debug("Published agent request", {
        agentName: agentConfig.name,
        pubkey: signer.pubkey,
        hasNDKAgentDefinitionEvent: !!ndkAgentEventId,
      });

      return requestEvent;
    } catch (error) {
      logger.error("Failed to publish agent request", {
        error,
        agentName: agentConfig.name,
      });
      throw error;
    }
  }

  /**
   * Publishes all agent-related events when creating a new agent
   */
  static async publishAgentCreation(
    signer: NDKPrivateKeySigner,
    agentConfig: Omit<AgentConfig, "nsec">,
    projectTitle: string,
    projectEvent: NDKProject,
    ndkAgentEventId?: string
  ): Promise<void> {
    // Publish profile event
    await AgentPublisher.publishAgentProfile(
      signer,
      agentConfig.name,
      agentConfig.role,
      projectTitle,
      projectEvent,
      ndkAgentEventId
    );

    // Publish request event
    await AgentPublisher.publishAgentRequest(signer, agentConfig, projectEvent, ndkAgentEventId);
  }
}
</file>

<file path="src/agents/AgentRegistry.ts">
import * as fs from "node:fs/promises";
import * as path from "node:path";
import type {
  AgentConfig,
  AgentConfigOptionalNsec,
  AgentInstance,
  StoredAgentData,
} from "@/agents/types";
import { ensureDirectory, fileExists, readFile, writeJsonFile } from "@/lib/fs";
import { DEFAULT_AGENT_LLM_CONFIG } from "@/llm/constants";
import { AgentPublisher } from "@/nostr/AgentPublisher";
import { configService } from "@/services";
import type { TenexAgents } from "@/services/config/types";
// Tool type removed - using AI SDK tools only
import { formatAnyError } from "@/utils/error-formatter";
import { logger } from "@/utils/logger";
import { type NDKProject } from "@nostr-dev-kit/ndk";
import { NDKPrivateKeySigner } from "@nostr-dev-kit/ndk";
import { CORE_AGENT_TOOLS, getDefaultToolsForAgent, DELEGATE_TOOLS, getDelegateToolsForAgent } from "./constants";
import { isValidToolName } from "@/tools/registry";
import { mcpService } from "@/services/mcp/MCPManager";

/**
 * AgentRegistry manages agent configuration and instances for a project.
 * Handles loading, saving, and publishing agents to the Nostr network.
 */
export class AgentRegistry {
  private agents: Map<string, AgentInstance> = new Map();
  private agentsByPubkey: Map<string, AgentInstance> = new Map();
  private agentsDir: string;
  private registry: TenexAgents = {};
  private globalRegistry: TenexAgents = {};
  private isGlobal: boolean;

  /**
   * Creates a new AgentRegistry instance.
   * @param basePath - Base directory path for the project
   * @param isGlobal - Whether this is the global agent registry
   */
  constructor(
    private basePath: string,
    isGlobal = false
  ) {
    this.isGlobal = isGlobal;
    // If basePath already includes .tenex, use it as is
    if (basePath.endsWith(".tenex")) {
      this.agentsDir = path.join(basePath, "agents");
    } else {
      this.agentsDir = path.join(basePath, ".tenex", "agents");
    }
  }

  async loadFromProject(ndkProject?: NDKProject): Promise<void> {
    // Ensure .tenex directory exists
    const tenexDir = this.basePath.endsWith(".tenex")
      ? this.basePath
      : path.join(this.basePath, ".tenex");
    await ensureDirectory(tenexDir);
    await ensureDirectory(this.agentsDir);

    // Store the NDKProject for PM determination
    this.ndkProject = ndkProject;

    // Load agents using ConfigService
    try {
      // Load global agents first if we're in a project context
      if (!this.isGlobal) {
        try {
          this.globalRegistry = await configService.loadTenexAgents(configService.getGlobalPath());
        } catch (error) {
          logger.debug("No global agents found or failed to load", { error });
          this.globalRegistry = {};
        }
      }

      // Load project/local agents
      this.registry = await configService.loadTenexAgents(tenexDir);

      // Load global agents first (if in project context)
      const loadedGlobalEventIds = new Set<string>();
      const loadedGlobalSlugs = new Set<string>();
      if (!this.isGlobal) {
        for (const [slug, registryEntry] of Object.entries(this.globalRegistry)) {
          logger.debug(`Loading global agent: ${slug}`, { registryEntry });
          await this.loadAgentBySlugInternal(slug, true);
          // Track global agent event IDs and slugs
          if (registryEntry.eventId) {
            loadedGlobalEventIds.add(registryEntry.eventId);
          }
          loadedGlobalSlugs.add(slug);
        }
      }

      // Load project/local agents (skip if they match a global agent's event ID or slug)
      for (const [slug, registryEntry] of Object.entries(this.registry)) {
        // Check if this project agent matches a global agent (same event ID or same slug)
        if (registryEntry.eventId && loadedGlobalEventIds.has(registryEntry.eventId)) {
          logger.info(`Skipping project agent "${slug}" - using global agent with same event ID`, {
            eventId: registryEntry.eventId,
          });
          continue;
        }
        if (loadedGlobalSlugs.has(slug)) {
          logger.info(`Skipping project agent "${slug}" - using global agent with same slug`);
          continue;
        }
        logger.debug(`Loading agent from registry: ${slug}`, { registryEntry });
        await this.loadAgentBySlugInternal(slug, false);
      }
    } catch (error) {
      logger.error("Failed to load agent registry", { error });
      this.registry = {};
    }
  }

  async ensureAgent(
    name: string,
    config: AgentConfigOptionalNsec,
    ndkProject?: NDKProject,
    fromGlobal = false
  ): Promise<AgentInstance> {
    // Check if agent already exists in memory
    const existingAgent = this.agents.get(name);
    if (existingAgent) {
      return existingAgent;
    }

    // Check if we're in a project context and this agent exists globally
    if (!this.isGlobal) {
      // Check by slug first (exact match)
      if (this.globalRegistry[name]) {
        logger.info(`Agent "${name}" already exists globally, using global agent`);
        // Load the global agent if not already loaded
        const globalAgent = this.agents.get(name);
        if (globalAgent) {
          return globalAgent;
        }
        // Load the global agent - use internal method to avoid recursion
        const loadedAgent = await this.loadAgentBySlugInternal(name, true);
        if (loadedAgent) {
          return loadedAgent;
        }
      }

      // Check by eventId if provided
      if (config.eventId) {
        for (const [globalSlug, globalEntry] of Object.entries(this.globalRegistry)) {
          if (globalEntry.eventId === config.eventId) {
            logger.info(
              `Agent with eventId ${config.eventId} already exists globally as "${globalSlug}", using global agent`,
              {
                localSlug: name,
                globalSlug,
              }
            );
            // Load the global agent if not already loaded
            const globalAgent = this.agents.get(globalSlug);
            if (globalAgent) {
              return globalAgent;
            }
            // Load the global agent - use internal method to avoid recursion
            const loadedAgent = await this.loadAgentBySlugInternal(globalSlug, true);
            if (loadedAgent) {
              return loadedAgent;
            }
          }
        }
      }
    }

    // Check if we have it in local registry
    let registryEntry = this.registry[name];
    let agentDefinition: StoredAgentData;

    if (!registryEntry) {
      // Generate new nsec for agent
      const signer = NDKPrivateKeySigner.generate();
      const nsec = signer.nsec;

      // Create new registry entry
      const fileName = `${config.eventId || name.toLowerCase().replace(/[^a-z0-9]/g, "-")}.json`;
      registryEntry = {
        nsec,
        file: fileName,
      };

      // Only add eventId if it exists
      if (config.eventId) {
        registryEntry.eventId = config.eventId;
      }


      // Save agent definition to file
      agentDefinition = {
        name: config.name,
        role: config.role,
        description: config.description,
        instructions: config.instructions,
        useCriteria: config.useCriteria,
        llmConfig: config.llmConfig,
        phase: config.phase,
      };

      // Include tools if explicitly provided
      if (config.tools !== undefined) {
        agentDefinition.tools = config.tools;
      }

      const definitionPath = path.join(this.agentsDir, fileName);
      await writeJsonFile(definitionPath, agentDefinition);

      this.registry[name] = registryEntry;
      await this.saveRegistry();

      logger.info(`Created new agent "${name}" with nsec`);

      // Publish kind:0 and request events for new agent
      const { nsec: _, ...configWithoutNsec } = config;
      await this.publishAgentEvents(signer, configWithoutNsec, registryEntry.eventId, ndkProject);
    } else {
      // Load agent definition from file
      const definitionPath = path.join(this.agentsDir, registryEntry.file);
      if (await fileExists(definitionPath)) {
        const content = await readFile(definitionPath, "utf-8");
        try {
          agentDefinition = JSON.parse(content);


          this.validateAgentDefinition(agentDefinition);
        } catch (error) {
          logger.error("Failed to parse or validate agent definition", {
            file: registryEntry.file,
            error,
          });
          throw new Error(`Invalid agent definition in ${registryEntry.file}: ${error}`);
        }
      } else {

        // Fallback: create definition from config if file doesn't exist (only include defined fields)
        agentDefinition = {
          name: config.name,
          role: config.role,
          ...(config.description !== undefined && { description: config.description }),
          ...(config.instructions !== undefined && { instructions: config.instructions }),
          ...(config.useCriteria !== undefined && { useCriteria: config.useCriteria }),
          ...(config.llmConfig !== undefined && { llmConfig: config.llmConfig }),
          ...(config.phase !== undefined && { phase: config.phase }),
        };
        await writeJsonFile(definitionPath, agentDefinition);
      }
    }

    // Create NDKPrivateKeySigner - generate new if nsec is empty
    let nsec = registryEntry.nsec;
    if (!nsec || nsec === "") {
      logger.warn(`Agent "${name}" has empty nsec, generating new one`);
      const newSigner = NDKPrivateKeySigner.generate();
      nsec = newSigner.nsec;
      
      // Update the registry with the new nsec
      registryEntry.nsec = nsec;
      this.registry[name] = registryEntry;
      await this.saveRegistry();
    }
    const signer = new NDKPrivateKeySigner(nsec);

    // Use the helper to build the agent instance
    const agent = await this.buildAgentInstance(
      name,
      agentDefinition,
      registryEntry,
      signer,
      fromGlobal
    );

    // Store in both maps
    this.agents.set(name, agent);
    this.agentsByPubkey.set(agent.pubkey, agent);

    return agent;
  }

  getAgent(name: string): AgentInstance | undefined {
    return this.agents.get(name);
  }

  getAgentByPubkey(pubkey: string): AgentInstance | undefined {
    return this.agentsByPubkey.get(pubkey);
  }

  getAllAgents(): AgentInstance[] {
    return Array.from(this.agents.values());
  }

  getAllAgentsMap(): Map<string, AgentInstance> {
    return new Map(this.agents);
  }

  /**
   * Get agents filtered by phase
   * @param phase - The phase to filter by (undefined returns agents without a phase)
   * @returns Array of agents matching the phase
   */
  getAgentsByPhase(phase: string | undefined): AgentInstance[] {
    const agents = Array.from(this.agents.values());
    
    if (phase === undefined) {
      // Return agents without a specific phase (universal agents)
      return agents.filter(agent => !agent.phase);
    }
    
    // Return agents matching the phase or universal agents
    const { normalizePhase } = require("@/conversations/utils/phaseUtils");
    const normalizedPhase = normalizePhase(phase);
    
    return agents.filter(agent => {
      if (!agent.phase) return true; // Universal agents work in all phases
      const agentPhase = normalizePhase(agent.phase);
      return agentPhase === normalizedPhase;
    });
  }
  
  /**
   * Set the PM for this project - updates registry and reassigns delegate tools
   * Note: This is synchronous. Call persistPMStatus() to save to disk.
   */
  setPMPubkey(pubkey: string): void {
    // Clear any existing PM flags in both registries
    for (const entry of Object.values(this.registry)) {
      delete entry.isPM;
    }
    for (const entry of Object.values(this.globalRegistry)) {
      delete entry.isPM;
    }
    
    // Find the agent with this pubkey
    const agentToSetAsPM = this.agentsByPubkey.get(pubkey);
    if (!agentToSetAsPM) {
      logger.error(`Failed to set PM - no agent found with pubkey ${pubkey}`);
      return;
    }
    
    // Find which registry contains this agent and set the flag
    let foundPM = false;
    for (const [slug, agent] of this.agents) {
      if (agent.pubkey === pubkey) {
        // Check both registries
        const registry = agent.isGlobal ? this.globalRegistry : this.registry;
        const registryEntry = registry[slug];
        if (registryEntry) {
          registryEntry.isPM = true;
          foundPM = true;
          break;
        }
      }
    }
    
    if (!foundPM) {
      logger.error(`Failed to set PM - agent not found in registry`);
      return;
    }
    
    // Reassign delegate tools for all loaded agents
    for (const agent of this.agents.values()) {
      agent.tools = agent.tools.filter(t => !DELEGATE_TOOLS.includes(t));
      const isPM = agent.pubkey === pubkey;
      const delegateTools = getDelegateToolsForAgent(isPM);
      agent.tools.push(...delegateTools);
    }
    
    logger.info(`Set PM to ${pubkey} and reassigned delegate tools`);
  }
  
  /**
   * Persist PM status to disk
   */
  async persistPMStatus(): Promise<void> {
    await this.saveRegistry();
    if (!this.isGlobal) {
      // Only save global registry if we modified it
      for (const entry of Object.values(this.globalRegistry)) {
        if (entry.isPM) {
          await this.saveGlobalRegistry();
          break;
        }
      }
    }
  }


  private async saveRegistry(): Promise<void> {
    if (this.isGlobal) {
      await configService.saveGlobalAgents(this.registry);
    } else {
      await configService.saveProjectAgents(this.basePath, this.registry);
    }
  }
  
  private async saveGlobalRegistry(): Promise<void> {
    await configService.saveGlobalAgents(this.globalRegistry);
  }

  /**
   * Remove an agent by its event ID
   * This removes the agent from memory and deletes its definition file
   */
  async removeAgentByEventId(eventId: string): Promise<boolean> {
    // Find the agent with this event ID
    let agentSlugToRemove: string | undefined;
    let agentToRemove: AgentInstance | undefined;

    for (const [slug, agent] of this.agents) {
      if (agent.eventId === eventId) {
        agentSlugToRemove = slug;
        agentToRemove = agent;
        break;
      }
    }

    if (!agentSlugToRemove || !agentToRemove) {
      logger.warn(`Agent with eventId ${eventId} not found for removal`);
      return false;
    }


    // Don't allow removing global agents from a project context
    if (agentToRemove.isGlobal && !this.isGlobal) {
      logger.warn(`Cannot remove global agent ${agentSlugToRemove} from project context. Remove it globally instead.`);
      return false;
    }

    // Remove from memory
    this.agents.delete(agentSlugToRemove);
    this.agentsByPubkey.delete(agentToRemove.pubkey);

    // Find registry info using pubkey to ensure we get the right registry
    const registryInfo = this.findRegistryEntryByPubkey(agentToRemove.pubkey);
    if (registryInfo) {
      // Delete the agent definition file
      try {
        const filePath = path.join(registryInfo.agentsDir, registryInfo.entry.file);
        await fs.unlink(filePath);
        logger.info(`Deleted agent definition file: ${filePath}`);
      } catch (error) {
        logger.warn("Failed to delete agent definition file", {
          error,
          slug: agentSlugToRemove,
        });
      }

      // Remove from the appropriate registry and save
      delete registryInfo.registry[agentSlugToRemove];
      
      // Save the appropriate registry
      if (registryInfo.registry === this.globalRegistry) {
        await this.saveGlobalRegistry();
      } else {
        await this.saveRegistry();
      }
    }

    logger.info(`Removed agent ${agentSlugToRemove} (eventId: ${eventId})`);
    return true;
  }


  /**
   * Find registry entry and path for an agent by its public key
   * Checks both local and global registries
   */
  private findRegistryEntryByPubkey(agentPubkey: string): {
    entry: TenexAgents[string];
    registry: TenexAgents;
    agentsDir: string;
    slug: string;
  } | null {
    // Check local registry first
    for (const [slug, entry] of Object.entries(this.registry)) {
      // Get the pubkey from the nsec
      try {
        const signer = new NDKPrivateKeySigner(entry.nsec);
        if (signer.pubkey === agentPubkey) {
          return {
            entry,
            registry: this.registry,
            agentsDir: this.agentsDir,
            slug,
          };
        }
      } catch (error) {
        logger.debug("Failed to decode nsec for registry entry", { slug, error });
      }
    }

    // Check global registry if not found locally
    if (!this.isGlobal) {
      for (const [slug, entry] of Object.entries(this.globalRegistry)) {
        try {
          const signer = new NDKPrivateKeySigner(entry.nsec);
          if (signer.pubkey === agentPubkey) {
            const globalPath = configService.getGlobalPath();
            return {
              entry,
              registry: this.globalRegistry,
              agentsDir: path.join(globalPath, "agents"),
              slug,
            };
          }
        } catch (error) {
          logger.debug("Failed to decode nsec for global registry entry", { slug, error });
        }
      }
    }

    return null;
  }

  /**
   * Update an agent's LLM configuration persistently
   */
  async updateAgentLLMConfig(agentPubkey: string, newLLMConfig: string): Promise<boolean> {
    // Find the agent by pubkey
    const agent = this.agentsByPubkey.get(agentPubkey);
    if (!agent) {
      logger.warn(`Agent with pubkey ${agentPubkey} not found for LLM config update`);
      return false;
    }

    // Update the agent in memory
    agent.llmConfig = newLLMConfig;

    // Find the registry entry by pubkey
    const registryInfo = this.findRegistryEntryByPubkey(agentPubkey);
    if (!registryInfo) {
      logger.warn(`Registry entry not found for agent with pubkey ${agentPubkey}`);
      return false;
    }

    // Update the agent definition file
    try {
      const definitionPath = path.join(registryInfo.agentsDir, registryInfo.entry.file);

      // Read existing definition
      let agentDefinition: StoredAgentData;
      try {
        const content = await fs.readFile(definitionPath, "utf-8");
        agentDefinition = JSON.parse(content);
      } catch (error) {
        logger.warn("Failed to read agent definition, creating from current state", {
          file: registryInfo.entry.file,
          error,
        });
        // Create definition from current agent state
        agentDefinition = {
          name: agent.name,
          role: agent.role,
          description: agent.description,
          instructions: agent.instructions,
          useCriteria: agent.useCriteria,
          llmConfig: newLLMConfig,
        };
      }

      // Update the llmConfig
      agentDefinition.llmConfig = newLLMConfig;

      // Save the updated definition
      await writeJsonFile(definitionPath, agentDefinition);

      logger.info(`Updated LLM config for agent ${agent.name} (${agent.slug})`, {
        newLLMConfig,
        file: registryInfo.entry.file,
      });

      return true;
    } catch (error) {
      logger.error("Failed to update agent LLM config", {
        agentSlug: agent.slug,
        error: formatAnyError(error),
      });
      return false;
    }
  }

  /**
   * Normalize agent tools by applying business rules:
   * - Remove delegation tools from requested tools (they're added based on PM status)
   * - Add appropriate delegation tools based on PM status
   * - Ensure core tools are always present
   * @param requestedTools - Tools requested/configured for the agent
   * @param isPM - Whether the agent is the Project Manager
   * @returns Normalized array of tool names
   */
  private normalizeAgentTools(requestedTools: string[], isPM: boolean): string[] {
    // Filter out delegation tools - they should never be in configuration
    let toolNames = requestedTools.filter(tool => !DELEGATE_TOOLS.includes(tool));
    
    // Add the correct delegation tools based on PM status
    const delegateTools = getDelegateToolsForAgent(isPM);
    toolNames.push(...delegateTools);
    
    // Ensure core tools are always included for ALL agents
    for (const coreTool of CORE_AGENT_TOOLS) {
      if (!toolNames.includes(coreTool)) {
        toolNames.push(coreTool);
      }
    }
    
    return toolNames;
  }

  /**
   * Update an agent's tools configuration persistently
   * @param agentPubkey - The public key of the agent to update
   * @param newToolNames - Array of tool names the agent should have access to
   * @returns true if successful, false otherwise
   */
  async updateAgentTools(agentPubkey: string, newToolNames: string[]): Promise<boolean> {
    // Find the agent by pubkey
    const agent = this.agentsByPubkey.get(agentPubkey);
    if (!agent) {
      logger.warn(`Agent with pubkey ${agentPubkey} not found for tools update`);
      return false;
    }

    // Find the registry entry by pubkey to get PM status
    const registryInfo = this.findRegistryEntryByPubkey(agentPubkey);
    if (!registryInfo) {
      logger.warn(`Registry entry not found for agent with pubkey ${agentPubkey}`);
      return false;
    }

    // Normalize tools according to business rules (delegation tools, core tools, etc.)
    const isPM = registryInfo.entry.isPM === true;
    const normalizedTools = this.normalizeAgentTools(newToolNames, isPM);

    // Validate the normalized tool names
    const validToolNames = normalizedTools.filter(isValidToolName);
    
    // Update the agent tools in memory
    agent.tools = validToolNames;

    // Update the agent definition file
    try {
      const definitionPath = path.join(registryInfo.agentsDir, registryInfo.entry.file);

      // Read existing definition
      let agentDefinition: StoredAgentData;
      try {
        const content = await fs.readFile(definitionPath, "utf-8");
        agentDefinition = JSON.parse(content);
      } catch (error) {
        logger.warn("Failed to read agent definition, creating from current state", {
          file: registryInfo.entry.file,
          error,
        });
        // Create definition from current agent state
        agentDefinition = {
          name: agent.name,
          role: agent.role,
          description: agent.description,
          instructions: agent.instructions,
          useCriteria: agent.useCriteria,
          llmConfig: agent.llmConfig,
          tools: newToolNames,
        };
      }

      // Update the tools
      agentDefinition.tools = newToolNames;

      // Save the updated definition
      await writeJsonFile(definitionPath, agentDefinition);

      logger.debug(`Persisted tools to ${registryInfo.entry.file}`, {
        agent: agent.slug,
        toolCount: newToolNames.length,
      });

      return true;
    } catch (error) {
      logger.error("Failed to update agent tools", {
        agentSlug: agent.slug,
        error: formatAnyError(error),
      });
      return false;
    }
  }

  private async publishAgentEvents(
    signer: NDKPrivateKeySigner,
    config: Omit<AgentConfig, "nsec">,
    ndkAgentEventId?: string,
    ndkProject?: NDKProject
  ): Promise<void> {
    try {
      let projectTitle: string;
      let projectEvent: NDKProject;

      // Require NDKProject to be passed
      if (!ndkProject) {
        logger.warn(
          "No NDKProject provided, skipping agent event publishing"
        );
        return;
      }
      
      projectTitle = ndkProject.tagValue("title") || "Unknown Project";
      projectEvent = ndkProject;

      // Publish agent profile (kind:0) and request event using static method
      await AgentPublisher.publishAgentCreation(
        signer,
        config,
        projectTitle,
        projectEvent,
        ndkAgentEventId
      );
    } catch (error) {
      logger.error("Failed to publish agent events", { error });
      // Don't throw - agent creation should succeed even if publishing fails
    }
  }

  private async loadAgentBySlugInternal(
    slug: string,
    fromGlobal = false
  ): Promise<AgentInstance | null> {
    const registryToUse = fromGlobal ? this.globalRegistry : this.registry;
    const registryEntry = registryToUse[slug];
    if (!registryEntry) {
      return null;
    }

    // Determine the correct agents directory
    const agentsDir = fromGlobal
      ? path.join(configService.getGlobalPath(), "agents")
      : this.agentsDir;

    // Load agent definition from file
    const definitionPath = path.join(agentsDir, registryEntry.file);
    if (!(await fileExists(definitionPath))) {
      // Missing file is not an error - it's a cache miss that will trigger fetch from Nostr
      logger.debug(`Agent definition file not found (cache miss): ${definitionPath}`);
      return null;
    }

    const content = await readFile(definitionPath, "utf-8");
    let agentDefinition: StoredAgentData;
    try {
      agentDefinition = JSON.parse(content);


      this.validateAgentDefinition(agentDefinition);
    } catch (error) {
      logger.error("Failed to parse or validate agent definition", {
        file: definitionPath,
        error,
      });
      throw new Error(`Invalid agent definition in ${definitionPath}: ${error}`);
    }

    // Create AgentConfig from definition
    const config: AgentConfig = {
      name: agentDefinition.name,
      role: agentDefinition.role,
      instructions: agentDefinition.instructions,
      useCriteria: agentDefinition.useCriteria,
      nsec: registryEntry.nsec,
      eventId: registryEntry.eventId,
      tools: agentDefinition.tools, // Preserve explicit tools configuration
      mcp: agentDefinition.mcp, // Preserve MCP configuration
      llmConfig: agentDefinition.llmConfig,
      phase: agentDefinition.phase,
    };

    // If loading from global registry, create agent directly without recursive ensureAgent call
    if (fromGlobal) {
      return this.createAgentInstance(slug, config, registryEntry);
    }

    return this.ensureAgent(slug, config, undefined, fromGlobal);
  }

  /**
   * Get the PM pubkey for this project
   */
  private getPMPubkey(): string | undefined {
    // Try ProjectContext first (most reliable when available)
    const { isProjectContextInitialized, getProjectContext } = require("@/services");
    if (isProjectContextInitialized()) {
      return getProjectContext().projectManager?.pubkey;
    }
    
    // Fall back to NDKProject if we have it
    if (this.ndkProject) {
      const pmEventId = this.ndkProject.tagValue("agent");
      // Find agent with this event ID
      for (const [_, agent] of this.agents) {
        if (agent.eventId === pmEventId) {
          return agent.pubkey;
        }
      }
    }
    
    // Last resort: first agent in registry
    const firstAgent = this.agents.values().next().value;
    return firstAgent?.pubkey;
  }

  /**
   * Helper method to build an AgentInstance from configuration and registry data
   * Centralizes the logic for creating agent instances to avoid duplication
   */
  private async buildAgentInstance(
    slug: string,
    agentDefinition: StoredAgentData,
    registryEntry: TenexAgents[string],
    signer: NDKPrivateKeySigner,
    isGlobal: boolean
  ): Promise<AgentInstance> {
    const pubkey = signer.pubkey;

    // Create Agent instance with all properties set
    const agent: AgentInstance = {
      name: agentDefinition.name,
      pubkey,
      signer,
      role: agentDefinition.role,
      description: agentDefinition.description,
      instructions: agentDefinition.instructions,
      useCriteria: agentDefinition.useCriteria,
      llmConfig: agentDefinition.llmConfig || DEFAULT_AGENT_LLM_CONFIG,
      tools: [], // Will be set next
      mcp: agentDefinition.mcp ?? true, // Default to true for all agents
      eventId: registryEntry.eventId,
      slug: slug,
      isGlobal: isGlobal,
      phase: agentDefinition.phase,
    };

    // Set tools - use explicit tools if configured, otherwise use defaults
    const requestedTools =
      agentDefinition.tools !== undefined ? agentDefinition.tools : getDefaultToolsForAgent(agent);
    
    // Normalize tools according to business rules (delegation tools, core tools, etc.)
    const isPM = registryEntry.isPM === true;
    let toolNames = this.normalizeAgentTools(requestedTools, isPM);

    // Validate tool names - we now store tool names as strings, not instances
    const validToolNames: string[] = [];
    const unknownTools: string[] = [];
    const requestedMcpTools: string[] = [];
    const unknownNonMcpTools: string[] = [];
    
    for (const toolName of toolNames) {
      if (isValidToolName(toolName)) {
        validToolNames.push(toolName);
      } else {
        // Check if it's an MCP tool (starts with "mcp__")
        if (toolName.startsWith("mcp__")) {
          requestedMcpTools.push(toolName);
        } else {
          unknownNonMcpTools.push(toolName);
          unknownTools.push(toolName);
        }
      }
    }
    
    // Handle MCP tools if agent has MCP access
    if (agent.mcp !== false && requestedMcpTools.length > 0) {
      try {
        const allMcpTools = mcpService.getCachedTools();
        
        // Check which requested MCP tools are available
        const availableMcpToolNames: string[] = [];
        const unavailableMcpTools: string[] = [];
        
        for (const toolName of requestedMcpTools) {
          if (allMcpTools[toolName]) {
            availableMcpToolNames.push(toolName);
            validToolNames.push(toolName);
          } else {
            unavailableMcpTools.push(toolName);
          }
        }
        
        if (unavailableMcpTools.length > 0) {
          logger.debug(`Agent "${slug}" requested MCP tools not yet available:`, unavailableMcpTools);
        }
      } catch (error) {
        logger.debug(`Could not load MCP tools for agent "${slug}":`, error);
      }
    } else if (agent.mcp !== false) {
      // Agent has MCP access but didn't request specific tools - give access to all
      try {
        const allMcpTools = mcpService.getCachedTools();
        for (const toolName of Object.keys(allMcpTools)) {
          validToolNames.push(toolName);
        }
      } catch (error) {
        logger.debug(`Could not load MCP tools for agent "${slug}":`, error);
      }
    }
    
    // Log warnings for unknown non-MCP tools
    if (unknownNonMcpTools.length > 0) {
      logger.warn(`Agent "${slug}" requested unknown tools:`, unknownNonMcpTools);
    }
    
    agent.tools = validToolNames;
    
    // Store the full list of requested tools (including unknown ones) in the agent definition
    // This ensures MCP tools are preserved even if not currently installed
    if (agentDefinition.tools !== undefined) {
      agentDefinition.tools = toolNames;
    }

    return agent;
  }

  /**
   * Create an agent instance directly without going through ensureAgent
   * Used to avoid infinite recursion when loading global agents
   */
  private async createAgentInstance(
    slug: string,
    config: AgentConfig,
    registryEntry: TenexAgents[string]
  ): Promise<AgentInstance> {
    // Create NDKPrivateKeySigner - generate new if nsec is empty
    let nsec = registryEntry.nsec;
    if (!nsec || nsec === "") {
      logger.warn(`Agent "${slug}" has empty nsec in createAgentInstance, generating new one`);
      const newSigner = NDKPrivateKeySigner.generate();
      nsec = newSigner.nsec;
      
      // Update the registry with the new nsec
      registryEntry.nsec = nsec;
      this.registry[slug] = registryEntry;
      await this.saveRegistry();
    }
    const signer = new NDKPrivateKeySigner(nsec);

    // Create agent definition from config (only include defined fields)
    const agentDefinition: StoredAgentData = {
      name: config.name,
      role: config.role,
      ...(config.description !== undefined && { description: config.description }),
      ...(config.instructions !== undefined && { instructions: config.instructions }),
      ...(config.useCriteria !== undefined && { useCriteria: config.useCriteria }),
      ...(config.llmConfig !== undefined && { llmConfig: config.llmConfig }),
      ...(config.tools !== undefined && { tools: config.tools }),
      ...(config.mcp !== undefined && { mcp: config.mcp }),
      ...(config.phase !== undefined && { phase: config.phase }),
    };

    // Use the helper to build the agent instance
    const agent = await this.buildAgentInstance(
      slug,
      agentDefinition,
      registryEntry,
      signer,
      true // createAgentInstance is only called for global agents
    );

    // Store in both maps
    this.agents.set(slug, agent);
    this.agentsByPubkey.set(agent.pubkey, agent);

    return agent;
  }

  /**
   * Validate an agent definition has all required fields
   */
  private validateAgentDefinition(definition: unknown): asserts definition is StoredAgentData {
    if (!definition || typeof definition !== "object") {
      throw new Error("Agent definition must be an object");
    }

    const def = definition as Record<string, unknown>;

    if (!def.name || typeof def.name !== "string") {
      throw new Error("Agent definition must have a name property");
    }

    if (!def.role || typeof def.role !== "string") {
      throw new Error("Agent definition must have a role property");
    }

    // Optional fields with type validation (null is allowed for all nullable fields)
    if (def.instructions !== undefined && def.instructions !== null && typeof def.instructions !== "string") {
      throw new Error("Agent instructions must be a string");
    }

    if (def.useCriteria !== undefined && def.useCriteria !== null && typeof def.useCriteria !== "string") {
      throw new Error("Agent useCriteria must be a string");
    }

    if (def.description !== undefined && def.description !== null && typeof def.description !== "string") {
      throw new Error("Agent description must be a string");
    }

    if (def.backend !== undefined && def.backend !== null && typeof def.backend !== "string") {
      throw new Error("Agent backend must be a string");
    }

    if (def.tools !== undefined && def.tools !== null && !Array.isArray(def.tools)) {
      throw new Error("Agent tools must be an array");
    }

    if (def.mcp !== undefined && def.mcp !== null && typeof def.mcp !== "boolean") {
      throw new Error("Agent mcp must be a boolean");
    }

    if (def.llmConfig !== undefined && def.llmConfig !== null && typeof def.llmConfig !== "string") {
      throw new Error("Agent llmConfig must be a string");
    }
  }

  /**
   * Republish kind:0 events for all agents
   * This is called when the project boots to ensure agents are discoverable
   */
  async republishAllAgentProfiles(ndkProject: NDKProject): Promise<void> {
    let projectTitle: string;
    let projectEvent: NDKProject;

    // NDKProject is required
    projectTitle = ndkProject.tagValue("title") || "Unknown Project";
    projectEvent = ndkProject;

    // Republish kind:0 for each agent
    for (const [slug, agent] of Array.from(this.agents.entries())) {
      try {
        await AgentPublisher.publishAgentProfile(
          agent.signer,
          agent.name,
          agent.role,
          projectTitle,
          projectEvent,
          agent.eventId
        );
      } catch (error) {
        logger.error(`Failed to republish kind:0 for agent: ${slug}`, {
          error,
          agentName: agent.name,
        });
        // Continue with other agents even if one fails
      }
    }
  }
}
</file>

<file path="src/nostr/AgentEventEncoder.ts">
import { NDKAgentLesson } from "@/events/NDKAgentLesson";
import { EVENT_KINDS, LanguageModelUsageWithCostUsd } from "@/llm/types";
import { getNDK } from "@/nostr/ndkClient";
import { getProjectContext } from "@/services";
import { logger } from "@/utils/logger";
import { NDKEvent, NDKKind, NDKTask } from "@nostr-dev-kit/ndk";

/**
 * Centralized module for encoding and decoding agent event semantics.
 * This module codifies the tagging structures and their meanings,
 * ensuring consistent event creation and interpretation across the system.
 */

// Intent types that agents can express
export interface CompletionIntent {
    content: string;
    summary?: string;
    usage?: LanguageModelUsageWithCostUsd;
    isReasoning?: boolean;
}

export interface DelegationIntent {
  recipients: string[];
  request: string;
  phase?: string;
}

export interface ConversationIntent {
  content: string;
  isReasoning?: boolean;
}

export interface ErrorIntent {
  message: string;
  errorType?: string;
}

export interface TypingIntent {
  state: "start" | "stop";
  message?: string;
}

export interface StreamingIntent {
  content: string;
  sequence: number;
  isReasoning?: boolean;
}

export interface LessonIntent {
  title: string;
  lesson: string;
  detailed?: string;
  category?: string;
  hashtags?: string[];
}

export interface StatusIntent {
  type: "status";
  agents: Array<{ pubkey: string; slug: string }>;
  models: Array<{ slug: string; agents: string[] }>;
  tools: Array<{ name: string; agents: string[] }>;
  queue?: string[];
}

export interface ToolUseIntent {
  toolName: string;
  content: string; // e.g., "Reading $path"
}

export type AgentIntent =
  | CompletionIntent
  | DelegationIntent
  | ConversationIntent
  | ErrorIntent
  | TypingIntent
  | StreamingIntent
  | LessonIntent
  | StatusIntent
  | ToolUseIntent;

// Execution context provided by RAL
export interface EventContext {
  triggeringEvent: NDKEvent;
  rootEvent: NDKEvent; // Now mandatory for better type safety
  conversationId: string; // Required for conversation lookup
  executionTime?: number;
  model?: string;
  cost?: number; // LLM cost in USD
  phase?: string; // Current phase for phase-aware events
}

/**
 * Encodes agent intents into properly tagged Nostr events.
 * All tagging logic is centralized here for consistency and testability.
 */
export class AgentEventEncoder {
    /**
     * Add conversation tags consistently to any event.
     * Centralizes conversation tagging logic for all agent events.
     */
    private addConversationTags(event: NDKEvent, context: EventContext): void {
        this.tagConversation(event, context.rootEvent);
        this.eTagParentEvent(event, context.rootEvent, context.triggeringEvent);
    }

    /**
     * Tags the root of the conversation
     */
    tagConversation(event: NDKEvent, rootEvent: NDKEvent): void {
        event.tag(["E", rootEvent.id]);
        event.tag(["K", rootEvent.kind.toString()]);
        event.tag(["P", rootEvent.pubkey]);
    }

    /**
     * "e"-tags this reply in the proper context.
     *
     * When the triggering event has the same author as the conversation root AND
     * when the triggering event, we want to publish to the root, and not thread it in
     * the triggering event; otherwise we thread inside the triggering event.
     */
    eTagParentEvent(event: NDKEvent, rootEvent: NDKEvent, triggeringEvent: NDKEvent): void {
        const triggeringEventFromOP = triggeringEvent.pubkey === rootEvent.pubkey;
        const triggeringEventFirstLevelReply = triggeringEvent.tagValue("e") === rootEvent.id;
        const replyToOP = triggeringEventFromOP && triggeringEventFirstLevelReply;
        const replyToEvent = replyToOP ? rootEvent : triggeringEvent;

        event.tag(["e", replyToEvent.id]);
    }

    /**
     * Encode a completion intent into a tagged event.
     * Handles both regular completions and delegation completions.
     */
    encodeCompletion(intent: CompletionIntent, context: EventContext): NDKEvent {
        const event = new NDKEvent(getNDK());
        event.kind = 1111;
        event.content = intent.content;

        // Add conversation tags (E, K, P for root)
        this.tagConversation(event, context.rootEvent);

        // Simply e-tag the triggering event
        event.tag(["e", context.triggeringEvent.id, "", "reply"]);

        // if the triggering event is authored by the same as the root event
        // and the triggering event is e-tagging the root event, let's also e-tag the root
        // event. This is so that this completion event also shows up in the main thread.
        const pTagsMatch = context.triggeringEvent.pubkey === context.rootEvent.pubkey;
        const triggerTagsRoot = context.triggeringEvent.tagValue("e") === context.rootEvent.id;

        if (pTagsMatch && triggerTagsRoot) {
            event.tag(["e", context.rootEvent.id, "", "root"]);
        }

        // p-tag the agent that triggered us
        event.tag(["p", context.triggeringEvent.pubkey]);

        // Mark as natural completion
        event.tag(["status", "completed"]);

        // Add reasoning tag if this is reasoning content
        if (intent.isReasoning) {
            event.tag(["reasoning"]);
        }

        // Add summary if provided
        if (intent.summary) {
            event.tag(["summary", intent.summary]);
        }

        // Add usage information if provided
        if (intent.usage) {
            this.addLLMUsageTags(event, intent.usage);
        }

        // Add standard metadata (without usage, which is now handled above)
        this.addStandardTags(event, context);

        logger.debug("Encoded completion event", {
            eventId: event.id,
            summary: intent.summary,
            completingTo: context.triggeringEvent.id?.substring(0, 8),
            completingToPubkey: context.triggeringEvent.pubkey?.substring(0, 8),
        });

        return event;
    }

    /**
     * Encode a delegation intent into a single kind:1111 conversation event.
     * Creates a single event with multiple p-tags for all recipients.
     */
    encodeDelegation(intent: DelegationIntent, context: EventContext): NDKEvent[] {
        const event = new NDKEvent(getNDK());
        event.kind = 1111; // NIP-22 comment/conversation kind
        event.content = intent.request;

        this.addConversationTags(event, context);

        // Add ALL recipients as p-tags in a single event
        for (const recipientPubkey of intent.recipients) {
            event.tag(["p", recipientPubkey]);
        }

        // Phase metadata if provided
        if (intent.phase) {
            event.tag(["phase", intent.phase]);
        }

        // Add standard metadata
        this.addStandardTags(event, context);

        logger.debug("Encoded delegation request", {
            phase: intent.phase,
            recipients: intent.recipients.map((r) => r.substring(0, 8)),
        });

        return [event];
    }

    /**
     * Encode a conversation intent into a response event.
     * Standard agent response without flow termination semantics.
     */
    encodeConversation(intent: ConversationIntent, context: EventContext): NDKEvent {
        const event = new NDKEvent(getNDK());
        event.kind = NDKKind.GenericReply;
        event.content = intent.content;

        // Add conversation tags
        this.addConversationTags(event, context);

        // Add reasoning tag if this is reasoning content
        if (intent.isReasoning) {
            event.tag(["reasoning"]);
        }

        // Add standard metadata
        this.addStandardTags(event, context);

        return event;
    }


    /**
     * Add standard metadata tags that all agent events should have.
     * Centralizes common tagging logic.
     */
    public addStandardTags(event: NDKEvent, context: EventContext): void {
        this.aTagProject(event);

        // Phase metadata
        if (context.phase) {
            event.tag(["phase", context.phase]);
        }

        // LLM metadata
        if (context.model) {
            event.tag(["llm-model", context.model]);
        }
        // Add cost metadata if available
        if (context.cost !== undefined) {
            // Format cost to avoid scientific notation and ensure proper decimal representation
            // Use toFixed with enough precision (10 decimal places) then remove trailing zeros
            const formattedCost = context.cost.toFixed(10).replace(/\.?0+$/, "");
            event.tag(["llm-cost-usd", formattedCost]);
        }
        if (context.executionTime) {
            event.tag(["execution-time", context.executionTime.toString()]);
        }
    }

    /**
     * Encode an error intent into an error event.
     */
    encodeError(intent: ErrorIntent, context: EventContext): NDKEvent {
        const event = new NDKEvent(getNDK());
        event.kind = NDKKind.GenericReply;
        event.content = intent.message;

        // Add conversation tags
        this.addConversationTags(event, context);

        // Mark as error
        event.tag(["error", intent.errorType || "system"]);

        // Add standard metadata
        this.addStandardTags(event, context);

        return event;
    }

    /**
     * Encode a typing indicator intent.
     */
    encodeTypingIndicator(
        intent: TypingIntent,
        context: EventContext,
        agent: { name: string }
    ): NDKEvent {
        const event = new NDKEvent(getNDK());

        // Use appropriate event kind based on state
        if (intent.state === "start") {
            event.kind = EVENT_KINDS.TYPING_INDICATOR;
            event.content = intent.message || `${agent.name} is typing`;
        } else {
            // Stop event uses different kind
            event.kind = EVENT_KINDS.TYPING_INDICATOR_STOP;
            event.content = "";
        }

        // Add conversation tags
        this.addConversationTags(event, context);

        // Add standard metadata tags (includes project tag)
        this.addStandardTags(event, context);

        return event;
    }

    /**
     * Encode a streaming progress intent.
     */
    encodeStreamingContent(intent: StreamingIntent, context: EventContext): NDKEvent {
        const event = new NDKEvent(getNDK());
        event.kind = EVENT_KINDS.STREAMING_RESPONSE;
        event.content = intent.content;

        // Add conversation tags for proper threading
        this.addConversationTags(event, context);

        // Add streaming-specific tags
        event.tag(["streaming", "true"]);
        event.tag(["sequence", intent.sequence.toString()]);

        // Add reasoning tag if this is reasoning content
        if (intent.isReasoning) {
            event.tag(["reasoning"]);
        }

        // Add standard metadata tags
        this.addStandardTags(event, context);

        return event;
    }


    /**
     * Add LLM usage metadata tags to an event.
     * Centralizes the encoding of usage information from AI SDK's LanguageModelUsageWithCostUsd.
     */
    private addLLMUsageTags(event: NDKEvent, usage: LanguageModelUsageWithCostUsd): void {
        if (usage.inputTokens !== undefined) {
            event.tag(["llm-prompt-tokens", usage.inputTokens.toString()]);
        }
        if (usage.outputTokens !== undefined) {
            event.tag(["llm-completion-tokens", usage.outputTokens.toString()]);
        }
        if (usage.totalTokens !== undefined) {
            event.tag(["llm-total-tokens", usage.totalTokens.toString()]);
        } else if (usage.inputTokens !== undefined && usage.outputTokens !== undefined) {
            // Fallback: calculate total if not provided
            event.tag(["llm-total-tokens", (usage.inputTokens + usage.outputTokens).toString()]);
        }

        if (usage.costUsd !== undefined) {
            event.tag(["llm-cost-usd", usage.costUsd.toString()]);
        }

        // Add additional usage metadata if available
        if ("reasoningTokens" in usage && usage.reasoningTokens !== undefined) {
            event.tag(["llm-reasoning-tokens", String(usage.reasoningTokens)]);
        }
        if ("cachedInputTokens" in usage && usage.cachedInputTokens !== undefined) {
            event.tag(["llm-cached-input-tokens", String(usage.cachedInputTokens)]);
        }
    }

    aTagProject(event: NDKEvent): undefined {
        const projectCtx = getProjectContext();
        event.tag(projectCtx.project.tagReference());
    }

    /**
     * p-tags the project owner
     */
    pTagProjectOwner(event: NDKEvent): undefined {
        const projectCtx = getProjectContext();
        event.tag(["p", projectCtx.project.pubkey]);
    }

    /**
     * Encode a task creation with proper conversation tagging.
     * Creates an NDKTask that references the triggering event.
     */
    encodeTask(
        title: string,
        content: string,
        context: EventContext,
        claudeSessionId?: string,
    ): NDKTask {
        const task = new NDKTask(getNDK());
        task.title = title;
        task.content = content;

        // Add conversation tags (E, K, P for root, e for triggering)
        this.addConversationTags(task, context);

        // Add session ID if provided
        if (claudeSessionId) {
            task.tags.push(["claude-session", claudeSessionId]);
        }

        // Add standard metadata tags (project, phase, etc)
        this.addStandardTags(task, context);

        return task;
    }

    /**
     * Encode a lesson learned intent.
     */
    encodeLesson(
        intent: LessonIntent,
        context: EventContext,
        agent: { eventId?: string }
    ): NDKAgentLesson {
        const lessonEvent = new NDKAgentLesson(getNDK());

        // Set core properties
        lessonEvent.title = intent.title;
        lessonEvent.lesson = intent.lesson;

        // Set optional properties
        if (intent.detailed) {
            lessonEvent.detailed = intent.detailed;
        }
        if (intent.category) {
            lessonEvent.category = intent.category;
        }
        if (intent.hashtags && intent.hashtags.length > 0) {
            lessonEvent.hashtags = intent.hashtags;
        }

        // Add reference to the agent event if available
        if (agent.eventId) {
            lessonEvent.agentDefinitionId = agent.eventId;
        }

        // Add standard metadata including project tag
        this.addStandardTags(lessonEvent, context);

        return lessonEvent;
    }

    /**
     * Encode a follow-up event to a previous delegation response.
     * Creates a threaded reply that maintains conversation context.
     *
     * @param responseEvent The event being responded to
     * @param message The follow-up message content
     * @returns The encoded follow-up event
     */
    encodeFollowUp(responseEvent: NDKEvent, message: string): NDKEvent {
        // Create a reply to the response event to maintain thread
        const followUpEvent = responseEvent.reply();

        // Handle e-tag to avoid deep nesting
        const eTagVal = responseEvent.tagValue("e");
        if (eTagVal) {
            followUpEvent.removeTag("e");
            followUpEvent.tags.push(["e", eTagVal]); // Root thread tag
        }

        followUpEvent.content = message;

        // Clean out p-tags and add recipient
        followUpEvent.tags = followUpEvent.tags.filter((t) => t[0] !== "p");
        followUpEvent.tag(responseEvent.author);

        return followUpEvent;
    }

    /**
     * Encode a tool usage event.
     * Creates an event that tracks tool invocation with output.
     */
    encodeToolUse(intent: ToolUseIntent, context: EventContext): NDKEvent {
        const event = new NDKEvent(getNDK());
        event.kind = NDKKind.GenericReply;
        event.content = intent.content;

        // Add conversation tags
        this.addConversationTags(event, context);

        // Add tool usage tags
        event.tag(["tool", intent.toolName]);

        // Add standard metadata
        this.addStandardTags(event, context);

        return event;
    }
}
</file>

<file path="src/tools/implementations/delegate_phase.ts">
import { tool } from 'ai';
import type { Tool } from 'ai';
import { DelegationService, type DelegationResponses } from "@/services/DelegationService";
import { resolveRecipientToPubkey } from "@/utils/agent-resolution";
import { logger } from "@/utils/logger";
import { z } from "zod";
import type { ExecutionContext } from "@/agents/execution/types";
import { NDKEventMetadata } from "@/events/NDKEventMetadata";
import { getNDK } from "@/nostr/ndkClient";

const delegatePhaseSchema = z.object({
  phase: z
    .string()
    .describe("The phase to switch to"),
  phase_instructions: z
    .string()
    .describe(
      "Detailed instructions and goals for this phase - what should be accomplished and how. Other agents are not aware of how YOU define phases; so you must provide clear and complete instructions of the goal, what to do, what not to do and phase constrains."
    ),
  recipient: z
    .string()
    .describe(
      "Agent slug (e.g., 'architect'), npub, or hex pubkey to delegate to in this phase."
    ),
  fullRequest: z
    .string()
    .describe(
      "The complete request or question to delegate - this becomes the phase reason and delegation content"
    ),
  title: z
    .string()
    .nullable()
    .describe("Title for this conversation (if not already set)."),
});

type DelegatePhaseInput = z.infer<typeof delegatePhaseSchema>;
type DelegatePhaseOutput = DelegationResponses;

// Core implementation - extracted from existing execute function
async function executeDelegatePhase(input: DelegatePhaseInput, context: ExecutionContext): Promise<DelegatePhaseOutput> {
  const { phase, phase_instructions, recipient, fullRequest, title } = input;

  // Resolve recipient to pubkey
  const pubkey = resolveRecipientToPubkey(recipient);
  if (!pubkey) {
    throw new Error(`Could not resolve recipient: ${recipient}`);
  }

  if (title) {
    const ndk = getNDK();

    const metadataEvent = new NDKEventMetadata(ndk);
    metadataEvent.kind = 513;
    metadataEvent.setConversationId(context.conversationId);
    metadataEvent.title = title;

    await metadataEvent.sign(context.agent.signer);
    await metadataEvent.publish();

    context.conversationCoordinator.setTitle(context.conversationId, title);
    logger.info(`Set conversation title: ${title}`);
  }

  logger.info("[delegate_phase() tool] üéØ Starting phase delegation", {
    fromAgent: context.agent.slug,
    phase: phase,
    recipient: recipient,
    mode: "synchronous",
  });

  // First, update the conversation phase
  await context.conversationCoordinator.updatePhase(
    context.conversationId,
    phase,
    fullRequest, // Use the fullRequest as the phase transition message
    context.agent.pubkey,
    context.agent.name,
    phase_instructions // Pass the custom phase instructions
  );

  // Use DelegationService to execute the delegation
  const delegationService = new DelegationService(
    context.agent,
    context.conversationId,
    context.conversationCoordinator,
    context.triggeringEvent,
    context.agentPublisher, // Pass the required AgentPublisher
    phase // Pass the new phase as context
  );
  
  const responses = await delegationService.execute({
    recipients: [pubkey],
    request: fullRequest,
    phase: phase, // Include phase in the delegation intent
  });
  
  logger.info("[delegate_phase() tool] ‚úÖ SYNCHRONOUS COMPLETE: Received responses", {
    phase: phase,
    recipient: recipient,
    responseCount: responses.responses.length,
    mode: "synchronous",
  });
  
  return responses;
}

// AI SDK tool factory
export function createDelegatePhaseTool(context: ExecutionContext): Tool<any, any> {
    return tool({
        description:
            "Switch conversation phase and delegate a question or task to a specific agent.  Use for complex multi-step operations that require specialized expertise. Provide complete context in the request - agents have no visibility into your conversation.",
        inputSchema: delegatePhaseSchema,
        execute: async (input: DelegatePhaseInput) => {
            return await executeDelegatePhase(input, context);
        },
    });
}

/**
 * Delegate Phase tool - enables the Project Manager to atomically switch phases and delegate work
 *
 * This tool combines phase switching with task delegation, ensuring the PM always:
 * 1. Switches to the appropriate phase for the work being done
 * 2. Provides custom phase instructions to guide agent behavior
 * 3. Delegates the task to the appropriate specialist agent(s)
 * 4. Sets up proper event-driven callbacks for task completion
 *
 * Phase can be:
 * - Standard phases: CHAT, BRAINSTORM, PLAN, EXECUTE, VERIFICATION, CHORES, REFLECTION
 * - Custom phases: Any string that represents a project-specific phase
 *
 * Phase Instructions:
 * - Detailed instructions that define what should be accomplished in this phase
 * - These instructions override standard phase definitions for custom phases
 * - Agents receive these instructions as part of their execution context
 *
 * The fullRequest serves dual purpose:
 * - Becomes the phase transition reason (context for all agents)
 * - Is the actual task delegated to the specified recipients
 *
 * Recipient can be:
 * - Agent slug (e.g., "architect", "planner") - resolved from project agents
 * - Agent name (e.g., "Architect", "Planner") - resolved from project agents
 * - Npub (e.g., "npub1...") - decoded to hex pubkey
 * - Hex pubkey (64 characters) - used directly
 *
 * If recipient cannot be resolved, the tool fails with an error.
 *
 * The agent should NOT complete after using delegate_phase.
 */
</file>

<file path="src/event-handler/index.ts">
import { formatAnyError } from "@/utils/error-formatter";
import { NDKEvent, NDKKind, NDKProject } from "@nostr-dev-kit/ndk";
import chalk from "chalk";
import { AgentExecutor } from "../agents/execution/AgentExecutor";
import { ConversationCoordinator } from "../conversations";
import { NDKEventMetadata } from "../events/NDKEventMetadata";
import { EVENT_KINDS } from "../llm/types";
import { getProjectContext } from "../services";
import { DelegationRegistry } from "../services/DelegationRegistry";
import { logger } from "../utils/logger";
import { handleNewConversation } from "./newConversation";
import { handleProjectEvent } from "./project";
import { handleChatMessage } from "./reply";
import { llmOpsRegistry } from "../services/LLMOperationsRegistry";


const IGNORED_EVENT_KINDS = [
  NDKKind.Metadata,
  EVENT_KINDS.PROJECT_STATUS as NDKKind,
  EVENT_KINDS.STREAMING_RESPONSE as NDKKind,
  EVENT_KINDS.TYPING_INDICATOR as NDKKind,
  EVENT_KINDS.TYPING_INDICATOR_STOP as NDKKind,
  EVENT_KINDS.OPERATIONS_STATUS as NDKKind,
];

const STOP_EVENT_KIND = 24134; // Ephemeral stop command for LLM operations

export class EventHandler {
  private conversationCoordinator!: ConversationCoordinator;
  private agentExecutor!: AgentExecutor;
  private isUpdatingProject = false;

  constructor(
    private projectPath: string,
  ) {}

  async initialize(): Promise<void> {
    // Initialize DelegationRegistry singleton first
    await DelegationRegistry.initialize();

    // Initialize components directly
    this.conversationCoordinator = new ConversationCoordinator(
      this.projectPath,
      undefined // default persistence
    );
    this.agentExecutor = new AgentExecutor();

    // Initialize components
    await this.conversationCoordinator.initialize();
  }

  getConversationCoordinator(): ConversationCoordinator {
    return this.conversationCoordinator;
  }

  async handleEvent(event: NDKEvent): Promise<void> {
    // Ignore kind 24010 (project status), 24111 (typing indicator), and 24112 (typing stop) events
    if (IGNORED_EVENT_KINDS.includes(event.kind)) return;

    // Debug: Check if event has proper NDKEvent methods
    if (typeof event.getMatchingTags !== 'function') {
      logger.error("Event is missing getMatchingTags method!", {
        eventId: event.id,
        eventKind: event.kind,
        hasGetMatchingTags: typeof event.getMatchingTags,
        hasEncode: typeof event.encode,
        eventConstructor: event.constructor?.name,
        eventPrototype: Object.getPrototypeOf(event)?.constructor?.name,
        eventKeys: Object.keys(event),
        isNDKEvent: event instanceof NDKEvent,
      });
      // Don't mask the issue - let it fail so we can trace it
    }

    // Try to get agent slug if the event is from an agent
    let fromIdentifier = event.pubkey;
    let forIdentifiers: string = "without any recipient";
    
    try {
      const projectCtx = getProjectContext();
      const agent = projectCtx.getAgentByPubkey(event.pubkey);
      if (agent) {
        fromIdentifier = agent.slug;
      }
      
      // Process p-tags to show agent slugs where possible
      let pTags: string[][] = [];
      try {
        pTags = event.getMatchingTags("p");
      } catch (err) {
        logger.error("Failed to get p-tags - event is not a proper NDKEvent!", {
          error: err,
          eventType: typeof event,
          eventConstructor: event?.constructor?.name,
          eventPrototype: Object.getPrototypeOf(event)?.constructor?.name,
          hasGetMatchingTags: typeof event?.getMatchingTags,
          eventKeys: Object.keys(event || {}),
          event: JSON.stringify(event, null, 2)
        });
        throw err;
      }
      if (pTags.length > 0) {
        const recipients = pTags.map((t) => {
          const pubkey = t[1];
          const recipientAgent = projectCtx.getAgentByPubkey(pubkey);
          return recipientAgent ? recipientAgent.slug : pubkey.substring(0, 8);
        });
        forIdentifiers = recipients.join(", ");
      }
    } catch {
      // Project context might not be available, continue with pubkey
      let pTags: string[][] = [];
      try {
        pTags = event.getMatchingTags("p");
      } catch (err) {
        logger.error("Failed to get p-tags (fallback) - event is not a proper NDKEvent!", {
          error: err,
          eventType: typeof event,
          eventConstructor: event?.constructor?.name,
          eventPrototype: Object.getPrototypeOf(event)?.constructor?.name,
          hasGetMatchingTags: typeof event?.getMatchingTags,
          eventKeys: Object.keys(event || {}),
          event: JSON.stringify(event, null, 2)
        });
        throw err;
      }
      if (pTags.length > 0) {
        forIdentifiers = pTags.map((t) => t[1].substring(0, 8)).join(", ");
      }
    }

    logger.info(
      `event handler, kind: ${event.kind} from ${fromIdentifier} for (${forIdentifiers}) (${event.encode()})`
    );

    // Check if this is a delegation response BEFORE routing
    const delegationRegistry = DelegationRegistry.getInstance();
    if (delegationRegistry.isDelegationResponse(event)) {
      await delegationRegistry.handleDelegationResponse(event);
      return; // Done - this was a delegation response
    }

    switch (event.kind) {
      case NDKKind.GenericReply: // kind 1111
        await handleChatMessage(event, {
          conversationCoordinator: this.conversationCoordinator,
          agentExecutor: this.agentExecutor,
        });
        break;

      case NDKKind.Thread: // kind 11
        await handleNewConversation(event, {
          conversationCoordinator: this.conversationCoordinator,
          agentExecutor: this.agentExecutor,
        });
        break;

      case NDKProject.kind: // kind 31933
        if (this.isUpdatingProject) {
          logger.warn("Project update already in progress, skipping event", {
            eventId: event.id,
          });
          return;
        }

        this.isUpdatingProject = true;
        try {
          await handleProjectEvent(event, this.projectPath);
        } finally {
          this.isUpdatingProject = false;
        }
        break;

      case EVENT_KINDS.AGENT_CONFIG_UPDATE:
        await this.handleAgentConfigUpdate(event);
        break;

      case 513: // NDKEventMetadata
        await this.handleMetadataEvent(event);
        break;
      
      case STOP_EVENT_KIND: // kind 24134 - Stop LLM operations
        await this.handleStopEvent(event);
        break;

      default:
        this.handleDefaultEvent(event);
    }
  }

  private async handleMetadataEvent(event: NDKEvent): Promise<void> {
    const metadata = NDKEventMetadata.from(event);
    const conversationId = metadata.conversationId;
    
    if (!conversationId) {
      logger.error("Metadata event missing conversation ID", event.inspect);
      return;
    }
    
    // Only update if we know this conversation
    if (this.conversationCoordinator.hasConversation(conversationId)) {
      const title = metadata.title;
      if (title) {
        this.conversationCoordinator.setTitle(conversationId, title);
        logger.info(`Updated conversation title: ${title} for ${conversationId.substring(0, 8)}`);
      }
    }
  }

  private async handleAgentConfigUpdate(event: NDKEvent): Promise<void> {
    try {
      // Extract the agent pubkey from the event tags
      const agentPubkey = event.tagValue("p");
      if (!agentPubkey) {
        logger.warn("AGENT_CONFIG_UPDATE event missing agent pubkey", {
          eventId: event.id,
        });
        return;
      }

      // Get the agent from the project context
      const projectContext = getProjectContext();
      const agent = projectContext.getAgentByPubkey(agentPubkey);

      if (!agent) {
        logger.warn("Agent not found for config change", {
          agentPubkey,
          availableAgents: projectContext.getAgentSlugs(),
        });
        return;
      }

      // Get the agent registry from ProjectContext (single source of truth)
      const agentRegistry = projectContext.agentRegistry;

      // Check for model configuration change
      const newModel = event.tagValue("model");
      if (newModel) {
        logger.info("Received agent config update request", {
          agentPubkey,
          newModel,
          eventId: event.id,
          from: event.pubkey,
        });

        // Update the agent's model configuration persistently
        // Since AgentRegistry is the single source of truth, this will update both
        // the in-memory instance and persist to disk
        const updated = await agentRegistry.updateAgentLLMConfig(agentPubkey, newModel);

        if (updated) {
          logger.info("Updated and persisted model configuration for agent", {
            agentName: agent.name,
            agentPubkey: agent.pubkey,
            newModel,
          });
        } else {
          logger.warn("Failed to update model configuration", {
            agentName: agent.name,
            agentPubkey: agent.pubkey,
            newModel,
          });
        }
      }

      // Check for tools configuration change
      // Extract all tool tags - these represent the exhaustive list of tools the agent should have
      const toolTags = event.tags.filter((tag) => tag[0] === "tool");
      if (toolTags.length > 0) {
        // Extract tool names from tags (format: ["tool", "<tool-name>"])
        const newToolNames = toolTags.map((tag) => tag[1]).filter((name) => name);

        logger.debug("Received tools config change request", {
          agentPubkey,
          agentSlug: agent.slug,
          toolCount: newToolNames.length,
          eventId: event.id,
        });

        // Update the agent's tools persistently
        // Since ProjectContext now uses AgentRegistry directly, this update
        // will immediately be reflected in all agent accesses
        const updated = await agentRegistry.updateAgentTools(agentPubkey, newToolNames);

        if (updated) {
          logger.info("Updated tools configuration", {
            agent: agent.slug,
            toolCount: newToolNames.length,
            newToolNames,
        });
        } else {
          logger.warn("Failed to update tools configuration", {
            agent: agent.slug,
            reason: "update returned false",
          });
        }
      }

      // If neither model nor tools were provided, log a warning
      if (!newModel && toolTags.length === 0) {
        logger.warn("AGENT_CONFIG_UPDATE event has neither model nor tool tags", {
          eventId: event.id,
          agentPubkey,
        });
      }
    } catch (error) {
      logger.error("Failed to handle config change", {
        eventId: event.id,
        error: formatAnyError(error),
      });
    }
  }

  private async handleStopEvent(event: NDKEvent): Promise<void> {
    const eTags = event.getMatchingTags("e");
    
    if (eTags.length === 0) {
      logger.warn("[EventHandler] Stop event received with no e-tags", {
        eventId: event.id?.substring(0, 8)
      });
      return;
    }
    
    let totalStopped = 0;
    
    for (const [_, eventId] of eTags) {
      const stopped = llmOpsRegistry.stopByEventId(eventId);
      if (stopped > 0) {
        logger.info(`[EventHandler] Stopped ${stopped} operations for event ${eventId.substring(0, 8)}`);
        totalStopped += stopped;
      }
    }
    
    if (totalStopped === 0) {
      logger.info("[EventHandler] No active operations to stop");
    } else {
      logger.info(`[EventHandler] Total operations stopped: ${totalStopped}`, {
        activeRemaining: llmOpsRegistry.getActiveOperationsCount()
      });
    }
  }

  private handleDefaultEvent(event: NDKEvent): void {
    if (event.content) {
      logger.info(
        chalk.white(
          `[handleDefaultEvent ${event.id.substring(0, 6)}] Receivend unhandled event kind ${event.kind}`
        ) +
          chalk.white(`[handleDefaultEvent ${event.id.substring(0, 6)}] Content: `) +
          chalk.gray(event.content.substring(0, 100) + (event.content.length > 100 ? "..." : ""))
      );
    }
  }

  async cleanup(): Promise<void> {
    // Save all conversations before shutting down
    await this.conversationCoordinator.cleanup();
    logger.info("EventHandler cleanup completed");
  }
}
</file>

<file path="src/agents/execution/AgentExecutor.ts">
import type { AgentInstance } from "@/agents/types";
import type { ConversationCoordinator } from "@/conversations";
import chalk from "chalk";
import type { EventContext } from "@/nostr/AgentEventEncoder";
import { AgentPublisher } from "@/nostr/AgentPublisher";
import {
    buildStandaloneSystemPromptMessages,
    buildSystemPromptMessages,
} from "@/prompts/utils/systemPromptBuilder";
import { getProjectContext, isProjectContextInitialized } from "@/services";
import { mcpService } from "@/services/mcp/MCPManager";
import { formatAnyError } from "@/utils/error-formatter";
import { logger } from "@/utils/logger";
import type { NDKEvent, NDKPrivateKeySigner, NDKProject } from "@nostr-dev-kit/ndk";
import type { ModelMessage } from "ai";
import { getToolsObject } from "@/tools/registry";
import type { ExecutionContext } from "./types";
import "@/prompts/fragments"; // Import fragment registration manifest
import { startExecutionTime, stopExecutionTime } from "@/conversations/executionTime";
import type { NDKAgentLesson } from "@/events/NDKAgentLesson";
import { configService } from "@/services";
import { llmOpsRegistry } from "@/services/LLMOperationsRegistry";
import { toolMessageStorage } from "@/conversations/persistence/ToolMessageStorage";

/**
 * Format MCP tool names for human readability
 * Converts "mcp__repomix__pack_codebase" to "repomix's pack_codebase"
 */
function formatMCPToolName(toolName: string): string {
    if (!toolName.startsWith('mcp__')) {
        return toolName;
    }
    
    // Split the MCP tool name: mcp__<server>__<tool>
    const parts = toolName.split('__');
    if (parts.length !== 3) {
        return toolName;
    }
    
    const [, serverName, toolMethod] = parts;
    
    // Simple format: server's tool_name
    return `${serverName}'s ${toolMethod.replace(/_/g, ' ')}`;
}

/**
 * Minimal context for standalone agent execution
 */
export interface StandaloneAgentContext {
    agents: Map<string, AgentInstance>;
    pubkey: string;
    signer: NDKPrivateKeySigner;
    project?: NDKProject;
    getLessonsForAgent?: (pubkey: string) => NDKAgentLesson[];
}

export class AgentExecutor {
    constructor(
        private standaloneContext?: StandaloneAgentContext
    ) {}

    /**
     * Execute an agent's assignment for a conversation with streaming
     */
    async execute(context: ExecutionContext): Promise<void> {
        // Build messages first
        const messages = await this.buildMessages(context, context.triggeringEvent);

        // Create AgentPublisher first so we can include it in context
        const agentPublisher = new AgentPublisher(
            context.agent
        );

        // Build full context with additional properties
        const fullContext: ExecutionContext = {
            ...context,
            conversationCoordinator: context.conversationCoordinator,
            agentPublisher, // Include the shared AgentPublisher instance
        };

        try {
            // Get fresh conversation data for execution time tracking
            const conversation = context.conversationCoordinator.getConversation(
                context.conversationId
            );
            if (!conversation) {
                throw new Error(`Conversation ${context.conversationId} not found`);
            }

            // Start execution time tracking
            startExecutionTime(conversation);

            // Log execution flow start
            logger.info(
                `Agent ${context.agent.name} starting execution in ${context.phase} phase`
            );

            // Publish typing indicator start using AgentPublisher
            const eventContext: EventContext = {
                triggeringEvent: context.triggeringEvent,
                rootEvent: conversation.history[0] ?? context.triggeringEvent, // Use triggering event as fallback
                conversationId: context.conversationId,
                model: context.agent.llmConfig, // Include LLM configuration
            };
            await agentPublisher.typing({ state: "start" }, eventContext);

            await this.executeWithStreaming(fullContext, messages);

            // Log execution flow complete
            logger.info(
                `Agent ${context.agent.name} completed execution successfully`
            );
        } catch (error) {
            // Log execution flow failure
            logger.error(`Agent ${context.agent.name} execution failed`, {
                conversationId: context.conversationId,
                agent: context.agent.name,
                error: formatAnyError(error),
                success: false,
            });
            throw error;
        } finally {
            const conversation = context.conversationCoordinator.getConversation(
                context.conversationId
            );
            if (conversation) stopExecutionTime(conversation);
            
            // Ensure typing indicator is stopped even on error
            try {
                const eventContext: EventContext = {
                    triggeringEvent: context.triggeringEvent,
                    rootEvent: conversation?.history[0] ?? context.triggeringEvent,
                    conversationId: context.conversationId,
                    model: context.agent.llmConfig, // Include LLM configuration
                };
                await agentPublisher.typing({ state: "stop" }, eventContext);
            } catch (typingError) {
                logger.warn("Failed to stop typing indicator", {
                    error: formatAnyError(typingError),
                });
            }
        }
    }

    /**
     * Build the messages array for the agent execution
     */
    private async buildMessages(
        context: ExecutionContext,
        _triggeringEvent: NDKEvent
    ): Promise<ModelMessage[]> {
        const messages: ModelMessage[] = [];

        // Get fresh conversation data
        const conversation = context.conversationCoordinator.getConversation(
            context.conversationId
        );
        if (!conversation) {
            throw new Error(`Conversation ${context.conversationId} not found`);
        }

        // Get MCP tools for the prompt
        const mcpTools = mcpService.getCachedTools();

        // Check if we're in standalone mode or project mode
        if (this.standaloneContext) {
            // Standalone mode - use minimal context
            const availableAgents = Array.from(this.standaloneContext.agents.values());

            // Get lessons if available
            const agentLessonsMap = new Map<string, NDKAgentLesson[]>();
            if (this.standaloneContext.getLessonsForAgent) {
                const lessons = this.standaloneContext.getLessonsForAgent(context.agent.pubkey);
                if (lessons.length > 0) {
                    agentLessonsMap.set(context.agent.pubkey, lessons);
                }
            }

            // Build standalone system prompt
            const systemMessages = buildStandaloneSystemPromptMessages({
                agent: context.agent,
                phase: context.phase,
                availableAgents,
                conversation,
                agentLessons: agentLessonsMap,
                mcpTools,
                triggeringEvent: context.triggeringEvent,
            });

            // Add all system messages
            for (const systemMsg of systemMessages) {
                messages.push(systemMsg.message);
            }
        } else if (isProjectContextInitialized()) {
            // Project mode - use full project context
            const projectCtx = getProjectContext();
            const project = projectCtx.project;

            // Create tag map for efficient lookup
            const tagMap = new Map<string, string>();
            for (const tag of project.tags) {
                if (tag.length >= 2 && tag[0] && tag[1]) {
                    tagMap.set(tag[0], tag[1]);
                }
            }

            // Get all available agents for delegations
            const availableAgents = Array.from(projectCtx.agents.values());

            // Build system prompt using the shared function
            // Only pass the current agent's lessons
            const agentLessonsMap = new Map<string, NDKAgentLesson[]>();
            const currentAgentLessons = projectCtx.getLessonsForAgent(context.agent.pubkey);

            if (currentAgentLessons.length > 0) {
                agentLessonsMap.set(context.agent.pubkey, currentAgentLessons);
            }

            // Check if this agent is the project manager
            const isProjectManager = context.agent.pubkey === projectCtx.getProjectManager().pubkey;

            // Build system prompt messages for all agents (including orchestrator)
            const systemMessages = buildSystemPromptMessages({
                agent: context.agent,
                phase: context.phase,
                project,
                availableAgents,
                conversation,
                agentLessons: agentLessonsMap,
                mcpTools,
                triggeringEvent: context.triggeringEvent,
                isProjectManager,
            });

            // Add all system messages
            for (const systemMsg of systemMessages) {
                messages.push(systemMsg.message);
            }
        } else {
            // Fallback: No context available - use absolute minimal prompt
            logger.warn("No context available for agent execution, using minimal prompt");
            messages.push({
                role: "system",
                content: `You are ${context.agent.name}. ${context.agent.instructions || ""}`,
            });
        }

        // Add special instruction if this is a reactivation after delegation completion
        if (context.isDelegationCompletion) {
            logger.info(
                "[AgentExecutor] üîÑ DELEGATION COMPLETION: Agent resumed after delegation",
                {
                    agent: context.agent.name,
                    triggeringEventId: context.triggeringEvent?.id?.substring(0, 8),
                    triggeringEventPubkey: context.triggeringEvent?.pubkey?.substring(0, 8),
                    mode: "delegation-completion",
                }
            );

            const delegationCompletionInstruction = `
=== CRITICAL: DELEGATION COMPLETION NOTIFICATION ===

STOP! A delegated task has JUST BEEN COMPLETED. The response is in the conversation above.

YOU MUST:
1. Pass the result back to the user in your response
2. Do NOT use ANY tools
3. Do NOT delegate again - the task is ALREADY DONE

THE TASK IS COMPLETE. DO NOT REPEAT IT.

Simply respond with the result from the conversation above.

DO NOT use delegate(), delegate_phase(), or any other tool.

=== END CRITICAL NOTIFICATION ===`;

            messages.push({ role: "system", content: delegationCompletionInstruction });
            logger.info(
                `[AgentExecutor] üîÅ Starting delegation completion flow for ${context.agent.name}`,
                {
                    conversationId: context.conversationId,
                    agentSlug: context.agent.slug,
                    mode: "delegation-completion",
                    reason: "delegation-completed",
                }
            );
        }

        // Check for #debug flag in triggering event content
        const hasDebugFlag = context.triggeringEvent?.content?.includes("#debug");
        if (hasDebugFlag) {
            const debugMetaCognitionPrompt = `
=== DEBUG MODE: META-COGNITIVE ANALYSIS REQUESTED ===

The user has included "#debug" in their message. They are asking you to explain your decision-making process.

Provide a transparent, honest analysis of:

1. **System Prompt Influence**: Which specific parts of your system prompt or instructions guided this decision
2. **Reasoning Chain**: The step-by-step thought process that led to your choice
3. **Alternatives Considered**: Other approaches you evaluated but didn't choose, and why
4. **Assumptions Made**: Any implicit assumptions about the project, user needs, or context
5. **Constraints Applied**: Technical, architectural, or guideline constraints that limited options
6. **Confidence Level**: How certain you were about this decision and any doubts you had
7. **Pattern Matching**: If you followed a common pattern or best practice, explain why it seemed applicable

Be completely transparent about your internal process. If you made a mistake or could have done better, acknowledge it. The goal is to help the user understand exactly how you arrived at your decision.
=== END DEBUG MODE ===`;

            messages.push({ role: "system", content: debugMetaCognitionPrompt });
            logger.info(`[AgentExecutor] Debug mode activated for agent ${context.agent.name}`, {
                conversationId: context.conversationId,
                agentSlug: context.agent.slug,
            });
        }

        // All agents now get conversation transcript
        const { messages: agentMessages } =
            await context.conversationCoordinator.buildAgentMessages(
                context.conversationId,
                context.agent,
                context.triggeringEvent
            );

        // Add the agent's messages
        messages.push(...agentMessages);

        return messages;
    }

    /**
     * Execute with streaming support
     */
    private async executeWithStreaming(
        context: ExecutionContext,
        messages: ModelMessage[]
    ): Promise<void> {
        // Get tools for response processing
        // Tools are already properly configured in AgentRegistry.buildAgentInstance
        const toolNames = context.agent.tools || [];

        // Get tools as a keyed object for AI SDK
        const toolsObject = toolNames.length > 0 ? getToolsObject(toolNames, context) : {};

        // Create a fresh LLMService instance for this execution
        // Use withAgent to create an LLMLogger instance with the agent name set
        const projectCtx = getProjectContext();
        const llmLogger = projectCtx.llmLogger.withAgent(context.agent.name);
        const llmService = configService.createLLMService(llmLogger, context.agent.llmConfig);
        
        const agentPublisher = context.agentPublisher;
        const eventContext: EventContext = {
            triggeringEvent: context.triggeringEvent,
            rootEvent: context.conversationCoordinator.getConversation(context.conversationId)?.history[0] ?? context.triggeringEvent,
            conversationId: context.conversationId,
            phase: context.phase,
            model: llmService.model
        };

        // Separate buffers for content and reasoning
        let contentBuffer = '';
        let reasoningBuffer = '';

        // Helper to flush accumulated content
        const flushContentBuffer = async (): Promise<void> => {
            console.log("called flushContentBuffer");
            if (contentBuffer.trim().length > 0) {
                console.log('publishing conversation event', contentBuffer.substring(0, 50));
                
                // Use regular conversation event for content
                agentPublisher.conversation({
                    content: contentBuffer
                }, eventContext);
                logger.info(`[AgentExecutor] Flushed content buffer (${contentBuffer.length} chars)`);
                
                contentBuffer = '';
            }
        };

        // Helper to flush accumulated reasoning
        const flushReasoningBuffer = async (): Promise<void> => {
            console.log("called flushReasoningBuffer");
            if (reasoningBuffer.trim().length > 0) {
                console.log('publishing reasoning event', reasoningBuffer.substring(0, 50));
                
                // Use conversation event with reasoning tag
                agentPublisher.conversation({
                    content: reasoningBuffer,
                    isReasoning: true
                }, eventContext);
                logger.info(`[AgentExecutor] Flushed reasoning buffer (${reasoningBuffer.length} chars)`);
                
                reasoningBuffer = '';
            }
        };

        // Wire up event handlers
        llmService.on('content', async (event) => {
            // Accumulate content instead of streaming immediately
            contentBuffer += event.delta;
            // Still stream deltas for real-time display
            await agentPublisher.handleContent(event, eventContext, false);
        });

        llmService.on('reasoning', async (event) => {
            // Accumulate reasoning separately
            reasoningBuffer += event.delta;
            // Stream reasoning deltas for real-time display with reasoning flag
            await agentPublisher.handleContent(event, eventContext, true);
        });
        
        llmService.on('chunk-type-change', async (event) => {
            logger.info(`[AgentExecutor] Chunk type changed from ${event.from} to ${event.to}`);
            // Flush both buffers on chunk type change
            await flushContentBuffer();
            await flushReasoningBuffer();
        });
        
        llmService.on('complete', async (event) => {
            // Check if we had reasoning or content before flushing
            const hadContent = contentBuffer.trim().length > 0;
            const hadReasoning = reasoningBuffer.trim().length > 0;

            if (event.message.trim()) {
                const isReasoning = hadReasoning && !hadContent;
                
                await agentPublisher.complete({
                    content: event.message,
                    usage: event.usage,
                    isReasoning
                }, eventContext);
                
                logger.info(`[AgentExecutor] Agent ${context.agent.name} completed (${event.message.length} chars, reasoning: ${isReasoning})`);
            }
            
            // Clear buffers
            contentBuffer = '';
            reasoningBuffer = '';
        });
        
        llmService.on('stream-error', (event) => {
            logger.error("[AgentExecutor] Stream error from LLMService", event);
        });

        // Tool execution tracking - store tool calls with their event IDs
        const toolExecutions = new Map<string, { 
            toolCall: any; 
            toolResult: any;
            toolEventId: string;
        }>();

        llmService.on('tool-will-execute', async (event) => {
            logger.info('[AgentExecutor] Tool will execute', {
                toolName: event.toolName,
                toolCallId: event.toolCallId,
            });
            
            // Get the tool to generate human-readable content
            const tool = toolsObject[event.toolName];
            const humanContent = tool?.getHumanReadableContent?.(event.args) 
                || (event.toolName.startsWith('mcp__') 
                    ? `Executing ${formatMCPToolName(event.toolName)}`
                    : `Executing ${event.toolName}`);

            // Publish the tool event immediately when starting execution
            const toolEvent = await agentPublisher.toolUse(
                {
                    toolName: event.toolName,
                    content: humanContent,
                },
                eventContext
            );
            
            // Store the tool call with its event ID for later association
            toolExecutions.set(event.toolCallId, {
                toolCall: {
                    toolCallId: event.toolCallId,
                    toolName: event.toolName,
                    input: event.args,
                },
                toolResult: null,
                toolEventId: toolEvent.id,
            });
        });

        llmService.on('tool-did-execute', async (event) => {
            logger.info('[AgentExecutor] Tool did execute', {
                toolName: event.toolName,
                toolCallId: event.toolCallId,
                error: event.error,
            });

            // Get the stored execution with its event ID
            const execution = toolExecutions.get(event.toolCallId);
            if (execution) {
                // Update with tool result
                execution.toolResult = {
                    toolCallId: event.toolCallId,
                    toolName: event.toolName,
                    output: event.result,
                    error: event.error,
                };

                // Store the full tool messages to filesystem using the original event ID
                await toolMessageStorage.store(
                    execution.toolEventId,  // Use the event ID from when we started
                    execution.toolCall,
                    execution.toolResult,
                    context.agent.pubkey
                );
            }
        });

        try {
            // Register operation with the LLM Operations Registry
            const abortSignal = llmOpsRegistry.registerOperation(context);
            
            // Single LLM call - let it run up to 20 steps
            await llmService.stream(messages, toolsObject, { abortSignal });
        } finally {
            // Complete the operation (handles both success and abort cases)
            llmOpsRegistry.completeOperation(context);
            
            // Clean up event listeners
            llmService.removeAllListeners();
        }
    }
}
</file>

<file path="src/conversations/services/ConversationCoordinator.ts">
import type { AgentInstance } from "@/agents/types";
import { logger } from "@/utils/logger";
import type { NDKEvent } from "@nostr-dev-kit/ndk";
import type { ModelMessage } from "ai";
import { AgentConversationContext } from "../AgentConversationContext";
import { buildPhaseInstructions, formatPhaseTransitionMessage } from "@/prompts/utils/systemPromptBuilder";
import { ensureExecutionTimeInitialized } from "../executionTime";
import { FileSystemAdapter } from "../persistence";
import type { ConversationPersistenceAdapter } from "../persistence/types";
import type { Phase, AgentState, Conversation, ConversationMetadata } from "../types";
import { ConversationEventProcessor } from "./ConversationEventProcessor";
import { ConversationPersistenceService, type IConversationPersistenceService } from "./ConversationPersistenceService";
import { ConversationStore } from "./ConversationStore";

/**
 * Coordinates between all conversation services.
 * Single Responsibility: Orchestrate calls to specialized services.
 */
export class ConversationCoordinator {
  private store: ConversationStore;
  private persistence: IConversationPersistenceService;
  private eventProcessor: ConversationEventProcessor;
  

  constructor(
    projectPath: string,
    persistence?: ConversationPersistenceAdapter
  ) {
    // Create services
    this.store = new ConversationStore();
    this.persistence = new ConversationPersistenceService(
      persistence || new FileSystemAdapter(projectPath)
    );
    this.eventProcessor = new ConversationEventProcessor();
  }

  /**
   * Initialize the coordinator
   */
  async initialize(): Promise<void> {
    await this.persistence.initialize();
    await this.loadConversations();
  }

  /**
   * Create a new conversation from an event
   */
  async createConversation(event: NDKEvent): Promise<Conversation> {
    const conversation = await this.eventProcessor.createConversationFromEvent(event);

    // Log conversation start
    logger.info(
      `Starting conversation ${conversation.id.substring(0, 8)} - "${event.content?.substring(0, 50)}..."`
    );

    // Store and persist
    this.store.set(conversation.id, conversation);
    await this.persistence.save(conversation);

    return conversation;
  }

  /**
   * Get a conversation by ID
   */
  getConversation(id: string): Conversation | undefined {
    const conversation = this.store.get(id);
    
    // Debug logging to trace session usage
    if (conversation?.agentStates) {
      for (const [agentSlug, state] of conversation.agentStates.entries()) {
        if (state.claudeSessionsByPhase) {
          logger.debug(`[ConversationCoordinator] Conversation ${id.substring(0, 8)} has sessions for agent ${agentSlug}:`, {
            conversationId: id,
            agentSlug,
            sessions: state.claudeSessionsByPhase,
          });
        }
      }
    }
    
    return conversation;
  }

  /**
   * Check if a conversation exists
   */
  hasConversation(id: string): boolean {
    return this.store.has(id);
  }

  /**
   * Set the title of a conversation
   */
  setTitle(conversationId: string, title: string): void {
    const conversation = this.store.get(conversationId);
    if (conversation) {
      conversation.title = title;
      // Note: Not persisting immediately to avoid race conditions
      // Will be persisted on next save operation
    }
  }

  /**
   * Get a conversation by event ID
   */
  getConversationByEvent(eventId: string): Conversation | undefined {
    return this.store.findByEvent(eventId);
  }

  /**
   * Get all conversations
   */
  getAllConversations(): Conversation[] {
    return this.store.getAll();
  }

  /**
   * Add an event to a conversation
   */
  async addEvent(conversationId: string, event: NDKEvent): Promise<void> {
    const conversation = this.store.get(conversationId);
    if (!conversation) {
      throw new Error(`Conversation ${conversationId} not found`);
    }

    this.eventProcessor.processIncomingEvent(conversation, event);
    await this.persistence.save(conversation);
  }

  /**
   * Update conversation metadata
   */
  async updateMetadata(
    conversationId: string,
    metadata: Partial<ConversationMetadata>
  ): Promise<void> {
    const conversation = this.store.get(conversationId);
    if (!conversation) {
      throw new Error(`Conversation ${conversationId} not found`);
    }

    this.eventProcessor.updateMetadata(conversation, metadata);
    await this.persistence.save(conversation);
  }

  /**
   * Update conversation phase
   */
  async updatePhase(
    id: string,
    phase: Phase,
    message: string,
    agentPubkey: string,
    agentName: string,
    phaseInstructions?: string
  ): Promise<boolean> {
    const conversation = this.store.get(id);
    if (!conversation) {
      throw new Error(`Conversation ${id} not found`);
    }

    const from = conversation.phase;

    // No execution queue logic needed

    // Update conversation
    if (from !== phase) {
      conversation.phase = phase;
      conversation.phaseInstructions = phaseInstructions;
      conversation.phaseStartedAt = Date.now();
    }

    logger.info(
      `Phase transition: ${from} ‚Üí ${phase} for conversation ${id.substring(0, 8)}`
    );

    await this.persistence.save(conversation);
    return true;
  }

  /**
   * Build messages for an agent
   */
  async buildAgentMessages(
    conversationId: string,
    targetAgent: AgentInstance,
    triggeringEvent?: NDKEvent
  ): Promise<{ messages: ModelMessage[] }> {
    const conversation = this.store.get(conversationId);
    if (!conversation) {
      throw new Error(`Conversation ${conversationId} not found`);
    }

    // Create a stateless agent context on-demand
    const context = new AgentConversationContext(conversationId, targetAgent.slug, targetAgent.pubkey);

    // Get or initialize the agent's state
    let agentState = conversation.agentStates.get(targetAgent.slug);
    if (!agentState) {
      agentState = {
        lastProcessedMessageIndex: 0,
        lastSeenPhase: undefined,
      };
      conversation.agentStates.set(targetAgent.slug, agentState);
    }

    // Check if we need phase instructions
    const needsPhaseInstructions = !agentState.lastSeenPhase || agentState.lastSeenPhase !== conversation.phase;
    let phaseInstructions: string | undefined;
    
    if (needsPhaseInstructions) {
      const instructions = buildPhaseInstructions(conversation.phase, conversation);
      if (agentState.lastSeenPhase) {
        phaseInstructions = formatPhaseTransitionMessage(
          agentState.lastSeenPhase,
          conversation.phase,
          instructions
        );
      } else {
        phaseInstructions = `=== CURRENT PHASE: ${conversation.phase.toUpperCase()} ===\n\n${instructions}`;
      }
      agentState.lastSeenPhase = conversation.phase;
    }

    // Build messages using the stateless context
    const messages = await context.buildMessages(
      conversation,
      agentState,
      triggeringEvent,
      phaseInstructions
    );

    // Update agent state
    agentState.lastProcessedMessageIndex = conversation.history.length;

    // Extract and update session ID if present in triggering event
    if (triggeringEvent) {
      const sessionId = context.extractSessionId(triggeringEvent);
      if (sessionId && conversation.phase) {
        if (!agentState.claudeSessionsByPhase) {
          agentState.claudeSessionsByPhase = {} as Record<Phase, string>;
        }
        agentState.claudeSessionsByPhase[conversation.phase] = sessionId;
      }
    }

    await this.persistence.save(conversation);

    return {
      messages,
    };
  }

  /**
   * Update an agent's state
   */
  async updateAgentState(
    conversationId: string,
    agentSlug: string,
    updates: Partial<AgentState>
  ): Promise<void> {
    const conversation = this.store.get(conversationId);
    if (!conversation) {
      throw new Error(`Conversation ${conversationId} not found`);
    }

    let agentState = conversation.agentStates.get(agentSlug);
    if (!agentState) {
      agentState = {
        lastProcessedMessageIndex: 0,
        lastSeenPhase: undefined,
      };
      conversation.agentStates.set(agentSlug, agentState);
    }

    Object.assign(agentState, updates);
    await this.persistence.save(conversation);
  }

  /**
   * Archive a conversation
   */
  async archiveConversation(conversationId: string): Promise<void> {
    await this.persistence.archive(conversationId);
    this.store.delete(conversationId);
  }

  /**
   * Search conversations
   */
  async searchConversations(query: string): Promise<Conversation[]> {
    return await this.persistence.search({ title: query });
  }

  /**
   * Clean up and save all conversations
   */
  async cleanup(): Promise<void> {
    const promises: Promise<void>[] = [];
    for (const conversation of this.store.getAll()) {
      promises.push(this.persistence.save(conversation));
    }
    await Promise.all(promises);
  }

  /**
   * Complete a conversation
   */
  async completeConversation(conversationId: string): Promise<void> {
    const conversation = this.store.get(conversationId);
    if (!conversation) {
      return;
    }

    this.eventProcessor.cleanupMetadata(conversation);
    this.store.delete(conversationId);

    await this.persistence.save(conversation);
  }


  /**
   * Get phase history for a conversation
   */
  getPhaseHistory(conversationId: string): NDKEvent[] {
    const conversation = this.store.get(conversationId);
    return conversation?.history || [];
  }


  /**
   * Clean up conversation metadata
   */
  cleanupConversationMetadata(conversationId: string): void {
    const conversation = this.store.get(conversationId);
    if (conversation) {
      this.eventProcessor.cleanupMetadata(conversation);
    }
  }

  // Private helper methods

  private async loadConversations(): Promise<void> {
    try {
      const conversations = await this.persistence.loadAll();

      for (const conversation of conversations) {
        ensureExecutionTimeInitialized(conversation);

        // Ensure agentStates is a Map
        if (!(conversation.agentStates instanceof Map)) {
          const statesObj = conversation.agentStates as Record<string, AgentState>;
          conversation.agentStates = new Map(Object.entries(statesObj || {}));
        }

        this.store.set(conversation.id, conversation);
      }
    } catch (error) {
      logger.error("[ConversationCoordinator] Failed to load conversations", { error });
    }
  }





}
</file>

</files>
